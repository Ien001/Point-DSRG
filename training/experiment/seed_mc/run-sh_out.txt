austin@vader:/media/ssd1/austin/Point-DSRG$ workon pdsrg
(pdsrg) austin@vader:/media/ssd1/austin/Point-DSRG$ cd training/experiment/seed_mc/
(pdsrg) austin@vader:/media/ssd1/austin/Point-DSRG/training/experiment/seed_mc$ bash run.sh
UNIQUESTRING 1
/media/ssd1/austin/Point-DSRG/deeplab-public-ver2/python
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0226 12:57:58.172931  7672 solver.cpp:48] Initializing solver from parameters:
train_net: "train-s.prototxt"
base_lr: 0.0005
display: 10
max_iter: 8000
lr_policy: "step"
gamma: 0.33
momentum: 0.9
weight_decay: 0.0005
stepsize: 1000
snapshot: 8000
snapshot_prefix: "models/model-s"
solver_mode: GPU
random_seed: 0
average_loss: 10
I0226 12:57:58.173106  7672 solver.cpp:81] Creating training net from train_net file: train-s.prototxt
I0226 12:57:58.174748  7672 net.cpp:49] Initializing net from parameters:
name: "DSRG"
state {
  phase: TRAIN
}
layer {
  name: "Input"
  type: "ImageData"
  top: "images_origin"
  top: "image_ids"
  transform_param {
    mirror: false
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  image_data_param {
    source: "list/input_list.txt"
    batch_size: 20
    shuffle: true
    new_height: 321
    new_width: 321
    root_folder: "/media/ssd1/austin/datasets/VOC/VOCdevkit/VOC2012/JPEGImages/"
  }
}
layer {
  name: "Annotation"
  type: "Python"
  bottom: "image_ids"
  bottom: "images_origin"
  top: "labels"
  top: "cues"
  top: "images"
  propagate_down: false
  propagate_down: false
  python_param {
    module: "pylayers"
    layer: "AnnotationLayer"
    param_str: "{\'cues\': \'localization_cues-sal.pickle\', \'mirror\': True}"
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "images"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    pad: 1
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    pad: 1
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    pad: 1
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    dilation: 2
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    dilation: 2
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    dilation: 2
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "pool5a"
  type: "Pooling"
  bottom: "pool5"
  top: "pool5a"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "fc6_1"
  type: "Convolution"
  bottom: "pool5a"
  top: "fc6_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    pad: 6
    kernel_size: 3
    dilation: 6
  }
}
layer {
  name: "relu6_1"
  type: "ReLU"
  bottom: "fc6_1"
  top: "fc6_1"
}
layer {
  name: "drop6_1"
  type: "Dropout"
  bottom: "fc6_1"
  top: "fc6_1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7_1"
  type: "Convolution"
  bottom: "fc6_1"
  top: "fc7_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    kernel_size: 1
  }
}
layer {
  name: "relu7_1"
  type: "ReLU"
  bottom: "fc7_1"
  top: "fc7_1"
}
layer {
  name: "drop7_1"
  type: "Dropout"
  bottom: "fc7_1"
  top: "fc7_1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8-SEC_1"
  type: "Convolution"
  bottom: "fc7_1"
  top: "fc8-SEC_1"
  param {
    lr_mult: 10
    decay_mult: 1
  }
  param {
    lr_mult: 20
    decay_mult: 0
  }
  convolution_param {
    num_output: 21
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fc6_2"
  type: "Convolution"
  bottom: "pool5a"
  top: "fc6_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    pad: 12
    kernel_size: 3
    dilation: 12
  }
}
layer {
  name: "relu6_2"
  type: "ReLU"
  bottom: "fc6_2"
  top: "fc6_2"
}
layer {
  name: "drop6_2"
  type: "Dropout"
  bottom: "fc6_2"
  top: "fc6_2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7_2"
  type: "Convolution"
  bottom: "fc6_2"
  top: "fc7_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    kernel_size: 1
  }
}
layer {
  name: "relu7_2"
  type: "ReLU"
  bottom: "fc7_2"
  top: "fc7_2"
}
layer {
  name: "drop7_2"
  type: "Dropout"
  bottom: "fc7_2"
  top: "fc7_2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8-SEC_2"
  type: "Convolution"
  bottom: "fc7_2"
  top: "fc8-SEC_2"
  param {
    lr_mult: 10
    decay_mult: 1
  }
  param {
    lr_mult: 20
    decay_mult: 0
  }
  convolution_param {
    num_output: 21
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fc6_3"
  type: "Convolution"
  bottom: "pool5a"
  top: "fc6_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    pad: 18
    kernel_size: 3
    dilation: 18
  }
}
layer {
  name: "relu6_3"
  type: "ReLU"
  bottom: "fc6_3"
  top: "fc6_3"
}
layer {
  name: "drop6_3"
  type: "Dropout"
  bottom: "fc6_3"
  top: "fc6_3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7_3"
  type: "Convolution"
  bottom: "fc6_3"
  top: "fc7_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    kernel_size: 1
  }
}
layer {
  name: "relu7_3"
  type: "ReLU"
  bottom: "fc7_3"
  top: "fc7_3"
}
layer {
  name: "drop7_3"
  type: "Dropout"
  bottom: "fc7_3"
  top: "fc7_3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8-SEC_3"
  type: "Convolution"
  bottom: "fc7_3"
  top: "fc8-SEC_3"
  param {
    lr_mult: 10
    decay_mult: 1
  }
  param {
    lr_mult: 20
    decay_mult: 0
  }
  convolution_param {
    num_output: 21
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fc6_4"
  type: "Convolution"
  bottom: "pool5a"
  top: "fc6_4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    pad: 24
    kernel_size: 3
    dilation: 24
  }
}
layer {
  name: "relu6_4"
  type: "ReLU"
  bottom: "fc6_4"
  top: "fc6_4"
}
layer {
  name: "drop6_4"
  type: "Dropout"
  bottom: "fc6_4"
  top: "fc6_4"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7_4"
  type: "Convolution"
  bottom: "fc6_4"
  top: "fc7_4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    kernel_size: 1
  }
}
layer {
  name: "relu7_4"
  type: "ReLU"
  bottom: "fc7_4"
  top: "fc7_4"
}
layer {
  name: "drop7_4"
  type: "Dropout"
  bottom: "fc7_4"
  top: "fc7_4"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8-SEC_4"
  type: "Convolution"
  bottom: "fc7_4"
  top: "fc8-SEC_4"
  param {
    lr_mult: 10
    decay_mult: 1
  }
  param {
    lr_mult: 20
    decay_mult: 0
  }
  convolution_param {
    num_output: 21
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fc8-SEC"
  type: "Eltwise"
  bottom: "fc8-SEC_1"
  bottom: "fc8-SEC_2"
  bottom: "fc8-SEC_3"
  bottom: "fc8-SEC_4"
  top: "fc8-SEC"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Softmax"
  type: "Python"
  bottom: "fc8-SEC"
  top: "fc8-SEC-Softmax"
  propagate_down: true
  python_param {
    module: "pylayers"
    layer: "SoftmaxLayer"
  }
}
layer {
  name: "CRF"
  type: "Python"
  bottom: "fc8-SEC-Softmax"
  bottom: "images"
  top: "fc8-SEC-CRF-log"
  propagate_down: true
  propagate_down: false
  python_param {
    module: "pylayers"
    layer: "CRFLayer"
  }
}
layer {
  name: "update-seed"
  type: "Python"
  bottom: "labels"
  bottom: "fc8-SEC-Softmax"
  bottom: "cues"
  bottom: "images"
  top: "cues-new"
  python_param {
    module: "pylayers"
    layer: "DSRGLayer"
    param_str: "{\'th1\': 0.99, \'th2\': 0.85}"
  }
}
layer {
  name: "loss-Seed"
  type: "Python"
  bottom: "fc8-SEC-Softmax"
  bottom: "cues-new"
  top: "loss-Seed"
  loss_weight: 1
  python_param {
    module: "pylayers"
    layer: "BalancedSeedLossLayer"
  }
}
layer {
  name: "loss-Constrain"
  type: "Python"
  bottom: "fc8-SEC-Softmax"
  bottom: "fc8-SEC-CRF-log"
  top: "loss-Constrain"
  loss_weight: 1
  python_param {
    module: "pylayers"
    layer: "ConstrainLossLayer"
  }
}
I0226 12:57:58.177682  7672 layer_factory.hpp:77] Creating layer Input
I0226 12:57:58.177718  7672 net.cpp:106] Creating Layer Input
I0226 12:57:58.177731  7672 net.cpp:411] Input -> images_origin
I0226 12:57:58.177752  7672 net.cpp:411] Input -> image_ids
I0226 12:57:58.177773  7672 image_data_layer.cpp:38] Opening file list/input_list.txt
I0226 12:57:58.182018  7672 image_data_layer.cpp:48] Shuffling data
I0226 12:57:58.182955  7672 image_data_layer.cpp:53] A total of 10582 images.
I0226 12:57:58.207993  7672 image_data_layer.cpp:80] output data size: 20,3,321,321
I0226 12:57:58.272689  7672 net.cpp:150] Setting up Input
I0226 12:57:58.272729  7672 net.cpp:157] Top shape: 20 3 321 321 (6182460)
I0226 12:57:58.272740  7672 net.cpp:157] Top shape: 20 (20)
I0226 12:57:58.272748  7672 net.cpp:165] Memory required for data: 24729920
I0226 12:57:58.272759  7672 layer_factory.hpp:77] Creating layer Annotation
I0226 12:57:58.544991  7672 net.cpp:106] Creating Layer Annotation
I0226 12:57:58.545038  7672 net.cpp:454] Annotation <- image_ids
I0226 12:57:58.545063  7672 net.cpp:454] Annotation <- images_origin
I0226 12:57:58.545083  7672 net.cpp:411] Annotation -> labels
I0226 12:57:58.545105  7672 net.cpp:411] Annotation -> cues
I0226 12:57:58.545123  7672 net.cpp:411] Annotation -> images
I0226 12:57:58.898331  7672 net.cpp:150] Setting up Annotation
I0226 12:57:58.898381  7672 net.cpp:157] Top shape: 20 1 1 21 (420)
I0226 12:57:58.898391  7672 net.cpp:157] Top shape: 20 21 41 41 (706020)
I0226 12:57:58.898399  7672 net.cpp:157] Top shape: 20 3 321 321 (6182460)
I0226 12:57:58.898406  7672 net.cpp:165] Memory required for data: 52285520
I0226 12:57:58.898417  7672 layer_factory.hpp:77] Creating layer images_Annotation_2_split
I0226 12:57:58.898435  7672 net.cpp:106] Creating Layer images_Annotation_2_split
I0226 12:57:58.898443  7672 net.cpp:454] images_Annotation_2_split <- images
I0226 12:57:58.898454  7672 net.cpp:411] images_Annotation_2_split -> images_Annotation_2_split_0
I0226 12:57:58.898468  7672 net.cpp:411] images_Annotation_2_split -> images_Annotation_2_split_1
I0226 12:57:58.898476  7672 net.cpp:411] images_Annotation_2_split -> images_Annotation_2_split_2
I0226 12:57:58.898521  7672 net.cpp:150] Setting up images_Annotation_2_split
I0226 12:57:58.898533  7672 net.cpp:157] Top shape: 20 3 321 321 (6182460)
I0226 12:57:58.898540  7672 net.cpp:157] Top shape: 20 3 321 321 (6182460)
I0226 12:57:58.898547  7672 net.cpp:157] Top shape: 20 3 321 321 (6182460)
I0226 12:57:58.898553  7672 net.cpp:165] Memory required for data: 126475040
I0226 12:57:58.898561  7672 layer_factory.hpp:77] Creating layer conv1_1
I0226 12:57:58.898576  7672 net.cpp:106] Creating Layer conv1_1
I0226 12:57:58.898581  7672 net.cpp:454] conv1_1 <- images_Annotation_2_split_0
I0226 12:57:58.898591  7672 net.cpp:411] conv1_1 -> conv1_1
I0226 12:57:58.900647  7672 net.cpp:150] Setting up conv1_1
I0226 12:57:58.900671  7672 net.cpp:157] Top shape: 20 64 321 321 (131892480)
I0226 12:57:58.900678  7672 net.cpp:165] Memory required for data: 654044960
I0226 12:57:58.900696  7672 layer_factory.hpp:77] Creating layer relu1_1
I0226 12:57:58.900708  7672 net.cpp:106] Creating Layer relu1_1
I0226 12:57:58.900715  7672 net.cpp:454] relu1_1 <- conv1_1
I0226 12:57:58.900724  7672 net.cpp:397] relu1_1 -> conv1_1 (in-place)
I0226 12:57:58.900737  7672 net.cpp:150] Setting up relu1_1
I0226 12:57:58.900743  7672 net.cpp:157] Top shape: 20 64 321 321 (131892480)
I0226 12:57:58.900750  7672 net.cpp:165] Memory required for data: 1181614880
I0226 12:57:58.900758  7672 layer_factory.hpp:77] Creating layer conv1_2
I0226 12:57:58.900768  7672 net.cpp:106] Creating Layer conv1_2
I0226 12:57:58.900774  7672 net.cpp:454] conv1_2 <- conv1_1
I0226 12:57:58.900781  7672 net.cpp:411] conv1_2 -> conv1_2
I0226 12:57:58.902256  7672 net.cpp:150] Setting up conv1_2
I0226 12:57:58.902292  7672 net.cpp:157] Top shape: 20 64 321 321 (131892480)
I0226 12:57:58.902299  7672 net.cpp:165] Memory required for data: 1709184800
I0226 12:57:58.902312  7672 layer_factory.hpp:77] Creating layer relu1_2
I0226 12:57:58.902321  7672 net.cpp:106] Creating Layer relu1_2
I0226 12:57:58.902328  7672 net.cpp:454] relu1_2 <- conv1_2
I0226 12:57:58.902336  7672 net.cpp:397] relu1_2 -> conv1_2 (in-place)
I0226 12:57:58.902345  7672 net.cpp:150] Setting up relu1_2
I0226 12:57:58.902353  7672 net.cpp:157] Top shape: 20 64 321 321 (131892480)
I0226 12:57:58.902359  7672 net.cpp:165] Memory required for data: 2236754720
I0226 12:57:58.902365  7672 layer_factory.hpp:77] Creating layer pool1
I0226 12:57:58.902376  7672 net.cpp:106] Creating Layer pool1
I0226 12:57:58.902384  7672 net.cpp:454] pool1 <- conv1_2
I0226 12:57:58.902390  7672 net.cpp:411] pool1 -> pool1
I0226 12:57:58.902429  7672 net.cpp:150] Setting up pool1
I0226 12:57:58.902439  7672 net.cpp:157] Top shape: 20 64 161 161 (33178880)
I0226 12:57:58.902446  7672 net.cpp:165] Memory required for data: 2369470240
I0226 12:57:58.902451  7672 layer_factory.hpp:77] Creating layer conv2_1
I0226 12:57:58.902462  7672 net.cpp:106] Creating Layer conv2_1
I0226 12:57:58.902469  7672 net.cpp:454] conv2_1 <- pool1
I0226 12:57:58.902478  7672 net.cpp:411] conv2_1 -> conv2_1
I0226 12:57:58.902703  7672 net.cpp:150] Setting up conv2_1
I0226 12:57:58.902715  7672 net.cpp:157] Top shape: 20 128 161 161 (66357760)
I0226 12:57:58.902722  7672 net.cpp:165] Memory required for data: 2634901280
I0226 12:57:58.902734  7672 layer_factory.hpp:77] Creating layer relu2_1
I0226 12:57:58.902741  7672 net.cpp:106] Creating Layer relu2_1
I0226 12:57:58.902748  7672 net.cpp:454] relu2_1 <- conv2_1
I0226 12:57:58.902756  7672 net.cpp:397] relu2_1 -> conv2_1 (in-place)
I0226 12:57:58.902765  7672 net.cpp:150] Setting up relu2_1
I0226 12:57:58.902771  7672 net.cpp:157] Top shape: 20 128 161 161 (66357760)
I0226 12:57:58.902778  7672 net.cpp:165] Memory required for data: 2900332320
I0226 12:57:58.902786  7672 layer_factory.hpp:77] Creating layer conv2_2
I0226 12:57:58.902794  7672 net.cpp:106] Creating Layer conv2_2
I0226 12:57:58.902801  7672 net.cpp:454] conv2_2 <- conv2_1
I0226 12:57:58.902809  7672 net.cpp:411] conv2_2 -> conv2_2
I0226 12:57:58.903120  7672 net.cpp:150] Setting up conv2_2
I0226 12:57:58.903133  7672 net.cpp:157] Top shape: 20 128 161 161 (66357760)
I0226 12:57:58.903141  7672 net.cpp:165] Memory required for data: 3165763360
I0226 12:57:58.903149  7672 layer_factory.hpp:77] Creating layer relu2_2
I0226 12:57:58.903157  7672 net.cpp:106] Creating Layer relu2_2
I0226 12:57:58.903163  7672 net.cpp:454] relu2_2 <- conv2_2
I0226 12:57:58.903172  7672 net.cpp:397] relu2_2 -> conv2_2 (in-place)
I0226 12:57:58.903179  7672 net.cpp:150] Setting up relu2_2
I0226 12:57:58.903187  7672 net.cpp:157] Top shape: 20 128 161 161 (66357760)
I0226 12:57:58.903192  7672 net.cpp:165] Memory required for data: 3431194400
I0226 12:57:58.903198  7672 layer_factory.hpp:77] Creating layer pool2
I0226 12:57:58.903206  7672 net.cpp:106] Creating Layer pool2
I0226 12:57:58.903213  7672 net.cpp:454] pool2 <- conv2_2
I0226 12:57:58.903220  7672 net.cpp:411] pool2 -> pool2
I0226 12:57:58.903252  7672 net.cpp:150] Setting up pool2
I0226 12:57:58.903261  7672 net.cpp:157] Top shape: 20 128 81 81 (16796160)
I0226 12:57:58.903267  7672 net.cpp:165] Memory required for data: 3498379040
I0226 12:57:58.903273  7672 layer_factory.hpp:77] Creating layer conv3_1
I0226 12:57:58.903283  7672 net.cpp:106] Creating Layer conv3_1
I0226 12:57:58.903290  7672 net.cpp:454] conv3_1 <- pool2
I0226 12:57:58.903297  7672 net.cpp:411] conv3_1 -> conv3_1
I0226 12:57:58.905934  7672 net.cpp:150] Setting up conv3_1
I0226 12:57:58.905961  7672 net.cpp:157] Top shape: 20 256 81 81 (33592320)
I0226 12:57:58.905969  7672 net.cpp:165] Memory required for data: 3632748320
I0226 12:57:58.905987  7672 layer_factory.hpp:77] Creating layer relu3_1
I0226 12:57:58.905997  7672 net.cpp:106] Creating Layer relu3_1
I0226 12:57:58.906006  7672 net.cpp:454] relu3_1 <- conv3_1
I0226 12:57:58.906018  7672 net.cpp:397] relu3_1 -> conv3_1 (in-place)
I0226 12:57:58.906029  7672 net.cpp:150] Setting up relu3_1
I0226 12:57:58.906052  7672 net.cpp:157] Top shape: 20 256 81 81 (33592320)
I0226 12:57:58.906080  7672 net.cpp:165] Memory required for data: 3767117600
I0226 12:57:58.906088  7672 layer_factory.hpp:77] Creating layer conv3_2
I0226 12:57:58.906103  7672 net.cpp:106] Creating Layer conv3_2
I0226 12:57:58.906112  7672 net.cpp:454] conv3_2 <- conv3_1
I0226 12:57:58.906123  7672 net.cpp:411] conv3_2 -> conv3_2
I0226 12:57:58.908140  7672 net.cpp:150] Setting up conv3_2
I0226 12:57:58.908171  7672 net.cpp:157] Top shape: 20 256 81 81 (33592320)
I0226 12:57:58.908185  7672 net.cpp:165] Memory required for data: 3901486880
I0226 12:57:58.908205  7672 layer_factory.hpp:77] Creating layer relu3_2
I0226 12:57:58.908224  7672 net.cpp:106] Creating Layer relu3_2
I0226 12:57:58.908237  7672 net.cpp:454] relu3_2 <- conv3_2
I0226 12:57:58.908253  7672 net.cpp:397] relu3_2 -> conv3_2 (in-place)
I0226 12:57:58.908272  7672 net.cpp:150] Setting up relu3_2
I0226 12:57:58.908288  7672 net.cpp:157] Top shape: 20 256 81 81 (33592320)
I0226 12:57:58.908300  7672 net.cpp:165] Memory required for data: 4035856160
I0226 12:57:58.908313  7672 layer_factory.hpp:77] Creating layer conv3_3
I0226 12:57:58.908334  7672 net.cpp:106] Creating Layer conv3_3
I0226 12:57:58.908347  7672 net.cpp:454] conv3_3 <- conv3_2
I0226 12:57:58.908365  7672 net.cpp:411] conv3_3 -> conv3_3
I0226 12:57:58.910333  7672 net.cpp:150] Setting up conv3_3
I0226 12:57:58.910359  7672 net.cpp:157] Top shape: 20 256 81 81 (33592320)
I0226 12:57:58.910368  7672 net.cpp:165] Memory required for data: 4170225440
I0226 12:57:58.910380  7672 layer_factory.hpp:77] Creating layer relu3_3
I0226 12:57:58.910395  7672 net.cpp:106] Creating Layer relu3_3
I0226 12:57:58.910404  7672 net.cpp:454] relu3_3 <- conv3_3
I0226 12:57:58.910415  7672 net.cpp:397] relu3_3 -> conv3_3 (in-place)
I0226 12:57:58.910428  7672 net.cpp:150] Setting up relu3_3
I0226 12:57:58.910437  7672 net.cpp:157] Top shape: 20 256 81 81 (33592320)
I0226 12:57:58.910445  7672 net.cpp:165] Memory required for data: 4304594720
I0226 12:57:58.910454  7672 layer_factory.hpp:77] Creating layer pool3
I0226 12:57:58.910464  7672 net.cpp:106] Creating Layer pool3
I0226 12:57:58.910471  7672 net.cpp:454] pool3 <- conv3_3
I0226 12:57:58.910482  7672 net.cpp:411] pool3 -> pool3
I0226 12:57:58.910542  7672 net.cpp:150] Setting up pool3
I0226 12:57:58.910557  7672 net.cpp:157] Top shape: 20 256 41 41 (8606720)
I0226 12:57:58.910565  7672 net.cpp:165] Memory required for data: 4339021600
I0226 12:57:58.910573  7672 layer_factory.hpp:77] Creating layer conv4_1
I0226 12:57:58.910588  7672 net.cpp:106] Creating Layer conv4_1
I0226 12:57:58.910596  7672 net.cpp:454] conv4_1 <- pool3
I0226 12:57:58.910609  7672 net.cpp:411] conv4_1 -> conv4_1
I0226 12:57:58.914850  7672 net.cpp:150] Setting up conv4_1
I0226 12:57:58.914909  7672 net.cpp:157] Top shape: 20 512 41 41 (17213440)
I0226 12:57:58.914927  7672 net.cpp:165] Memory required for data: 4407875360
I0226 12:57:58.914947  7672 layer_factory.hpp:77] Creating layer relu4_1
I0226 12:57:58.914963  7672 net.cpp:106] Creating Layer relu4_1
I0226 12:57:58.914978  7672 net.cpp:454] relu4_1 <- conv4_1
I0226 12:57:58.914994  7672 net.cpp:397] relu4_1 -> conv4_1 (in-place)
I0226 12:57:58.915012  7672 net.cpp:150] Setting up relu4_1
I0226 12:57:58.915027  7672 net.cpp:157] Top shape: 20 512 41 41 (17213440)
I0226 12:57:58.915040  7672 net.cpp:165] Memory required for data: 4476729120
I0226 12:57:58.915053  7672 layer_factory.hpp:77] Creating layer conv4_2
I0226 12:57:58.915074  7672 net.cpp:106] Creating Layer conv4_2
I0226 12:57:58.915089  7672 net.cpp:454] conv4_2 <- conv4_1
I0226 12:57:58.915105  7672 net.cpp:411] conv4_2 -> conv4_2
I0226 12:57:58.920092  7672 net.cpp:150] Setting up conv4_2
I0226 12:57:58.920128  7672 net.cpp:157] Top shape: 20 512 41 41 (17213440)
I0226 12:57:58.920135  7672 net.cpp:165] Memory required for data: 4545582880
I0226 12:57:58.920151  7672 layer_factory.hpp:77] Creating layer relu4_2
I0226 12:57:58.920161  7672 net.cpp:106] Creating Layer relu4_2
I0226 12:57:58.920168  7672 net.cpp:454] relu4_2 <- conv4_2
I0226 12:57:58.920176  7672 net.cpp:397] relu4_2 -> conv4_2 (in-place)
I0226 12:57:58.920186  7672 net.cpp:150] Setting up relu4_2
I0226 12:57:58.920192  7672 net.cpp:157] Top shape: 20 512 41 41 (17213440)
I0226 12:57:58.920198  7672 net.cpp:165] Memory required for data: 4614436640
I0226 12:57:58.920204  7672 layer_factory.hpp:77] Creating layer conv4_3
I0226 12:57:58.920214  7672 net.cpp:106] Creating Layer conv4_3
I0226 12:57:58.920222  7672 net.cpp:454] conv4_3 <- conv4_2
I0226 12:57:58.920230  7672 net.cpp:411] conv4_3 -> conv4_3
I0226 12:57:58.925249  7672 net.cpp:150] Setting up conv4_3
I0226 12:57:58.925271  7672 net.cpp:157] Top shape: 20 512 41 41 (17213440)
I0226 12:57:58.925277  7672 net.cpp:165] Memory required for data: 4683290400
I0226 12:57:58.925287  7672 layer_factory.hpp:77] Creating layer relu4_3
I0226 12:57:58.925299  7672 net.cpp:106] Creating Layer relu4_3
I0226 12:57:58.925307  7672 net.cpp:454] relu4_3 <- conv4_3
I0226 12:57:58.925315  7672 net.cpp:397] relu4_3 -> conv4_3 (in-place)
I0226 12:57:58.925325  7672 net.cpp:150] Setting up relu4_3
I0226 12:57:58.925333  7672 net.cpp:157] Top shape: 20 512 41 41 (17213440)
I0226 12:57:58.925338  7672 net.cpp:165] Memory required for data: 4752144160
I0226 12:57:58.925356  7672 layer_factory.hpp:77] Creating layer pool4
I0226 12:57:58.925365  7672 net.cpp:106] Creating Layer pool4
I0226 12:57:58.925371  7672 net.cpp:454] pool4 <- conv4_3
I0226 12:57:58.925379  7672 net.cpp:411] pool4 -> pool4
I0226 12:57:58.925416  7672 net.cpp:150] Setting up pool4
I0226 12:57:58.925426  7672 net.cpp:157] Top shape: 20 512 41 41 (17213440)
I0226 12:57:58.925433  7672 net.cpp:165] Memory required for data: 4820997920
I0226 12:57:58.925439  7672 layer_factory.hpp:77] Creating layer conv5_1
I0226 12:57:58.925451  7672 net.cpp:106] Creating Layer conv5_1
I0226 12:57:58.925457  7672 net.cpp:454] conv5_1 <- pool4
I0226 12:57:58.925465  7672 net.cpp:411] conv5_1 -> conv5_1
I0226 12:57:58.931324  7672 net.cpp:150] Setting up conv5_1
I0226 12:57:58.931358  7672 net.cpp:157] Top shape: 20 512 41 41 (17213440)
I0226 12:57:58.931365  7672 net.cpp:165] Memory required for data: 4889851680
I0226 12:57:58.931375  7672 layer_factory.hpp:77] Creating layer relu5_1
I0226 12:57:58.931385  7672 net.cpp:106] Creating Layer relu5_1
I0226 12:57:58.931392  7672 net.cpp:454] relu5_1 <- conv5_1
I0226 12:57:58.931401  7672 net.cpp:397] relu5_1 -> conv5_1 (in-place)
I0226 12:57:58.931411  7672 net.cpp:150] Setting up relu5_1
I0226 12:57:58.931418  7672 net.cpp:157] Top shape: 20 512 41 41 (17213440)
I0226 12:57:58.931424  7672 net.cpp:165] Memory required for data: 4958705440
I0226 12:57:58.931432  7672 layer_factory.hpp:77] Creating layer conv5_2
I0226 12:57:58.931443  7672 net.cpp:106] Creating Layer conv5_2
I0226 12:57:58.931450  7672 net.cpp:454] conv5_2 <- conv5_1
I0226 12:57:58.931458  7672 net.cpp:411] conv5_2 -> conv5_2
I0226 12:57:58.936849  7672 net.cpp:150] Setting up conv5_2
I0226 12:57:58.936885  7672 net.cpp:157] Top shape: 20 512 41 41 (17213440)
I0226 12:57:58.936892  7672 net.cpp:165] Memory required for data: 5027559200
I0226 12:57:58.936903  7672 layer_factory.hpp:77] Creating layer relu5_2
I0226 12:57:58.936913  7672 net.cpp:106] Creating Layer relu5_2
I0226 12:57:58.936921  7672 net.cpp:454] relu5_2 <- conv5_2
I0226 12:57:58.936931  7672 net.cpp:397] relu5_2 -> conv5_2 (in-place)
I0226 12:57:58.936942  7672 net.cpp:150] Setting up relu5_2
I0226 12:57:58.936950  7672 net.cpp:157] Top shape: 20 512 41 41 (17213440)
I0226 12:57:58.936962  7672 net.cpp:165] Memory required for data: 5096412960
I0226 12:57:58.936974  7672 layer_factory.hpp:77] Creating layer conv5_3
I0226 12:57:58.936985  7672 net.cpp:106] Creating Layer conv5_3
I0226 12:57:58.936993  7672 net.cpp:454] conv5_3 <- conv5_2
I0226 12:57:58.937008  7672 net.cpp:411] conv5_3 -> conv5_3
I0226 12:57:58.943507  7672 net.cpp:150] Setting up conv5_3
I0226 12:57:58.943536  7672 net.cpp:157] Top shape: 20 512 41 41 (17213440)
I0226 12:57:58.943545  7672 net.cpp:165] Memory required for data: 5165266720
I0226 12:57:58.943559  7672 layer_factory.hpp:77] Creating layer relu5_3
I0226 12:57:58.943576  7672 net.cpp:106] Creating Layer relu5_3
I0226 12:57:58.943586  7672 net.cpp:454] relu5_3 <- conv5_3
I0226 12:57:58.943598  7672 net.cpp:397] relu5_3 -> conv5_3 (in-place)
I0226 12:57:58.943611  7672 net.cpp:150] Setting up relu5_3
I0226 12:57:58.943621  7672 net.cpp:157] Top shape: 20 512 41 41 (17213440)
I0226 12:57:58.943629  7672 net.cpp:165] Memory required for data: 5234120480
I0226 12:57:58.943637  7672 layer_factory.hpp:77] Creating layer pool5
I0226 12:57:58.943662  7672 net.cpp:106] Creating Layer pool5
I0226 12:57:58.943675  7672 net.cpp:454] pool5 <- conv5_3
I0226 12:57:58.943686  7672 net.cpp:411] pool5 -> pool5
I0226 12:57:58.943734  7672 net.cpp:150] Setting up pool5
I0226 12:57:58.943748  7672 net.cpp:157] Top shape: 20 512 41 41 (17213440)
I0226 12:57:58.943758  7672 net.cpp:165] Memory required for data: 5302974240
I0226 12:57:58.943766  7672 layer_factory.hpp:77] Creating layer pool5a
I0226 12:57:58.943776  7672 net.cpp:106] Creating Layer pool5a
I0226 12:57:58.943785  7672 net.cpp:454] pool5a <- pool5
I0226 12:57:58.943795  7672 net.cpp:411] pool5a -> pool5a
I0226 12:57:58.943825  7672 net.cpp:150] Setting up pool5a
I0226 12:57:58.943835  7672 net.cpp:157] Top shape: 20 512 41 41 (17213440)
I0226 12:57:58.943845  7672 net.cpp:165] Memory required for data: 5371828000
I0226 12:57:58.943856  7672 layer_factory.hpp:77] Creating layer pool5a_pool5a_0_split
I0226 12:57:58.943869  7672 net.cpp:106] Creating Layer pool5a_pool5a_0_split
I0226 12:57:58.943878  7672 net.cpp:454] pool5a_pool5a_0_split <- pool5a
I0226 12:57:58.943888  7672 net.cpp:411] pool5a_pool5a_0_split -> pool5a_pool5a_0_split_0
I0226 12:57:58.943902  7672 net.cpp:411] pool5a_pool5a_0_split -> pool5a_pool5a_0_split_1
I0226 12:57:58.943912  7672 net.cpp:411] pool5a_pool5a_0_split -> pool5a_pool5a_0_split_2
I0226 12:57:58.943934  7672 net.cpp:411] pool5a_pool5a_0_split -> pool5a_pool5a_0_split_3
I0226 12:57:58.943998  7672 net.cpp:150] Setting up pool5a_pool5a_0_split
I0226 12:57:58.944010  7672 net.cpp:157] Top shape: 20 512 41 41 (17213440)
I0226 12:57:58.944020  7672 net.cpp:157] Top shape: 20 512 41 41 (17213440)
I0226 12:57:58.944030  7672 net.cpp:157] Top shape: 20 512 41 41 (17213440)
I0226 12:57:58.944039  7672 net.cpp:157] Top shape: 20 512 41 41 (17213440)
I0226 12:57:58.944047  7672 net.cpp:165] Memory required for data: 5647243040
I0226 12:57:58.944056  7672 layer_factory.hpp:77] Creating layer fc6_1
I0226 12:57:58.944069  7672 net.cpp:106] Creating Layer fc6_1
I0226 12:57:58.944078  7672 net.cpp:454] fc6_1 <- pool5a_pool5a_0_split_0
I0226 12:57:58.944090  7672 net.cpp:411] fc6_1 -> fc6_1
I0226 12:57:58.958226  7672 net.cpp:150] Setting up fc6_1
I0226 12:57:58.958259  7672 net.cpp:157] Top shape: 20 1024 41 41 (34426880)
I0226 12:57:58.958269  7672 net.cpp:165] Memory required for data: 5784950560
I0226 12:57:58.958283  7672 layer_factory.hpp:77] Creating layer relu6_1
I0226 12:57:58.958300  7672 net.cpp:106] Creating Layer relu6_1
I0226 12:57:58.958312  7672 net.cpp:454] relu6_1 <- fc6_1
I0226 12:57:58.958323  7672 net.cpp:397] relu6_1 -> fc6_1 (in-place)
I0226 12:57:58.958336  7672 net.cpp:150] Setting up relu6_1
I0226 12:57:58.958346  7672 net.cpp:157] Top shape: 20 1024 41 41 (34426880)
I0226 12:57:58.958355  7672 net.cpp:165] Memory required for data: 5922658080
I0226 12:57:58.958364  7672 layer_factory.hpp:77] Creating layer drop6_1
I0226 12:57:58.958380  7672 net.cpp:106] Creating Layer drop6_1
I0226 12:57:58.958389  7672 net.cpp:454] drop6_1 <- fc6_1
I0226 12:57:58.958400  7672 net.cpp:397] drop6_1 -> fc6_1 (in-place)
I0226 12:57:58.958436  7672 net.cpp:150] Setting up drop6_1
I0226 12:57:58.958456  7672 net.cpp:157] Top shape: 20 1024 41 41 (34426880)
I0226 12:57:58.958465  7672 net.cpp:165] Memory required for data: 6060365600
I0226 12:57:58.958474  7672 layer_factory.hpp:77] Creating layer fc7_1
I0226 12:57:58.958488  7672 net.cpp:106] Creating Layer fc7_1
I0226 12:57:58.958497  7672 net.cpp:454] fc7_1 <- fc6_1
I0226 12:57:58.958508  7672 net.cpp:411] fc7_1 -> fc7_1
I0226 12:57:58.966336  7672 net.cpp:150] Setting up fc7_1
I0226 12:57:58.966389  7672 net.cpp:157] Top shape: 20 1024 41 41 (34426880)
I0226 12:57:58.966411  7672 net.cpp:165] Memory required for data: 6198073120
I0226 12:57:58.966441  7672 layer_factory.hpp:77] Creating layer relu7_1
I0226 12:57:58.966466  7672 net.cpp:106] Creating Layer relu7_1
I0226 12:57:58.966488  7672 net.cpp:454] relu7_1 <- fc7_1
I0226 12:57:58.966514  7672 net.cpp:397] relu7_1 -> fc7_1 (in-place)
I0226 12:57:58.966536  7672 net.cpp:150] Setting up relu7_1
I0226 12:57:58.966552  7672 net.cpp:157] Top shape: 20 1024 41 41 (34426880)
I0226 12:57:58.966573  7672 net.cpp:165] Memory required for data: 6335780640
I0226 12:57:58.966593  7672 layer_factory.hpp:77] Creating layer drop7_1
I0226 12:57:58.966620  7672 net.cpp:106] Creating Layer drop7_1
I0226 12:57:58.966637  7672 net.cpp:454] drop7_1 <- fc7_1
I0226 12:57:58.966652  7672 net.cpp:397] drop7_1 -> fc7_1 (in-place)
I0226 12:57:58.966703  7672 net.cpp:150] Setting up drop7_1
I0226 12:57:58.966723  7672 net.cpp:157] Top shape: 20 1024 41 41 (34426880)
I0226 12:57:58.966737  7672 net.cpp:165] Memory required for data: 6473488160
I0226 12:57:58.966750  7672 layer_factory.hpp:77] Creating layer fc8-SEC_1
I0226 12:57:58.966770  7672 net.cpp:106] Creating Layer fc8-SEC_1
I0226 12:57:58.966784  7672 net.cpp:454] fc8-SEC_1 <- fc7_1
I0226 12:57:58.966800  7672 net.cpp:411] fc8-SEC_1 -> fc8-SEC_1
I0226 12:57:58.967643  7672 net.cpp:150] Setting up fc8-SEC_1
I0226 12:57:58.967669  7672 net.cpp:157] Top shape: 20 21 41 41 (706020)
I0226 12:57:58.967681  7672 net.cpp:165] Memory required for data: 6476312240
I0226 12:57:58.967700  7672 layer_factory.hpp:77] Creating layer fc6_2
I0226 12:57:58.967717  7672 net.cpp:106] Creating Layer fc6_2
I0226 12:57:58.967731  7672 net.cpp:454] fc6_2 <- pool5a_pool5a_0_split_1
I0226 12:57:58.967748  7672 net.cpp:411] fc6_2 -> fc6_2
I0226 12:57:58.980681  7672 net.cpp:150] Setting up fc6_2
I0226 12:57:58.980707  7672 net.cpp:157] Top shape: 20 1024 41 41 (34426880)
I0226 12:57:58.980717  7672 net.cpp:165] Memory required for data: 6614019760
I0226 12:57:58.980737  7672 layer_factory.hpp:77] Creating layer relu6_2
I0226 12:57:58.980758  7672 net.cpp:106] Creating Layer relu6_2
I0226 12:57:58.980773  7672 net.cpp:454] relu6_2 <- fc6_2
I0226 12:57:58.980792  7672 net.cpp:397] relu6_2 -> fc6_2 (in-place)
I0226 12:57:58.980818  7672 net.cpp:150] Setting up relu6_2
I0226 12:57:58.980839  7672 net.cpp:157] Top shape: 20 1024 41 41 (34426880)
I0226 12:57:58.980862  7672 net.cpp:165] Memory required for data: 6751727280
I0226 12:57:58.980878  7672 layer_factory.hpp:77] Creating layer drop6_2
I0226 12:57:58.980893  7672 net.cpp:106] Creating Layer drop6_2
I0226 12:57:58.980906  7672 net.cpp:454] drop6_2 <- fc6_2
I0226 12:57:58.980923  7672 net.cpp:397] drop6_2 -> fc6_2 (in-place)
I0226 12:57:58.980967  7672 net.cpp:150] Setting up drop6_2
I0226 12:57:58.980983  7672 net.cpp:157] Top shape: 20 1024 41 41 (34426880)
I0226 12:57:58.980998  7672 net.cpp:165] Memory required for data: 6889434800
I0226 12:57:58.981010  7672 layer_factory.hpp:77] Creating layer fc7_2
I0226 12:57:58.981029  7672 net.cpp:106] Creating Layer fc7_2
I0226 12:57:58.981041  7672 net.cpp:454] fc7_2 <- fc6_2
I0226 12:57:58.981056  7672 net.cpp:411] fc7_2 -> fc7_2
I0226 12:57:58.985816  7672 net.cpp:150] Setting up fc7_2
I0226 12:57:58.985843  7672 net.cpp:157] Top shape: 20 1024 41 41 (34426880)
I0226 12:57:58.985853  7672 net.cpp:165] Memory required for data: 7027142320
I0226 12:57:58.985867  7672 layer_factory.hpp:77] Creating layer relu7_2
I0226 12:57:58.985880  7672 net.cpp:106] Creating Layer relu7_2
I0226 12:57:58.985890  7672 net.cpp:454] relu7_2 <- fc7_2
I0226 12:57:58.985901  7672 net.cpp:397] relu7_2 -> fc7_2 (in-place)
I0226 12:57:58.985914  7672 net.cpp:150] Setting up relu7_2
I0226 12:57:58.985924  7672 net.cpp:157] Top shape: 20 1024 41 41 (34426880)
I0226 12:57:58.985932  7672 net.cpp:165] Memory required for data: 7164849840
I0226 12:57:58.985940  7672 layer_factory.hpp:77] Creating layer drop7_2
I0226 12:57:58.985951  7672 net.cpp:106] Creating Layer drop7_2
I0226 12:57:58.985960  7672 net.cpp:454] drop7_2 <- fc7_2
I0226 12:57:58.985968  7672 net.cpp:397] drop7_2 -> fc7_2 (in-place)
I0226 12:57:58.986001  7672 net.cpp:150] Setting up drop7_2
I0226 12:57:58.986012  7672 net.cpp:157] Top shape: 20 1024 41 41 (34426880)
I0226 12:57:58.986021  7672 net.cpp:165] Memory required for data: 7302557360
I0226 12:57:58.986028  7672 layer_factory.hpp:77] Creating layer fc8-SEC_2
I0226 12:57:58.986042  7672 net.cpp:106] Creating Layer fc8-SEC_2
I0226 12:57:58.986052  7672 net.cpp:454] fc8-SEC_2 <- fc7_2
I0226 12:57:58.986061  7672 net.cpp:411] fc8-SEC_2 -> fc8-SEC_2
I0226 12:57:58.986579  7672 net.cpp:150] Setting up fc8-SEC_2
I0226 12:57:58.986596  7672 net.cpp:157] Top shape: 20 21 41 41 (706020)
I0226 12:57:58.986605  7672 net.cpp:165] Memory required for data: 7305381440
I0226 12:57:58.986616  7672 layer_factory.hpp:77] Creating layer fc6_3
I0226 12:57:58.986630  7672 net.cpp:106] Creating Layer fc6_3
I0226 12:57:58.986640  7672 net.cpp:454] fc6_3 <- pool5a_pool5a_0_split_2
I0226 12:57:58.986651  7672 net.cpp:411] fc6_3 -> fc6_3
I0226 12:57:59.002532  7672 net.cpp:150] Setting up fc6_3
I0226 12:57:59.002569  7672 net.cpp:157] Top shape: 20 1024 41 41 (34426880)
I0226 12:57:59.002581  7672 net.cpp:165] Memory required for data: 7443088960
I0226 12:57:59.002598  7672 layer_factory.hpp:77] Creating layer relu6_3
I0226 12:57:59.002614  7672 net.cpp:106] Creating Layer relu6_3
I0226 12:57:59.002626  7672 net.cpp:454] relu6_3 <- fc6_3
I0226 12:57:59.002640  7672 net.cpp:397] relu6_3 -> fc6_3 (in-place)
I0226 12:57:59.002655  7672 net.cpp:150] Setting up relu6_3
I0226 12:57:59.002669  7672 net.cpp:157] Top shape: 20 1024 41 41 (34426880)
I0226 12:57:59.002679  7672 net.cpp:165] Memory required for data: 7580796480
I0226 12:57:59.002698  7672 layer_factory.hpp:77] Creating layer drop6_3
I0226 12:57:59.002712  7672 net.cpp:106] Creating Layer drop6_3
I0226 12:57:59.002722  7672 net.cpp:454] drop6_3 <- fc6_3
I0226 12:57:59.002732  7672 net.cpp:397] drop6_3 -> fc6_3 (in-place)
I0226 12:57:59.002771  7672 net.cpp:150] Setting up drop6_3
I0226 12:57:59.002785  7672 net.cpp:157] Top shape: 20 1024 41 41 (34426880)
I0226 12:57:59.002796  7672 net.cpp:165] Memory required for data: 7718504000
I0226 12:57:59.002806  7672 layer_factory.hpp:77] Creating layer fc7_3
I0226 12:57:59.002822  7672 net.cpp:106] Creating Layer fc7_3
I0226 12:57:59.002835  7672 net.cpp:454] fc7_3 <- fc6_3
I0226 12:57:59.002848  7672 net.cpp:411] fc7_3 -> fc7_3
I0226 12:57:59.006129  7672 net.cpp:150] Setting up fc7_3
I0226 12:57:59.006160  7672 net.cpp:157] Top shape: 20 1024 41 41 (34426880)
I0226 12:57:59.006171  7672 net.cpp:165] Memory required for data: 7856211520
I0226 12:57:59.006191  7672 layer_factory.hpp:77] Creating layer relu7_3
I0226 12:57:59.006208  7672 net.cpp:106] Creating Layer relu7_3
I0226 12:57:59.006219  7672 net.cpp:454] relu7_3 <- fc7_3
I0226 12:57:59.006232  7672 net.cpp:397] relu7_3 -> fc7_3 (in-place)
I0226 12:57:59.006247  7672 net.cpp:150] Setting up relu7_3
I0226 12:57:59.006259  7672 net.cpp:157] Top shape: 20 1024 41 41 (34426880)
I0226 12:57:59.006269  7672 net.cpp:165] Memory required for data: 7993919040
I0226 12:57:59.006279  7672 layer_factory.hpp:77] Creating layer drop7_3
I0226 12:57:59.006292  7672 net.cpp:106] Creating Layer drop7_3
I0226 12:57:59.006302  7672 net.cpp:454] drop7_3 <- fc7_3
I0226 12:57:59.006315  7672 net.cpp:397] drop7_3 -> fc7_3 (in-place)
I0226 12:57:59.006353  7672 net.cpp:150] Setting up drop7_3
I0226 12:57:59.006372  7672 net.cpp:157] Top shape: 20 1024 41 41 (34426880)
I0226 12:57:59.006382  7672 net.cpp:165] Memory required for data: 8131626560
I0226 12:57:59.006392  7672 layer_factory.hpp:77] Creating layer fc8-SEC_3
I0226 12:57:59.006410  7672 net.cpp:106] Creating Layer fc8-SEC_3
I0226 12:57:59.006422  7672 net.cpp:454] fc8-SEC_3 <- fc7_3
I0226 12:57:59.006435  7672 net.cpp:411] fc8-SEC_3 -> fc8-SEC_3
I0226 12:57:59.007083  7672 net.cpp:150] Setting up fc8-SEC_3
I0226 12:57:59.007104  7672 net.cpp:157] Top shape: 20 21 41 41 (706020)
I0226 12:57:59.007114  7672 net.cpp:165] Memory required for data: 8134450640
I0226 12:57:59.007128  7672 layer_factory.hpp:77] Creating layer fc6_4
I0226 12:57:59.007158  7672 net.cpp:106] Creating Layer fc6_4
I0226 12:57:59.007172  7672 net.cpp:454] fc6_4 <- pool5a_pool5a_0_split_3
I0226 12:57:59.007186  7672 net.cpp:411] fc6_4 -> fc6_4
I0226 12:57:59.016839  7672 net.cpp:150] Setting up fc6_4
I0226 12:57:59.016861  7672 net.cpp:157] Top shape: 20 1024 41 41 (34426880)
I0226 12:57:59.016868  7672 net.cpp:165] Memory required for data: 8272158160
I0226 12:57:59.016877  7672 layer_factory.hpp:77] Creating layer relu6_4
I0226 12:57:59.016886  7672 net.cpp:106] Creating Layer relu6_4
I0226 12:57:59.016893  7672 net.cpp:454] relu6_4 <- fc6_4
I0226 12:57:59.016901  7672 net.cpp:397] relu6_4 -> fc6_4 (in-place)
I0226 12:57:59.016911  7672 net.cpp:150] Setting up relu6_4
I0226 12:57:59.016917  7672 net.cpp:157] Top shape: 20 1024 41 41 (34426880)
I0226 12:57:59.016922  7672 net.cpp:165] Memory required for data: 8409865680
I0226 12:57:59.016928  7672 layer_factory.hpp:77] Creating layer drop6_4
I0226 12:57:59.016935  7672 net.cpp:106] Creating Layer drop6_4
I0226 12:57:59.016942  7672 net.cpp:454] drop6_4 <- fc6_4
I0226 12:57:59.016948  7672 net.cpp:397] drop6_4 -> fc6_4 (in-place)
I0226 12:57:59.016971  7672 net.cpp:150] Setting up drop6_4
I0226 12:57:59.016983  7672 net.cpp:157] Top shape: 20 1024 41 41 (34426880)
I0226 12:57:59.016988  7672 net.cpp:165] Memory required for data: 8547573200
I0226 12:57:59.016996  7672 layer_factory.hpp:77] Creating layer fc7_4
I0226 12:57:59.017006  7672 net.cpp:106] Creating Layer fc7_4
I0226 12:57:59.017011  7672 net.cpp:454] fc7_4 <- fc6_4
I0226 12:57:59.017019  7672 net.cpp:411] fc7_4 -> fc7_4
I0226 12:57:59.019276  7672 net.cpp:150] Setting up fc7_4
I0226 12:57:59.019326  7672 net.cpp:157] Top shape: 20 1024 41 41 (34426880)
I0226 12:57:59.019333  7672 net.cpp:165] Memory required for data: 8685280720
I0226 12:57:59.019342  7672 layer_factory.hpp:77] Creating layer relu7_4
I0226 12:57:59.019351  7672 net.cpp:106] Creating Layer relu7_4
I0226 12:57:59.019357  7672 net.cpp:454] relu7_4 <- fc7_4
I0226 12:57:59.019366  7672 net.cpp:397] relu7_4 -> fc7_4 (in-place)
I0226 12:57:59.019374  7672 net.cpp:150] Setting up relu7_4
I0226 12:57:59.019382  7672 net.cpp:157] Top shape: 20 1024 41 41 (34426880)
I0226 12:57:59.019388  7672 net.cpp:165] Memory required for data: 8822988240
I0226 12:57:59.019393  7672 layer_factory.hpp:77] Creating layer drop7_4
I0226 12:57:59.019402  7672 net.cpp:106] Creating Layer drop7_4
I0226 12:57:59.019407  7672 net.cpp:454] drop7_4 <- fc7_4
I0226 12:57:59.019413  7672 net.cpp:397] drop7_4 -> fc7_4 (in-place)
I0226 12:57:59.019438  7672 net.cpp:150] Setting up drop7_4
I0226 12:57:59.019445  7672 net.cpp:157] Top shape: 20 1024 41 41 (34426880)
I0226 12:57:59.019451  7672 net.cpp:165] Memory required for data: 8960695760
I0226 12:57:59.019456  7672 layer_factory.hpp:77] Creating layer fc8-SEC_4
I0226 12:57:59.019470  7672 net.cpp:106] Creating Layer fc8-SEC_4
I0226 12:57:59.019476  7672 net.cpp:454] fc8-SEC_4 <- fc7_4
I0226 12:57:59.019484  7672 net.cpp:411] fc8-SEC_4 -> fc8-SEC_4
I0226 12:57:59.019843  7672 net.cpp:150] Setting up fc8-SEC_4
I0226 12:57:59.019857  7672 net.cpp:157] Top shape: 20 21 41 41 (706020)
I0226 12:57:59.019863  7672 net.cpp:165] Memory required for data: 8963519840
I0226 12:57:59.019873  7672 layer_factory.hpp:77] Creating layer fc8-SEC
I0226 12:57:59.019894  7672 net.cpp:106] Creating Layer fc8-SEC
I0226 12:57:59.019902  7672 net.cpp:454] fc8-SEC <- fc8-SEC_1
I0226 12:57:59.019909  7672 net.cpp:454] fc8-SEC <- fc8-SEC_2
I0226 12:57:59.019932  7672 net.cpp:454] fc8-SEC <- fc8-SEC_3
I0226 12:57:59.019940  7672 net.cpp:454] fc8-SEC <- fc8-SEC_4
I0226 12:57:59.019948  7672 net.cpp:411] fc8-SEC -> fc8-SEC
I0226 12:57:59.019978  7672 net.cpp:150] Setting up fc8-SEC
I0226 12:57:59.019986  7672 net.cpp:157] Top shape: 20 21 41 41 (706020)
I0226 12:57:59.019992  7672 net.cpp:165] Memory required for data: 8966343920
I0226 12:57:59.020000  7672 layer_factory.hpp:77] Creating layer Softmax
I0226 12:57:59.020051  7672 net.cpp:106] Creating Layer Softmax
I0226 12:57:59.020061  7672 net.cpp:454] Softmax <- fc8-SEC
I0226 12:57:59.020083  7672 net.cpp:411] Softmax -> fc8-SEC-Softmax
I0226 12:57:59.472357  7672 net.cpp:150] Setting up Softmax
I0226 12:57:59.472407  7672 net.cpp:157] Top shape: 20 21 41 41 (706020)
I0226 12:57:59.472415  7672 net.cpp:165] Memory required for data: 8969168000
I0226 12:57:59.472426  7672 layer_factory.hpp:77] Creating layer fc8-SEC-Softmax_Softmax_0_split
I0226 12:57:59.472442  7672 net.cpp:106] Creating Layer fc8-SEC-Softmax_Softmax_0_split
I0226 12:57:59.472451  7672 net.cpp:454] fc8-SEC-Softmax_Softmax_0_split <- fc8-SEC-Softmax
I0226 12:57:59.472465  7672 net.cpp:411] fc8-SEC-Softmax_Softmax_0_split -> fc8-SEC-Softmax_Softmax_0_split_0
I0226 12:57:59.472483  7672 net.cpp:411] fc8-SEC-Softmax_Softmax_0_split -> fc8-SEC-Softmax_Softmax_0_split_1
I0226 12:57:59.472492  7672 net.cpp:411] fc8-SEC-Softmax_Softmax_0_split -> fc8-SEC-Softmax_Softmax_0_split_2
I0226 12:57:59.472501  7672 net.cpp:411] fc8-SEC-Softmax_Softmax_0_split -> fc8-SEC-Softmax_Softmax_0_split_3
I0226 12:57:59.472565  7672 net.cpp:150] Setting up fc8-SEC-Softmax_Softmax_0_split
I0226 12:57:59.472575  7672 net.cpp:157] Top shape: 20 21 41 41 (706020)
I0226 12:57:59.472582  7672 net.cpp:157] Top shape: 20 21 41 41 (706020)
I0226 12:57:59.472589  7672 net.cpp:157] Top shape: 20 21 41 41 (706020)
I0226 12:57:59.472595  7672 net.cpp:157] Top shape: 20 21 41 41 (706020)
I0226 12:57:59.472601  7672 net.cpp:165] Memory required for data: 8980464320
I0226 12:57:59.472609  7672 layer_factory.hpp:77] Creating layer CRF
I0226 12:57:59.472642  7672 net.cpp:106] Creating Layer CRF
I0226 12:57:59.472652  7672 net.cpp:454] CRF <- fc8-SEC-Softmax_Softmax_0_split_0
I0226 12:57:59.472661  7672 net.cpp:454] CRF <- images_Annotation_2_split_1
I0226 12:57:59.472671  7672 net.cpp:411] CRF -> fc8-SEC-CRF-log
I0226 12:57:59.473924  7672 net.cpp:150] Setting up CRF
I0226 12:57:59.473959  7672 net.cpp:157] Top shape: 20 21 41 41 (706020)
I0226 12:57:59.473966  7672 net.cpp:165] Memory required for data: 8983288400
I0226 12:57:59.473974  7672 layer_factory.hpp:77] Creating layer update-seed
I0226 12:57:59.474004  7672 net.cpp:106] Creating Layer update-seed
I0226 12:57:59.474014  7672 net.cpp:454] update-seed <- labels
I0226 12:57:59.474022  7672 net.cpp:454] update-seed <- fc8-SEC-Softmax_Softmax_0_split_1
I0226 12:57:59.474030  7672 net.cpp:454] update-seed <- cues
I0226 12:57:59.474036  7672 net.cpp:454] update-seed <- images_Annotation_2_split_2
I0226 12:57:59.474045  7672 net.cpp:411] update-seed -> cues-new
I0226 12:57:59.673449  7672 net.cpp:150] Setting up update-seed
I0226 12:57:59.673503  7672 net.cpp:157] Top shape: 20 21 41 41 (706020)
I0226 12:57:59.673516  7672 net.cpp:165] Memory required for data: 8986112480
I0226 12:57:59.673532  7672 layer_factory.hpp:77] Creating layer loss-Seed
I0226 12:57:59.673632  7672 net.cpp:106] Creating Layer loss-Seed
I0226 12:57:59.673650  7672 net.cpp:454] loss-Seed <- fc8-SEC-Softmax_Softmax_0_split_2
I0226 12:57:59.673679  7672 net.cpp:454] loss-Seed <- cues-new
I0226 12:57:59.673694  7672 net.cpp:411] loss-Seed -> loss-Seed
I0226 12:58:00.010113  7672 net.cpp:150] Setting up loss-Seed
I0226 12:58:00.010166  7672 net.cpp:157] Top shape: 1 (1)
I0226 12:58:00.010177  7672 net.cpp:160]     with loss weight 1
I0226 12:58:00.010205  7672 net.cpp:165] Memory required for data: 8986112484
I0226 12:58:00.010218  7672 layer_factory.hpp:77] Creating layer loss-Constrain
I0226 12:58:00.010283  7672 net.cpp:106] Creating Layer loss-Constrain
I0226 12:58:00.010301  7672 net.cpp:454] loss-Constrain <- fc8-SEC-Softmax_Softmax_0_split_3
I0226 12:58:00.010315  7672 net.cpp:454] loss-Constrain <- fc8-SEC-CRF-log
I0226 12:58:00.010335  7672 net.cpp:411] loss-Constrain -> loss-Constrain
I0226 12:58:00.258813  7672 net.cpp:150] Setting up loss-Constrain
I0226 12:58:00.258862  7672 net.cpp:157] Top shape: 1 (1)
I0226 12:58:00.258868  7672 net.cpp:160]     with loss weight 1
I0226 12:58:00.258893  7672 net.cpp:165] Memory required for data: 8986112488
I0226 12:58:00.258903  7672 net.cpp:226] loss-Constrain needs backward computation.
I0226 12:58:00.258911  7672 net.cpp:226] loss-Seed needs backward computation.
I0226 12:58:00.258920  7672 net.cpp:226] update-seed needs backward computation.
I0226 12:58:00.258936  7672 net.cpp:226] CRF needs backward computation.
I0226 12:58:00.258944  7672 net.cpp:226] fc8-SEC-Softmax_Softmax_0_split needs backward computation.
I0226 12:58:00.258954  7672 net.cpp:226] Softmax needs backward computation.
I0226 12:58:00.258960  7672 net.cpp:226] fc8-SEC needs backward computation.
I0226 12:58:00.258976  7672 net.cpp:226] fc8-SEC_4 needs backward computation.
I0226 12:58:00.258985  7672 net.cpp:226] drop7_4 needs backward computation.
I0226 12:58:00.258991  7672 net.cpp:226] relu7_4 needs backward computation.
I0226 12:58:00.258997  7672 net.cpp:226] fc7_4 needs backward computation.
I0226 12:58:00.259003  7672 net.cpp:226] drop6_4 needs backward computation.
I0226 12:58:00.259009  7672 net.cpp:226] relu6_4 needs backward computation.
I0226 12:58:00.259016  7672 net.cpp:226] fc6_4 needs backward computation.
I0226 12:58:00.259024  7672 net.cpp:226] fc8-SEC_3 needs backward computation.
I0226 12:58:00.259034  7672 net.cpp:226] drop7_3 needs backward computation.
I0226 12:58:00.259040  7672 net.cpp:226] relu7_3 needs backward computation.
I0226 12:58:00.259047  7672 net.cpp:226] fc7_3 needs backward computation.
I0226 12:58:00.259053  7672 net.cpp:226] drop6_3 needs backward computation.
I0226 12:58:00.259059  7672 net.cpp:226] relu6_3 needs backward computation.
I0226 12:58:00.259065  7672 net.cpp:226] fc6_3 needs backward computation.
I0226 12:58:00.259074  7672 net.cpp:226] fc8-SEC_2 needs backward computation.
I0226 12:58:00.259083  7672 net.cpp:226] drop7_2 needs backward computation.
I0226 12:58:00.259089  7672 net.cpp:226] relu7_2 needs backward computation.
I0226 12:58:00.259095  7672 net.cpp:226] fc7_2 needs backward computation.
I0226 12:58:00.259101  7672 net.cpp:226] drop6_2 needs backward computation.
I0226 12:58:00.259109  7672 net.cpp:226] relu6_2 needs backward computation.
I0226 12:58:00.259114  7672 net.cpp:226] fc6_2 needs backward computation.
I0226 12:58:00.259120  7672 net.cpp:226] fc8-SEC_1 needs backward computation.
I0226 12:58:00.259129  7672 net.cpp:226] drop7_1 needs backward computation.
I0226 12:58:00.259135  7672 net.cpp:226] relu7_1 needs backward computation.
I0226 12:58:00.259141  7672 net.cpp:226] fc7_1 needs backward computation.
I0226 12:58:00.259150  7672 net.cpp:226] drop6_1 needs backward computation.
I0226 12:58:00.259155  7672 net.cpp:226] relu6_1 needs backward computation.
I0226 12:58:00.259161  7672 net.cpp:226] fc6_1 needs backward computation.
I0226 12:58:00.259168  7672 net.cpp:226] pool5a_pool5a_0_split needs backward computation.
I0226 12:58:00.259174  7672 net.cpp:226] pool5a needs backward computation.
I0226 12:58:00.259181  7672 net.cpp:226] pool5 needs backward computation.
I0226 12:58:00.259189  7672 net.cpp:226] relu5_3 needs backward computation.
I0226 12:58:00.259196  7672 net.cpp:226] conv5_3 needs backward computation.
I0226 12:58:00.259205  7672 net.cpp:226] relu5_2 needs backward computation.
I0226 12:58:00.259212  7672 net.cpp:226] conv5_2 needs backward computation.
I0226 12:58:00.259218  7672 net.cpp:226] relu5_1 needs backward computation.
I0226 12:58:00.259224  7672 net.cpp:226] conv5_1 needs backward computation.
I0226 12:58:00.259232  7672 net.cpp:226] pool4 needs backward computation.
I0226 12:58:00.259239  7672 net.cpp:226] relu4_3 needs backward computation.
I0226 12:58:00.259248  7672 net.cpp:226] conv4_3 needs backward computation.
I0226 12:58:00.259255  7672 net.cpp:226] relu4_2 needs backward computation.
I0226 12:58:00.259261  7672 net.cpp:226] conv4_2 needs backward computation.
I0226 12:58:00.259268  7672 net.cpp:226] relu4_1 needs backward computation.
I0226 12:58:00.259274  7672 net.cpp:226] conv4_1 needs backward computation.
I0226 12:58:00.259280  7672 net.cpp:226] pool3 needs backward computation.
I0226 12:58:00.259292  7672 net.cpp:226] relu3_3 needs backward computation.
I0226 12:58:00.259299  7672 net.cpp:226] conv3_3 needs backward computation.
I0226 12:58:00.259307  7672 net.cpp:226] relu3_2 needs backward computation.
I0226 12:58:00.259315  7672 net.cpp:226] conv3_2 needs backward computation.
I0226 12:58:00.259322  7672 net.cpp:226] relu3_1 needs backward computation.
I0226 12:58:00.259328  7672 net.cpp:226] conv3_1 needs backward computation.
I0226 12:58:00.259335  7672 net.cpp:226] pool2 needs backward computation.
I0226 12:58:00.259342  7672 net.cpp:226] relu2_2 needs backward computation.
I0226 12:58:00.259348  7672 net.cpp:226] conv2_2 needs backward computation.
I0226 12:58:00.259356  7672 net.cpp:226] relu2_1 needs backward computation.
I0226 12:58:00.259362  7672 net.cpp:226] conv2_1 needs backward computation.
I0226 12:58:00.259369  7672 net.cpp:226] pool1 needs backward computation.
I0226 12:58:00.259375  7672 net.cpp:226] relu1_2 needs backward computation.
I0226 12:58:00.259382  7672 net.cpp:226] conv1_2 needs backward computation.
I0226 12:58:00.259387  7672 net.cpp:226] relu1_1 needs backward computation.
I0226 12:58:00.259393  7672 net.cpp:226] conv1_1 needs backward computation.
I0226 12:58:00.259402  7672 net.cpp:228] images_Annotation_2_split does not need backward computation.
I0226 12:58:00.259411  7672 net.cpp:228] Annotation does not need backward computation.
I0226 12:58:00.259421  7672 net.cpp:228] Input does not need backward computation.
I0226 12:58:00.259428  7672 net.cpp:270] This network produces output loss-Constrain
I0226 12:58:00.259435  7672 net.cpp:270] This network produces output loss-Seed
I0226 12:58:00.259487  7672 net.cpp:283] Network initialization done.
I0226 12:58:00.259791  7672 solver.cpp:60] Solver scaffolding done.
Loading pretrained model weights from ../../vgg16_20M_mc.caffemodel
I0226 12:58:00.350406  7672 net.cpp:816] Ignoring source layer input
I0226 12:58:00.365911  7672 net.cpp:816] Ignoring source layer fc8-pascal_1
I0226 12:58:00.370177  7672 net.cpp:816] Ignoring source layer fc8-pascal_2
I0226 12:58:00.374469  7672 net.cpp:816] Ignoring source layer fc8-pascal_3
I0226 12:58:00.378682  7672 net.cpp:816] Ignoring source layer fc8-pascal_4
Solving...
I0226 12:58:00.386410  7672 solver.cpp:280] Solving DSRG
I0226 12:58:00.386420  7672 solver.cpp:281] Learning Rate Policy: step
/home/austin/.virtualenvs/pdsrg/local/lib/python2.7/site-packages/scipy/ndimage/interpolation.py:568: UserWarning: From scipy 0.13.0, the output shape of zoom() is calculated with round() instead of int() - for these inputs the size of the returned array has changed.
  "the returned array has changed.", UserWarning)
I0226 12:58:03.767403  7672 solver.cpp:229] Iteration 0, loss = 6.45416
I0226 12:58:03.767443  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.273182 (* 1 = 0.273182 loss)
I0226 12:58:03.767457  7672 solver.cpp:245]     Train net output #1: loss-Seed = 6.18098 (* 1 = 6.18098 loss)
I0226 12:58:03.767470  7672 sgd_solver.cpp:106] Iteration 0, lr = 0.0005
I0226 12:58:30.887818  7672 solver.cpp:229] Iteration 10, loss = 4.57974
I0226 12:58:30.887857  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.412636 (* 1 = 0.412636 loss)
I0226 12:58:30.887868  7672 solver.cpp:245]     Train net output #1: loss-Seed = 3.45855 (* 1 = 3.45855 loss)
I0226 12:58:30.887878  7672 sgd_solver.cpp:106] Iteration 10, lr = 0.0005
I0226 12:58:58.656028  7672 solver.cpp:229] Iteration 20, loss = 3.175
I0226 12:58:58.656064  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.491657 (* 1 = 0.491657 loss)
I0226 12:58:58.656075  7672 solver.cpp:245]     Train net output #1: loss-Seed = 2.82766 (* 1 = 2.82766 loss)
I0226 12:58:58.656086  7672 sgd_solver.cpp:106] Iteration 20, lr = 0.0005
I0226 12:59:26.234637  7672 solver.cpp:229] Iteration 30, loss = 2.31688
I0226 12:59:26.234688  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.426957 (* 1 = 0.426957 loss)
I0226 12:59:26.234699  7672 solver.cpp:245]     Train net output #1: loss-Seed = 2.08089 (* 1 = 2.08089 loss)
I0226 12:59:26.234709  7672 sgd_solver.cpp:106] Iteration 30, lr = 0.0005
I0226 12:59:53.924569  7672 solver.cpp:229] Iteration 40, loss = 2.11886
I0226 12:59:53.924621  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.335709 (* 1 = 0.335709 loss)
I0226 12:59:53.924633  7672 solver.cpp:245]     Train net output #1: loss-Seed = 1.74352 (* 1 = 1.74352 loss)
I0226 12:59:53.924643  7672 sgd_solver.cpp:106] Iteration 40, lr = 0.0005
I0226 13:00:21.636942  7672 solver.cpp:229] Iteration 50, loss = 2.0208
I0226 13:00:21.636996  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.285397 (* 1 = 0.285397 loss)
I0226 13:00:21.637006  7672 solver.cpp:245]     Train net output #1: loss-Seed = 1.73989 (* 1 = 1.73989 loss)
I0226 13:00:21.637017  7672 sgd_solver.cpp:106] Iteration 50, lr = 0.0005
I0226 13:00:49.416612  7672 solver.cpp:229] Iteration 60, loss = 1.9095
I0226 13:00:49.416651  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.316207 (* 1 = 0.316207 loss)
I0226 13:00:49.416661  7672 solver.cpp:245]     Train net output #1: loss-Seed = 1.75347 (* 1 = 1.75347 loss)
I0226 13:00:49.416672  7672 sgd_solver.cpp:106] Iteration 60, lr = 0.0005
I0226 13:01:17.186136  7672 solver.cpp:229] Iteration 70, loss = 1.76433
I0226 13:01:17.186187  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.330091 (* 1 = 0.330091 loss)
I0226 13:01:17.186197  7672 solver.cpp:245]     Train net output #1: loss-Seed = 1.46913 (* 1 = 1.46913 loss)
I0226 13:01:17.186208  7672 sgd_solver.cpp:106] Iteration 70, lr = 0.0005
I0226 13:01:45.060755  7672 solver.cpp:229] Iteration 80, loss = 1.5983
I0226 13:01:45.060809  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.300338 (* 1 = 0.300338 loss)
I0226 13:01:45.060820  7672 solver.cpp:245]     Train net output #1: loss-Seed = 1.23014 (* 1 = 1.23014 loss)
I0226 13:01:45.060832  7672 sgd_solver.cpp:106] Iteration 80, lr = 0.0005
I0226 13:02:13.168575  7672 solver.cpp:229] Iteration 90, loss = 1.70587
I0226 13:02:13.168612  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.329982 (* 1 = 0.329982 loss)
I0226 13:02:13.168624  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.923981 (* 1 = 0.923981 loss)
I0226 13:02:13.168634  7672 sgd_solver.cpp:106] Iteration 90, lr = 0.0005
I0226 13:02:41.232503  7672 solver.cpp:229] Iteration 100, loss = 1.7275
I0226 13:02:41.232573  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.374617 (* 1 = 0.374617 loss)
I0226 13:02:41.232584  7672 solver.cpp:245]     Train net output #1: loss-Seed = 1.50632 (* 1 = 1.50632 loss)
I0226 13:02:41.232595  7672 sgd_solver.cpp:106] Iteration 100, lr = 0.0005
I0226 13:03:09.463585  7672 solver.cpp:229] Iteration 110, loss = 1.66132
I0226 13:03:09.463639  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.389133 (* 1 = 0.389133 loss)
I0226 13:03:09.463651  7672 solver.cpp:245]     Train net output #1: loss-Seed = 1.20922 (* 1 = 1.20922 loss)
I0226 13:03:09.463660  7672 sgd_solver.cpp:106] Iteration 110, lr = 0.0005
I0226 13:03:37.641785  7672 solver.cpp:229] Iteration 120, loss = 1.58145
I0226 13:03:37.641824  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.33419 (* 1 = 0.33419 loss)
I0226 13:03:37.641836  7672 solver.cpp:245]     Train net output #1: loss-Seed = 1.16098 (* 1 = 1.16098 loss)
I0226 13:03:37.641846  7672 sgd_solver.cpp:106] Iteration 120, lr = 0.0005
I0226 13:04:05.569936  7672 solver.cpp:229] Iteration 130, loss = 1.74716
I0226 13:04:05.569977  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.334051 (* 1 = 0.334051 loss)
I0226 13:04:05.569988  7672 solver.cpp:245]     Train net output #1: loss-Seed = 1.37672 (* 1 = 1.37672 loss)
I0226 13:04:05.569998  7672 sgd_solver.cpp:106] Iteration 130, lr = 0.0005
I0226 13:04:33.656155  7672 solver.cpp:229] Iteration 140, loss = 1.57244
I0226 13:04:33.656208  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.346448 (* 1 = 0.346448 loss)
I0226 13:04:33.656219  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.984681 (* 1 = 0.984681 loss)
I0226 13:04:33.656230  7672 sgd_solver.cpp:106] Iteration 140, lr = 0.0005
I0226 13:05:01.537676  7672 solver.cpp:229] Iteration 150, loss = 1.59143
I0226 13:05:01.537730  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.318977 (* 1 = 0.318977 loss)
I0226 13:05:01.537741  7672 solver.cpp:245]     Train net output #1: loss-Seed = 1.53338 (* 1 = 1.53338 loss)
I0226 13:05:01.537752  7672 sgd_solver.cpp:106] Iteration 150, lr = 0.0005
I0226 13:05:29.679502  7672 solver.cpp:229] Iteration 160, loss = 1.66573
I0226 13:05:29.679543  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.308931 (* 1 = 0.308931 loss)
I0226 13:05:29.679554  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.84828 (* 1 = 0.84828 loss)
I0226 13:05:29.679565  7672 sgd_solver.cpp:106] Iteration 160, lr = 0.0005
I0226 13:05:57.589710  7672 solver.cpp:229] Iteration 170, loss = 1.52472
I0226 13:05:57.589751  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.270127 (* 1 = 0.270127 loss)
I0226 13:05:57.589761  7672 solver.cpp:245]     Train net output #1: loss-Seed = 1.28152 (* 1 = 1.28152 loss)
I0226 13:05:57.589771  7672 sgd_solver.cpp:106] Iteration 170, lr = 0.0005
I0226 13:06:25.832283  7672 solver.cpp:229] Iteration 180, loss = 1.55152
I0226 13:06:25.832319  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.337738 (* 1 = 0.337738 loss)
I0226 13:06:25.832330  7672 solver.cpp:245]     Train net output #1: loss-Seed = 1.1849 (* 1 = 1.1849 loss)
I0226 13:06:25.832341  7672 sgd_solver.cpp:106] Iteration 180, lr = 0.0005
I0226 13:06:53.734203  7672 solver.cpp:229] Iteration 190, loss = 1.6082
I0226 13:06:53.734256  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.309212 (* 1 = 0.309212 loss)
I0226 13:06:53.734266  7672 solver.cpp:245]     Train net output #1: loss-Seed = 1.78035 (* 1 = 1.78035 loss)
I0226 13:06:53.734277  7672 sgd_solver.cpp:106] Iteration 190, lr = 0.0005
I0226 13:07:21.546998  7672 solver.cpp:229] Iteration 200, loss = 1.4813
I0226 13:07:21.547037  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.337423 (* 1 = 0.337423 loss)
I0226 13:07:21.547049  7672 solver.cpp:245]     Train net output #1: loss-Seed = 1.14009 (* 1 = 1.14009 loss)
I0226 13:07:21.547058  7672 sgd_solver.cpp:106] Iteration 200, lr = 0.0005
I0226 13:07:49.497150  7672 solver.cpp:229] Iteration 210, loss = 1.54201
I0226 13:07:49.497189  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.251577 (* 1 = 0.251577 loss)
I0226 13:07:49.497200  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.804541 (* 1 = 0.804541 loss)
I0226 13:07:49.497211  7672 sgd_solver.cpp:106] Iteration 210, lr = 0.0005
I0226 13:08:17.573983  7672 solver.cpp:229] Iteration 220, loss = 1.48652
I0226 13:08:17.574034  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.304423 (* 1 = 0.304423 loss)
I0226 13:08:17.574045  7672 solver.cpp:245]     Train net output #1: loss-Seed = 1.23347 (* 1 = 1.23347 loss)
I0226 13:08:17.574055  7672 sgd_solver.cpp:106] Iteration 220, lr = 0.0005
I0226 13:08:45.585176  7672 solver.cpp:229] Iteration 230, loss = 1.54257
I0226 13:08:45.585218  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.287248 (* 1 = 0.287248 loss)
I0226 13:08:45.585229  7672 solver.cpp:245]     Train net output #1: loss-Seed = 1.57188 (* 1 = 1.57188 loss)
I0226 13:08:45.585240  7672 sgd_solver.cpp:106] Iteration 230, lr = 0.0005
I0226 13:09:13.500622  7672 solver.cpp:229] Iteration 240, loss = 1.42201
I0226 13:09:13.500677  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.253454 (* 1 = 0.253454 loss)
I0226 13:09:13.500689  7672 solver.cpp:245]     Train net output #1: loss-Seed = 1.17117 (* 1 = 1.17117 loss)
I0226 13:09:13.500700  7672 sgd_solver.cpp:106] Iteration 240, lr = 0.0005
I0226 13:09:41.498778  7672 solver.cpp:229] Iteration 250, loss = 1.43773
I0226 13:09:41.498819  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.291323 (* 1 = 0.291323 loss)
I0226 13:09:41.498831  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.997581 (* 1 = 0.997581 loss)
I0226 13:09:41.498841  7672 sgd_solver.cpp:106] Iteration 250, lr = 0.0005
I0226 13:10:09.560780  7672 solver.cpp:229] Iteration 260, loss = 1.42745
I0226 13:10:09.560822  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.328878 (* 1 = 0.328878 loss)
I0226 13:10:09.560832  7672 solver.cpp:245]     Train net output #1: loss-Seed = 1.03139 (* 1 = 1.03139 loss)
I0226 13:10:09.560842  7672 sgd_solver.cpp:106] Iteration 260, lr = 0.0005
I0226 13:10:37.595904  7672 solver.cpp:229] Iteration 270, loss = 1.52451
I0226 13:10:37.595957  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.280736 (* 1 = 0.280736 loss)
I0226 13:10:37.595968  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.94816 (* 1 = 0.94816 loss)
I0226 13:10:37.595979  7672 sgd_solver.cpp:106] Iteration 270, lr = 0.0005
I0226 13:11:05.598194  7672 solver.cpp:229] Iteration 280, loss = 1.3822
I0226 13:11:05.598248  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.266441 (* 1 = 0.266441 loss)
I0226 13:11:05.598259  7672 solver.cpp:245]     Train net output #1: loss-Seed = 1.20377 (* 1 = 1.20377 loss)
I0226 13:11:05.598270  7672 sgd_solver.cpp:106] Iteration 280, lr = 0.0005
I0226 13:11:33.702440  7672 solver.cpp:229] Iteration 290, loss = 1.4386
I0226 13:11:33.702476  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.28464 (* 1 = 0.28464 loss)
I0226 13:11:33.702487  7672 solver.cpp:245]     Train net output #1: loss-Seed = 1.16845 (* 1 = 1.16845 loss)
I0226 13:11:33.702497  7672 sgd_solver.cpp:106] Iteration 290, lr = 0.0005
I0226 13:12:01.780692  7672 solver.cpp:229] Iteration 300, loss = 1.38494
I0226 13:12:01.780731  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.292661 (* 1 = 0.292661 loss)
I0226 13:12:01.780743  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.903354 (* 1 = 0.903354 loss)
I0226 13:12:01.780755  7672 sgd_solver.cpp:106] Iteration 300, lr = 0.0005
I0226 13:12:29.766811  7672 solver.cpp:229] Iteration 310, loss = 1.39921
I0226 13:12:29.766865  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.330528 (* 1 = 0.330528 loss)
I0226 13:12:29.766918  7672 solver.cpp:245]     Train net output #1: loss-Seed = 1.21053 (* 1 = 1.21053 loss)
I0226 13:12:29.766944  7672 sgd_solver.cpp:106] Iteration 310, lr = 0.0005
I0226 13:12:57.833868  7672 solver.cpp:229] Iteration 320, loss = 1.34568
I0226 13:12:57.833922  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.293306 (* 1 = 0.293306 loss)
I0226 13:12:57.833933  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.959664 (* 1 = 0.959664 loss)
I0226 13:12:57.833945  7672 sgd_solver.cpp:106] Iteration 320, lr = 0.0005
I0226 13:13:25.733758  7672 solver.cpp:229] Iteration 330, loss = 1.46295
I0226 13:13:25.733811  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.294033 (* 1 = 0.294033 loss)
I0226 13:13:25.733822  7672 solver.cpp:245]     Train net output #1: loss-Seed = 1.16925 (* 1 = 1.16925 loss)
I0226 13:13:25.733832  7672 sgd_solver.cpp:106] Iteration 330, lr = 0.0005
I0226 13:13:53.688738  7672 solver.cpp:229] Iteration 340, loss = 1.54989
I0226 13:13:53.688788  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.343935 (* 1 = 0.343935 loss)
I0226 13:13:53.688799  7672 solver.cpp:245]     Train net output #1: loss-Seed = 1.34921 (* 1 = 1.34921 loss)
I0226 13:13:53.688810  7672 sgd_solver.cpp:106] Iteration 340, lr = 0.0005
I0226 13:14:21.675873  7672 solver.cpp:229] Iteration 350, loss = 1.38536
I0226 13:14:21.675911  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.326522 (* 1 = 0.326522 loss)
I0226 13:14:21.675923  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.994576 (* 1 = 0.994576 loss)
I0226 13:14:21.675935  7672 sgd_solver.cpp:106] Iteration 350, lr = 0.0005
I0226 13:14:49.817113  7672 solver.cpp:229] Iteration 360, loss = 1.46898
I0226 13:14:49.817164  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.31529 (* 1 = 0.31529 loss)
I0226 13:14:49.817176  7672 solver.cpp:245]     Train net output #1: loss-Seed = 1.03415 (* 1 = 1.03415 loss)
I0226 13:14:49.817186  7672 sgd_solver.cpp:106] Iteration 360, lr = 0.0005
I0226 13:15:17.724925  7672 solver.cpp:229] Iteration 370, loss = 1.35791
I0226 13:15:17.724963  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.33227 (* 1 = 0.33227 loss)
I0226 13:15:17.724974  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.945599 (* 1 = 0.945599 loss)
I0226 13:15:17.724984  7672 sgd_solver.cpp:106] Iteration 370, lr = 0.0005
I0226 13:15:45.746170  7672 solver.cpp:229] Iteration 380, loss = 1.43926
I0226 13:15:45.746222  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.336891 (* 1 = 0.336891 loss)
I0226 13:15:45.746232  7672 solver.cpp:245]     Train net output #1: loss-Seed = 1.21079 (* 1 = 1.21079 loss)
I0226 13:15:45.746243  7672 sgd_solver.cpp:106] Iteration 380, lr = 0.0005
I0226 13:16:13.707716  7672 solver.cpp:229] Iteration 390, loss = 1.30699
I0226 13:16:13.707753  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.279804 (* 1 = 0.279804 loss)
I0226 13:16:13.707764  7672 solver.cpp:245]     Train net output #1: loss-Seed = 1.00302 (* 1 = 1.00302 loss)
I0226 13:16:13.707775  7672 sgd_solver.cpp:106] Iteration 390, lr = 0.0005
I0226 13:16:41.756006  7672 solver.cpp:229] Iteration 400, loss = 1.38309
I0226 13:16:41.756060  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.31254 (* 1 = 0.31254 loss)
I0226 13:16:41.756072  7672 solver.cpp:245]     Train net output #1: loss-Seed = 1.26471 (* 1 = 1.26471 loss)
I0226 13:16:41.756083  7672 sgd_solver.cpp:106] Iteration 400, lr = 0.0005
I0226 13:17:09.850282  7672 solver.cpp:229] Iteration 410, loss = 1.44541
I0226 13:17:09.850337  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.336612 (* 1 = 0.336612 loss)
I0226 13:17:09.850347  7672 solver.cpp:245]     Train net output #1: loss-Seed = 1.08156 (* 1 = 1.08156 loss)
I0226 13:17:09.850358  7672 sgd_solver.cpp:106] Iteration 410, lr = 0.0005
I0226 13:17:37.811211  7672 solver.cpp:229] Iteration 420, loss = 1.46382
I0226 13:17:37.811251  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.295195 (* 1 = 0.295195 loss)
I0226 13:17:37.811264  7672 solver.cpp:245]     Train net output #1: loss-Seed = 1.00324 (* 1 = 1.00324 loss)
I0226 13:17:37.811273  7672 sgd_solver.cpp:106] Iteration 420, lr = 0.0005
I0226 13:18:06.022308  7672 solver.cpp:229] Iteration 430, loss = 1.36571
I0226 13:18:06.022364  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.290798 (* 1 = 0.290798 loss)
I0226 13:18:06.022377  7672 solver.cpp:245]     Train net output #1: loss-Seed = 1.14779 (* 1 = 1.14779 loss)
I0226 13:18:06.022387  7672 sgd_solver.cpp:106] Iteration 430, lr = 0.0005
I0226 13:18:34.085181  7672 solver.cpp:229] Iteration 440, loss = 1.40767
I0226 13:18:34.085218  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.284541 (* 1 = 0.284541 loss)
I0226 13:18:34.085230  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.871064 (* 1 = 0.871064 loss)
I0226 13:18:34.085240  7672 sgd_solver.cpp:106] Iteration 440, lr = 0.0005
I0226 13:19:02.072994  7672 solver.cpp:229] Iteration 450, loss = 1.46414
I0226 13:19:02.073048  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.278086 (* 1 = 0.278086 loss)
I0226 13:19:02.073060  7672 solver.cpp:245]     Train net output #1: loss-Seed = 1.16542 (* 1 = 1.16542 loss)
I0226 13:19:02.073071  7672 sgd_solver.cpp:106] Iteration 450, lr = 0.0005
I0226 13:19:30.067847  7672 solver.cpp:229] Iteration 460, loss = 1.29402
I0226 13:19:30.067884  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.302012 (* 1 = 0.302012 loss)
I0226 13:19:30.067895  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.904683 (* 1 = 0.904683 loss)
I0226 13:19:30.067906  7672 sgd_solver.cpp:106] Iteration 460, lr = 0.0005
I0226 13:19:58.105587  7672 solver.cpp:229] Iteration 470, loss = 1.28486
I0226 13:19:58.105660  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.286356 (* 1 = 0.286356 loss)
I0226 13:19:58.105672  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.785172 (* 1 = 0.785172 loss)
I0226 13:19:58.105682  7672 sgd_solver.cpp:106] Iteration 470, lr = 0.0005
I0226 13:20:26.255681  7672 solver.cpp:229] Iteration 480, loss = 1.37612
I0226 13:20:26.255717  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.284387 (* 1 = 0.284387 loss)
I0226 13:20:26.255728  7672 solver.cpp:245]     Train net output #1: loss-Seed = 1.10109 (* 1 = 1.10109 loss)
I0226 13:20:26.255738  7672 sgd_solver.cpp:106] Iteration 480, lr = 0.0005
I0226 13:20:54.380000  7672 solver.cpp:229] Iteration 490, loss = 1.40073
I0226 13:20:54.380055  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.298151 (* 1 = 0.298151 loss)
I0226 13:20:54.380067  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.983824 (* 1 = 0.983824 loss)
I0226 13:20:54.380079  7672 sgd_solver.cpp:106] Iteration 490, lr = 0.0005
I0226 13:21:22.383358  7672 solver.cpp:229] Iteration 500, loss = 1.29696
I0226 13:21:22.383407  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.271364 (* 1 = 0.271364 loss)
I0226 13:21:22.383419  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.886595 (* 1 = 0.886595 loss)
I0226 13:21:22.383430  7672 sgd_solver.cpp:106] Iteration 500, lr = 0.0005
I0226 13:21:50.279026  7672 solver.cpp:229] Iteration 510, loss = 1.34395
I0226 13:21:50.279063  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.26918 (* 1 = 0.26918 loss)
I0226 13:21:50.279074  7672 solver.cpp:245]     Train net output #1: loss-Seed = 1.12859 (* 1 = 1.12859 loss)
I0226 13:21:50.279085  7672 sgd_solver.cpp:106] Iteration 510, lr = 0.0005
I0226 13:22:18.231869  7672 solver.cpp:229] Iteration 520, loss = 1.40893
I0226 13:22:18.231909  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.321824 (* 1 = 0.321824 loss)
I0226 13:22:18.231920  7672 solver.cpp:245]     Train net output #1: loss-Seed = 1.11537 (* 1 = 1.11537 loss)
I0226 13:22:18.231930  7672 sgd_solver.cpp:106] Iteration 520, lr = 0.0005
I0226 13:22:46.198261  7672 solver.cpp:229] Iteration 530, loss = 1.29552
I0226 13:22:46.198313  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.30029 (* 1 = 0.30029 loss)
I0226 13:22:46.198324  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.900158 (* 1 = 0.900158 loss)
I0226 13:22:46.198334  7672 sgd_solver.cpp:106] Iteration 530, lr = 0.0005
I0226 13:23:13.946768  7672 solver.cpp:229] Iteration 540, loss = 1.23211
I0226 13:23:13.946820  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.306824 (* 1 = 0.306824 loss)
I0226 13:23:13.946830  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.945483 (* 1 = 0.945483 loss)
I0226 13:23:13.946841  7672 sgd_solver.cpp:106] Iteration 540, lr = 0.0005
I0226 13:23:42.079288  7672 solver.cpp:229] Iteration 550, loss = 1.23147
I0226 13:23:42.079324  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.281071 (* 1 = 0.281071 loss)
I0226 13:23:42.079335  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.806704 (* 1 = 0.806704 loss)
I0226 13:23:42.079345  7672 sgd_solver.cpp:106] Iteration 550, lr = 0.0005
I0226 13:24:09.948463  7672 solver.cpp:229] Iteration 560, loss = 1.21843
I0226 13:24:09.948500  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.298002 (* 1 = 0.298002 loss)
I0226 13:24:09.948511  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.957836 (* 1 = 0.957836 loss)
I0226 13:24:09.948523  7672 sgd_solver.cpp:106] Iteration 560, lr = 0.0005
I0226 13:24:38.612262  7672 solver.cpp:229] Iteration 570, loss = 1.15213
I0226 13:24:38.612301  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.300333 (* 1 = 0.300333 loss)
I0226 13:24:38.612313  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.930424 (* 1 = 0.930424 loss)
I0226 13:24:38.612324  7672 sgd_solver.cpp:106] Iteration 570, lr = 0.0005
I0226 13:25:06.560570  7672 solver.cpp:229] Iteration 580, loss = 1.14572
I0226 13:25:06.560623  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.243906 (* 1 = 0.243906 loss)
I0226 13:25:06.560634  7672 solver.cpp:245]     Train net output #1: loss-Seed = 1.01023 (* 1 = 1.01023 loss)
I0226 13:25:06.560644  7672 sgd_solver.cpp:106] Iteration 580, lr = 0.0005
I0226 13:25:34.729619  7672 solver.cpp:229] Iteration 590, loss = 1.2446
I0226 13:25:34.729660  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.274542 (* 1 = 0.274542 loss)
I0226 13:25:34.729671  7672 solver.cpp:245]     Train net output #1: loss-Seed = 1.02934 (* 1 = 1.02934 loss)
I0226 13:25:34.729681  7672 sgd_solver.cpp:106] Iteration 590, lr = 0.0005
I0226 13:26:02.882144  7672 solver.cpp:229] Iteration 600, loss = 1.27193
I0226 13:26:02.882200  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.25248 (* 1 = 0.25248 loss)
I0226 13:26:02.882210  7672 solver.cpp:245]     Train net output #1: loss-Seed = 1.15662 (* 1 = 1.15662 loss)
I0226 13:26:02.882220  7672 sgd_solver.cpp:106] Iteration 600, lr = 0.0005
I0226 13:26:31.016793  7672 solver.cpp:229] Iteration 610, loss = 1.20428
I0226 13:26:31.016847  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.283928 (* 1 = 0.283928 loss)
I0226 13:26:31.016858  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.962482 (* 1 = 0.962482 loss)
I0226 13:26:31.016870  7672 sgd_solver.cpp:106] Iteration 610, lr = 0.0005
I0226 13:26:59.198762  7672 solver.cpp:229] Iteration 620, loss = 1.25021
I0226 13:26:59.198799  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.323297 (* 1 = 0.323297 loss)
I0226 13:26:59.198810  7672 solver.cpp:245]     Train net output #1: loss-Seed = 1.32163 (* 1 = 1.32163 loss)
I0226 13:26:59.198822  7672 sgd_solver.cpp:106] Iteration 620, lr = 0.0005
I0226 13:27:27.067049  7672 solver.cpp:229] Iteration 630, loss = 1.15965
I0226 13:27:27.067087  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.254916 (* 1 = 0.254916 loss)
I0226 13:27:27.067101  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.915049 (* 1 = 0.915049 loss)
I0226 13:27:27.067112  7672 sgd_solver.cpp:106] Iteration 630, lr = 0.0005
I0226 13:27:54.969679  7672 solver.cpp:229] Iteration 640, loss = 1.20854
I0226 13:27:54.969741  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.260615 (* 1 = 0.260615 loss)
I0226 13:27:54.969758  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.804493 (* 1 = 0.804493 loss)
I0226 13:27:54.969774  7672 sgd_solver.cpp:106] Iteration 640, lr = 0.0005
I0226 13:28:23.107373  7672 solver.cpp:229] Iteration 650, loss = 1.24515
I0226 13:28:23.107414  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.295955 (* 1 = 0.295955 loss)
I0226 13:28:23.107424  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.88698 (* 1 = 0.88698 loss)
I0226 13:28:23.107435  7672 sgd_solver.cpp:106] Iteration 650, lr = 0.0005
I0226 13:28:51.200181  7672 solver.cpp:229] Iteration 660, loss = 1.21818
I0226 13:28:51.200219  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.308379 (* 1 = 0.308379 loss)
I0226 13:28:51.200230  7672 solver.cpp:245]     Train net output #1: loss-Seed = 1.07595 (* 1 = 1.07595 loss)
I0226 13:28:51.200242  7672 sgd_solver.cpp:106] Iteration 660, lr = 0.0005
I0226 13:29:19.242421  7672 solver.cpp:229] Iteration 670, loss = 1.2358
I0226 13:29:19.242460  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.279183 (* 1 = 0.279183 loss)
I0226 13:29:19.242471  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.668346 (* 1 = 0.668346 loss)
I0226 13:29:19.242481  7672 sgd_solver.cpp:106] Iteration 670, lr = 0.0005
I0226 13:29:47.279289  7672 solver.cpp:229] Iteration 680, loss = 1.12135
I0226 13:29:47.279328  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.249496 (* 1 = 0.249496 loss)
I0226 13:29:47.279340  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.664051 (* 1 = 0.664051 loss)
I0226 13:29:47.279350  7672 sgd_solver.cpp:106] Iteration 680, lr = 0.0005
I0226 13:30:15.315194  7672 solver.cpp:229] Iteration 690, loss = 1.25746
I0226 13:30:15.315232  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.283634 (* 1 = 0.283634 loss)
I0226 13:30:15.315243  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.966076 (* 1 = 0.966076 loss)
I0226 13:30:15.315254  7672 sgd_solver.cpp:106] Iteration 690, lr = 0.0005
I0226 13:30:43.434231  7672 solver.cpp:229] Iteration 700, loss = 1.24739
I0226 13:30:43.434268  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.280598 (* 1 = 0.280598 loss)
I0226 13:30:43.434279  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.888397 (* 1 = 0.888397 loss)
I0226 13:30:43.434291  7672 sgd_solver.cpp:106] Iteration 700, lr = 0.0005
I0226 13:31:11.463174  7672 solver.cpp:229] Iteration 710, loss = 1.16775
I0226 13:31:11.463213  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.292753 (* 1 = 0.292753 loss)
I0226 13:31:11.463225  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.825805 (* 1 = 0.825805 loss)
I0226 13:31:11.463235  7672 sgd_solver.cpp:106] Iteration 710, lr = 0.0005
I0226 13:31:39.442809  7672 solver.cpp:229] Iteration 720, loss = 1.23852
I0226 13:31:39.442847  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.303267 (* 1 = 0.303267 loss)
I0226 13:31:39.442859  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.723005 (* 1 = 0.723005 loss)
I0226 13:31:39.442870  7672 sgd_solver.cpp:106] Iteration 720, lr = 0.0005
I0226 13:32:07.405720  7672 solver.cpp:229] Iteration 730, loss = 1.0875
I0226 13:32:07.405771  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.25438 (* 1 = 0.25438 loss)
I0226 13:32:07.405783  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.822826 (* 1 = 0.822826 loss)
I0226 13:32:07.405793  7672 sgd_solver.cpp:106] Iteration 730, lr = 0.0005
I0226 13:32:35.347877  7672 solver.cpp:229] Iteration 740, loss = 1.15079
I0226 13:32:35.347918  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.346156 (* 1 = 0.346156 loss)
I0226 13:32:35.347930  7672 solver.cpp:245]     Train net output #1: loss-Seed = 1.07982 (* 1 = 1.07982 loss)
I0226 13:32:35.347940  7672 sgd_solver.cpp:106] Iteration 740, lr = 0.0005
I0226 13:33:03.564900  7672 solver.cpp:229] Iteration 750, loss = 1.04264
I0226 13:33:03.564939  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.313197 (* 1 = 0.313197 loss)
I0226 13:33:03.564949  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.656137 (* 1 = 0.656137 loss)
I0226 13:33:03.564960  7672 sgd_solver.cpp:106] Iteration 750, lr = 0.0005
I0226 13:33:31.627794  7672 solver.cpp:229] Iteration 760, loss = 1.24334
I0226 13:33:31.627832  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.321109 (* 1 = 0.321109 loss)
I0226 13:33:31.627845  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.86559 (* 1 = 0.86559 loss)
I0226 13:33:31.627854  7672 sgd_solver.cpp:106] Iteration 760, lr = 0.0005
I0226 13:33:59.703685  7672 solver.cpp:229] Iteration 770, loss = 1.1693
I0226 13:33:59.703739  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.253494 (* 1 = 0.253494 loss)
I0226 13:33:59.703752  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.752742 (* 1 = 0.752742 loss)
I0226 13:33:59.703761  7672 sgd_solver.cpp:106] Iteration 770, lr = 0.0005
I0226 13:34:27.738441  7672 solver.cpp:229] Iteration 780, loss = 1.18901
I0226 13:34:27.738479  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.266991 (* 1 = 0.266991 loss)
I0226 13:34:27.738492  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.753341 (* 1 = 0.753341 loss)
I0226 13:34:27.738502  7672 sgd_solver.cpp:106] Iteration 780, lr = 0.0005
I0226 13:34:55.877755  7672 solver.cpp:229] Iteration 790, loss = 1.2191
I0226 13:34:55.877794  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.315913 (* 1 = 0.315913 loss)
I0226 13:34:55.877804  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.91576 (* 1 = 0.91576 loss)
I0226 13:34:55.877815  7672 sgd_solver.cpp:106] Iteration 790, lr = 0.0005
I0226 13:35:23.946099  7672 solver.cpp:229] Iteration 800, loss = 1.22007
I0226 13:35:23.946168  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.27771 (* 1 = 0.27771 loss)
I0226 13:35:23.946188  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.827131 (* 1 = 0.827131 loss)
I0226 13:35:23.946207  7672 sgd_solver.cpp:106] Iteration 800, lr = 0.0005
I0226 13:35:51.972766  7672 solver.cpp:229] Iteration 810, loss = 1.23514
I0226 13:35:51.972805  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.295737 (* 1 = 0.295737 loss)
I0226 13:35:51.972815  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.972473 (* 1 = 0.972473 loss)
I0226 13:35:51.972826  7672 sgd_solver.cpp:106] Iteration 810, lr = 0.0005
I0226 13:36:20.258070  7672 solver.cpp:229] Iteration 820, loss = 1.12834
I0226 13:36:20.258124  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.298862 (* 1 = 0.298862 loss)
I0226 13:36:20.258136  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.869049 (* 1 = 0.869049 loss)
I0226 13:36:20.258146  7672 sgd_solver.cpp:106] Iteration 820, lr = 0.0005
I0226 13:36:48.261443  7672 solver.cpp:229] Iteration 830, loss = 1.12127
I0226 13:36:48.261497  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.230791 (* 1 = 0.230791 loss)
I0226 13:36:48.261508  7672 solver.cpp:245]     Train net output #1: loss-Seed = 1.30407 (* 1 = 1.30407 loss)
I0226 13:36:48.261518  7672 sgd_solver.cpp:106] Iteration 830, lr = 0.0005
I0226 13:37:16.292593  7672 solver.cpp:229] Iteration 840, loss = 1.22139
I0226 13:37:16.292634  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.294602 (* 1 = 0.294602 loss)
I0226 13:37:16.292645  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.773986 (* 1 = 0.773986 loss)
I0226 13:37:16.292655  7672 sgd_solver.cpp:106] Iteration 840, lr = 0.0005
I0226 13:37:44.417505  7672 solver.cpp:229] Iteration 850, loss = 1.11048
I0226 13:37:44.417554  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.282299 (* 1 = 0.282299 loss)
I0226 13:37:44.417564  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.697804 (* 1 = 0.697804 loss)
I0226 13:37:44.417574  7672 sgd_solver.cpp:106] Iteration 850, lr = 0.0005
I0226 13:38:12.544045  7672 solver.cpp:229] Iteration 860, loss = 1.20888
I0226 13:38:12.544100  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.27406 (* 1 = 0.27406 loss)
I0226 13:38:12.544111  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.701828 (* 1 = 0.701828 loss)
I0226 13:38:12.544121  7672 sgd_solver.cpp:106] Iteration 860, lr = 0.0005
I0226 13:38:40.657773  7672 solver.cpp:229] Iteration 870, loss = 1.30035
I0226 13:38:40.657812  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.293911 (* 1 = 0.293911 loss)
I0226 13:38:40.657824  7672 solver.cpp:245]     Train net output #1: loss-Seed = 1.273 (* 1 = 1.273 loss)
I0226 13:38:40.657835  7672 sgd_solver.cpp:106] Iteration 870, lr = 0.0005
I0226 13:39:09.005957  7672 solver.cpp:229] Iteration 880, loss = 1.20045
I0226 13:39:09.005993  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.264131 (* 1 = 0.264131 loss)
I0226 13:39:09.006006  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.940284 (* 1 = 0.940284 loss)
I0226 13:39:09.006016  7672 sgd_solver.cpp:106] Iteration 880, lr = 0.0005
I0226 13:39:36.830188  7672 solver.cpp:229] Iteration 890, loss = 1.15308
I0226 13:39:36.830240  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.273052 (* 1 = 0.273052 loss)
I0226 13:39:36.830251  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.68326 (* 1 = 0.68326 loss)
I0226 13:39:36.830261  7672 sgd_solver.cpp:106] Iteration 890, lr = 0.0005
I0226 13:40:04.808564  7672 solver.cpp:229] Iteration 900, loss = 1.11915
I0226 13:40:04.808603  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.250992 (* 1 = 0.250992 loss)
I0226 13:40:04.808614  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.703522 (* 1 = 0.703522 loss)
I0226 13:40:04.808625  7672 sgd_solver.cpp:106] Iteration 900, lr = 0.0005
I0226 13:40:32.721846  7672 solver.cpp:229] Iteration 910, loss = 1.19493
I0226 13:40:32.721884  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.304386 (* 1 = 0.304386 loss)
I0226 13:40:32.721895  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.88013 (* 1 = 0.88013 loss)
I0226 13:40:32.721905  7672 sgd_solver.cpp:106] Iteration 910, lr = 0.0005
I0226 13:41:00.714159  7672 solver.cpp:229] Iteration 920, loss = 1.16401
I0226 13:41:00.714196  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.287454 (* 1 = 0.287454 loss)
I0226 13:41:00.714208  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.821926 (* 1 = 0.821926 loss)
I0226 13:41:00.714220  7672 sgd_solver.cpp:106] Iteration 920, lr = 0.0005
I0226 13:41:28.840927  7672 solver.cpp:229] Iteration 930, loss = 1.17072
I0226 13:41:28.840966  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.316128 (* 1 = 0.316128 loss)
I0226 13:41:28.840978  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.849253 (* 1 = 0.849253 loss)
I0226 13:41:28.840989  7672 sgd_solver.cpp:106] Iteration 930, lr = 0.0005
I0226 13:41:56.787680  7672 solver.cpp:229] Iteration 940, loss = 1.20412
I0226 13:41:56.787719  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.261591 (* 1 = 0.261591 loss)
I0226 13:41:56.787730  7672 solver.cpp:245]     Train net output #1: loss-Seed = 1.20714 (* 1 = 1.20714 loss)
I0226 13:41:56.787740  7672 sgd_solver.cpp:106] Iteration 940, lr = 0.0005
I0226 13:42:24.833307  7672 solver.cpp:229] Iteration 950, loss = 1.13744
I0226 13:42:24.833359  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.239609 (* 1 = 0.239609 loss)
I0226 13:42:24.833380  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.885418 (* 1 = 0.885418 loss)
I0226 13:42:24.833397  7672 sgd_solver.cpp:106] Iteration 950, lr = 0.0005
I0226 13:42:52.968547  7672 solver.cpp:229] Iteration 960, loss = 1.13541
I0226 13:42:52.968585  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.264017 (* 1 = 0.264017 loss)
I0226 13:42:52.968596  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.973418 (* 1 = 0.973418 loss)
I0226 13:42:52.968606  7672 sgd_solver.cpp:106] Iteration 960, lr = 0.0005
I0226 13:43:20.923426  7672 solver.cpp:229] Iteration 970, loss = 1.26046
I0226 13:43:20.923475  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.306619 (* 1 = 0.306619 loss)
I0226 13:43:20.923486  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.942351 (* 1 = 0.942351 loss)
I0226 13:43:20.923497  7672 sgd_solver.cpp:106] Iteration 970, lr = 0.0005
I0226 13:43:48.958886  7672 solver.cpp:229] Iteration 980, loss = 1.28088
I0226 13:43:48.958926  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.28553 (* 1 = 0.28553 loss)
I0226 13:43:48.958940  7672 solver.cpp:245]     Train net output #1: loss-Seed = 1.14329 (* 1 = 1.14329 loss)
I0226 13:43:48.958950  7672 sgd_solver.cpp:106] Iteration 980, lr = 0.0005
I0226 13:44:16.886096  7672 solver.cpp:229] Iteration 990, loss = 1.21972
I0226 13:44:16.886152  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.273335 (* 1 = 0.273335 loss)
I0226 13:44:16.886162  7672 solver.cpp:245]     Train net output #1: loss-Seed = 1.18019 (* 1 = 1.18019 loss)
I0226 13:44:16.886173  7672 sgd_solver.cpp:106] Iteration 990, lr = 0.0005
I0226 13:44:44.727898  7672 solver.cpp:229] Iteration 1000, loss = 1.10811
I0226 13:44:44.727952  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.32813 (* 1 = 0.32813 loss)
I0226 13:44:44.727964  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.697205 (* 1 = 0.697205 loss)
I0226 13:44:44.727974  7672 sgd_solver.cpp:106] Iteration 1000, lr = 0.000165
I0226 13:45:12.756861  7672 solver.cpp:229] Iteration 1010, loss = 1.18769
I0226 13:45:12.756898  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.279676 (* 1 = 0.279676 loss)
I0226 13:45:12.756909  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.726216 (* 1 = 0.726216 loss)
I0226 13:45:12.756919  7672 sgd_solver.cpp:106] Iteration 1010, lr = 0.000165
I0226 13:45:40.852732  7672 solver.cpp:229] Iteration 1020, loss = 1.12339
I0226 13:45:40.852784  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.239666 (* 1 = 0.239666 loss)
I0226 13:45:40.852797  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.889876 (* 1 = 0.889876 loss)
I0226 13:45:40.852807  7672 sgd_solver.cpp:106] Iteration 1020, lr = 0.000165
I0226 13:46:08.871430  7672 solver.cpp:229] Iteration 1030, loss = 1.05746
I0226 13:46:08.871466  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.315939 (* 1 = 0.315939 loss)
I0226 13:46:08.871477  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.847241 (* 1 = 0.847241 loss)
I0226 13:46:08.871487  7672 sgd_solver.cpp:106] Iteration 1030, lr = 0.000165
I0226 13:46:36.817802  7672 solver.cpp:229] Iteration 1040, loss = 1.08429
I0226 13:46:36.817839  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.260892 (* 1 = 0.260892 loss)
I0226 13:46:36.817850  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.945769 (* 1 = 0.945769 loss)
I0226 13:46:36.817860  7672 sgd_solver.cpp:106] Iteration 1040, lr = 0.000165
I0226 13:47:04.921463  7672 solver.cpp:229] Iteration 1050, loss = 1.13595
I0226 13:47:04.921501  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.256255 (* 1 = 0.256255 loss)
I0226 13:47:04.921514  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.981061 (* 1 = 0.981061 loss)
I0226 13:47:04.921524  7672 sgd_solver.cpp:106] Iteration 1050, lr = 0.000165
I0226 13:47:33.172206  7672 solver.cpp:229] Iteration 1060, loss = 1.09414
I0226 13:47:33.172246  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.275188 (* 1 = 0.275188 loss)
I0226 13:47:33.172258  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.806042 (* 1 = 0.806042 loss)
I0226 13:47:33.172269  7672 sgd_solver.cpp:106] Iteration 1060, lr = 0.000165
I0226 13:48:01.172219  7672 solver.cpp:229] Iteration 1070, loss = 1.02089
I0226 13:48:01.172257  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.257161 (* 1 = 0.257161 loss)
I0226 13:48:01.172268  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.822752 (* 1 = 0.822752 loss)
I0226 13:48:01.172278  7672 sgd_solver.cpp:106] Iteration 1070, lr = 0.000165
I0226 13:48:29.030268  7672 solver.cpp:229] Iteration 1080, loss = 1.05558
I0226 13:48:29.030308  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.283631 (* 1 = 0.283631 loss)
I0226 13:48:29.030318  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.820871 (* 1 = 0.820871 loss)
I0226 13:48:29.030329  7672 sgd_solver.cpp:106] Iteration 1080, lr = 0.000165
I0226 13:48:56.882841  7672 solver.cpp:229] Iteration 1090, loss = 1.06034
I0226 13:48:56.882917  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.26703 (* 1 = 0.26703 loss)
I0226 13:48:56.882928  7672 solver.cpp:245]     Train net output #1: loss-Seed = 1.15205 (* 1 = 1.15205 loss)
I0226 13:48:56.882938  7672 sgd_solver.cpp:106] Iteration 1090, lr = 0.000165
I0226 13:49:24.999984  7672 solver.cpp:229] Iteration 1100, loss = 1.03977
I0226 13:49:25.000037  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.251793 (* 1 = 0.251793 loss)
I0226 13:49:25.000049  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.593183 (* 1 = 0.593183 loss)
I0226 13:49:25.000059  7672 sgd_solver.cpp:106] Iteration 1100, lr = 0.000165
I0226 13:49:52.970686  7672 solver.cpp:229] Iteration 1110, loss = 0.979184
I0226 13:49:52.970726  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.231899 (* 1 = 0.231899 loss)
I0226 13:49:52.970737  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.552977 (* 1 = 0.552977 loss)
I0226 13:49:52.970747  7672 sgd_solver.cpp:106] Iteration 1110, lr = 0.000165
I0226 13:50:20.708919  7672 solver.cpp:229] Iteration 1120, loss = 0.964813
I0226 13:50:20.708956  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.235055 (* 1 = 0.235055 loss)
I0226 13:50:20.708968  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.826877 (* 1 = 0.826877 loss)
I0226 13:50:20.708978  7672 sgd_solver.cpp:106] Iteration 1120, lr = 0.000165
I0226 13:50:48.667508  7672 solver.cpp:229] Iteration 1130, loss = 0.987658
I0226 13:50:48.667562  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.269362 (* 1 = 0.269362 loss)
I0226 13:50:48.667574  7672 solver.cpp:245]     Train net output #1: loss-Seed = 1.01249 (* 1 = 1.01249 loss)
I0226 13:50:48.667584  7672 sgd_solver.cpp:106] Iteration 1130, lr = 0.000165
I0226 13:51:16.511298  7672 solver.cpp:229] Iteration 1140, loss = 1.09731
I0226 13:51:16.511351  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.248567 (* 1 = 0.248567 loss)
I0226 13:51:16.511363  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.763349 (* 1 = 0.763349 loss)
I0226 13:51:16.511373  7672 sgd_solver.cpp:106] Iteration 1140, lr = 0.000165
I0226 13:51:44.393352  7672 solver.cpp:229] Iteration 1150, loss = 1.05109
I0226 13:51:44.393401  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.29199 (* 1 = 0.29199 loss)
I0226 13:51:44.393412  7672 solver.cpp:245]     Train net output #1: loss-Seed = 1.02263 (* 1 = 1.02263 loss)
I0226 13:51:44.393422  7672 sgd_solver.cpp:106] Iteration 1150, lr = 0.000165
I0226 13:52:12.081378  7672 solver.cpp:229] Iteration 1160, loss = 1.04241
I0226 13:52:12.081418  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.305613 (* 1 = 0.305613 loss)
I0226 13:52:12.081429  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.727619 (* 1 = 0.727619 loss)
I0226 13:52:12.081439  7672 sgd_solver.cpp:106] Iteration 1160, lr = 0.000165
I0226 13:52:39.932138  7672 solver.cpp:229] Iteration 1170, loss = 0.979643
I0226 13:52:39.932191  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.257091 (* 1 = 0.257091 loss)
I0226 13:52:39.932202  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.737171 (* 1 = 0.737171 loss)
I0226 13:52:39.932212  7672 sgd_solver.cpp:106] Iteration 1170, lr = 0.000165
I0226 13:53:07.834523  7672 solver.cpp:229] Iteration 1180, loss = 0.983437
I0226 13:53:07.834561  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.277478 (* 1 = 0.277478 loss)
I0226 13:53:07.834573  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.914333 (* 1 = 0.914333 loss)
I0226 13:53:07.834583  7672 sgd_solver.cpp:106] Iteration 1180, lr = 0.000165
I0226 13:53:35.831158  7672 solver.cpp:229] Iteration 1190, loss = 0.961023
I0226 13:53:35.831195  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.26511 (* 1 = 0.26511 loss)
I0226 13:53:35.831207  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.614681 (* 1 = 0.614681 loss)
I0226 13:53:35.831218  7672 sgd_solver.cpp:106] Iteration 1190, lr = 0.000165
I0226 13:54:03.912079  7672 solver.cpp:229] Iteration 1200, loss = 1.10896
I0226 13:54:03.912132  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.298003 (* 1 = 0.298003 loss)
I0226 13:54:03.912144  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.935355 (* 1 = 0.935355 loss)
I0226 13:54:03.912155  7672 sgd_solver.cpp:106] Iteration 1200, lr = 0.000165
I0226 13:54:31.989935  7672 solver.cpp:229] Iteration 1210, loss = 0.993931
I0226 13:54:31.989987  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.246296 (* 1 = 0.246296 loss)
I0226 13:54:31.990000  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.741796 (* 1 = 0.741796 loss)
I0226 13:54:31.990010  7672 sgd_solver.cpp:106] Iteration 1210, lr = 0.000165
I0226 13:55:00.216848  7672 solver.cpp:229] Iteration 1220, loss = 1.00326
I0226 13:55:00.216899  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.259198 (* 1 = 0.259198 loss)
I0226 13:55:00.216910  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.79907 (* 1 = 0.79907 loss)
I0226 13:55:00.216922  7672 sgd_solver.cpp:106] Iteration 1220, lr = 0.000165
I0226 13:55:28.446755  7672 solver.cpp:229] Iteration 1230, loss = 0.989422
I0226 13:55:28.446791  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.291912 (* 1 = 0.291912 loss)
I0226 13:55:28.446802  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.591733 (* 1 = 0.591733 loss)
I0226 13:55:28.446812  7672 sgd_solver.cpp:106] Iteration 1230, lr = 0.000165
I0226 13:55:56.342222  7672 solver.cpp:229] Iteration 1240, loss = 0.997664
I0226 13:55:56.342272  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.238614 (* 1 = 0.238614 loss)
I0226 13:55:56.342284  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.57585 (* 1 = 0.57585 loss)
I0226 13:55:56.342294  7672 sgd_solver.cpp:106] Iteration 1240, lr = 0.000165
I0226 13:56:24.416204  7672 solver.cpp:229] Iteration 1250, loss = 1.0149
I0226 13:56:24.416241  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.240788 (* 1 = 0.240788 loss)
I0226 13:56:24.416254  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.558944 (* 1 = 0.558944 loss)
I0226 13:56:24.416263  7672 sgd_solver.cpp:106] Iteration 1250, lr = 0.000165
I0226 13:56:52.516944  7672 solver.cpp:229] Iteration 1260, loss = 0.985344
I0226 13:56:52.516981  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.302796 (* 1 = 0.302796 loss)
I0226 13:56:52.516993  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.746645 (* 1 = 0.746645 loss)
I0226 13:56:52.517004  7672 sgd_solver.cpp:106] Iteration 1260, lr = 0.000165
I0226 13:57:20.455199  7672 solver.cpp:229] Iteration 1270, loss = 0.979969
I0226 13:57:20.455235  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.277413 (* 1 = 0.277413 loss)
I0226 13:57:20.455246  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.772665 (* 1 = 0.772665 loss)
I0226 13:57:20.455256  7672 sgd_solver.cpp:106] Iteration 1270, lr = 0.000165
I0226 13:57:48.378015  7672 solver.cpp:229] Iteration 1280, loss = 1.00466
I0226 13:57:48.378051  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.271298 (* 1 = 0.271298 loss)
I0226 13:57:48.378063  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.960421 (* 1 = 0.960421 loss)
I0226 13:57:48.378073  7672 sgd_solver.cpp:106] Iteration 1280, lr = 0.000165
I0226 13:58:16.157889  7672 solver.cpp:229] Iteration 1290, loss = 1.02195
I0226 13:58:16.157941  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.283231 (* 1 = 0.283231 loss)
I0226 13:58:16.157953  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.749528 (* 1 = 0.749528 loss)
I0226 13:58:16.157963  7672 sgd_solver.cpp:106] Iteration 1290, lr = 0.000165
I0226 13:58:43.970566  7672 solver.cpp:229] Iteration 1300, loss = 0.938505
I0226 13:58:43.970605  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.278027 (* 1 = 0.278027 loss)
I0226 13:58:43.970616  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.59935 (* 1 = 0.59935 loss)
I0226 13:58:43.970626  7672 sgd_solver.cpp:106] Iteration 1300, lr = 0.000165
I0226 13:59:11.913492  7672 solver.cpp:229] Iteration 1310, loss = 1.01788
I0226 13:59:11.913527  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.252272 (* 1 = 0.252272 loss)
I0226 13:59:11.913537  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.949033 (* 1 = 0.949033 loss)
I0226 13:59:11.913547  7672 sgd_solver.cpp:106] Iteration 1310, lr = 0.000165
I0226 13:59:39.474836  7672 solver.cpp:229] Iteration 1320, loss = 1.02381
I0226 13:59:39.474902  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.262524 (* 1 = 0.262524 loss)
I0226 13:59:39.474915  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.583167 (* 1 = 0.583167 loss)
I0226 13:59:39.474923  7672 sgd_solver.cpp:106] Iteration 1320, lr = 0.000165
I0226 14:00:07.743173  7672 solver.cpp:229] Iteration 1330, loss = 1.01319
I0226 14:00:07.743211  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.266419 (* 1 = 0.266419 loss)
I0226 14:00:07.743222  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.823357 (* 1 = 0.823357 loss)
I0226 14:00:07.743245  7672 sgd_solver.cpp:106] Iteration 1330, lr = 0.000165
I0226 14:00:35.929486  7672 solver.cpp:229] Iteration 1340, loss = 1.07688
I0226 14:00:35.929538  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.276177 (* 1 = 0.276177 loss)
I0226 14:00:35.929548  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.818886 (* 1 = 0.818886 loss)
I0226 14:00:35.929558  7672 sgd_solver.cpp:106] Iteration 1340, lr = 0.000165
I0226 14:01:04.020148  7672 solver.cpp:229] Iteration 1350, loss = 1.02999
I0226 14:01:04.020184  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.29601 (* 1 = 0.29601 loss)
I0226 14:01:04.020196  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.869527 (* 1 = 0.869527 loss)
I0226 14:01:04.020206  7672 sgd_solver.cpp:106] Iteration 1350, lr = 0.000165
I0226 14:01:31.898746  7672 solver.cpp:229] Iteration 1360, loss = 1.08792
I0226 14:01:31.898797  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.26779 (* 1 = 0.26779 loss)
I0226 14:01:31.898808  7672 solver.cpp:245]     Train net output #1: loss-Seed = 1.02649 (* 1 = 1.02649 loss)
I0226 14:01:31.898818  7672 sgd_solver.cpp:106] Iteration 1360, lr = 0.000165
I0226 14:01:59.865819  7672 solver.cpp:229] Iteration 1370, loss = 1.00509
I0226 14:01:59.865855  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.288347 (* 1 = 0.288347 loss)
I0226 14:01:59.865866  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.670597 (* 1 = 0.670597 loss)
I0226 14:01:59.865876  7672 sgd_solver.cpp:106] Iteration 1370, lr = 0.000165
I0226 14:02:27.916319  7672 solver.cpp:229] Iteration 1380, loss = 1.02487
I0226 14:02:27.916357  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.250749 (* 1 = 0.250749 loss)
I0226 14:02:27.916368  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.609889 (* 1 = 0.609889 loss)
I0226 14:02:27.916378  7672 sgd_solver.cpp:106] Iteration 1380, lr = 0.000165
I0226 14:02:55.840476  7672 solver.cpp:229] Iteration 1390, loss = 0.999671
I0226 14:02:55.840513  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.227582 (* 1 = 0.227582 loss)
I0226 14:02:55.840525  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.615825 (* 1 = 0.615825 loss)
I0226 14:02:55.840536  7672 sgd_solver.cpp:106] Iteration 1390, lr = 0.000165
I0226 14:03:23.730856  7672 solver.cpp:229] Iteration 1400, loss = 1.03604
I0226 14:03:23.730933  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.219291 (* 1 = 0.219291 loss)
I0226 14:03:23.730944  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.535638 (* 1 = 0.535638 loss)
I0226 14:03:23.730955  7672 sgd_solver.cpp:106] Iteration 1400, lr = 0.000165
I0226 14:03:51.731508  7672 solver.cpp:229] Iteration 1410, loss = 0.952627
I0226 14:03:51.731544  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.241094 (* 1 = 0.241094 loss)
I0226 14:03:51.731556  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.681294 (* 1 = 0.681294 loss)
I0226 14:03:51.731566  7672 sgd_solver.cpp:106] Iteration 1410, lr = 0.000165
I0226 14:04:19.836688  7672 solver.cpp:229] Iteration 1420, loss = 0.995614
I0226 14:04:19.836726  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.244465 (* 1 = 0.244465 loss)
I0226 14:04:19.836738  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.674787 (* 1 = 0.674787 loss)
I0226 14:04:19.836748  7672 sgd_solver.cpp:106] Iteration 1420, lr = 0.000165
I0226 14:04:48.026795  7672 solver.cpp:229] Iteration 1430, loss = 1.02055
I0226 14:04:48.026834  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.266151 (* 1 = 0.266151 loss)
I0226 14:04:48.026844  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.861437 (* 1 = 0.861437 loss)
I0226 14:04:48.026855  7672 sgd_solver.cpp:106] Iteration 1430, lr = 0.000165
I0226 14:05:15.887495  7672 solver.cpp:229] Iteration 1440, loss = 1.04203
I0226 14:05:15.887542  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.237642 (* 1 = 0.237642 loss)
I0226 14:05:15.887559  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.591332 (* 1 = 0.591332 loss)
I0226 14:05:15.887575  7672 sgd_solver.cpp:106] Iteration 1440, lr = 0.000165
I0226 14:05:43.998450  7672 solver.cpp:229] Iteration 1450, loss = 1.01962
I0226 14:05:43.998488  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.256946 (* 1 = 0.256946 loss)
I0226 14:05:43.998499  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.721475 (* 1 = 0.721475 loss)
I0226 14:05:43.998509  7672 sgd_solver.cpp:106] Iteration 1450, lr = 0.000165
I0226 14:06:11.649641  7672 solver.cpp:229] Iteration 1460, loss = 1.01465
I0226 14:06:11.649695  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.276548 (* 1 = 0.276548 loss)
I0226 14:06:11.649715  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.766761 (* 1 = 0.766761 loss)
I0226 14:06:11.649729  7672 sgd_solver.cpp:106] Iteration 1460, lr = 0.000165
I0226 14:06:39.448385  7672 solver.cpp:229] Iteration 1470, loss = 0.924622
I0226 14:06:39.448438  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.230432 (* 1 = 0.230432 loss)
I0226 14:06:39.448449  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.569883 (* 1 = 0.569883 loss)
I0226 14:06:39.448460  7672 sgd_solver.cpp:106] Iteration 1470, lr = 0.000165
I0226 14:07:07.467361  7672 solver.cpp:229] Iteration 1480, loss = 1.03308
I0226 14:07:07.467397  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.246916 (* 1 = 0.246916 loss)
I0226 14:07:07.467409  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.789873 (* 1 = 0.789873 loss)
I0226 14:07:07.467419  7672 sgd_solver.cpp:106] Iteration 1480, lr = 0.000165
I0226 14:07:35.471750  7672 solver.cpp:229] Iteration 1490, loss = 1.03349
I0226 14:07:35.471796  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.277749 (* 1 = 0.277749 loss)
I0226 14:07:35.471820  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.779205 (* 1 = 0.779205 loss)
I0226 14:07:35.471840  7672 sgd_solver.cpp:106] Iteration 1490, lr = 0.000165
I0226 14:08:03.244117  7672 solver.cpp:229] Iteration 1500, loss = 1.04583
I0226 14:08:03.244169  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.219567 (* 1 = 0.219567 loss)
I0226 14:08:03.244181  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.725888 (* 1 = 0.725888 loss)
I0226 14:08:03.244191  7672 sgd_solver.cpp:106] Iteration 1500, lr = 0.000165
I0226 14:08:31.121778  7672 solver.cpp:229] Iteration 1510, loss = 1.07458
I0226 14:08:31.121814  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.274279 (* 1 = 0.274279 loss)
I0226 14:08:31.121824  7672 solver.cpp:245]     Train net output #1: loss-Seed = 1.069 (* 1 = 1.069 loss)
I0226 14:08:31.121835  7672 sgd_solver.cpp:106] Iteration 1510, lr = 0.000165
I0226 14:08:59.159130  7672 solver.cpp:229] Iteration 1520, loss = 1.03967
I0226 14:08:59.159176  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.291386 (* 1 = 0.291386 loss)
I0226 14:08:59.159188  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.949098 (* 1 = 0.949098 loss)
I0226 14:08:59.159198  7672 sgd_solver.cpp:106] Iteration 1520, lr = 0.000165
I0226 14:09:27.008051  7672 solver.cpp:229] Iteration 1530, loss = 1.09812
I0226 14:09:27.008106  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.238486 (* 1 = 0.238486 loss)
I0226 14:09:27.008118  7672 solver.cpp:245]     Train net output #1: loss-Seed = 1.02313 (* 1 = 1.02313 loss)
I0226 14:09:27.008128  7672 sgd_solver.cpp:106] Iteration 1530, lr = 0.000165
I0226 14:09:55.059427  7672 solver.cpp:229] Iteration 1540, loss = 1.00749
I0226 14:09:55.059466  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.282527 (* 1 = 0.282527 loss)
I0226 14:09:55.059478  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.812933 (* 1 = 0.812933 loss)
I0226 14:09:55.059489  7672 sgd_solver.cpp:106] Iteration 1540, lr = 0.000165
I0226 14:10:22.958689  7672 solver.cpp:229] Iteration 1550, loss = 1.02147
I0226 14:10:22.958727  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.278022 (* 1 = 0.278022 loss)
I0226 14:10:22.958739  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.937713 (* 1 = 0.937713 loss)
I0226 14:10:22.958748  7672 sgd_solver.cpp:106] Iteration 1550, lr = 0.000165
I0226 14:10:50.801558  7672 solver.cpp:229] Iteration 1560, loss = 1.00749
I0226 14:10:50.801595  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.237332 (* 1 = 0.237332 loss)
I0226 14:10:50.801607  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.733561 (* 1 = 0.733561 loss)
I0226 14:10:50.801617  7672 sgd_solver.cpp:106] Iteration 1560, lr = 0.000165
I0226 14:11:18.600347  7672 solver.cpp:229] Iteration 1570, loss = 0.943306
I0226 14:11:18.600397  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.206622 (* 1 = 0.206622 loss)
I0226 14:11:18.600409  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.51718 (* 1 = 0.51718 loss)
I0226 14:11:18.600419  7672 sgd_solver.cpp:106] Iteration 1570, lr = 0.000165
I0226 14:11:46.305564  7672 solver.cpp:229] Iteration 1580, loss = 0.905439
I0226 14:11:46.305616  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.272697 (* 1 = 0.272697 loss)
I0226 14:11:46.305629  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.706194 (* 1 = 0.706194 loss)
I0226 14:11:46.305639  7672 sgd_solver.cpp:106] Iteration 1580, lr = 0.000165
I0226 14:12:14.168622  7672 solver.cpp:229] Iteration 1590, loss = 0.970955
I0226 14:12:14.168674  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.268209 (* 1 = 0.268209 loss)
I0226 14:12:14.168686  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.659881 (* 1 = 0.659881 loss)
I0226 14:12:14.168696  7672 sgd_solver.cpp:106] Iteration 1590, lr = 0.000165
I0226 14:12:42.144704  7672 solver.cpp:229] Iteration 1600, loss = 1.00872
I0226 14:12:42.144742  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.253431 (* 1 = 0.253431 loss)
I0226 14:12:42.144753  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.726231 (* 1 = 0.726231 loss)
I0226 14:12:42.144763  7672 sgd_solver.cpp:106] Iteration 1600, lr = 0.000165
I0226 14:13:09.951807  7672 solver.cpp:229] Iteration 1610, loss = 0.943237
I0226 14:13:09.951844  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.26333 (* 1 = 0.26333 loss)
I0226 14:13:09.951856  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.787089 (* 1 = 0.787089 loss)
I0226 14:13:09.951866  7672 sgd_solver.cpp:106] Iteration 1610, lr = 0.000165
I0226 14:13:37.944363  7672 solver.cpp:229] Iteration 1620, loss = 0.937375
I0226 14:13:37.944432  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.208598 (* 1 = 0.208598 loss)
I0226 14:13:37.944443  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.435748 (* 1 = 0.435748 loss)
I0226 14:13:37.944453  7672 sgd_solver.cpp:106] Iteration 1620, lr = 0.000165
I0226 14:14:06.036309  7672 solver.cpp:229] Iteration 1630, loss = 1.01466
I0226 14:14:06.036346  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.260756 (* 1 = 0.260756 loss)
I0226 14:14:06.036357  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.878879 (* 1 = 0.878879 loss)
I0226 14:14:06.036368  7672 sgd_solver.cpp:106] Iteration 1630, lr = 0.000165
I0226 14:14:33.873387  7672 solver.cpp:229] Iteration 1640, loss = 0.947099
I0226 14:14:33.873423  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.24044 (* 1 = 0.24044 loss)
I0226 14:14:33.873435  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.530648 (* 1 = 0.530648 loss)
I0226 14:14:33.873445  7672 sgd_solver.cpp:106] Iteration 1640, lr = 0.000165
I0226 14:15:01.861553  7672 solver.cpp:229] Iteration 1650, loss = 0.887789
I0226 14:15:01.861618  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.224372 (* 1 = 0.224372 loss)
I0226 14:15:01.861639  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.560489 (* 1 = 0.560489 loss)
I0226 14:15:01.861656  7672 sgd_solver.cpp:106] Iteration 1650, lr = 0.000165
I0226 14:15:29.860719  7672 solver.cpp:229] Iteration 1660, loss = 0.946493
I0226 14:15:29.860757  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.241491 (* 1 = 0.241491 loss)
I0226 14:15:29.860769  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.510115 (* 1 = 0.510115 loss)
I0226 14:15:29.860779  7672 sgd_solver.cpp:106] Iteration 1660, lr = 0.000165
I0226 14:15:57.654304  7672 solver.cpp:229] Iteration 1670, loss = 0.955511
I0226 14:15:57.654341  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.26823 (* 1 = 0.26823 loss)
I0226 14:15:57.654351  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.640702 (* 1 = 0.640702 loss)
I0226 14:15:57.654361  7672 sgd_solver.cpp:106] Iteration 1670, lr = 0.000165
I0226 14:16:25.770269  7672 solver.cpp:229] Iteration 1680, loss = 1.02613
I0226 14:16:25.770308  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.273528 (* 1 = 0.273528 loss)
I0226 14:16:25.770320  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.790805 (* 1 = 0.790805 loss)
I0226 14:16:25.770330  7672 sgd_solver.cpp:106] Iteration 1680, lr = 0.000165
I0226 14:16:53.987143  7672 solver.cpp:229] Iteration 1690, loss = 0.933253
I0226 14:16:53.987181  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.249246 (* 1 = 0.249246 loss)
I0226 14:16:53.987192  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.637902 (* 1 = 0.637902 loss)
I0226 14:16:53.987202  7672 sgd_solver.cpp:106] Iteration 1690, lr = 0.000165
I0226 14:17:21.964977  7672 solver.cpp:229] Iteration 1700, loss = 0.971727
I0226 14:17:21.965015  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.257283 (* 1 = 0.257283 loss)
I0226 14:17:21.965028  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.816396 (* 1 = 0.816396 loss)
I0226 14:17:21.965037  7672 sgd_solver.cpp:106] Iteration 1700, lr = 0.000165
I0226 14:17:49.763221  7672 solver.cpp:229] Iteration 1710, loss = 0.981727
I0226 14:17:49.763259  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.268695 (* 1 = 0.268695 loss)
I0226 14:17:49.763273  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.743051 (* 1 = 0.743051 loss)
I0226 14:17:49.763283  7672 sgd_solver.cpp:106] Iteration 1710, lr = 0.000165
I0226 14:18:17.774178  7672 solver.cpp:229] Iteration 1720, loss = 0.966001
I0226 14:18:17.774214  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.311191 (* 1 = 0.311191 loss)
I0226 14:18:17.774224  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.728169 (* 1 = 0.728169 loss)
I0226 14:18:17.774235  7672 sgd_solver.cpp:106] Iteration 1720, lr = 0.000165
I0226 14:18:45.642973  7672 solver.cpp:229] Iteration 1730, loss = 0.976445
I0226 14:18:45.643010  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.276632 (* 1 = 0.276632 loss)
I0226 14:18:45.643023  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.744373 (* 1 = 0.744373 loss)
I0226 14:18:45.643033  7672 sgd_solver.cpp:106] Iteration 1730, lr = 0.000165
I0226 14:19:13.585841  7672 solver.cpp:229] Iteration 1740, loss = 0.988364
I0226 14:19:13.585875  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.244648 (* 1 = 0.244648 loss)
I0226 14:19:13.585886  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.626616 (* 1 = 0.626616 loss)
I0226 14:19:13.585896  7672 sgd_solver.cpp:106] Iteration 1740, lr = 0.000165
I0226 14:19:41.417011  7672 solver.cpp:229] Iteration 1750, loss = 0.923777
I0226 14:19:41.417047  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.270835 (* 1 = 0.270835 loss)
I0226 14:19:41.417059  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.768515 (* 1 = 0.768515 loss)
I0226 14:19:41.417069  7672 sgd_solver.cpp:106] Iteration 1750, lr = 0.000165
I0226 14:20:09.481340  7672 solver.cpp:229] Iteration 1760, loss = 1.01043
I0226 14:20:09.481379  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.265417 (* 1 = 0.265417 loss)
I0226 14:20:09.481390  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.829218 (* 1 = 0.829218 loss)
I0226 14:20:09.481400  7672 sgd_solver.cpp:106] Iteration 1760, lr = 0.000165
I0226 14:20:38.132922  7672 solver.cpp:229] Iteration 1770, loss = 1.00932
I0226 14:20:38.132977  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.221459 (* 1 = 0.221459 loss)
I0226 14:20:38.132987  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.718459 (* 1 = 0.718459 loss)
I0226 14:20:38.132997  7672 sgd_solver.cpp:106] Iteration 1770, lr = 0.000165
I0226 14:21:05.972309  7672 solver.cpp:229] Iteration 1780, loss = 0.977671
I0226 14:21:05.972345  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.258884 (* 1 = 0.258884 loss)
I0226 14:21:05.972357  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.595215 (* 1 = 0.595215 loss)
I0226 14:21:05.972368  7672 sgd_solver.cpp:106] Iteration 1780, lr = 0.000165
I0226 14:21:34.157768  7672 solver.cpp:229] Iteration 1790, loss = 0.981249
I0226 14:21:34.157820  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.219384 (* 1 = 0.219384 loss)
I0226 14:21:34.157832  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.731878 (* 1 = 0.731878 loss)
I0226 14:21:34.157842  7672 sgd_solver.cpp:106] Iteration 1790, lr = 0.000165
I0226 14:22:02.760749  7672 solver.cpp:229] Iteration 1800, loss = 0.980799
I0226 14:22:02.760794  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.224417 (* 1 = 0.224417 loss)
I0226 14:22:02.760807  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.449148 (* 1 = 0.449148 loss)
I0226 14:22:02.760818  7672 sgd_solver.cpp:106] Iteration 1800, lr = 0.000165
I0226 14:22:31.565760  7672 solver.cpp:229] Iteration 1810, loss = 0.971994
I0226 14:22:31.565814  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.245419 (* 1 = 0.245419 loss)
I0226 14:22:31.565834  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.676486 (* 1 = 0.676486 loss)
I0226 14:22:31.565850  7672 sgd_solver.cpp:106] Iteration 1810, lr = 0.000165
I0226 14:23:00.605165  7672 solver.cpp:229] Iteration 1820, loss = 0.923256
I0226 14:23:00.605207  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.28068 (* 1 = 0.28068 loss)
I0226 14:23:00.605219  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.806627 (* 1 = 0.806627 loss)
I0226 14:23:00.605229  7672 sgd_solver.cpp:106] Iteration 1820, lr = 0.000165
I0226 14:23:28.434264  7672 solver.cpp:229] Iteration 1830, loss = 0.974337
I0226 14:23:28.434303  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.268282 (* 1 = 0.268282 loss)
I0226 14:23:28.434314  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.746367 (* 1 = 0.746367 loss)
I0226 14:23:28.434324  7672 sgd_solver.cpp:106] Iteration 1830, lr = 0.000165
I0226 14:23:56.681893  7672 solver.cpp:229] Iteration 1840, loss = 0.977804
I0226 14:23:56.681947  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.2428 (* 1 = 0.2428 loss)
I0226 14:23:56.681959  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.511803 (* 1 = 0.511803 loss)
I0226 14:23:56.681969  7672 sgd_solver.cpp:106] Iteration 1840, lr = 0.000165
I0226 14:24:25.733090  7672 solver.cpp:229] Iteration 1850, loss = 0.982042
I0226 14:24:25.733134  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.26759 (* 1 = 0.26759 loss)
I0226 14:24:25.733146  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.622427 (* 1 = 0.622427 loss)
I0226 14:24:25.733156  7672 sgd_solver.cpp:106] Iteration 1850, lr = 0.000165
I0226 14:24:56.250349  7672 solver.cpp:229] Iteration 1860, loss = 0.949517
I0226 14:24:56.250411  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.273083 (* 1 = 0.273083 loss)
I0226 14:24:56.250428  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.606805 (* 1 = 0.606805 loss)
I0226 14:24:56.250447  7672 sgd_solver.cpp:106] Iteration 1860, lr = 0.000165
I0226 14:25:29.790231  7672 solver.cpp:229] Iteration 1870, loss = 0.983798
I0226 14:25:29.790298  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.29767 (* 1 = 0.29767 loss)
I0226 14:25:29.790320  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.83348 (* 1 = 0.83348 loss)
I0226 14:25:29.790340  7672 sgd_solver.cpp:106] Iteration 1870, lr = 0.000165
I0226 14:26:02.002777  7672 solver.cpp:229] Iteration 1880, loss = 0.96339
I0226 14:26:02.002885  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.272841 (* 1 = 0.272841 loss)
I0226 14:26:02.002903  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.705923 (* 1 = 0.705923 loss)
I0226 14:26:02.002916  7672 sgd_solver.cpp:106] Iteration 1880, lr = 0.000165
I0226 14:26:31.073818  7672 solver.cpp:229] Iteration 1890, loss = 0.870155
I0226 14:26:31.073882  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.240267 (* 1 = 0.240267 loss)
I0226 14:26:31.073899  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.513198 (* 1 = 0.513198 loss)
I0226 14:26:31.073913  7672 sgd_solver.cpp:106] Iteration 1890, lr = 0.000165
I0226 14:27:00.623754  7672 solver.cpp:229] Iteration 1900, loss = 1.0126
I0226 14:27:00.623814  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.215727 (* 1 = 0.215727 loss)
I0226 14:27:00.623826  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.595487 (* 1 = 0.595487 loss)
I0226 14:27:00.623836  7672 sgd_solver.cpp:106] Iteration 1900, lr = 0.000165
I0226 14:27:30.362541  7672 solver.cpp:229] Iteration 1910, loss = 0.98104
I0226 14:27:30.362587  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.241863 (* 1 = 0.241863 loss)
I0226 14:27:30.362599  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.699803 (* 1 = 0.699803 loss)
I0226 14:27:30.362609  7672 sgd_solver.cpp:106] Iteration 1910, lr = 0.000165
I0226 14:28:00.218420  7672 solver.cpp:229] Iteration 1920, loss = 0.974123
I0226 14:28:00.218464  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.244364 (* 1 = 0.244364 loss)
I0226 14:28:00.218475  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.535399 (* 1 = 0.535399 loss)
I0226 14:28:00.218487  7672 sgd_solver.cpp:106] Iteration 1920, lr = 0.000165
I0226 14:28:30.958346  7672 solver.cpp:229] Iteration 1930, loss = 1.04734
I0226 14:28:30.958433  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.234349 (* 1 = 0.234349 loss)
I0226 14:28:30.958458  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.94946 (* 1 = 0.94946 loss)
I0226 14:28:30.958482  7672 sgd_solver.cpp:106] Iteration 1930, lr = 0.000165
I0226 14:29:03.621619  7672 solver.cpp:229] Iteration 1940, loss = 0.993598
I0226 14:29:03.621676  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.252926 (* 1 = 0.252926 loss)
I0226 14:29:03.621688  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.79218 (* 1 = 0.79218 loss)
I0226 14:29:03.621698  7672 sgd_solver.cpp:106] Iteration 1940, lr = 0.000165
I0226 14:29:35.591789  7672 solver.cpp:229] Iteration 1950, loss = 0.973893
I0226 14:29:35.591871  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.237385 (* 1 = 0.237385 loss)
I0226 14:29:35.591914  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.698871 (* 1 = 0.698871 loss)
I0226 14:29:35.591949  7672 sgd_solver.cpp:106] Iteration 1950, lr = 0.000165
I0226 14:30:06.778421  7672 solver.cpp:229] Iteration 1960, loss = 0.971894
I0226 14:30:06.778473  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.216699 (* 1 = 0.216699 loss)
I0226 14:30:06.778484  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.475113 (* 1 = 0.475113 loss)
I0226 14:30:06.778496  7672 sgd_solver.cpp:106] Iteration 1960, lr = 0.000165
[I0226 14:30:34.497045  7672 solver.cpp:229] Iteration 1970, loss = 0.958921
I0226 14:30:34.497082  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.272262 (* 1 = 0.272262 loss)
I0226 14:30:34.497094  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.727481 (* 1 = 0.727481 loss)
I0226 14:30:34.497104  7672 sgd_solver.cpp:106] Iteration 1970, lr = 0.000165
I0226 14:31:02.130565  7672 solver.cpp:229] Iteration 1980, loss = 0.947615
I0226 14:31:02.130618  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.291286 (* 1 = 0.291286 loss)
I0226 14:31:02.130630  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.742141 (* 1 = 0.742141 loss)
I0226 14:31:02.130640  7672 sgd_solver.cpp:106] Iteration 1980, lr = 0.000165
I0226 14:31:29.841388  7672 solver.cpp:229] Iteration 1990, loss = 0.921818
I0226 14:31:29.841440  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.26117 (* 1 = 0.26117 loss)
I0226 14:31:29.841451  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.705061 (* 1 = 0.705061 loss)
I0226 14:31:29.841462  7672 sgd_solver.cpp:106] Iteration 1990, lr = 0.000165
I0226 14:31:57.587591  7672 solver.cpp:229] Iteration 2000, loss = 0.924924
I0226 14:31:57.587628  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.279651 (* 1 = 0.279651 loss)
I0226 14:31:57.587641  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.802074 (* 1 = 0.802074 loss)
I0226 14:31:57.587651  7672 sgd_solver.cpp:106] Iteration 2000, lr = 5.445e-05
I0226 14:32:25.380462  7672 solver.cpp:229] Iteration 2010, loss = 1.03573
I0226 14:32:25.380501  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.277927 (* 1 = 0.277927 loss)
I0226 14:32:25.380512  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.786247 (* 1 = 0.786247 loss)
I0226 14:32:25.380522  7672 sgd_solver.cpp:106] Iteration 2010, lr = 5.445e-05
I0226 14:32:53.232894  7672 solver.cpp:229] Iteration 2020, loss = 1.00348
I0226 14:32:53.232947  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.274953 (* 1 = 0.274953 loss)
I0226 14:32:53.232959  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.762409 (* 1 = 0.762409 loss)
I0226 14:32:53.232969  7672 sgd_solver.cpp:106] Iteration 2020, lr = 5.445e-05
I0226 14:33:21.184551  7672 solver.cpp:229] Iteration 2030, loss = 0.983874
I0226 14:33:21.184587  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.283186 (* 1 = 0.283186 loss)
I0226 14:33:21.184599  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.824475 (* 1 = 0.824475 loss)
I0226 14:33:21.184609  7672 sgd_solver.cpp:106] Iteration 2030, lr = 5.445e-05
I0226 14:33:49.115718  7672 solver.cpp:229] Iteration 2040, loss = 0.960333
I0226 14:33:49.115772  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.240047 (* 1 = 0.240047 loss)
I0226 14:33:49.115782  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.588596 (* 1 = 0.588596 loss)
I0226 14:33:49.115793  7672 sgd_solver.cpp:106] Iteration 2040, lr = 5.445e-05
I0226 14:34:17.190685  7672 solver.cpp:229] Iteration 2050, loss = 0.99571
I0226 14:34:17.190737  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.285772 (* 1 = 0.285772 loss)
I0226 14:34:17.190748  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.786823 (* 1 = 0.786823 loss)
I0226 14:34:17.190773  7672 sgd_solver.cpp:106] Iteration 2050, lr = 5.445e-05
I0226 14:34:45.060122  7672 solver.cpp:229] Iteration 2060, loss = 1.01771
I0226 14:34:45.060174  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.260222 (* 1 = 0.260222 loss)
I0226 14:34:45.060186  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.593005 (* 1 = 0.593005 loss)
I0226 14:34:45.060196  7672 sgd_solver.cpp:106] Iteration 2060, lr = 5.445e-05
I0226 14:35:12.840618  7672 solver.cpp:229] Iteration 2070, loss = 0.986824
I0226 14:35:12.840669  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.30647 (* 1 = 0.30647 loss)
I0226 14:35:12.840682  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.835526 (* 1 = 0.835526 loss)
I0226 14:35:12.840692  7672 sgd_solver.cpp:106] Iteration 2070, lr = 5.445e-05
I0226 14:35:40.815227  7672 solver.cpp:229] Iteration 2080, loss = 1.08408
I0226 14:35:40.815263  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.260712 (* 1 = 0.260712 loss)
I0226 14:35:40.815275  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.901858 (* 1 = 0.901858 loss)
I0226 14:35:40.815285  7672 sgd_solver.cpp:106] Iteration 2080, lr = 5.445e-05
I0226 14:36:08.690160  7672 solver.cpp:229] Iteration 2090, loss = 1.00085
I0226 14:36:08.690212  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.25455 (* 1 = 0.25455 loss)
I0226 14:36:08.690222  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.556821 (* 1 = 0.556821 loss)
I0226 14:36:08.690232  7672 sgd_solver.cpp:106] Iteration 2090, lr = 5.445e-05
I0226 14:36:36.279287  7672 solver.cpp:229] Iteration 2100, loss = 0.925486
I0226 14:36:36.279335  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.233036 (* 1 = 0.233036 loss)
I0226 14:36:36.279345  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.485588 (* 1 = 0.485588 loss)
I0226 14:36:36.279356  7672 sgd_solver.cpp:106] Iteration 2100, lr = 5.445e-05
I0226 14:37:04.252970  7672 solver.cpp:229] Iteration 2110, loss = 0.934199
I0226 14:37:04.253011  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.208416 (* 1 = 0.208416 loss)
I0226 14:37:04.253022  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.584925 (* 1 = 0.584925 loss)
I0226 14:37:04.253033  7672 sgd_solver.cpp:106] Iteration 2110, lr = 5.445e-05
I0226 14:37:32.202312  7672 solver.cpp:229] Iteration 2120, loss = 0.949443
I0226 14:37:32.202368  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.266857 (* 1 = 0.266857 loss)
I0226 14:37:32.202380  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.706262 (* 1 = 0.706262 loss)
I0226 14:37:32.202390  7672 sgd_solver.cpp:106] Iteration 2120, lr = 5.445e-05
I0226 14:38:00.263202  7672 solver.cpp:229] Iteration 2130, loss = 0.894606
I0226 14:38:00.263242  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.252097 (* 1 = 0.252097 loss)
I0226 14:38:00.263253  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.655462 (* 1 = 0.655462 loss)
I0226 14:38:00.263264  7672 sgd_solver.cpp:106] Iteration 2130, lr = 5.445e-05
I0226 14:38:29.628243  7672 solver.cpp:229] Iteration 2140, loss = 0.916362
I0226 14:38:29.628286  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.283295 (* 1 = 0.283295 loss)
I0226 14:38:29.628298  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.848116 (* 1 = 0.848116 loss)
I0226 14:38:29.628307  7672 sgd_solver.cpp:106] Iteration 2140, lr = 5.445e-05
I0226 14:39:05.549649  7672 solver.cpp:229] Iteration 2150, loss = 0.890203
I0226 14:39:05.549747  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.285115 (* 1 = 0.285115 loss)
I0226 14:39:05.549772  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.578128 (* 1 = 0.578128 loss)
I0226 14:39:05.549811  7672 sgd_solver.cpp:106] Iteration 2150, lr = 5.445e-05
I0226 14:39:38.822311  7672 solver.cpp:229] Iteration 2160, loss = 0.963911
I0226 14:39:38.822355  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.256675 (* 1 = 0.256675 loss)
I0226 14:39:38.822365  7672 solver.cpp:245]     Train net output #1: loss-Seed = 1.06379 (* 1 = 1.06379 loss)
I0226 14:39:38.822376  7672 sgd_solver.cpp:106] Iteration 2160, lr = 5.445e-05
I0226 14:40:11.048545  7672 solver.cpp:229] Iteration 2170, loss = 0.935899
I0226 14:40:11.048594  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.23377 (* 1 = 0.23377 loss)
I0226 14:40:11.048609  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.693703 (* 1 = 0.693703 loss)
I0226 14:40:11.048622  7672 sgd_solver.cpp:106] Iteration 2170, lr = 5.445e-05
I0226 14:40:42.118835  7672 solver.cpp:229] Iteration 2180, loss = 0.922934
I0226 14:40:42.118912  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.255346 (* 1 = 0.255346 loss)
I0226 14:40:42.118926  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.743265 (* 1 = 0.743265 loss)
I0226 14:40:42.118937  7672 sgd_solver.cpp:106] Iteration 2180, lr = 5.445e-05
I0226 14:41:12.236279  7672 solver.cpp:229] Iteration 2190, loss = 0.829995
I0226 14:41:12.236332  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.2493 (* 1 = 0.2493 loss)
I0226 14:41:12.236351  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.475214 (* 1 = 0.475214 loss)
I0226 14:41:12.236367  7672 sgd_solver.cpp:106] Iteration 2190, lr = 5.445e-05
I0226 14:41:43.687026  7672 solver.cpp:229] Iteration 2200, loss = 0.836371
I0226 14:41:43.687080  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.222132 (* 1 = 0.222132 loss)
I0226 14:41:43.687099  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.687063 (* 1 = 0.687063 loss)
I0226 14:41:43.687114  7672 sgd_solver.cpp:106] Iteration 2200, lr = 5.445e-05
I0226 14:42:15.462747  7672 solver.cpp:229] Iteration 2210, loss = 0.955675
I0226 14:42:15.462841  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.236114 (* 1 = 0.236114 loss)
I0226 14:42:15.462903  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.58704 (* 1 = 0.58704 loss)
I0226 14:42:15.462935  7672 sgd_solver.cpp:106] Iteration 2210, lr = 5.445e-05
I0226 14:42:46.569180  7672 solver.cpp:229] Iteration 2220, loss = 0.931037
I0226 14:42:46.569223  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.251673 (* 1 = 0.251673 loss)
I0226 14:42:46.569234  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.713642 (* 1 = 0.713642 loss)
I0226 14:42:46.569244  7672 sgd_solver.cpp:106] Iteration 2220, lr = 5.445e-05
I0226 14:43:17.820026  7672 solver.cpp:229] Iteration 2230, loss = 0.963786
I0226 14:43:17.820096  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.259585 (* 1 = 0.259585 loss)
I0226 14:43:17.820122  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.762597 (* 1 = 0.762597 loss)
I0226 14:43:17.820150  7672 sgd_solver.cpp:106] Iteration 2230, lr = 5.445e-05
I0226 14:43:49.092978  7672 solver.cpp:229] Iteration 2240, loss = 1.01261
I0226 14:43:49.093045  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.256757 (* 1 = 0.256757 loss)
I0226 14:43:49.093060  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.668849 (* 1 = 0.668849 loss)
I0226 14:43:49.093073  7672 sgd_solver.cpp:106] Iteration 2240, lr = 5.445e-05
I0226 14:44:20.381783  7672 solver.cpp:229] Iteration 2250, loss = 0.960044
I0226 14:44:20.381871  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.252479 (* 1 = 0.252479 loss)
I0226 14:44:20.381906  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.860298 (* 1 = 0.860298 loss)
I0226 14:44:20.381927  7672 sgd_solver.cpp:106] Iteration 2250, lr = 5.445e-05
I0226 14:44:52.051945  7672 solver.cpp:229] Iteration 2260, loss = 0.950744
I0226 14:44:52.052009  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.274295 (* 1 = 0.274295 loss)
I0226 14:44:52.052027  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.774283 (* 1 = 0.774283 loss)
I0226 14:44:52.052040  7672 sgd_solver.cpp:106] Iteration 2260, lr = 5.445e-05
I0226 14:45:21.195098  7672 solver.cpp:229] Iteration 2270, loss = 0.939886
I0226 14:45:21.195134  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.259788 (* 1 = 0.259788 loss)
I0226 14:45:21.195145  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.985753 (* 1 = 0.985753 loss)
I0226 14:45:21.195156  7672 sgd_solver.cpp:106] Iteration 2270, lr = 5.445e-05
I0226 14:45:49.129559  7672 solver.cpp:229] Iteration 2280, loss = 0.882832
I0226 14:45:49.129611  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.229766 (* 1 = 0.229766 loss)
I0226 14:45:49.129638  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.565059 (* 1 = 0.565059 loss)
I0226 14:45:49.129647  7672 sgd_solver.cpp:106] Iteration 2280, lr = 5.445e-05
I0226 14:46:17.094584  7672 solver.cpp:229] Iteration 2290, loss = 0.888646
I0226 14:46:17.094637  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.224422 (* 1 = 0.224422 loss)
I0226 14:46:17.094663  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.673517 (* 1 = 0.673517 loss)
I0226 14:46:17.094674  7672 sgd_solver.cpp:106] Iteration 2290, lr = 5.445e-05
I0226 14:46:44.827162  7672 solver.cpp:229] Iteration 2300, loss = 0.907159
I0226 14:46:44.827198  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.277253 (* 1 = 0.277253 loss)
I0226 14:46:44.827210  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.626145 (* 1 = 0.626145 loss)
I0226 14:46:44.827220  7672 sgd_solver.cpp:106] Iteration 2300, lr = 5.445e-05
I0226 14:47:12.720263  7672 solver.cpp:229] Iteration 2310, loss = 0.953412
I0226 14:47:12.720299  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.296765 (* 1 = 0.296765 loss)
I0226 14:47:12.720312  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.775769 (* 1 = 0.775769 loss)
I0226 14:47:12.720322  7672 sgd_solver.cpp:106] Iteration 2310, lr = 5.445e-05
I0226 14:47:40.568624  7672 solver.cpp:229] Iteration 2320, loss = 0.977378
I0226 14:47:40.568678  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.252777 (* 1 = 0.252777 loss)
I0226 14:47:40.568691  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.69644 (* 1 = 0.69644 loss)
I0226 14:47:40.568701  7672 sgd_solver.cpp:106] Iteration 2320, lr = 5.445e-05
I0226 14:48:08.368243  7672 solver.cpp:229] Iteration 2330, loss = 0.997586
I0226 14:48:08.368295  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.287724 (* 1 = 0.287724 loss)
I0226 14:48:08.368306  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.758418 (* 1 = 0.758418 loss)
I0226 14:48:08.368317  7672 sgd_solver.cpp:106] Iteration 2330, lr = 5.445e-05
I0226 14:48:36.340237  7672 solver.cpp:229] Iteration 2340, loss = 0.92774
I0226 14:48:36.340276  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.235936 (* 1 = 0.235936 loss)
I0226 14:48:36.340288  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.501433 (* 1 = 0.501433 loss)
I0226 14:48:36.340298  7672 sgd_solver.cpp:106] Iteration 2340, lr = 5.445e-05
I0226 14:49:04.126405  7672 solver.cpp:229] Iteration 2350, loss = 1.00642
I0226 14:49:04.126458  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.311108 (* 1 = 0.311108 loss)
I0226 14:49:04.126471  7672 solver.cpp:245]     Train net output #1: loss-Seed = 1.00429 (* 1 = 1.00429 loss)
I0226 14:49:04.126482  7672 sgd_solver.cpp:106] Iteration 2350, lr = 5.445e-05
I0226 14:49:31.880465  7672 solver.cpp:229] Iteration 2360, loss = 1.00042
I0226 14:49:31.880517  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.294958 (* 1 = 0.294958 loss)
I0226 14:49:31.880527  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.810533 (* 1 = 0.810533 loss)
I0226 14:49:31.880538  7672 sgd_solver.cpp:106] Iteration 2360, lr = 5.445e-05
I0226 14:49:59.822609  7672 solver.cpp:229] Iteration 2370, loss = 0.995556
I0226 14:49:59.822661  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.269159 (* 1 = 0.269159 loss)
I0226 14:49:59.822674  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.74279 (* 1 = 0.74279 loss)
I0226 14:49:59.822683  7672 sgd_solver.cpp:106] Iteration 2370, lr = 5.445e-05
I0226 14:50:27.676894  7672 solver.cpp:229] Iteration 2380, loss = 0.911914
I0226 14:50:27.676934  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.258046 (* 1 = 0.258046 loss)
I0226 14:50:27.676944  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.69763 (* 1 = 0.69763 loss)
I0226 14:50:27.676955  7672 sgd_solver.cpp:106] Iteration 2380, lr = 5.445e-05
I0226 14:50:55.544708  7672 solver.cpp:229] Iteration 2390, loss = 1.00956
I0226 14:50:55.544746  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.267577 (* 1 = 0.267577 loss)
I0226 14:50:55.544759  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.624412 (* 1 = 0.624412 loss)
I0226 14:50:55.544769  7672 sgd_solver.cpp:106] Iteration 2390, lr = 5.445e-05
I0226 14:51:23.372483  7672 solver.cpp:229] Iteration 2400, loss = 0.910212
I0226 14:51:23.372535  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.247509 (* 1 = 0.247509 loss)
I0226 14:51:23.372547  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.652666 (* 1 = 0.652666 loss)
I0226 14:51:23.372557  7672 sgd_solver.cpp:106] Iteration 2400, lr = 5.445e-05
I0226 14:51:51.253674  7672 solver.cpp:229] Iteration 2410, loss = 0.944472
I0226 14:51:51.253711  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.271946 (* 1 = 0.271946 loss)
I0226 14:51:51.253722  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.679947 (* 1 = 0.679947 loss)
I0226 14:51:51.253733  7672 sgd_solver.cpp:106] Iteration 2410, lr = 5.445e-05
I0226 14:52:19.116470  7672 solver.cpp:229] Iteration 2420, loss = 0.94216
I0226 14:52:19.116523  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.259164 (* 1 = 0.259164 loss)
I0226 14:52:19.116534  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.661156 (* 1 = 0.661156 loss)
I0226 14:52:19.116545  7672 sgd_solver.cpp:106] Iteration 2420, lr = 5.445e-05
I0226 14:52:46.670537  7672 solver.cpp:229] Iteration 2430, loss = 0.926123
I0226 14:52:46.670572  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.258865 (* 1 = 0.258865 loss)
I0226 14:52:46.670581  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.665287 (* 1 = 0.665287 loss)
I0226 14:52:46.670590  7672 sgd_solver.cpp:106] Iteration 2430, lr = 5.445e-05
I0226 14:53:14.539410  7672 solver.cpp:229] Iteration 2440, loss = 0.94071
I0226 14:53:14.539448  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.262965 (* 1 = 0.262965 loss)
I0226 14:53:14.539459  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.623267 (* 1 = 0.623267 loss)
I0226 14:53:14.539469  7672 sgd_solver.cpp:106] Iteration 2440, lr = 5.445e-05
I0226 14:53:42.391127  7672 solver.cpp:229] Iteration 2450, loss = 0.917716
I0226 14:53:42.391165  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.249822 (* 1 = 0.249822 loss)
I0226 14:53:42.391176  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.528137 (* 1 = 0.528137 loss)
I0226 14:53:42.391186  7672 sgd_solver.cpp:106] Iteration 2450, lr = 5.445e-05
I0226 14:54:10.257216  7672 solver.cpp:229] Iteration 2460, loss = 0.95154
I0226 14:54:10.257253  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.263362 (* 1 = 0.263362 loss)
I0226 14:54:10.257264  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.555178 (* 1 = 0.555178 loss)
I0226 14:54:10.257275  7672 sgd_solver.cpp:106] Iteration 2460, lr = 5.445e-05
I0226 14:54:38.105967  7672 solver.cpp:229] Iteration 2470, loss = 0.927676
I0226 14:54:38.106003  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.269101 (* 1 = 0.269101 loss)
I0226 14:54:38.106014  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.696696 (* 1 = 0.696696 loss)
I0226 14:54:38.106024  7672 sgd_solver.cpp:106] Iteration 2470, lr = 5.445e-05
I0226 14:55:05.849936  7672 solver.cpp:229] Iteration 2480, loss = 0.956298
I0226 14:55:05.849972  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.265933 (* 1 = 0.265933 loss)
I0226 14:55:05.849983  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.956778 (* 1 = 0.956778 loss)
I0226 14:55:05.849993  7672 sgd_solver.cpp:106] Iteration 2480, lr = 5.445e-05
I0226 14:55:33.708391  7672 solver.cpp:229] Iteration 2490, loss = 0.971718
I0226 14:55:33.708428  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.294797 (* 1 = 0.294797 loss)
I0226 14:55:33.708441  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.682565 (* 1 = 0.682565 loss)
I0226 14:55:33.708451  7672 sgd_solver.cpp:106] Iteration 2490, lr = 5.445e-05
I0226 14:56:01.874970  7672 solver.cpp:229] Iteration 2500, loss = 0.923788
I0226 14:56:01.875007  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.270925 (* 1 = 0.270925 loss)
I0226 14:56:01.875020  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.786332 (* 1 = 0.786332 loss)
I0226 14:56:01.875031  7672 sgd_solver.cpp:106] Iteration 2500, lr = 5.445e-05
I0226 14:56:30.969632  7672 solver.cpp:229] Iteration 2510, loss = 0.979552
I0226 14:56:30.969708  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.239045 (* 1 = 0.239045 loss)
I0226 14:56:30.969739  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.724615 (* 1 = 0.724615 loss)
I0226 14:56:30.969760  7672 sgd_solver.cpp:106] Iteration 2510, lr = 5.445e-05
I0226 14:57:06.256922  7672 solver.cpp:229] Iteration 2520, loss = 0.961596
I0226 14:57:06.256963  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.26967 (* 1 = 0.26967 loss)
I0226 14:57:06.256974  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.704972 (* 1 = 0.704972 loss)
I0226 14:57:06.256992  7672 sgd_solver.cpp:106] Iteration 2520, lr = 5.445e-05
I0226 14:57:40.777570  7672 solver.cpp:229] Iteration 2530, loss = 0.971319
I0226 14:57:40.777649  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.253501 (* 1 = 0.253501 loss)
I0226 14:57:40.777667  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.709436 (* 1 = 0.709436 loss)
I0226 14:57:40.777679  7672 sgd_solver.cpp:106] Iteration 2530, lr = 5.445e-05
I0226 14:58:13.635663  7672 solver.cpp:229] Iteration 2540, loss = 0.897459
I0226 14:58:13.635728  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.26604 (* 1 = 0.26604 loss)
I0226 14:58:13.635748  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.739262 (* 1 = 0.739262 loss)
I0226 14:58:13.635764  7672 sgd_solver.cpp:106] Iteration 2540, lr = 5.445e-05
I0226 14:58:45.280855  7672 solver.cpp:229] Iteration 2550, loss = 0.968919
I0226 14:58:45.280920  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.256672 (* 1 = 0.256672 loss)
I0226 14:58:45.280942  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.65474 (* 1 = 0.65474 loss)
I0226 14:58:45.280972  7672 sgd_solver.cpp:106] Iteration 2550, lr = 5.445e-05
I0226 14:59:16.826350  7672 solver.cpp:229] Iteration 2560, loss = 0.948774
I0226 14:59:16.826412  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.263166 (* 1 = 0.263166 loss)
I0226 14:59:16.826431  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.5991 (* 1 = 0.5991 loss)
I0226 14:59:16.826444  7672 sgd_solver.cpp:106] Iteration 2560, lr = 5.445e-05
I0226 14:59:49.321645  7672 solver.cpp:229] Iteration 2570, loss = 0.946283
I0226 14:59:49.321687  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.184539 (* 1 = 0.184539 loss)
I0226 14:59:49.321700  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.563551 (* 1 = 0.563551 loss)
I0226 14:59:49.321710  7672 sgd_solver.cpp:106] Iteration 2570, lr = 5.445e-05
I0226 15:00:20.852807  7672 solver.cpp:229] Iteration 2580, loss = 0.96447
I0226 15:00:20.852864  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.294561 (* 1 = 0.294561 loss)
I0226 15:00:20.852880  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.727229 (* 1 = 0.727229 loss)
I0226 15:00:20.852891  7672 sgd_solver.cpp:106] Iteration 2580, lr = 5.445e-05
I0226 15:00:52.762689  7672 solver.cpp:229] Iteration 2590, loss = 0.851633
I0226 15:00:52.762748  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.229592 (* 1 = 0.229592 loss)
I0226 15:00:52.762760  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.682448 (* 1 = 0.682448 loss)
I0226 15:00:52.762771  7672 sgd_solver.cpp:106] Iteration 2590, lr = 5.445e-05
I0226 15:01:22.622385  7672 solver.cpp:229] Iteration 2600, loss = 0.898774
I0226 15:01:22.622448  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.241664 (* 1 = 0.241664 loss)
I0226 15:01:22.622460  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.564086 (* 1 = 0.564086 loss)
I0226 15:01:22.622470  7672 sgd_solver.cpp:106] Iteration 2600, lr = 5.445e-05
I0226 15:01:50.461555  7672 solver.cpp:229] Iteration 2610, loss = 0.919399
I0226 15:01:50.461606  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.262435 (* 1 = 0.262435 loss)
I0226 15:01:50.461617  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.733314 (* 1 = 0.733314 loss)
I0226 15:01:50.461627  7672 sgd_solver.cpp:106] Iteration 2610, lr = 5.445e-05
I0226 15:02:18.428344  7672 solver.cpp:229] Iteration 2620, loss = 0.943676
I0226 15:02:18.428381  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.218926 (* 1 = 0.218926 loss)
I0226 15:02:18.428392  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.434342 (* 1 = 0.434342 loss)
I0226 15:02:18.428402  7672 sgd_solver.cpp:106] Iteration 2620, lr = 5.445e-05
I0226 15:02:46.599428  7672 solver.cpp:229] Iteration 2630, loss = 0.979458
I0226 15:02:46.599495  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.292545 (* 1 = 0.292545 loss)
I0226 15:02:46.599521  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.703234 (* 1 = 0.703234 loss)
I0226 15:02:46.599532  7672 sgd_solver.cpp:106] Iteration 2630, lr = 5.445e-05
I0226 15:03:18.479143  7672 solver.cpp:229] Iteration 2640, loss = 0.968978
I0226 15:03:18.479220  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.247081 (* 1 = 0.247081 loss)
I0226 15:03:18.479244  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.582465 (* 1 = 0.582465 loss)
I0226 15:03:18.479264  7672 sgd_solver.cpp:106] Iteration 2640, lr = 5.445e-05
I0226 15:03:52.220180  7672 solver.cpp:229] Iteration 2650, loss = 0.92656
I0226 15:03:52.220221  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.240039 (* 1 = 0.240039 loss)
I0226 15:03:52.220232  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.646697 (* 1 = 0.646697 loss)
I0226 15:03:52.220243  7672 sgd_solver.cpp:106] Iteration 2650, lr = 5.445e-05
I0226 15:04:26.313248  7672 solver.cpp:229] Iteration 2660, loss = 0.977113
I0226 15:04:26.313323  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.252943 (* 1 = 0.252943 loss)
I0226 15:04:26.313346  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.734935 (* 1 = 0.734935 loss)
I0226 15:04:26.313372  7672 sgd_solver.cpp:106] Iteration 2660, lr = 5.445e-05
I0226 15:04:58.192304  7672 solver.cpp:229] Iteration 2670, loss = 0.99683
I0226 15:04:58.192350  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.286731 (* 1 = 0.286731 loss)
I0226 15:04:58.192365  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.637851 (* 1 = 0.637851 loss)
I0226 15:04:58.192380  7672 sgd_solver.cpp:106] Iteration 2670, lr = 5.445e-05
I0226 15:05:29.389278  7672 solver.cpp:229] Iteration 2680, loss = 0.916483
I0226 15:05:29.389331  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.277211 (* 1 = 0.277211 loss)
I0226 15:05:29.389348  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.770769 (* 1 = 0.770769 loss)
I0226 15:05:29.389364  7672 sgd_solver.cpp:106] Iteration 2680, lr = 5.445e-05
I0226 15:06:00.468219  7672 solver.cpp:229] Iteration 2690, loss = 0.931095
I0226 15:06:00.468267  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.290856 (* 1 = 0.290856 loss)
I0226 15:06:00.468286  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.627668 (* 1 = 0.627668 loss)
I0226 15:06:00.468303  7672 sgd_solver.cpp:106] Iteration 2690, lr = 5.445e-05
I0226 15:06:31.689678  7672 solver.cpp:229] Iteration 2700, loss = 0.852374
I0226 15:06:31.689735  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.211919 (* 1 = 0.211919 loss)
I0226 15:06:31.689746  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.569849 (* 1 = 0.569849 loss)
I0226 15:06:31.689757  7672 sgd_solver.cpp:106] Iteration 2700, lr = 5.445e-05
I0226 15:07:02.468736  7672 solver.cpp:229] Iteration 2710, loss = 0.909393
I0226 15:07:02.468780  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.244243 (* 1 = 0.244243 loss)
I0226 15:07:02.468793  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.627754 (* 1 = 0.627754 loss)
I0226 15:07:02.468813  7672 sgd_solver.cpp:106] Iteration 2710, lr = 5.445e-05
I0226 15:07:33.573472  7672 solver.cpp:229] Iteration 2720, loss = 0.920243
I0226 15:07:33.573510  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.249344 (* 1 = 0.249344 loss)
I0226 15:07:33.573521  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.767251 (* 1 = 0.767251 loss)
I0226 15:07:33.573534  7672 sgd_solver.cpp:106] Iteration 2720, lr = 5.445e-05
I0226 15:08:04.450178  7672 solver.cpp:229] Iteration 2730, loss = 0.918306
I0226 15:08:04.450228  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.248088 (* 1 = 0.248088 loss)
I0226 15:08:04.450248  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.567162 (* 1 = 0.567162 loss)
I0226 15:08:04.450259  7672 sgd_solver.cpp:106] Iteration 2730, lr = 5.445e-05
I0226 15:08:35.061234  7672 solver.cpp:229] Iteration 2740, loss = 0.897422
I0226 15:08:35.061282  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.269798 (* 1 = 0.269798 loss)
I0226 15:08:35.061295  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.588581 (* 1 = 0.588581 loss)
I0226 15:08:35.061305  7672 sgd_solver.cpp:106] Iteration 2740, lr = 5.445e-05
I0226 15:09:06.016820  7672 solver.cpp:229] Iteration 2750, loss = 0.93055
I0226 15:09:06.016887  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.241567 (* 1 = 0.241567 loss)
I0226 15:09:06.016904  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.590602 (* 1 = 0.590602 loss)
I0226 15:09:06.016922  7672 sgd_solver.cpp:106] Iteration 2750, lr = 5.445e-05
I0226 15:09:36.740151  7672 solver.cpp:229] Iteration 2760, loss = 0.954323
I0226 15:09:36.740195  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.272333 (* 1 = 0.272333 loss)
I0226 15:09:36.740206  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.772321 (* 1 = 0.772321 loss)
I0226 15:09:36.740216  7672 sgd_solver.cpp:106] Iteration 2760, lr = 5.445e-05
I0226 15:10:08.117700  7672 solver.cpp:229] Iteration 2770, loss = 0.948612
I0226 15:10:08.117741  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.251707 (* 1 = 0.251707 loss)
I0226 15:10:08.117753  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.668866 (* 1 = 0.668866 loss)
I0226 15:10:08.117764  7672 sgd_solver.cpp:106] Iteration 2770, lr = 5.445e-05
I0226 15:10:39.204203  7672 solver.cpp:229] Iteration 2780, loss = 0.913542
I0226 15:10:39.204246  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.263683 (* 1 = 0.263683 loss)
I0226 15:10:39.204258  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.704972 (* 1 = 0.704972 loss)
I0226 15:10:39.204273  7672 sgd_solver.cpp:106] Iteration 2780, lr = 5.445e-05
I0226 15:11:10.380410  7672 solver.cpp:229] Iteration 2790, loss = 1.06229
I0226 15:11:10.380458  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.279953 (* 1 = 0.279953 loss)
I0226 15:11:10.380470  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.979529 (* 1 = 0.979529 loss)
I0226 15:11:10.380481  7672 sgd_solver.cpp:106] Iteration 2790, lr = 5.445e-05
I0226 15:11:41.848388  7672 solver.cpp:229] Iteration 2800, loss = 0.906873
I0226 15:11:41.848434  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.289318 (* 1 = 0.289318 loss)
I0226 15:11:41.848453  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.677968 (* 1 = 0.677968 loss)
I0226 15:11:41.848469  7672 sgd_solver.cpp:106] Iteration 2800, lr = 5.445e-05
I0226 15:12:12.247006  7672 solver.cpp:229] Iteration 2810, loss = 0.909462
I0226 15:12:12.247067  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.239006 (* 1 = 0.239006 loss)
I0226 15:12:12.247087  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.904421 (* 1 = 0.904421 loss)
I0226 15:12:12.247103  7672 sgd_solver.cpp:106] Iteration 2810, lr = 5.445e-05
I0226 15:12:43.028247  7672 solver.cpp:229] Iteration 2820, loss = 0.988381
I0226 15:12:43.028295  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.274267 (* 1 = 0.274267 loss)
I0226 15:12:43.028316  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.645289 (* 1 = 0.645289 loss)
I0226 15:12:43.028331  7672 sgd_solver.cpp:106] Iteration 2820, lr = 5.445e-05
I0226 15:13:14.234992  7672 solver.cpp:229] Iteration 2830, loss = 0.934147
I0226 15:13:14.235033  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.209839 (* 1 = 0.209839 loss)
I0226 15:13:14.235047  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.693493 (* 1 = 0.693493 loss)
I0226 15:13:14.235061  7672 sgd_solver.cpp:106] Iteration 2830, lr = 5.445e-05
I0226 15:13:46.017109  7672 solver.cpp:229] Iteration 2840, loss = 0.942146
I0226 15:13:46.017149  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.24186 (* 1 = 0.24186 loss)
I0226 15:13:46.017161  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.64722 (* 1 = 0.64722 loss)
I0226 15:13:46.017171  7672 sgd_solver.cpp:106] Iteration 2840, lr = 5.445e-05
I0226 15:14:16.983333  7672 solver.cpp:229] Iteration 2850, loss = 0.902648
I0226 15:14:16.983382  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.24469 (* 1 = 0.24469 loss)
I0226 15:14:16.983395  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.651618 (* 1 = 0.651618 loss)
I0226 15:14:16.983405  7672 sgd_solver.cpp:106] Iteration 2850, lr = 5.445e-05
I0226 15:14:47.779601  7672 solver.cpp:229] Iteration 2860, loss = 0.892033
I0226 15:14:47.779654  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.23837 (* 1 = 0.23837 loss)
I0226 15:14:47.779665  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.646342 (* 1 = 0.646342 loss)
I0226 15:14:47.779675  7672 sgd_solver.cpp:106] Iteration 2860, lr = 5.445e-05
I0226 15:15:18.370278  7672 solver.cpp:229] Iteration 2870, loss = 0.912702
I0226 15:15:18.370321  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.216148 (* 1 = 0.216148 loss)
I0226 15:15:18.370333  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.863056 (* 1 = 0.863056 loss)
I0226 15:15:18.370344  7672 sgd_solver.cpp:106] Iteration 2870, lr = 5.445e-05
I0226 15:15:49.588035  7672 solver.cpp:229] Iteration 2880, loss = 0.890648
I0226 15:15:49.588091  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.262263 (* 1 = 0.262263 loss)
I0226 15:15:49.588102  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.560196 (* 1 = 0.560196 loss)
I0226 15:15:49.588112  7672 sgd_solver.cpp:106] Iteration 2880, lr = 5.445e-05
I0226 15:16:19.909814  7672 solver.cpp:229] Iteration 2890, loss = 0.911437
I0226 15:16:19.909857  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.244576 (* 1 = 0.244576 loss)
I0226 15:16:19.909868  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.763683 (* 1 = 0.763683 loss)
I0226 15:16:19.909878  7672 sgd_solver.cpp:106] Iteration 2890, lr = 5.445e-05
I0226 15:16:49.906100  7672 solver.cpp:229] Iteration 2900, loss = 0.880213
I0226 15:16:49.906164  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.265736 (* 1 = 0.265736 loss)
I0226 15:16:49.906189  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.699741 (* 1 = 0.699741 loss)
I0226 15:16:49.906208  7672 sgd_solver.cpp:106] Iteration 2900, lr = 5.445e-05
I0226 15:17:20.578249  7672 solver.cpp:229] Iteration 2910, loss = 0.985254
I0226 15:17:20.578297  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.243607 (* 1 = 0.243607 loss)
I0226 15:17:20.578308  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.523897 (* 1 = 0.523897 loss)
I0226 15:17:20.578322  7672 sgd_solver.cpp:106] Iteration 2910, lr = 5.445e-05
I0226 15:17:51.133656  7672 solver.cpp:229] Iteration 2920, loss = 0.897839
I0226 15:17:51.133697  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.255652 (* 1 = 0.255652 loss)
I0226 15:17:51.133709  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.578304 (* 1 = 0.578304 loss)
I0226 15:17:51.133719  7672 sgd_solver.cpp:106] Iteration 2920, lr = 5.445e-05
I0226 15:18:22.074218  7672 solver.cpp:229] Iteration 2930, loss = 0.985816
I0226 15:18:22.074283  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.241005 (* 1 = 0.241005 loss)
I0226 15:18:22.074295  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.880025 (* 1 = 0.880025 loss)
I0226 15:18:22.074306  7672 sgd_solver.cpp:106] Iteration 2930, lr = 5.445e-05
I0226 15:18:52.645421  7672 solver.cpp:229] Iteration 2940, loss = 0.982627
I0226 15:18:52.645474  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.241503 (* 1 = 0.241503 loss)
I0226 15:18:52.645493  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.721748 (* 1 = 0.721748 loss)
I0226 15:18:52.645509  7672 sgd_solver.cpp:106] Iteration 2940, lr = 5.445e-05
I0226 15:19:23.690829  7672 solver.cpp:229] Iteration 2950, loss = 0.952178
I0226 15:19:23.690912  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.277469 (* 1 = 0.277469 loss)
I0226 15:19:23.690941  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.765189 (* 1 = 0.765189 loss)
I0226 15:19:23.690953  7672 sgd_solver.cpp:106] Iteration 2950, lr = 5.445e-05
I0226 15:19:54.607792  7672 solver.cpp:229] Iteration 2960, loss = 0.899677
I0226 15:19:54.607839  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.274256 (* 1 = 0.274256 loss)
I0226 15:19:54.607851  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.697095 (* 1 = 0.697095 loss)
I0226 15:19:54.607862  7672 sgd_solver.cpp:106] Iteration 2960, lr = 5.445e-05
I0226 15:20:25.907984  7672 solver.cpp:229] Iteration 2970, loss = 0.912258
I0226 15:20:25.908026  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.224243 (* 1 = 0.224243 loss)
I0226 15:20:25.908037  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.547669 (* 1 = 0.547669 loss)
I0226 15:20:25.908048  7672 sgd_solver.cpp:106] Iteration 2970, lr = 5.445e-05
I0226 15:20:56.246963  7672 solver.cpp:229] Iteration 2980, loss = 0.931322
I0226 15:20:56.247025  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.223745 (* 1 = 0.223745 loss)
I0226 15:20:56.247045  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.693361 (* 1 = 0.693361 loss)
I0226 15:20:56.247061  7672 sgd_solver.cpp:106] Iteration 2980, lr = 5.445e-05
I0226 15:21:27.906718  7672 solver.cpp:229] Iteration 2990, loss = 0.876685
I0226 15:21:27.906798  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.248314 (* 1 = 0.248314 loss)
I0226 15:21:27.906814  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.580447 (* 1 = 0.580447 loss)
I0226 15:21:27.906833  7672 sgd_solver.cpp:106] Iteration 2990, lr = 5.445e-05
I0226 15:21:59.494259  7672 solver.cpp:229] Iteration 3000, loss = 0.962165
I0226 15:21:59.494314  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.273307 (* 1 = 0.273307 loss)
I0226 15:21:59.494333  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.606884 (* 1 = 0.606884 loss)
I0226 15:21:59.494352  7672 sgd_solver.cpp:106] Iteration 3000, lr = 1.79685e-05
I0226 15:22:29.989780  7672 solver.cpp:229] Iteration 3010, loss = 0.937652
I0226 15:22:29.989823  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.22984 (* 1 = 0.22984 loss)
I0226 15:22:29.989835  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.836305 (* 1 = 0.836305 loss)
I0226 15:22:29.989845  7672 sgd_solver.cpp:106] Iteration 3010, lr = 1.79685e-05
I0226 15:23:00.171015  7672 solver.cpp:229] Iteration 3020, loss = 0.886737
I0226 15:23:00.171073  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.25726 (* 1 = 0.25726 loss)
I0226 15:23:00.171085  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.784013 (* 1 = 0.784013 loss)
I0226 15:23:00.171097  7672 sgd_solver.cpp:106] Iteration 3020, lr = 1.79685e-05
I0226 15:23:31.459524  7672 solver.cpp:229] Iteration 3030, loss = 0.904983
I0226 15:23:31.459586  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.24158 (* 1 = 0.24158 loss)
I0226 15:23:31.459604  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.77588 (* 1 = 0.77588 loss)
I0226 15:23:31.459620  7672 sgd_solver.cpp:106] Iteration 3030, lr = 1.79685e-05
I0226 15:24:01.737414  7672 solver.cpp:229] Iteration 3040, loss = 0.922413
I0226 15:24:01.737459  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.212028 (* 1 = 0.212028 loss)
I0226 15:24:01.737471  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.504948 (* 1 = 0.504948 loss)
I0226 15:24:01.737483  7672 sgd_solver.cpp:106] Iteration 3040, lr = 1.79685e-05
I0226 15:24:32.036816  7672 solver.cpp:229] Iteration 3050, loss = 0.9379
I0226 15:24:32.036856  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.288492 (* 1 = 0.288492 loss)
I0226 15:24:32.036868  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.654096 (* 1 = 0.654096 loss)
I0226 15:24:32.036878  7672 sgd_solver.cpp:106] Iteration 3050, lr = 1.79685e-05
I0226 15:25:02.628181  7672 solver.cpp:229] Iteration 3060, loss = 0.902547
I0226 15:25:02.628232  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.269339 (* 1 = 0.269339 loss)
I0226 15:25:02.628254  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.624105 (* 1 = 0.624105 loss)
I0226 15:25:02.628271  7672 sgd_solver.cpp:106] Iteration 3060, lr = 1.79685e-05
I0226 15:25:33.302431  7672 solver.cpp:229] Iteration 3070, loss = 1.01389
I0226 15:25:33.302481  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.256631 (* 1 = 0.256631 loss)
I0226 15:25:33.302496  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.804896 (* 1 = 0.804896 loss)
I0226 15:25:33.302515  7672 sgd_solver.cpp:106] Iteration 3070, lr = 1.79685e-05
I0226 15:26:04.130676  7672 solver.cpp:229] Iteration 3080, loss = 0.910112
I0226 15:26:04.130733  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.26205 (* 1 = 0.26205 loss)
I0226 15:26:04.130743  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.585989 (* 1 = 0.585989 loss)
I0226 15:26:04.130754  7672 sgd_solver.cpp:106] Iteration 3080, lr = 1.79685e-05
I0226 15:26:35.019729  7672 solver.cpp:229] Iteration 3090, loss = 0.901251
I0226 15:26:35.019770  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.237878 (* 1 = 0.237878 loss)
I0226 15:26:35.019783  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.797823 (* 1 = 0.797823 loss)
I0226 15:26:35.019793  7672 sgd_solver.cpp:106] Iteration 3090, lr = 1.79685e-05
I0226 15:27:05.552230  7672 solver.cpp:229] Iteration 3100, loss = 0.909511
I0226 15:27:05.552273  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.246563 (* 1 = 0.246563 loss)
I0226 15:27:05.552285  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.582912 (* 1 = 0.582912 loss)
I0226 15:27:05.552297  7672 sgd_solver.cpp:106] Iteration 3100, lr = 1.79685e-05
I0226 15:27:36.662362  7672 solver.cpp:229] Iteration 3110, loss = 0.942976
I0226 15:27:36.662405  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.266644 (* 1 = 0.266644 loss)
I0226 15:27:36.662416  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.76903 (* 1 = 0.76903 loss)
I0226 15:27:36.662428  7672 sgd_solver.cpp:106] Iteration 3110, lr = 1.79685e-05
I0226 15:28:06.942522  7672 solver.cpp:229] Iteration 3120, loss = 0.916562
I0226 15:28:06.942585  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.250462 (* 1 = 0.250462 loss)
I0226 15:28:06.942603  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.521314 (* 1 = 0.521314 loss)
I0226 15:28:06.942622  7672 sgd_solver.cpp:106] Iteration 3120, lr = 1.79685e-05
I0226 15:28:37.689961  7672 solver.cpp:229] Iteration 3130, loss = 0.890448
I0226 15:28:37.690021  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.281121 (* 1 = 0.281121 loss)
I0226 15:28:37.690033  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.772733 (* 1 = 0.772733 loss)
I0226 15:28:37.690044  7672 sgd_solver.cpp:106] Iteration 3130, lr = 1.79685e-05
I0226 15:29:08.398092  7672 solver.cpp:229] Iteration 3140, loss = 0.902456
I0226 15:29:08.398147  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.244111 (* 1 = 0.244111 loss)
I0226 15:29:08.398159  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.537156 (* 1 = 0.537156 loss)
I0226 15:29:08.398169  7672 sgd_solver.cpp:106] Iteration 3140, lr = 1.79685e-05
I0226 15:29:39.628739  7672 solver.cpp:229] Iteration 3150, loss = 0.953349
I0226 15:29:39.628779  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.280764 (* 1 = 0.280764 loss)
I0226 15:29:39.628790  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.925233 (* 1 = 0.925233 loss)
I0226 15:29:39.628801  7672 sgd_solver.cpp:106] Iteration 3150, lr = 1.79685e-05
I0226 15:30:10.484380  7672 solver.cpp:229] Iteration 3160, loss = 0.949326
I0226 15:30:10.484424  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.250513 (* 1 = 0.250513 loss)
I0226 15:30:10.484441  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.753707 (* 1 = 0.753707 loss)
I0226 15:30:10.484455  7672 sgd_solver.cpp:106] Iteration 3160, lr = 1.79685e-05
I0226 15:30:41.147372  7672 solver.cpp:229] Iteration 3170, loss = 0.903481
I0226 15:30:41.147433  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.249024 (* 1 = 0.249024 loss)
I0226 15:30:41.147470  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.990111 (* 1 = 0.990111 loss)
I0226 15:30:41.147490  7672 sgd_solver.cpp:106] Iteration 3170, lr = 1.79685e-05
I0226 15:31:12.561606  7672 solver.cpp:229] Iteration 3180, loss = 0.87953
I0226 15:31:12.561666  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.228097 (* 1 = 0.228097 loss)
I0226 15:31:12.561682  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.607051 (* 1 = 0.607051 loss)
I0226 15:31:12.561694  7672 sgd_solver.cpp:106] Iteration 3180, lr = 1.79685e-05
I0226 15:31:43.779783  7672 solver.cpp:229] Iteration 3190, loss = 0.941632
I0226 15:31:43.779829  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.256587 (* 1 = 0.256587 loss)
I0226 15:31:43.779842  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.939705 (* 1 = 0.939705 loss)
I0226 15:31:43.779855  7672 sgd_solver.cpp:106] Iteration 3190, lr = 1.79685e-05
I0226 15:32:14.519912  7672 solver.cpp:229] Iteration 3200, loss = 0.945389
I0226 15:32:14.519968  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.246542 (* 1 = 0.246542 loss)
I0226 15:32:14.519987  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.634357 (* 1 = 0.634357 loss)
I0226 15:32:14.520002  7672 sgd_solver.cpp:106] Iteration 3200, lr = 1.79685e-05
I0226 15:32:45.794564  7672 solver.cpp:229] Iteration 3210, loss = 0.910493
I0226 15:32:45.794605  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.268553 (* 1 = 0.268553 loss)
I0226 15:32:45.794617  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.606887 (* 1 = 0.606887 loss)
I0226 15:32:45.794629  7672 sgd_solver.cpp:106] Iteration 3210, lr = 1.79685e-05
I0226 15:33:16.258422  7672 solver.cpp:229] Iteration 3220, loss = 0.913033
I0226 15:33:16.258530  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.246229 (* 1 = 0.246229 loss)
I0226 15:33:16.258550  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.742452 (* 1 = 0.742452 loss)
I0226 15:33:16.258565  7672 sgd_solver.cpp:106] Iteration 3220, lr = 1.79685e-05
I0226 15:33:47.967206  7672 solver.cpp:229] Iteration 3230, loss = 0.93017
I0226 15:33:47.967293  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.25948 (* 1 = 0.25948 loss)
I0226 15:33:47.967339  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.649892 (* 1 = 0.649892 loss)
I0226 15:33:47.967365  7672 sgd_solver.cpp:106] Iteration 3230, lr = 1.79685e-05
I0226 15:34:19.151739  7672 solver.cpp:229] Iteration 3240, loss = 0.957619
I0226 15:34:19.151782  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.278967 (* 1 = 0.278967 loss)
I0226 15:34:19.151794  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.893713 (* 1 = 0.893713 loss)
I0226 15:34:19.151805  7672 sgd_solver.cpp:106] Iteration 3240, lr = 1.79685e-05
I0226 15:34:50.132982  7672 solver.cpp:229] Iteration 3250, loss = 0.862224
I0226 15:34:50.133029  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.284365 (* 1 = 0.284365 loss)
I0226 15:34:50.133042  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.878677 (* 1 = 0.878677 loss)
I0226 15:34:50.133054  7672 sgd_solver.cpp:106] Iteration 3250, lr = 1.79685e-05
I0226 15:35:21.058563  7672 solver.cpp:229] Iteration 3260, loss = 0.910959
I0226 15:35:21.058609  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.227564 (* 1 = 0.227564 loss)
I0226 15:35:21.058620  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.653756 (* 1 = 0.653756 loss)
I0226 15:35:21.058632  7672 sgd_solver.cpp:106] Iteration 3260, lr = 1.79685e-05
I0226 15:35:52.212105  7672 solver.cpp:229] Iteration 3270, loss = 0.912805
I0226 15:35:52.212149  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.248251 (* 1 = 0.248251 loss)
I0226 15:35:52.212160  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.926405 (* 1 = 0.926405 loss)
I0226 15:35:52.212172  7672 sgd_solver.cpp:106] Iteration 3270, lr = 1.79685e-05
I0226 15:36:23.223393  7672 solver.cpp:229] Iteration 3280, loss = 0.923939
I0226 15:36:23.223435  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.261973 (* 1 = 0.261973 loss)
I0226 15:36:23.223446  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.651278 (* 1 = 0.651278 loss)
I0226 15:36:23.223459  7672 sgd_solver.cpp:106] Iteration 3280, lr = 1.79685e-05
I0226 15:36:53.838372  7672 solver.cpp:229] Iteration 3290, loss = 0.922211
I0226 15:36:53.838440  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.262147 (* 1 = 0.262147 loss)
I0226 15:36:53.838459  7672 solver.cpp:245]     Train net output #1: loss-Seed = 1.0034 (* 1 = 1.0034 loss)
I0226 15:36:53.838475  7672 sgd_solver.cpp:106] Iteration 3290, lr = 1.79685e-05
I0226 15:37:24.563259  7672 solver.cpp:229] Iteration 3300, loss = 0.918348
I0226 15:37:24.563297  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.250012 (* 1 = 0.250012 loss)
I0226 15:37:24.563308  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.53151 (* 1 = 0.53151 loss)
I0226 15:37:24.563319  7672 sgd_solver.cpp:106] Iteration 3300, lr = 1.79685e-05
I0226 15:37:55.308712  7672 solver.cpp:229] Iteration 3310, loss = 0.896851
I0226 15:37:55.308753  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.292586 (* 1 = 0.292586 loss)
I0226 15:37:55.308764  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.829767 (* 1 = 0.829767 loss)
I0226 15:37:55.308775  7672 sgd_solver.cpp:106] Iteration 3310, lr = 1.79685e-05
I0226 15:38:25.799655  7672 solver.cpp:229] Iteration 3320, loss = 0.956316
I0226 15:38:25.799703  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.311275 (* 1 = 0.311275 loss)
I0226 15:38:25.799718  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.84839 (* 1 = 0.84839 loss)
I0226 15:38:25.799733  7672 sgd_solver.cpp:106] Iteration 3320, lr = 1.79685e-05
I0226 15:38:56.515076  7672 solver.cpp:229] Iteration 3330, loss = 0.877461
I0226 15:38:56.515132  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.271995 (* 1 = 0.271995 loss)
I0226 15:38:56.515146  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.622843 (* 1 = 0.622843 loss)
I0226 15:38:56.515157  7672 sgd_solver.cpp:106] Iteration 3330, lr = 1.79685e-05
I0226 15:39:26.836376  7672 solver.cpp:229] Iteration 3340, loss = 0.863516
I0226 15:39:26.836427  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.217685 (* 1 = 0.217685 loss)
I0226 15:39:26.836443  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.593225 (* 1 = 0.593225 loss)
I0226 15:39:26.836459  7672 sgd_solver.cpp:106] Iteration 3340, lr = 1.79685e-05
I0226 15:39:58.446105  7672 solver.cpp:229] Iteration 3350, loss = 0.916168
I0226 15:39:58.446174  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.202297 (* 1 = 0.202297 loss)
I0226 15:39:58.446187  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.633741 (* 1 = 0.633741 loss)
I0226 15:39:58.446202  7672 sgd_solver.cpp:106] Iteration 3350, lr = 1.79685e-05
I0226 15:40:29.342860  7672 solver.cpp:229] Iteration 3360, loss = 0.999475
I0226 15:40:29.342918  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.244358 (* 1 = 0.244358 loss)
I0226 15:40:29.342931  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.618216 (* 1 = 0.618216 loss)
I0226 15:40:29.342941  7672 sgd_solver.cpp:106] Iteration 3360, lr = 1.79685e-05
I0226 15:41:00.286172  7672 solver.cpp:229] Iteration 3370, loss = 0.894111
I0226 15:41:00.286223  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.237696 (* 1 = 0.237696 loss)
I0226 15:41:00.286240  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.583616 (* 1 = 0.583616 loss)
I0226 15:41:00.286255  7672 sgd_solver.cpp:106] Iteration 3370, lr = 1.79685e-05
I0226 15:41:31.403425  7672 solver.cpp:229] Iteration 3380, loss = 0.920101
I0226 15:41:31.403468  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.255715 (* 1 = 0.255715 loss)
I0226 15:41:31.403481  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.558409 (* 1 = 0.558409 loss)
I0226 15:41:31.403491  7672 sgd_solver.cpp:106] Iteration 3380, lr = 1.79685e-05
I0226 15:42:02.586199  7672 solver.cpp:229] Iteration 3390, loss = 0.914983
I0226 15:42:02.586241  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.238519 (* 1 = 0.238519 loss)
I0226 15:42:02.586252  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.671394 (* 1 = 0.671394 loss)
I0226 15:42:02.586264  7672 sgd_solver.cpp:106] Iteration 3390, lr = 1.79685e-05
I0226 15:42:33.179076  7672 solver.cpp:229] Iteration 3400, loss = 0.909977
I0226 15:42:33.179116  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.24748 (* 1 = 0.24748 loss)
I0226 15:42:33.179128  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.824642 (* 1 = 0.824642 loss)
I0226 15:42:33.179138  7672 sgd_solver.cpp:106] Iteration 3400, lr = 1.79685e-05
I0226 15:43:03.316787  7672 solver.cpp:229] Iteration 3410, loss = 0.895098
I0226 15:43:03.316860  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.247514 (* 1 = 0.247514 loss)
I0226 15:43:03.316887  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.515189 (* 1 = 0.515189 loss)
I0226 15:43:03.316915  7672 sgd_solver.cpp:106] Iteration 3410, lr = 1.79685e-05
I0226 15:43:34.154201  7672 solver.cpp:229] Iteration 3420, loss = 0.895573
I0226 15:43:34.154238  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.263878 (* 1 = 0.263878 loss)
I0226 15:43:34.154250  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.602878 (* 1 = 0.602878 loss)
I0226 15:43:34.154261  7672 sgd_solver.cpp:106] Iteration 3420, lr = 1.79685e-05
I0226 15:44:04.703821  7672 solver.cpp:229] Iteration 3430, loss = 0.898311
I0226 15:44:04.703896  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.257169 (* 1 = 0.257169 loss)
I0226 15:44:04.703930  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.579893 (* 1 = 0.579893 loss)
I0226 15:44:04.703948  7672 sgd_solver.cpp:106] Iteration 3430, lr = 1.79685e-05
I0226 15:44:35.164012  7672 solver.cpp:229] Iteration 3440, loss = 0.872105
I0226 15:44:35.164067  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.242378 (* 1 = 0.242378 loss)
I0226 15:44:35.164077  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.70622 (* 1 = 0.70622 loss)
I0226 15:44:35.164088  7672 sgd_solver.cpp:106] Iteration 3440, lr = 1.79685e-05
I0226 15:45:05.669718  7672 solver.cpp:229] Iteration 3450, loss = 0.915251
I0226 15:45:05.669764  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.238943 (* 1 = 0.238943 loss)
I0226 15:45:05.669776  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.514318 (* 1 = 0.514318 loss)
I0226 15:45:05.669787  7672 sgd_solver.cpp:106] Iteration 3450, lr = 1.79685e-05
I0226 15:45:36.533107  7672 solver.cpp:229] Iteration 3460, loss = 0.934865
I0226 15:45:36.533171  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.221112 (* 1 = 0.221112 loss)
I0226 15:45:36.533192  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.857752 (* 1 = 0.857752 loss)
I0226 15:45:36.533215  7672 sgd_solver.cpp:106] Iteration 3460, lr = 1.79685e-05
I0226 15:46:07.405411  7672 solver.cpp:229] Iteration 3470, loss = 0.897937
I0226 15:46:07.405453  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.273694 (* 1 = 0.273694 loss)
I0226 15:46:07.405465  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.784081 (* 1 = 0.784081 loss)
I0226 15:46:07.405477  7672 sgd_solver.cpp:106] Iteration 3470, lr = 1.79685e-05
I0226 15:46:37.966629  7672 solver.cpp:229] Iteration 3480, loss = 0.92279
I0226 15:46:37.966670  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.252627 (* 1 = 0.252627 loss)
I0226 15:46:37.966681  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.896722 (* 1 = 0.896722 loss)
I0226 15:46:37.966691  7672 sgd_solver.cpp:106] Iteration 3480, lr = 1.79685e-05
I0226 15:47:08.652781  7672 solver.cpp:229] Iteration 3490, loss = 0.924631
I0226 15:47:08.652824  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.259975 (* 1 = 0.259975 loss)
I0226 15:47:08.652838  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.693715 (* 1 = 0.693715 loss)
I0226 15:47:08.652849  7672 sgd_solver.cpp:106] Iteration 3490, lr = 1.79685e-05
I0226 15:47:39.773648  7672 solver.cpp:229] Iteration 3500, loss = 0.921074
I0226 15:47:39.773690  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.201494 (* 1 = 0.201494 loss)
I0226 15:47:39.773702  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.684005 (* 1 = 0.684005 loss)
I0226 15:47:39.773715  7672 sgd_solver.cpp:106] Iteration 3500, lr = 1.79685e-05
I0226 15:48:10.874675  7672 solver.cpp:229] Iteration 3510, loss = 0.925057
I0226 15:48:10.874729  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.228433 (* 1 = 0.228433 loss)
I0226 15:48:10.874740  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.660611 (* 1 = 0.660611 loss)
I0226 15:48:10.874766  7672 sgd_solver.cpp:106] Iteration 3510, lr = 1.79685e-05
I0226 15:48:41.165136  7672 solver.cpp:229] Iteration 3520, loss = 1.015
I0226 15:48:41.165179  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.306357 (* 1 = 0.306357 loss)
I0226 15:48:41.165190  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.720786 (* 1 = 0.720786 loss)
I0226 15:48:41.165201  7672 sgd_solver.cpp:106] Iteration 3520, lr = 1.79685e-05
I0226 15:49:12.305162  7672 solver.cpp:229] Iteration 3530, loss = 0.922019
I0226 15:49:12.305209  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.228545 (* 1 = 0.228545 loss)
I0226 15:49:12.305225  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.629836 (* 1 = 0.629836 loss)
I0226 15:49:12.305238  7672 sgd_solver.cpp:106] Iteration 3530, lr = 1.79685e-05
I0226 15:49:42.951223  7672 solver.cpp:229] Iteration 3540, loss = 0.885533
I0226 15:49:42.951279  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.249161 (* 1 = 0.249161 loss)
I0226 15:49:42.951303  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.537279 (* 1 = 0.537279 loss)
I0226 15:49:42.951323  7672 sgd_solver.cpp:106] Iteration 3540, lr = 1.79685e-05
I0226 15:50:13.556411  7672 solver.cpp:229] Iteration 3550, loss = 0.906821
I0226 15:50:13.556458  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.233246 (* 1 = 0.233246 loss)
I0226 15:50:13.556473  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.481168 (* 1 = 0.481168 loss)
I0226 15:50:13.556484  7672 sgd_solver.cpp:106] Iteration 3550, lr = 1.79685e-05
I0226 15:50:44.665992  7672 solver.cpp:229] Iteration 3560, loss = 0.917387
I0226 15:50:44.666036  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.264748 (* 1 = 0.264748 loss)
I0226 15:50:44.666047  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.742676 (* 1 = 0.742676 loss)
I0226 15:50:44.666059  7672 sgd_solver.cpp:106] Iteration 3560, lr = 1.79685e-05
I0226 15:51:15.210326  7672 solver.cpp:229] Iteration 3570, loss = 0.872171
I0226 15:51:15.210391  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.243975 (* 1 = 0.243975 loss)
I0226 15:51:15.210412  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.742277 (* 1 = 0.742277 loss)
I0226 15:51:15.210431  7672 sgd_solver.cpp:106] Iteration 3570, lr = 1.79685e-05
I0226 15:51:46.514554  7672 solver.cpp:229] Iteration 3580, loss = 0.872951
I0226 15:51:46.514616  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.221122 (* 1 = 0.221122 loss)
I0226 15:51:46.514628  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.685546 (* 1 = 0.685546 loss)
I0226 15:51:46.514638  7672 sgd_solver.cpp:106] Iteration 3580, lr = 1.79685e-05
I0226 15:52:17.129355  7672 solver.cpp:229] Iteration 3590, loss = 0.930519
I0226 15:52:17.129406  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.233904 (* 1 = 0.233904 loss)
I0226 15:52:17.129423  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.744465 (* 1 = 0.744465 loss)
I0226 15:52:17.129436  7672 sgd_solver.cpp:106] Iteration 3590, lr = 1.79685e-05
I0226 15:52:48.252032  7672 solver.cpp:229] Iteration 3600, loss = 0.999169
I0226 15:52:48.252089  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.259372 (* 1 = 0.259372 loss)
I0226 15:52:48.252110  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.984404 (* 1 = 0.984404 loss)
I0226 15:52:48.252127  7672 sgd_solver.cpp:106] Iteration 3600, lr = 1.79685e-05
I0226 15:53:19.232533  7672 solver.cpp:229] Iteration 3610, loss = 0.952182
I0226 15:53:19.232575  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.231027 (* 1 = 0.231027 loss)
I0226 15:53:19.232587  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.547361 (* 1 = 0.547361 loss)
I0226 15:53:19.232599  7672 sgd_solver.cpp:106] Iteration 3610, lr = 1.79685e-05
I0226 15:53:49.579566  7672 solver.cpp:229] Iteration 3620, loss = 0.938916
I0226 15:53:49.579602  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.267194 (* 1 = 0.267194 loss)
I0226 15:53:49.579613  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.819554 (* 1 = 0.819554 loss)
I0226 15:53:49.579625  7672 sgd_solver.cpp:106] Iteration 3620, lr = 1.79685e-05
I0226 15:54:20.983534  7672 solver.cpp:229] Iteration 3630, loss = 0.888405
I0226 15:54:20.983587  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.272329 (* 1 = 0.272329 loss)
I0226 15:54:20.983608  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.677906 (* 1 = 0.677906 loss)
I0226 15:54:20.983619  7672 sgd_solver.cpp:106] Iteration 3630, lr = 1.79685e-05
I0226 15:54:52.144968  7672 solver.cpp:229] Iteration 3640, loss = 1.01729
I0226 15:54:52.145014  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.249441 (* 1 = 0.249441 loss)
I0226 15:54:52.145030  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.836813 (* 1 = 0.836813 loss)
I0226 15:54:52.145042  7672 sgd_solver.cpp:106] Iteration 3640, lr = 1.79685e-05
I0226 15:55:23.384181  7672 solver.cpp:229] Iteration 3650, loss = 1.00823
I0226 15:55:23.384220  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.250266 (* 1 = 0.250266 loss)
I0226 15:55:23.384232  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.671941 (* 1 = 0.671941 loss)
I0226 15:55:23.384243  7672 sgd_solver.cpp:106] Iteration 3650, lr = 1.79685e-05
I0226 15:55:53.773870  7672 solver.cpp:229] Iteration 3660, loss = 0.858763
I0226 15:55:53.773932  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.209695 (* 1 = 0.209695 loss)
I0226 15:55:53.773955  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.525831 (* 1 = 0.525831 loss)
I0226 15:55:53.773977  7672 sgd_solver.cpp:106] Iteration 3660, lr = 1.79685e-05
I0226 15:56:24.293568  7672 solver.cpp:229] Iteration 3670, loss = 0.892524
I0226 15:56:24.293618  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.227219 (* 1 = 0.227219 loss)
I0226 15:56:24.293629  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.608864 (* 1 = 0.608864 loss)
I0226 15:56:24.293640  7672 sgd_solver.cpp:106] Iteration 3670, lr = 1.79685e-05
I0226 15:56:55.292907  7672 solver.cpp:229] Iteration 3680, loss = 0.955359
I0226 15:56:55.292953  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.281367 (* 1 = 0.281367 loss)
I0226 15:56:55.292968  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.710178 (* 1 = 0.710178 loss)
I0226 15:56:55.292982  7672 sgd_solver.cpp:106] Iteration 3680, lr = 1.79685e-05
I0226 15:57:26.226438  7672 solver.cpp:229] Iteration 3690, loss = 0.896926
I0226 15:57:26.226495  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.221682 (* 1 = 0.221682 loss)
I0226 15:57:26.226508  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.704868 (* 1 = 0.704868 loss)
I0226 15:57:26.226526  7672 sgd_solver.cpp:106] Iteration 3690, lr = 1.79685e-05
I0226 15:57:57.489148  7672 solver.cpp:229] Iteration 3700, loss = 0.877184
I0226 15:57:57.489190  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.260091 (* 1 = 0.260091 loss)
I0226 15:57:57.489202  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.693469 (* 1 = 0.693469 loss)
I0226 15:57:57.489212  7672 sgd_solver.cpp:106] Iteration 3700, lr = 1.79685e-05
I0226 15:58:29.180985  7672 solver.cpp:229] Iteration 3710, loss = 0.903482
I0226 15:58:29.181031  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.250874 (* 1 = 0.250874 loss)
I0226 15:58:29.181043  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.688464 (* 1 = 0.688464 loss)
I0226 15:58:29.181054  7672 sgd_solver.cpp:106] Iteration 3710, lr = 1.79685e-05
I0226 15:58:59.445250  7672 solver.cpp:229] Iteration 3720, loss = 0.965856
I0226 15:58:59.445302  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.264753 (* 1 = 0.264753 loss)
I0226 15:58:59.445319  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.710082 (* 1 = 0.710082 loss)
I0226 15:58:59.445333  7672 sgd_solver.cpp:106] Iteration 3720, lr = 1.79685e-05
I0226 15:59:30.711922  7672 solver.cpp:229] Iteration 3730, loss = 0.933405
I0226 15:59:30.711973  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.242831 (* 1 = 0.242831 loss)
I0226 15:59:30.711990  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.64614 (* 1 = 0.64614 loss)
I0226 15:59:30.712008  7672 sgd_solver.cpp:106] Iteration 3730, lr = 1.79685e-05
I0226 16:00:02.998499  7672 solver.cpp:229] Iteration 3740, loss = 0.97515
I0226 16:00:02.998554  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.267289 (* 1 = 0.267289 loss)
I0226 16:00:02.998574  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.613332 (* 1 = 0.613332 loss)
I0226 16:00:02.998592  7672 sgd_solver.cpp:106] Iteration 3740, lr = 1.79685e-05
I0226 16:00:33.464145  7672 solver.cpp:229] Iteration 3750, loss = 0.91214
I0226 16:00:33.464197  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.256937 (* 1 = 0.256937 loss)
I0226 16:00:33.464212  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.825088 (* 1 = 0.825088 loss)
I0226 16:00:33.464223  7672 sgd_solver.cpp:106] Iteration 3750, lr = 1.79685e-05
I0226 16:01:03.791522  7672 solver.cpp:229] Iteration 3760, loss = 0.920436
I0226 16:01:03.791574  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.288286 (* 1 = 0.288286 loss)
I0226 16:01:03.791594  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.628728 (* 1 = 0.628728 loss)
I0226 16:01:03.791609  7672 sgd_solver.cpp:106] Iteration 3760, lr = 1.79685e-05
I0226 16:01:34.466238  7672 solver.cpp:229] Iteration 3770, loss = 0.938542
I0226 16:01:34.466346  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.277613 (* 1 = 0.277613 loss)
I0226 16:01:34.466398  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.842693 (* 1 = 0.842693 loss)
I0226 16:01:34.466439  7672 sgd_solver.cpp:106] Iteration 3770, lr = 1.79685e-05
I0226 16:02:05.632757  7672 solver.cpp:229] Iteration 3780, loss = 0.901521
I0226 16:02:05.632807  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.243323 (* 1 = 0.243323 loss)
I0226 16:02:05.632827  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.689578 (* 1 = 0.689578 loss)
I0226 16:02:05.632840  7672 sgd_solver.cpp:106] Iteration 3780, lr = 1.79685e-05
I0226 16:02:35.905490  7672 solver.cpp:229] Iteration 3790, loss = 0.921235
I0226 16:02:35.905532  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.264539 (* 1 = 0.264539 loss)
I0226 16:02:35.905544  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.700143 (* 1 = 0.700143 loss)
I0226 16:02:35.905555  7672 sgd_solver.cpp:106] Iteration 3790, lr = 1.79685e-05
I0226 16:03:06.836066  7672 solver.cpp:229] Iteration 3800, loss = 0.849313
I0226 16:03:06.836130  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.264938 (* 1 = 0.264938 loss)
I0226 16:03:06.836150  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.666908 (* 1 = 0.666908 loss)
I0226 16:03:06.836167  7672 sgd_solver.cpp:106] Iteration 3800, lr = 1.79685e-05
I0226 16:03:37.574373  7672 solver.cpp:229] Iteration 3810, loss = 0.983279
I0226 16:03:37.574417  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.256703 (* 1 = 0.256703 loss)
I0226 16:03:37.574429  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.675794 (* 1 = 0.675794 loss)
I0226 16:03:37.574440  7672 sgd_solver.cpp:106] Iteration 3810, lr = 1.79685e-05
I0226 16:04:07.822646  7672 solver.cpp:229] Iteration 3820, loss = 0.946594
I0226 16:04:07.822724  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.250258 (* 1 = 0.250258 loss)
I0226 16:04:07.822746  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.56887 (* 1 = 0.56887 loss)
I0226 16:04:07.822765  7672 sgd_solver.cpp:106] Iteration 3820, lr = 1.79685e-05
I0226 16:04:38.345309  7672 solver.cpp:229] Iteration 3830, loss = 0.901551
I0226 16:04:38.345356  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.205426 (* 1 = 0.205426 loss)
I0226 16:04:38.345368  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.537144 (* 1 = 0.537144 loss)
I0226 16:04:38.345381  7672 sgd_solver.cpp:106] Iteration 3830, lr = 1.79685e-05
I0226 16:05:08.534827  7672 solver.cpp:229] Iteration 3840, loss = 0.930534
I0226 16:05:08.534865  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.239528 (* 1 = 0.239528 loss)
I0226 16:05:08.534889  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.649385 (* 1 = 0.649385 loss)
I0226 16:05:08.534916  7672 sgd_solver.cpp:106] Iteration 3840, lr = 1.79685e-05
I0226 16:05:39.374151  7672 solver.cpp:229] Iteration 3850, loss = 0.954841
I0226 16:05:39.374208  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.226512 (* 1 = 0.226512 loss)
I0226 16:05:39.374219  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.645784 (* 1 = 0.645784 loss)
I0226 16:05:39.374229  7672 sgd_solver.cpp:106] Iteration 3850, lr = 1.79685e-05
I0226 16:06:10.143507  7672 solver.cpp:229] Iteration 3860, loss = 0.906278
I0226 16:06:10.143568  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.218546 (* 1 = 0.218546 loss)
I0226 16:06:10.143590  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.497108 (* 1 = 0.497108 loss)
I0226 16:06:10.143628  7672 sgd_solver.cpp:106] Iteration 3860, lr = 1.79685e-05
I0226 16:06:41.416343  7672 solver.cpp:229] Iteration 3870, loss = 0.943231
I0226 16:06:41.416385  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.236664 (* 1 = 0.236664 loss)
I0226 16:06:41.416398  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.787462 (* 1 = 0.787462 loss)
I0226 16:06:41.416409  7672 sgd_solver.cpp:106] Iteration 3870, lr = 1.79685e-05
I0226 16:07:12.488711  7672 solver.cpp:229] Iteration 3880, loss = 0.98761
I0226 16:07:12.488767  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.248725 (* 1 = 0.248725 loss)
I0226 16:07:12.488778  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.825119 (* 1 = 0.825119 loss)
I0226 16:07:12.488790  7672 sgd_solver.cpp:106] Iteration 3880, lr = 1.79685e-05
I0226 16:07:42.966367  7672 solver.cpp:229] Iteration 3890, loss = 0.868006
I0226 16:07:42.966423  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.270038 (* 1 = 0.270038 loss)
I0226 16:07:42.966437  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.768876 (* 1 = 0.768876 loss)
I0226 16:07:42.966451  7672 sgd_solver.cpp:106] Iteration 3890, lr = 1.79685e-05
I0226 16:08:13.481791  7672 solver.cpp:229] Iteration 3900, loss = 1.01888
I0226 16:08:13.481830  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.235741 (* 1 = 0.235741 loss)
I0226 16:08:13.481842  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.866646 (* 1 = 0.866646 loss)
I0226 16:08:13.481854  7672 sgd_solver.cpp:106] Iteration 3900, lr = 1.79685e-05
I0226 16:08:44.479632  7672 solver.cpp:229] Iteration 3910, loss = 0.911135
I0226 16:08:44.479686  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.257466 (* 1 = 0.257466 loss)
I0226 16:08:44.479703  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.729593 (* 1 = 0.729593 loss)
I0226 16:08:44.479723  7672 sgd_solver.cpp:106] Iteration 3910, lr = 1.79685e-05
I0226 16:09:15.053072  7672 solver.cpp:229] Iteration 3920, loss = 0.94613
I0226 16:09:15.053119  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.288993 (* 1 = 0.288993 loss)
I0226 16:09:15.053135  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.636472 (* 1 = 0.636472 loss)
I0226 16:09:15.053148  7672 sgd_solver.cpp:106] Iteration 3920, lr = 1.79685e-05
I0226 16:09:46.231568  7672 solver.cpp:229] Iteration 3930, loss = 0.889975
I0226 16:09:46.231629  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.263713 (* 1 = 0.263713 loss)
I0226 16:09:46.231647  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.774089 (* 1 = 0.774089 loss)
I0226 16:09:46.231667  7672 sgd_solver.cpp:106] Iteration 3930, lr = 1.79685e-05
I0226 16:10:16.799532  7672 solver.cpp:229] Iteration 3940, loss = 0.944036
I0226 16:10:16.799578  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.252726 (* 1 = 0.252726 loss)
I0226 16:10:16.799589  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.725548 (* 1 = 0.725548 loss)
I0226 16:10:16.799602  7672 sgd_solver.cpp:106] Iteration 3940, lr = 1.79685e-05
I0226 16:10:47.292950  7672 solver.cpp:229] Iteration 3950, loss = 0.893343
I0226 16:10:47.293001  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.259969 (* 1 = 0.259969 loss)
I0226 16:10:47.293015  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.783734 (* 1 = 0.783734 loss)
I0226 16:10:47.293030  7672 sgd_solver.cpp:106] Iteration 3950, lr = 1.79685e-05
I0226 16:11:17.995635  7672 solver.cpp:229] Iteration 3960, loss = 0.933276
I0226 16:11:17.995707  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.286925 (* 1 = 0.286925 loss)
I0226 16:11:17.995723  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.736602 (* 1 = 0.736602 loss)
I0226 16:11:17.995735  7672 sgd_solver.cpp:106] Iteration 3960, lr = 1.79685e-05
I0226 16:11:48.945471  7672 solver.cpp:229] Iteration 3970, loss = 0.854011
I0226 16:11:48.945519  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.252012 (* 1 = 0.252012 loss)
I0226 16:11:48.945533  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.781806 (* 1 = 0.781806 loss)
I0226 16:11:48.945544  7672 sgd_solver.cpp:106] Iteration 3970, lr = 1.79685e-05
I0226 16:12:19.742579  7672 solver.cpp:229] Iteration 3980, loss = 0.885518
I0226 16:12:19.742640  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.278477 (* 1 = 0.278477 loss)
I0226 16:12:19.742666  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.767865 (* 1 = 0.767865 loss)
I0226 16:12:19.742683  7672 sgd_solver.cpp:106] Iteration 3980, lr = 1.79685e-05
I0226 16:12:49.870426  7672 solver.cpp:229] Iteration 3990, loss = 0.887844
I0226 16:12:49.870471  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.257359 (* 1 = 0.257359 loss)
I0226 16:12:49.870481  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.670463 (* 1 = 0.670463 loss)
I0226 16:12:49.870492  7672 sgd_solver.cpp:106] Iteration 3990, lr = 1.79685e-05
I0226 16:13:20.426251  7672 solver.cpp:229] Iteration 4000, loss = 0.88627
I0226 16:13:20.426312  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.239214 (* 1 = 0.239214 loss)
I0226 16:13:20.426334  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.619936 (* 1 = 0.619936 loss)
I0226 16:13:20.426352  7672 sgd_solver.cpp:106] Iteration 4000, lr = 5.92961e-06
I0226 16:13:51.325907  7672 solver.cpp:229] Iteration 4010, loss = 0.930779
I0226 16:13:51.325953  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.278157 (* 1 = 0.278157 loss)
I0226 16:13:51.325964  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.868056 (* 1 = 0.868056 loss)
I0226 16:13:51.325975  7672 sgd_solver.cpp:106] Iteration 4010, lr = 5.92961e-06
I0226 16:14:21.984388  7672 solver.cpp:229] Iteration 4020, loss = 0.932682
I0226 16:14:21.984474  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.235819 (* 1 = 0.235819 loss)
I0226 16:14:21.984505  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.661351 (* 1 = 0.661351 loss)
I0226 16:14:21.984539  7672 sgd_solver.cpp:106] Iteration 4020, lr = 5.92961e-06
I0226 16:14:53.463145  7672 solver.cpp:229] Iteration 4030, loss = 0.89909
I0226 16:14:53.463212  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.254891 (* 1 = 0.254891 loss)
I0226 16:14:53.463243  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.966995 (* 1 = 0.966995 loss)
I0226 16:14:53.463263  7672 sgd_solver.cpp:106] Iteration 4030, lr = 5.92961e-06
I0226 16:15:23.713467  7672 solver.cpp:229] Iteration 4040, loss = 0.89949
I0226 16:15:23.713506  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.26062 (* 1 = 0.26062 loss)
I0226 16:15:23.713518  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.598447 (* 1 = 0.598447 loss)
I0226 16:15:23.713528  7672 sgd_solver.cpp:106] Iteration 4040, lr = 5.92961e-06
I0226 16:15:54.754153  7672 solver.cpp:229] Iteration 4050, loss = 0.8959
I0226 16:15:54.754201  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.256891 (* 1 = 0.256891 loss)
I0226 16:15:54.754214  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.634574 (* 1 = 0.634574 loss)
I0226 16:15:54.754225  7672 sgd_solver.cpp:106] Iteration 4050, lr = 5.92961e-06
I0226 16:16:25.551867  7672 solver.cpp:229] Iteration 4060, loss = 0.916568
I0226 16:16:25.551934  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.227816 (* 1 = 0.227816 loss)
I0226 16:16:25.551954  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.782807 (* 1 = 0.782807 loss)
I0226 16:16:25.551971  7672 sgd_solver.cpp:106] Iteration 4060, lr = 5.92961e-06
I0226 16:16:56.439291  7672 solver.cpp:229] Iteration 4070, loss = 0.899691
I0226 16:16:56.439330  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.238045 (* 1 = 0.238045 loss)
I0226 16:16:56.439342  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.538788 (* 1 = 0.538788 loss)
I0226 16:16:56.439352  7672 sgd_solver.cpp:106] Iteration 4070, lr = 5.92961e-06
I0226 16:17:26.839515  7672 solver.cpp:229] Iteration 4080, loss = 0.901149
I0226 16:17:26.839573  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.26443 (* 1 = 0.26443 loss)
I0226 16:17:26.839589  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.724652 (* 1 = 0.724652 loss)
I0226 16:17:26.839601  7672 sgd_solver.cpp:106] Iteration 4080, lr = 5.92961e-06
I0226 16:17:57.873495  7672 solver.cpp:229] Iteration 4090, loss = 0.909449
I0226 16:17:57.873535  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.263927 (* 1 = 0.263927 loss)
I0226 16:17:57.873546  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.764354 (* 1 = 0.764354 loss)
I0226 16:17:57.873558  7672 sgd_solver.cpp:106] Iteration 4090, lr = 5.92961e-06
I0226 16:18:28.534853  7672 solver.cpp:229] Iteration 4100, loss = 0.96105
I0226 16:18:28.534960  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.262954 (* 1 = 0.262954 loss)
I0226 16:18:28.534984  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.542668 (* 1 = 0.542668 loss)
I0226 16:18:28.535001  7672 sgd_solver.cpp:106] Iteration 4100, lr = 5.92961e-06
I0226 16:18:59.308655  7672 solver.cpp:229] Iteration 4110, loss = 0.877341
I0226 16:18:59.308693  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.236651 (* 1 = 0.236651 loss)
I0226 16:18:59.308706  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.691188 (* 1 = 0.691188 loss)
I0226 16:18:59.308717  7672 sgd_solver.cpp:106] Iteration 4110, lr = 5.92961e-06
I0226 16:19:30.304447  7672 solver.cpp:229] Iteration 4120, loss = 0.917366
I0226 16:19:30.304502  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.209067 (* 1 = 0.209067 loss)
I0226 16:19:30.304522  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.938795 (* 1 = 0.938795 loss)
I0226 16:19:30.304540  7672 sgd_solver.cpp:106] Iteration 4120, lr = 5.92961e-06
I0226 16:20:01.157007  7672 solver.cpp:229] Iteration 4130, loss = 0.881839
I0226 16:20:01.157078  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.294279 (* 1 = 0.294279 loss)
I0226 16:20:01.157090  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.645101 (* 1 = 0.645101 loss)
I0226 16:20:01.157101  7672 sgd_solver.cpp:106] Iteration 4130, lr = 5.92961e-06
I0226 16:20:32.072841  7672 solver.cpp:229] Iteration 4140, loss = 0.919424
I0226 16:20:32.072894  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.223854 (* 1 = 0.223854 loss)
I0226 16:20:32.072911  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.723965 (* 1 = 0.723965 loss)
I0226 16:20:32.072927  7672 sgd_solver.cpp:106] Iteration 4140, lr = 5.92961e-06
I0226 16:21:03.378296  7672 solver.cpp:229] Iteration 4150, loss = 0.923633
I0226 16:21:03.378365  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.238888 (* 1 = 0.238888 loss)
I0226 16:21:03.378382  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.695172 (* 1 = 0.695172 loss)
I0226 16:21:03.378396  7672 sgd_solver.cpp:106] Iteration 4150, lr = 5.92961e-06
I0226 16:21:34.176273  7672 solver.cpp:229] Iteration 4160, loss = 0.934142
I0226 16:21:34.176323  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.241553 (* 1 = 0.241553 loss)
I0226 16:21:34.176339  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.70312 (* 1 = 0.70312 loss)
I0226 16:21:34.176350  7672 sgd_solver.cpp:106] Iteration 4160, lr = 5.92961e-06
I0226 16:22:04.823856  7672 solver.cpp:229] Iteration 4170, loss = 0.884962
I0226 16:22:04.823897  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.234517 (* 1 = 0.234517 loss)
I0226 16:22:04.823909  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.572736 (* 1 = 0.572736 loss)
I0226 16:22:04.823920  7672 sgd_solver.cpp:106] Iteration 4170, lr = 5.92961e-06
I0226 16:22:35.465319  7672 solver.cpp:229] Iteration 4180, loss = 0.852795
I0226 16:22:35.465368  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.260691 (* 1 = 0.260691 loss)
I0226 16:22:35.465382  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.559555 (* 1 = 0.559555 loss)
I0226 16:22:35.465394  7672 sgd_solver.cpp:106] Iteration 4180, lr = 5.92961e-06
I0226 16:23:06.120149  7672 solver.cpp:229] Iteration 4190, loss = 0.974791
I0226 16:23:06.120189  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.260832 (* 1 = 0.260832 loss)
I0226 16:23:06.120201  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.635564 (* 1 = 0.635564 loss)
I0226 16:23:06.120213  7672 sgd_solver.cpp:106] Iteration 4190, lr = 5.92961e-06
I0226 16:23:36.962536  7672 solver.cpp:229] Iteration 4200, loss = 0.812072
I0226 16:23:36.962579  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.258312 (* 1 = 0.258312 loss)
I0226 16:23:36.962591  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.497332 (* 1 = 0.497332 loss)
I0226 16:23:36.962602  7672 sgd_solver.cpp:106] Iteration 4200, lr = 5.92961e-06
I0226 16:24:08.075821  7672 solver.cpp:229] Iteration 4210, loss = 0.879422
I0226 16:24:08.075861  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.233874 (* 1 = 0.233874 loss)
I0226 16:24:08.075873  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.523491 (* 1 = 0.523491 loss)
I0226 16:24:08.075884  7672 sgd_solver.cpp:106] Iteration 4210, lr = 5.92961e-06
I0226 16:24:39.088253  7672 solver.cpp:229] Iteration 4220, loss = 0.927386
I0226 16:24:39.088310  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.257664 (* 1 = 0.257664 loss)
I0226 16:24:39.088331  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.839625 (* 1 = 0.839625 loss)
I0226 16:24:39.088349  7672 sgd_solver.cpp:106] Iteration 4220, lr = 5.92961e-06
I0226 16:25:09.897096  7672 solver.cpp:229] Iteration 4230, loss = 0.927017
I0226 16:25:09.897163  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.231786 (* 1 = 0.231786 loss)
I0226 16:25:09.897186  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.643471 (* 1 = 0.643471 loss)
I0226 16:25:09.897204  7672 sgd_solver.cpp:106] Iteration 4230, lr = 5.92961e-06
I0226 16:25:40.223902  7672 solver.cpp:229] Iteration 4240, loss = 0.973283
I0226 16:25:40.223963  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.251326 (* 1 = 0.251326 loss)
I0226 16:25:40.223990  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.776475 (* 1 = 0.776475 loss)
I0226 16:25:40.224011  7672 sgd_solver.cpp:106] Iteration 4240, lr = 5.92961e-06
I0226 16:26:11.202497  7672 solver.cpp:229] Iteration 4250, loss = 0.887041
I0226 16:26:11.202548  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.244004 (* 1 = 0.244004 loss)
I0226 16:26:11.202564  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.756421 (* 1 = 0.756421 loss)
I0226 16:26:11.202591  7672 sgd_solver.cpp:106] Iteration 4250, lr = 5.92961e-06
I0226 16:26:41.542891  7672 solver.cpp:229] Iteration 4260, loss = 0.879963
I0226 16:26:41.542929  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.248567 (* 1 = 0.248567 loss)
I0226 16:26:41.542940  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.711593 (* 1 = 0.711593 loss)
I0226 16:26:41.542951  7672 sgd_solver.cpp:106] Iteration 4260, lr = 5.92961e-06
I0226 16:27:11.823175  7672 solver.cpp:229] Iteration 4270, loss = 0.879457
I0226 16:27:11.823240  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.241843 (* 1 = 0.241843 loss)
I0226 16:27:11.823266  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.744391 (* 1 = 0.744391 loss)
I0226 16:27:11.823285  7672 sgd_solver.cpp:106] Iteration 4270, lr = 5.92961e-06
I0226 16:27:41.951807  7672 solver.cpp:229] Iteration 4280, loss = 0.88942
I0226 16:27:41.951850  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.248585 (* 1 = 0.248585 loss)
I0226 16:27:41.951862  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.583544 (* 1 = 0.583544 loss)
I0226 16:27:41.951872  7672 sgd_solver.cpp:106] Iteration 4280, lr = 5.92961e-06
I0226 16:28:12.502076  7672 solver.cpp:229] Iteration 4290, loss = 0.942344
I0226 16:28:12.502137  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.259091 (* 1 = 0.259091 loss)
I0226 16:28:12.502163  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.702495 (* 1 = 0.702495 loss)
I0226 16:28:12.502182  7672 sgd_solver.cpp:106] Iteration 4290, lr = 5.92961e-06
I0226 16:28:43.894567  7672 solver.cpp:229] Iteration 4300, loss = 0.868265
I0226 16:28:43.894628  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.252148 (* 1 = 0.252148 loss)
I0226 16:28:43.894649  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.720156 (* 1 = 0.720156 loss)
I0226 16:28:43.894665  7672 sgd_solver.cpp:106] Iteration 4300, lr = 5.92961e-06
I0226 16:29:14.792255  7672 solver.cpp:229] Iteration 4310, loss = 0.907041
I0226 16:29:14.792294  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.210741 (* 1 = 0.210741 loss)
I0226 16:29:14.792306  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.559775 (* 1 = 0.559775 loss)
I0226 16:29:14.792317  7672 sgd_solver.cpp:106] Iteration 4310, lr = 5.92961e-06
I0226 16:29:45.092065  7672 solver.cpp:229] Iteration 4320, loss = 0.920901
I0226 16:29:45.092106  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.260385 (* 1 = 0.260385 loss)
I0226 16:29:45.092125  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.608205 (* 1 = 0.608205 loss)
I0226 16:29:45.092151  7672 sgd_solver.cpp:106] Iteration 4320, lr = 5.92961e-06
I0226 16:30:15.868345  7672 solver.cpp:229] Iteration 4330, loss = 0.837847
I0226 16:30:15.868412  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.212929 (* 1 = 0.212929 loss)
I0226 16:30:15.868433  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.436031 (* 1 = 0.436031 loss)
I0226 16:30:15.868456  7672 sgd_solver.cpp:106] Iteration 4330, lr = 5.92961e-06
I0226 16:30:46.856734  7672 solver.cpp:229] Iteration 4340, loss = 0.933827
I0226 16:30:46.856801  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.289354 (* 1 = 0.289354 loss)
I0226 16:30:46.856823  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.672718 (* 1 = 0.672718 loss)
I0226 16:30:46.856844  7672 sgd_solver.cpp:106] Iteration 4340, lr = 5.92961e-06
I0226 16:31:17.682992  7672 solver.cpp:229] Iteration 4350, loss = 0.895691
I0226 16:31:17.683059  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.245891 (* 1 = 0.245891 loss)
I0226 16:31:17.683089  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.569775 (* 1 = 0.569775 loss)
I0226 16:31:17.683116  7672 sgd_solver.cpp:106] Iteration 4350, lr = 5.92961e-06
I0226 16:31:48.710620  7672 solver.cpp:229] Iteration 4360, loss = 0.916479
I0226 16:31:48.710664  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.259911 (* 1 = 0.259911 loss)
I0226 16:31:48.710675  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.804729 (* 1 = 0.804729 loss)
I0226 16:31:48.710685  7672 sgd_solver.cpp:106] Iteration 4360, lr = 5.92961e-06
I0226 16:32:19.519595  7672 solver.cpp:229] Iteration 4370, loss = 0.977652
I0226 16:32:19.519654  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.259793 (* 1 = 0.259793 loss)
I0226 16:32:19.519666  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.531364 (* 1 = 0.531364 loss)
I0226 16:32:19.519677  7672 sgd_solver.cpp:106] Iteration 4370, lr = 5.92961e-06
I0226 16:32:50.395088  7672 solver.cpp:229] Iteration 4380, loss = 0.896294
I0226 16:32:50.395129  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.258569 (* 1 = 0.258569 loss)
I0226 16:32:50.395143  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.70292 (* 1 = 0.70292 loss)
I0226 16:32:50.395154  7672 sgd_solver.cpp:106] Iteration 4380, lr = 5.92961e-06
I0226 16:33:20.726280  7672 solver.cpp:229] Iteration 4390, loss = 0.943247
I0226 16:33:20.726321  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.231408 (* 1 = 0.231408 loss)
I0226 16:33:20.726333  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.655077 (* 1 = 0.655077 loss)
I0226 16:33:20.726344  7672 sgd_solver.cpp:106] Iteration 4390, lr = 5.92961e-06
I0226 16:33:51.497776  7672 solver.cpp:229] Iteration 4400, loss = 0.938028
I0226 16:33:51.497817  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.24035 (* 1 = 0.24035 loss)
I0226 16:33:51.497828  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.72138 (* 1 = 0.72138 loss)
I0226 16:33:51.497838  7672 sgd_solver.cpp:106] Iteration 4400, lr = 5.92961e-06
I0226 16:34:23.016165  7672 solver.cpp:229] Iteration 4410, loss = 0.894464
I0226 16:34:23.016243  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.223578 (* 1 = 0.223578 loss)
I0226 16:34:23.016288  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.520283 (* 1 = 0.520283 loss)
I0226 16:34:23.016317  7672 sgd_solver.cpp:106] Iteration 4410, lr = 5.92961e-06
I0226 16:34:51.661137  7672 solver.cpp:229] Iteration 4420, loss = 0.949117
I0226 16:34:51.661190  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.266269 (* 1 = 0.266269 loss)
I0226 16:34:51.661201  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.716671 (* 1 = 0.716671 loss)
I0226 16:34:51.661211  7672 sgd_solver.cpp:106] Iteration 4420, lr = 5.92961e-06
I0226 16:35:19.418107  7672 solver.cpp:229] Iteration 4430, loss = 0.902148
I0226 16:35:19.418159  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.217366 (* 1 = 0.217366 loss)
I0226 16:35:19.418170  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.560127 (* 1 = 0.560127 loss)
I0226 16:35:19.418181  7672 sgd_solver.cpp:106] Iteration 4430, lr = 5.92961e-06
I0226 16:35:47.189905  7672 solver.cpp:229] Iteration 4440, loss = 0.913421
I0226 16:35:47.189958  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.260686 (* 1 = 0.260686 loss)
I0226 16:35:47.189968  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.814304 (* 1 = 0.814304 loss)
I0226 16:35:47.189980  7672 sgd_solver.cpp:106] Iteration 4440, lr = 5.92961e-06
I0226 16:36:15.019160  7672 solver.cpp:229] Iteration 4450, loss = 0.940594
I0226 16:36:15.019208  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.245471 (* 1 = 0.245471 loss)
I0226 16:36:15.019219  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.608234 (* 1 = 0.608234 loss)
I0226 16:36:15.019230  7672 sgd_solver.cpp:106] Iteration 4450, lr = 5.92961e-06
I0226 16:36:42.794765  7672 solver.cpp:229] Iteration 4460, loss = 0.884979
I0226 16:36:42.794811  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.231313 (* 1 = 0.231313 loss)
I0226 16:36:42.794822  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.468501 (* 1 = 0.468501 loss)
I0226 16:36:42.794833  7672 sgd_solver.cpp:106] Iteration 4460, lr = 5.92961e-06
I0226 16:37:10.834013  7672 solver.cpp:229] Iteration 4470, loss = 0.86687
I0226 16:37:10.834051  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.298248 (* 1 = 0.298248 loss)
I0226 16:37:10.834062  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.719455 (* 1 = 0.719455 loss)
I0226 16:37:10.834074  7672 sgd_solver.cpp:106] Iteration 4470, lr = 5.92961e-06
I0226 16:37:41.734953  7672 solver.cpp:229] Iteration 4480, loss = 0.879772
I0226 16:37:41.735059  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.249883 (* 1 = 0.249883 loss)
I0226 16:37:41.735100  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.740396 (* 1 = 0.740396 loss)
I0226 16:37:41.735153  7672 sgd_solver.cpp:106] Iteration 4480, lr = 5.92961e-06
I0226 16:38:15.827215  7672 solver.cpp:229] Iteration 4490, loss = 0.890306
I0226 16:38:15.827306  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.20353 (* 1 = 0.20353 loss)
I0226 16:38:15.827337  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.44538 (* 1 = 0.44538 loss)
I0226 16:38:15.827359  7672 sgd_solver.cpp:106] Iteration 4490, lr = 5.92961e-06
I0226 16:38:48.827869  7672 solver.cpp:229] Iteration 4500, loss = 0.937196
I0226 16:38:48.827914  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.243325 (* 1 = 0.243325 loss)
I0226 16:38:48.827929  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.995168 (* 1 = 0.995168 loss)
I0226 16:38:48.827939  7672 sgd_solver.cpp:106] Iteration 4500, lr = 5.92961e-06
I0226 16:39:21.303182  7672 solver.cpp:229] Iteration 4510, loss = 0.961732
I0226 16:39:21.303308  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.263247 (* 1 = 0.263247 loss)
I0226 16:39:21.303375  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.661428 (* 1 = 0.661428 loss)
I0226 16:39:21.303421  7672 sgd_solver.cpp:106] Iteration 4510, lr = 5.92961e-06
I0226 16:39:52.466043  7672 solver.cpp:229] Iteration 4520, loss = 0.928133
I0226 16:39:52.466091  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.25337 (* 1 = 0.25337 loss)
I0226 16:39:52.466106  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.688767 (* 1 = 0.688767 loss)
I0226 16:39:52.466120  7672 sgd_solver.cpp:106] Iteration 4520, lr = 5.92961e-06
I0226 16:40:25.493774  7672 solver.cpp:229] Iteration 4530, loss = 0.900804
I0226 16:40:25.493826  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.19486 (* 1 = 0.19486 loss)
I0226 16:40:25.493844  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.469557 (* 1 = 0.469557 loss)
I0226 16:40:25.493861  7672 sgd_solver.cpp:106] Iteration 4530, lr = 5.92961e-06
I0226 16:40:57.254158  7672 solver.cpp:229] Iteration 4540, loss = 0.866742
I0226 16:40:57.254215  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.219191 (* 1 = 0.219191 loss)
I0226 16:40:57.254227  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.538703 (* 1 = 0.538703 loss)
I0226 16:40:57.254238  7672 sgd_solver.cpp:106] Iteration 4540, lr = 5.92961e-06
I0226 16:41:29.048182  7672 solver.cpp:229] Iteration 4550, loss = 0.847873
I0226 16:41:29.048223  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.220005 (* 1 = 0.220005 loss)
I0226 16:41:29.048234  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.475213 (* 1 = 0.475213 loss)
I0226 16:41:29.048245  7672 sgd_solver.cpp:106] Iteration 4550, lr = 5.92961e-06
I0226 16:42:00.851092  7672 solver.cpp:229] Iteration 4560, loss = 0.915952
I0226 16:42:00.851156  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.282077 (* 1 = 0.282077 loss)
I0226 16:42:00.851176  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.659106 (* 1 = 0.659106 loss)
I0226 16:42:00.851194  7672 sgd_solver.cpp:106] Iteration 4560, lr = 5.92961e-06
I0226 16:42:32.705974  7672 solver.cpp:229] Iteration 4570, loss = 0.935628
I0226 16:42:32.706018  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.232652 (* 1 = 0.232652 loss)
I0226 16:42:32.706029  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.634303 (* 1 = 0.634303 loss)
I0226 16:42:32.706040  7672 sgd_solver.cpp:106] Iteration 4570, lr = 5.92961e-06
I0226 16:43:04.527469  7672 solver.cpp:229] Iteration 4580, loss = 0.815978
I0226 16:43:04.527518  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.184632 (* 1 = 0.184632 loss)
I0226 16:43:04.527530  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.460525 (* 1 = 0.460525 loss)
I0226 16:43:04.527546  7672 sgd_solver.cpp:106] Iteration 4580, lr = 5.92961e-06
I0226 16:43:35.882369  7672 solver.cpp:229] Iteration 4590, loss = 0.933691
I0226 16:43:35.882411  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.249801 (* 1 = 0.249801 loss)
I0226 16:43:35.882421  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.644122 (* 1 = 0.644122 loss)
I0226 16:43:35.882431  7672 sgd_solver.cpp:106] Iteration 4590, lr = 5.92961e-06
I0226 16:44:07.043500  7672 solver.cpp:229] Iteration 4600, loss = 0.941333
I0226 16:44:07.043542  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.245183 (* 1 = 0.245183 loss)
I0226 16:44:07.043555  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.736196 (* 1 = 0.736196 loss)
I0226 16:44:07.043565  7672 sgd_solver.cpp:106] Iteration 4600, lr = 5.92961e-06
I0226 16:44:38.547093  7672 solver.cpp:229] Iteration 4610, loss = 0.919251
I0226 16:44:38.547168  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.2519 (* 1 = 0.2519 loss)
I0226 16:44:38.547195  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.646185 (* 1 = 0.646185 loss)
I0226 16:44:38.547219  7672 sgd_solver.cpp:106] Iteration 4610, lr = 5.92961e-06
I0226 16:45:10.493357  7672 solver.cpp:229] Iteration 4620, loss = 0.964365
I0226 16:45:10.493422  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.257602 (* 1 = 0.257602 loss)
I0226 16:45:10.493446  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.741179 (* 1 = 0.741179 loss)
I0226 16:45:10.493464  7672 sgd_solver.cpp:106] Iteration 4620, lr = 5.92961e-06
I0226 16:45:42.391451  7672 solver.cpp:229] Iteration 4630, loss = 0.968547
I0226 16:45:42.391505  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.261189 (* 1 = 0.261189 loss)
I0226 16:45:42.391523  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.646588 (* 1 = 0.646588 loss)
I0226 16:45:42.391538  7672 sgd_solver.cpp:106] Iteration 4630, lr = 5.92961e-06
I0226 16:46:13.966959  7672 solver.cpp:229] Iteration 4640, loss = 0.957309
I0226 16:46:13.967002  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.262347 (* 1 = 0.262347 loss)
I0226 16:46:13.967015  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.929791 (* 1 = 0.929791 loss)
I0226 16:46:13.967025  7672 sgd_solver.cpp:106] Iteration 4640, lr = 5.92961e-06
I0226 16:46:45.661834  7672 solver.cpp:229] Iteration 4650, loss = 0.907729
I0226 16:46:45.661931  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.249049 (* 1 = 0.249049 loss)
I0226 16:46:45.661960  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.601163 (* 1 = 0.601163 loss)
I0226 16:46:45.661986  7672 sgd_solver.cpp:106] Iteration 4650, lr = 5.92961e-06
I0226 16:47:19.979249  7672 solver.cpp:229] Iteration 4660, loss = 0.903344
I0226 16:47:19.979292  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.233582 (* 1 = 0.233582 loss)
I0226 16:47:19.979305  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.528709 (* 1 = 0.528709 loss)
I0226 16:47:19.979316  7672 sgd_solver.cpp:106] Iteration 4660, lr = 5.92961e-06
I0226 16:47:50.909961  7672 solver.cpp:229] Iteration 4670, loss = 0.854943
I0226 16:47:50.910022  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.232724 (* 1 = 0.232724 loss)
I0226 16:47:50.910042  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.566365 (* 1 = 0.566365 loss)
I0226 16:47:50.910065  7672 sgd_solver.cpp:106] Iteration 4670, lr = 5.92961e-06
I0226 16:48:22.108937  7672 solver.cpp:229] Iteration 4680, loss = 0.851685
I0226 16:48:22.108991  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.217336 (* 1 = 0.217336 loss)
I0226 16:48:22.109007  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.464768 (* 1 = 0.464768 loss)
I0226 16:48:22.109021  7672 sgd_solver.cpp:106] Iteration 4680, lr = 5.92961e-06
I0226 16:48:53.980413  7672 solver.cpp:229] Iteration 4690, loss = 0.998035
I0226 16:48:53.980486  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.283679 (* 1 = 0.283679 loss)
I0226 16:48:53.980515  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.753623 (* 1 = 0.753623 loss)
I0226 16:48:53.980535  7672 sgd_solver.cpp:106] Iteration 4690, lr = 5.92961e-06
I0226 16:49:25.060956  7672 solver.cpp:229] Iteration 4700, loss = 0.862743
I0226 16:49:25.061004  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.237315 (* 1 = 0.237315 loss)
I0226 16:49:25.061015  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.583689 (* 1 = 0.583689 loss)
I0226 16:49:25.061028  7672 sgd_solver.cpp:106] Iteration 4700, lr = 5.92961e-06
I0226 16:49:55.555977  7672 solver.cpp:229] Iteration 4710, loss = 0.885328
I0226 16:49:55.556033  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.211986 (* 1 = 0.211986 loss)
I0226 16:49:55.556051  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.618099 (* 1 = 0.618099 loss)
I0226 16:49:55.556068  7672 sgd_solver.cpp:106] Iteration 4710, lr = 5.92961e-06
I0226 16:50:29.468143  7672 solver.cpp:229] Iteration 4720, loss = 0.930072
I0226 16:50:29.468256  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.229645 (* 1 = 0.229645 loss)
I0226 16:50:29.468288  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.609369 (* 1 = 0.609369 loss)
I0226 16:50:29.468317  7672 sgd_solver.cpp:106] Iteration 4720, lr = 5.92961e-06
I0226 16:51:01.909214  7672 solver.cpp:229] Iteration 4730, loss = 1.00806
I0226 16:51:01.909292  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.21405 (* 1 = 0.21405 loss)
I0226 16:51:01.909312  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.869111 (* 1 = 0.869111 loss)
I0226 16:51:01.909332  7672 sgd_solver.cpp:106] Iteration 4730, lr = 5.92961e-06
I0226 16:51:33.432243  7672 solver.cpp:229] Iteration 4740, loss = 0.971859
I0226 16:51:33.432299  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.243844 (* 1 = 0.243844 loss)
I0226 16:51:33.432319  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.921356 (* 1 = 0.921356 loss)
I0226 16:51:33.432339  7672 sgd_solver.cpp:106] Iteration 4740, lr = 5.92961e-06
I0226 16:52:04.804865  7672 solver.cpp:229] Iteration 4750, loss = 0.858864
I0226 16:52:04.804920  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.294507 (* 1 = 0.294507 loss)
I0226 16:52:04.804941  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.739907 (* 1 = 0.739907 loss)
I0226 16:52:04.804960  7672 sgd_solver.cpp:106] Iteration 4750, lr = 5.92961e-06
I0226 16:52:35.810197  7672 solver.cpp:229] Iteration 4760, loss = 0.913809
I0226 16:52:35.810264  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.274236 (* 1 = 0.274236 loss)
I0226 16:52:35.810286  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.678498 (* 1 = 0.678498 loss)
I0226 16:52:35.810302  7672 sgd_solver.cpp:106] Iteration 4760, lr = 5.92961e-06
I0226 16:53:06.930869  7672 solver.cpp:229] Iteration 4770, loss = 0.898061
I0226 16:53:06.930963  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.251493 (* 1 = 0.251493 loss)
I0226 16:53:06.930981  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.633628 (* 1 = 0.633628 loss)
I0226 16:53:06.931005  7672 sgd_solver.cpp:106] Iteration 4770, lr = 5.92961e-06
I0226 16:53:38.501165  7672 solver.cpp:229] Iteration 4780, loss = 0.926795
I0226 16:53:38.501207  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.228825 (* 1 = 0.228825 loss)
I0226 16:53:38.501219  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.593388 (* 1 = 0.593388 loss)
I0226 16:53:38.501230  7672 sgd_solver.cpp:106] Iteration 4780, lr = 5.92961e-06
I0226 16:54:09.428169  7672 solver.cpp:229] Iteration 4790, loss = 0.880997
I0226 16:54:09.428208  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.261753 (* 1 = 0.261753 loss)
I0226 16:54:09.428220  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.681747 (* 1 = 0.681747 loss)
I0226 16:54:09.428232  7672 sgd_solver.cpp:106] Iteration 4790, lr = 5.92961e-06
I0226 16:54:43.092308  7672 solver.cpp:229] Iteration 4800, loss = 0.929922
I0226 16:54:43.092377  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.235941 (* 1 = 0.235941 loss)
I0226 16:54:43.092399  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.851109 (* 1 = 0.851109 loss)
I0226 16:54:43.092420  7672 sgd_solver.cpp:106] Iteration 4800, lr = 5.92961e-06
I0226 16:55:17.914353  7672 solver.cpp:229] Iteration 4810, loss = 0.887453
I0226 16:55:17.914422  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.257217 (* 1 = 0.257217 loss)
I0226 16:55:17.914448  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.603341 (* 1 = 0.603341 loss)
I0226 16:55:17.914470  7672 sgd_solver.cpp:106] Iteration 4810, lr = 5.92961e-06
I0226 16:55:50.092589  7672 solver.cpp:229] Iteration 4820, loss = 0.968193
I0226 16:55:50.092679  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.264311 (* 1 = 0.264311 loss)
I0226 16:55:50.092711  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.868167 (* 1 = 0.868167 loss)
I0226 16:55:50.092738  7672 sgd_solver.cpp:106] Iteration 4820, lr = 5.92961e-06
I0226 16:56:22.423144  7672 solver.cpp:229] Iteration 4830, loss = 0.934106
I0226 16:56:22.423245  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.263147 (* 1 = 0.263147 loss)
I0226 16:56:22.423275  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.704183 (* 1 = 0.704183 loss)
I0226 16:56:22.423307  7672 sgd_solver.cpp:106] Iteration 4830, lr = 5.92961e-06
I0226 16:56:54.536334  7672 solver.cpp:229] Iteration 4840, loss = 0.883957
I0226 16:56:54.536391  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.241181 (* 1 = 0.241181 loss)
I0226 16:56:54.536408  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.651869 (* 1 = 0.651869 loss)
I0226 16:56:54.536423  7672 sgd_solver.cpp:106] Iteration 4840, lr = 5.92961e-06
I0226 16:57:26.281494  7672 solver.cpp:229] Iteration 4850, loss = 1.01659
I0226 16:57:26.281545  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.251837 (* 1 = 0.251837 loss)
I0226 16:57:26.281563  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.829147 (* 1 = 0.829147 loss)
I0226 16:57:26.281577  7672 sgd_solver.cpp:106] Iteration 4850, lr = 5.92961e-06
I0226 16:57:58.447986  7672 solver.cpp:229] Iteration 4860, loss = 0.895301
I0226 16:57:58.448038  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.26727 (* 1 = 0.26727 loss)
I0226 16:57:58.448055  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.778191 (* 1 = 0.778191 loss)
I0226 16:57:58.448071  7672 sgd_solver.cpp:106] Iteration 4860, lr = 5.92961e-06
I0226 16:58:30.519678  7672 solver.cpp:229] Iteration 4870, loss = 0.904009
I0226 16:58:30.519739  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.253639 (* 1 = 0.253639 loss)
I0226 16:58:30.519757  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.626412 (* 1 = 0.626412 loss)
I0226 16:58:30.519775  7672 sgd_solver.cpp:106] Iteration 4870, lr = 5.92961e-06
I0226 16:59:02.385618  7672 solver.cpp:229] Iteration 4880, loss = 0.856307
I0226 16:59:02.385686  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.252048 (* 1 = 0.252048 loss)
I0226 16:59:02.385705  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.653749 (* 1 = 0.653749 loss)
I0226 16:59:02.385726  7672 sgd_solver.cpp:106] Iteration 4880, lr = 5.92961e-06
I0226 16:59:34.033562  7672 solver.cpp:229] Iteration 4890, loss = 0.898942
I0226 16:59:34.033646  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.253231 (* 1 = 0.253231 loss)
I0226 16:59:34.033673  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.661159 (* 1 = 0.661159 loss)
I0226 16:59:34.033697  7672 sgd_solver.cpp:106] Iteration 4890, lr = 5.92961e-06
I0226 17:00:05.430567  7672 solver.cpp:229] Iteration 4900, loss = 0.823109
I0226 17:00:05.430621  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.25149 (* 1 = 0.25149 loss)
I0226 17:00:05.430635  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.571519 (* 1 = 0.571519 loss)
I0226 17:00:05.430649  7672 sgd_solver.cpp:106] Iteration 4900, lr = 5.92961e-06
I0226 17:00:37.226773  7672 solver.cpp:229] Iteration 4910, loss = 0.89681
I0226 17:00:37.226828  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.205206 (* 1 = 0.205206 loss)
I0226 17:00:37.226856  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.679884 (* 1 = 0.679884 loss)
I0226 17:00:37.226910  7672 sgd_solver.cpp:106] Iteration 4910, lr = 5.92961e-06
I0226 17:01:09.402252  7672 solver.cpp:229] Iteration 4920, loss = 0.964089
I0226 17:01:09.402299  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.270418 (* 1 = 0.270418 loss)
I0226 17:01:09.402310  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.72013 (* 1 = 0.72013 loss)
I0226 17:01:09.402321  7672 sgd_solver.cpp:106] Iteration 4920, lr = 5.92961e-06
I0226 17:01:41.158473  7672 solver.cpp:229] Iteration 4930, loss = 0.900779
I0226 17:01:41.158591  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.243275 (* 1 = 0.243275 loss)
I0226 17:01:41.158619  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.65244 (* 1 = 0.65244 loss)
I0226 17:01:41.158648  7672 sgd_solver.cpp:106] Iteration 4930, lr = 5.92961e-06
I0226 17:02:12.874814  7672 solver.cpp:229] Iteration 4940, loss = 0.913547
I0226 17:02:12.874902  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.216287 (* 1 = 0.216287 loss)
I0226 17:02:12.874922  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.776024 (* 1 = 0.776024 loss)
I0226 17:02:12.874938  7672 sgd_solver.cpp:106] Iteration 4940, lr = 5.92961e-06
I0226 17:02:45.096487  7672 solver.cpp:229] Iteration 4950, loss = 0.907643
I0226 17:02:45.096540  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.239818 (* 1 = 0.239818 loss)
I0226 17:02:45.096551  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.530618 (* 1 = 0.530618 loss)
I0226 17:02:45.096562  7672 sgd_solver.cpp:106] Iteration 4950, lr = 5.92961e-06
I0226 17:03:16.736990  7672 solver.cpp:229] Iteration 4960, loss = 0.838465
I0226 17:03:16.737047  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.22064 (* 1 = 0.22064 loss)
I0226 17:03:16.737067  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.661803 (* 1 = 0.661803 loss)
I0226 17:03:16.737083  7672 sgd_solver.cpp:106] Iteration 4960, lr = 5.92961e-06
I0226 17:03:48.063148  7672 solver.cpp:229] Iteration 4970, loss = 0.931743
I0226 17:03:48.063256  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.241485 (* 1 = 0.241485 loss)
I0226 17:03:48.063290  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.72687 (* 1 = 0.72687 loss)
I0226 17:03:48.063318  7672 sgd_solver.cpp:106] Iteration 4970, lr = 5.92961e-06
I0226 17:04:20.430033  7672 solver.cpp:229] Iteration 4980, loss = 0.905467
I0226 17:04:20.430078  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.28467 (* 1 = 0.28467 loss)
I0226 17:04:20.430088  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.73044 (* 1 = 0.73044 loss)
I0226 17:04:20.430100  7672 sgd_solver.cpp:106] Iteration 4980, lr = 5.92961e-06
I0226 17:04:52.178658  7672 solver.cpp:229] Iteration 4990, loss = 0.894711
I0226 17:04:52.178721  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.23103 (* 1 = 0.23103 loss)
I0226 17:04:52.178737  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.713159 (* 1 = 0.713159 loss)
I0226 17:04:52.178752  7672 sgd_solver.cpp:106] Iteration 4990, lr = 5.92961e-06
I0226 17:05:22.858582  7672 solver.cpp:229] Iteration 5000, loss = 1.00026
I0226 17:05:22.858639  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.257148 (* 1 = 0.257148 loss)
I0226 17:05:22.858662  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.616129 (* 1 = 0.616129 loss)
I0226 17:05:22.858681  7672 sgd_solver.cpp:106] Iteration 5000, lr = 1.95677e-06
I0226 17:05:54.814237  7672 solver.cpp:229] Iteration 5010, loss = 0.914518
I0226 17:05:54.814291  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.282797 (* 1 = 0.282797 loss)
I0226 17:05:54.814303  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.707433 (* 1 = 0.707433 loss)
I0226 17:05:54.814319  7672 sgd_solver.cpp:106] Iteration 5010, lr = 1.95677e-06
I0226 17:06:25.255172  7672 solver.cpp:229] Iteration 5020, loss = 0.897893
I0226 17:06:25.255209  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.219549 (* 1 = 0.219549 loss)
I0226 17:06:25.255223  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.669486 (* 1 = 0.669486 loss)
I0226 17:06:25.255234  7672 sgd_solver.cpp:106] Iteration 5020, lr = 1.95677e-06
I0226 17:06:53.065970  7672 solver.cpp:229] Iteration 5030, loss = 0.887551
I0226 17:06:53.066025  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.250258 (* 1 = 0.250258 loss)
I0226 17:06:53.066036  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.586092 (* 1 = 0.586092 loss)
I0226 17:06:53.066047  7672 sgd_solver.cpp:106] Iteration 5030, lr = 1.95677e-06
I0226 17:07:20.882136  7672 solver.cpp:229] Iteration 5040, loss = 0.888979
I0226 17:07:20.882189  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.235802 (* 1 = 0.235802 loss)
I0226 17:07:20.882200  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.518256 (* 1 = 0.518256 loss)
I0226 17:07:20.882212  7672 sgd_solver.cpp:106] Iteration 5040, lr = 1.95677e-06
I0226 17:07:48.475417  7672 solver.cpp:229] Iteration 5050, loss = 0.884651
I0226 17:07:48.475471  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.260696 (* 1 = 0.260696 loss)
I0226 17:07:48.475481  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.751178 (* 1 = 0.751178 loss)
I0226 17:07:48.475492  7672 sgd_solver.cpp:106] Iteration 5050, lr = 1.95677e-06
I0226 17:08:16.202759  7672 solver.cpp:229] Iteration 5060, loss = 0.867926
I0226 17:08:16.202812  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.230662 (* 1 = 0.230662 loss)
I0226 17:08:16.202837  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.549135 (* 1 = 0.549135 loss)
I0226 17:08:16.202848  7672 sgd_solver.cpp:106] Iteration 5060, lr = 1.95677e-06
I0226 17:08:44.032739  7672 solver.cpp:229] Iteration 5070, loss = 0.908877
I0226 17:08:44.032791  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.232573 (* 1 = 0.232573 loss)
I0226 17:08:44.032804  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.617003 (* 1 = 0.617003 loss)
I0226 17:08:44.032814  7672 sgd_solver.cpp:106] Iteration 5070, lr = 1.95677e-06
I0226 17:09:11.706599  7672 solver.cpp:229] Iteration 5080, loss = 0.934066
I0226 17:09:11.706653  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.222958 (* 1 = 0.222958 loss)
I0226 17:09:11.706665  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.645798 (* 1 = 0.645798 loss)
I0226 17:09:11.706676  7672 sgd_solver.cpp:106] Iteration 5080, lr = 1.95677e-06
I0226 17:09:39.518293  7672 solver.cpp:229] Iteration 5090, loss = 0.929164
I0226 17:09:39.518347  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.272561 (* 1 = 0.272561 loss)
I0226 17:09:39.518357  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.652868 (* 1 = 0.652868 loss)
I0226 17:09:39.518368  7672 sgd_solver.cpp:106] Iteration 5090, lr = 1.95677e-06
I0226 17:10:07.174223  7672 solver.cpp:229] Iteration 5100, loss = 0.864779
I0226 17:10:07.174276  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.263785 (* 1 = 0.263785 loss)
I0226 17:10:07.174288  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.768428 (* 1 = 0.768428 loss)
I0226 17:10:07.174299  7672 sgd_solver.cpp:106] Iteration 5100, lr = 1.95677e-06
I0226 17:10:34.903976  7672 solver.cpp:229] Iteration 5110, loss = 0.899245
I0226 17:10:34.904013  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.228963 (* 1 = 0.228963 loss)
I0226 17:10:34.904024  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.697517 (* 1 = 0.697517 loss)
I0226 17:10:34.904036  7672 sgd_solver.cpp:106] Iteration 5110, lr = 1.95677e-06
I0226 17:11:02.712589  7672 solver.cpp:229] Iteration 5120, loss = 0.849661
I0226 17:11:02.712641  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.286436 (* 1 = 0.286436 loss)
I0226 17:11:02.712653  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.794862 (* 1 = 0.794862 loss)
I0226 17:11:02.712664  7672 sgd_solver.cpp:106] Iteration 5120, lr = 1.95677e-06
I0226 17:11:30.589517  7672 solver.cpp:229] Iteration 5130, loss = 0.888811
I0226 17:11:30.589572  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.221924 (* 1 = 0.221924 loss)
I0226 17:11:30.589589  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.724802 (* 1 = 0.724802 loss)
I0226 17:11:30.589603  7672 sgd_solver.cpp:106] Iteration 5130, lr = 1.95677e-06
I0226 17:11:58.557420  7672 solver.cpp:229] Iteration 5140, loss = 0.930387
I0226 17:11:58.557487  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.291881 (* 1 = 0.291881 loss)
I0226 17:11:58.557498  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.67305 (* 1 = 0.67305 loss)
I0226 17:11:58.557509  7672 sgd_solver.cpp:106] Iteration 5140, lr = 1.95677e-06
I0226 17:12:26.546032  7672 solver.cpp:229] Iteration 5150, loss = 1.01682
I0226 17:12:26.546070  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.229254 (* 1 = 0.229254 loss)
I0226 17:12:26.546082  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.774263 (* 1 = 0.774263 loss)
I0226 17:12:26.546092  7672 sgd_solver.cpp:106] Iteration 5150, lr = 1.95677e-06
I0226 17:12:54.396136  7672 solver.cpp:229] Iteration 5160, loss = 0.888027
I0226 17:12:54.396189  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.286582 (* 1 = 0.286582 loss)
I0226 17:12:54.396216  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.56893 (* 1 = 0.56893 loss)
I0226 17:12:54.396227  7672 sgd_solver.cpp:106] Iteration 5160, lr = 1.95677e-06
I0226 17:13:22.256460  7672 solver.cpp:229] Iteration 5170, loss = 0.923284
I0226 17:13:22.256515  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.229406 (* 1 = 0.229406 loss)
I0226 17:13:22.256525  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.550955 (* 1 = 0.550955 loss)
I0226 17:13:22.256536  7672 sgd_solver.cpp:106] Iteration 5170, lr = 1.95677e-06
I0226 17:13:50.147987  7672 solver.cpp:229] Iteration 5180, loss = 0.922208
I0226 17:13:50.148025  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.270738 (* 1 = 0.270738 loss)
I0226 17:13:50.148036  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.74527 (* 1 = 0.74527 loss)
I0226 17:13:50.148047  7672 sgd_solver.cpp:106] Iteration 5180, lr = 1.95677e-06
I0226 17:14:17.884423  7672 solver.cpp:229] Iteration 5190, loss = 0.91778
I0226 17:14:17.884475  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.227168 (* 1 = 0.227168 loss)
I0226 17:14:17.884487  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.553705 (* 1 = 0.553705 loss)
I0226 17:14:17.884497  7672 sgd_solver.cpp:106] Iteration 5190, lr = 1.95677e-06
I0226 17:14:45.650856  7672 solver.cpp:229] Iteration 5200, loss = 0.859925
I0226 17:14:45.650920  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.208642 (* 1 = 0.208642 loss)
I0226 17:14:45.650931  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.475236 (* 1 = 0.475236 loss)
I0226 17:14:45.650943  7672 sgd_solver.cpp:106] Iteration 5200, lr = 1.95677e-06
I0226 17:15:13.364603  7672 solver.cpp:229] Iteration 5210, loss = 0.898754
I0226 17:15:13.364639  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.204724 (* 1 = 0.204724 loss)
I0226 17:15:13.364650  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.415052 (* 1 = 0.415052 loss)
I0226 17:15:13.364661  7672 sgd_solver.cpp:106] Iteration 5210, lr = 1.95677e-06
I0226 17:15:41.178701  7672 solver.cpp:229] Iteration 5220, loss = 0.957384
I0226 17:15:41.178738  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.261148 (* 1 = 0.261148 loss)
I0226 17:15:41.178750  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.676492 (* 1 = 0.676492 loss)
I0226 17:15:41.178761  7672 sgd_solver.cpp:106] Iteration 5220, lr = 1.95677e-06
I0226 17:16:08.930128  7672 solver.cpp:229] Iteration 5230, loss = 0.913681
I0226 17:16:08.930189  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.245267 (* 1 = 0.245267 loss)
I0226 17:16:08.930200  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.886865 (* 1 = 0.886865 loss)
I0226 17:16:08.930212  7672 sgd_solver.cpp:106] Iteration 5230, lr = 1.95677e-06
I0226 17:16:36.716694  7672 solver.cpp:229] Iteration 5240, loss = 0.880849
I0226 17:16:36.716748  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.263887 (* 1 = 0.263887 loss)
I0226 17:16:36.716760  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.698679 (* 1 = 0.698679 loss)
I0226 17:16:36.716771  7672 sgd_solver.cpp:106] Iteration 5240, lr = 1.95677e-06
I0226 17:17:04.474689  7672 solver.cpp:229] Iteration 5250, loss = 0.887168
I0226 17:17:04.474741  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.267056 (* 1 = 0.267056 loss)
I0226 17:17:04.474753  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.714136 (* 1 = 0.714136 loss)
I0226 17:17:04.474766  7672 sgd_solver.cpp:106] Iteration 5250, lr = 1.95677e-06
I0226 17:17:32.238395  7672 solver.cpp:229] Iteration 5260, loss = 0.915724
I0226 17:17:32.238432  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.263107 (* 1 = 0.263107 loss)
I0226 17:17:32.238445  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.740383 (* 1 = 0.740383 loss)
I0226 17:17:32.238456  7672 sgd_solver.cpp:106] Iteration 5260, lr = 1.95677e-06
I0226 17:18:00.137265  7672 solver.cpp:229] Iteration 5270, loss = 0.93331
I0226 17:18:00.137316  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.244627 (* 1 = 0.244627 loss)
I0226 17:18:00.137327  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.685436 (* 1 = 0.685436 loss)
I0226 17:18:00.137338  7672 sgd_solver.cpp:106] Iteration 5270, lr = 1.95677e-06
I0226 17:18:27.943267  7672 solver.cpp:229] Iteration 5280, loss = 0.905452
I0226 17:18:27.943305  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.263578 (* 1 = 0.263578 loss)
I0226 17:18:27.943315  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.773569 (* 1 = 0.773569 loss)
I0226 17:18:27.943326  7672 sgd_solver.cpp:106] Iteration 5280, lr = 1.95677e-06
I0226 17:18:55.763685  7672 solver.cpp:229] Iteration 5290, loss = 0.999749
I0226 17:18:55.763739  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.277808 (* 1 = 0.277808 loss)
I0226 17:18:55.763751  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.842592 (* 1 = 0.842592 loss)
I0226 17:18:55.763761  7672 sgd_solver.cpp:106] Iteration 5290, lr = 1.95677e-06
I0226 17:19:23.566088  7672 solver.cpp:229] Iteration 5300, loss = 0.897779
I0226 17:19:23.566138  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.199451 (* 1 = 0.199451 loss)
I0226 17:19:23.566149  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.571993 (* 1 = 0.571993 loss)
I0226 17:19:23.566159  7672 sgd_solver.cpp:106] Iteration 5300, lr = 1.95677e-06
I0226 17:19:51.371711  7672 solver.cpp:229] Iteration 5310, loss = 0.932645
I0226 17:19:51.371748  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.255269 (* 1 = 0.255269 loss)
I0226 17:19:51.371760  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.908728 (* 1 = 0.908728 loss)
I0226 17:19:51.371771  7672 sgd_solver.cpp:106] Iteration 5310, lr = 1.95677e-06
I0226 17:20:19.131484  7672 solver.cpp:229] Iteration 5320, loss = 0.860547
I0226 17:20:19.131520  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.275588 (* 1 = 0.275588 loss)
I0226 17:20:19.131531  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.643095 (* 1 = 0.643095 loss)
I0226 17:20:19.131541  7672 sgd_solver.cpp:106] Iteration 5320, lr = 1.95677e-06
I0226 17:20:46.786553  7672 solver.cpp:229] Iteration 5330, loss = 0.902727
I0226 17:20:46.786592  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.222961 (* 1 = 0.222961 loss)
I0226 17:20:46.786603  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.529445 (* 1 = 0.529445 loss)
I0226 17:20:46.786614  7672 sgd_solver.cpp:106] Iteration 5330, lr = 1.95677e-06
I0226 17:21:14.559239  7672 solver.cpp:229] Iteration 5340, loss = 0.946599
I0226 17:21:14.559275  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.287534 (* 1 = 0.287534 loss)
I0226 17:21:14.559286  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.723218 (* 1 = 0.723218 loss)
I0226 17:21:14.559298  7672 sgd_solver.cpp:106] Iteration 5340, lr = 1.95677e-06
I0226 17:21:42.367292  7672 solver.cpp:229] Iteration 5350, loss = 0.865905
I0226 17:21:42.367329  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.269156 (* 1 = 0.269156 loss)
I0226 17:21:42.367341  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.599702 (* 1 = 0.599702 loss)
I0226 17:21:42.367352  7672 sgd_solver.cpp:106] Iteration 5350, lr = 1.95677e-06
I0226 17:22:10.136786  7672 solver.cpp:229] Iteration 5360, loss = 0.932121
I0226 17:22:10.136839  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.331888 (* 1 = 0.331888 loss)
I0226 17:22:10.136852  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.672162 (* 1 = 0.672162 loss)
I0226 17:22:10.136862  7672 sgd_solver.cpp:106] Iteration 5360, lr = 1.95677e-06
I0226 17:22:37.857843  7672 solver.cpp:229] Iteration 5370, loss = 0.828441
I0226 17:22:37.857882  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.246767 (* 1 = 0.246767 loss)
I0226 17:22:37.857893  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.580645 (* 1 = 0.580645 loss)
I0226 17:22:37.857904  7672 sgd_solver.cpp:106] Iteration 5370, lr = 1.95677e-06
I0226 17:23:05.551753  7672 solver.cpp:229] Iteration 5380, loss = 0.976653
I0226 17:23:05.551807  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.278793 (* 1 = 0.278793 loss)
I0226 17:23:05.551818  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.822831 (* 1 = 0.822831 loss)
I0226 17:23:05.551831  7672 sgd_solver.cpp:106] Iteration 5380, lr = 1.95677e-06
I0226 17:23:33.499065  7672 solver.cpp:229] Iteration 5390, loss = 0.974183
I0226 17:23:33.499102  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.274714 (* 1 = 0.274714 loss)
I0226 17:23:33.499114  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.554716 (* 1 = 0.554716 loss)
I0226 17:23:33.499125  7672 sgd_solver.cpp:106] Iteration 5390, lr = 1.95677e-06
I0226 17:24:01.327474  7672 solver.cpp:229] Iteration 5400, loss = 0.894509
I0226 17:24:01.327512  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.261643 (* 1 = 0.261643 loss)
I0226 17:24:01.327522  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.644956 (* 1 = 0.644956 loss)
I0226 17:24:01.327533  7672 sgd_solver.cpp:106] Iteration 5400, lr = 1.95677e-06
I0226 17:24:29.097198  7672 solver.cpp:229] Iteration 5410, loss = 0.952612
I0226 17:24:29.097249  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.278238 (* 1 = 0.278238 loss)
I0226 17:24:29.097260  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.78457 (* 1 = 0.78457 loss)
I0226 17:24:29.097271  7672 sgd_solver.cpp:106] Iteration 5410, lr = 1.95677e-06
I0226 17:24:56.876571  7672 solver.cpp:229] Iteration 5420, loss = 0.957357
I0226 17:24:56.876610  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.266655 (* 1 = 0.266655 loss)
I0226 17:24:56.876621  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.656157 (* 1 = 0.656157 loss)
I0226 17:24:56.876631  7672 sgd_solver.cpp:106] Iteration 5420, lr = 1.95677e-06
I0226 17:25:24.547788  7672 solver.cpp:229] Iteration 5430, loss = 0.840517
I0226 17:25:24.547840  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.234464 (* 1 = 0.234464 loss)
I0226 17:25:24.547852  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.606196 (* 1 = 0.606196 loss)
I0226 17:25:24.547863  7672 sgd_solver.cpp:106] Iteration 5430, lr = 1.95677e-06
I0226 17:25:52.415963  7672 solver.cpp:229] Iteration 5440, loss = 0.897432
I0226 17:25:52.416015  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.298888 (* 1 = 0.298888 loss)
I0226 17:25:52.416028  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.647331 (* 1 = 0.647331 loss)
I0226 17:25:52.416038  7672 sgd_solver.cpp:106] Iteration 5440, lr = 1.95677e-06
I0226 17:26:20.204773  7672 solver.cpp:229] Iteration 5450, loss = 0.916504
I0226 17:26:20.204809  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.242101 (* 1 = 0.242101 loss)
I0226 17:26:20.204823  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.594122 (* 1 = 0.594122 loss)
I0226 17:26:20.204833  7672 sgd_solver.cpp:106] Iteration 5450, lr = 1.95677e-06
I0226 17:26:48.045970  7672 solver.cpp:229] Iteration 5460, loss = 0.903139
I0226 17:26:48.046008  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.272079 (* 1 = 0.272079 loss)
I0226 17:26:48.046020  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.60949 (* 1 = 0.60949 loss)
I0226 17:26:48.046031  7672 sgd_solver.cpp:106] Iteration 5460, lr = 1.95677e-06
I0226 17:27:15.667058  7672 solver.cpp:229] Iteration 5470, loss = 0.859732
I0226 17:27:15.667096  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.243431 (* 1 = 0.243431 loss)
I0226 17:27:15.667109  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.624851 (* 1 = 0.624851 loss)
I0226 17:27:15.667119  7672 sgd_solver.cpp:106] Iteration 5470, lr = 1.95677e-06
I0226 17:27:43.388774  7672 solver.cpp:229] Iteration 5480, loss = 0.859117
I0226 17:27:43.388829  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.250574 (* 1 = 0.250574 loss)
I0226 17:27:43.388841  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.608574 (* 1 = 0.608574 loss)
I0226 17:27:43.388852  7672 sgd_solver.cpp:106] Iteration 5480, lr = 1.95677e-06
I0226 17:28:11.335074  7672 solver.cpp:229] Iteration 5490, loss = 0.88836
I0226 17:28:11.335111  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.252857 (* 1 = 0.252857 loss)
I0226 17:28:11.335121  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.6342 (* 1 = 0.6342 loss)
I0226 17:28:11.335134  7672 sgd_solver.cpp:106] Iteration 5490, lr = 1.95677e-06
I0226 17:28:39.146968  7672 solver.cpp:229] Iteration 5500, loss = 0.875131
I0226 17:28:39.147006  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.246498 (* 1 = 0.246498 loss)
I0226 17:28:39.147018  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.649002 (* 1 = 0.649002 loss)
I0226 17:28:39.147029  7672 sgd_solver.cpp:106] Iteration 5500, lr = 1.95677e-06
I0226 17:29:06.850404  7672 solver.cpp:229] Iteration 5510, loss = 0.932166
I0226 17:29:06.850440  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.224062 (* 1 = 0.224062 loss)
I0226 17:29:06.850450  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.530065 (* 1 = 0.530065 loss)
I0226 17:29:06.850459  7672 sgd_solver.cpp:106] Iteration 5510, lr = 1.95677e-06
I0226 17:29:34.523298  7672 solver.cpp:229] Iteration 5520, loss = 0.907966
I0226 17:29:34.523335  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.26345 (* 1 = 0.26345 loss)
I0226 17:29:34.523346  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.6367 (* 1 = 0.6367 loss)
I0226 17:29:34.523357  7672 sgd_solver.cpp:106] Iteration 5520, lr = 1.95677e-06
I0226 17:30:02.221905  7672 solver.cpp:229] Iteration 5530, loss = 0.871108
I0226 17:30:02.221959  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.28289 (* 1 = 0.28289 loss)
I0226 17:30:02.221971  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.808137 (* 1 = 0.808137 loss)
I0226 17:30:02.221982  7672 sgd_solver.cpp:106] Iteration 5530, lr = 1.95677e-06
I0226 17:30:29.889421  7672 solver.cpp:229] Iteration 5540, loss = 0.867077
I0226 17:30:29.889475  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.246438 (* 1 = 0.246438 loss)
I0226 17:30:29.889487  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.594824 (* 1 = 0.594824 loss)
I0226 17:30:29.889497  7672 sgd_solver.cpp:106] Iteration 5540, lr = 1.95677e-06
I0226 17:30:57.746091  7672 solver.cpp:229] Iteration 5550, loss = 0.953052
I0226 17:30:57.746129  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.210599 (* 1 = 0.210599 loss)
I0226 17:30:57.746140  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.703501 (* 1 = 0.703501 loss)
I0226 17:30:57.746150  7672 sgd_solver.cpp:106] Iteration 5550, lr = 1.95677e-06
I0226 17:31:25.516120  7672 solver.cpp:229] Iteration 5560, loss = 0.947041
I0226 17:31:25.516157  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.238419 (* 1 = 0.238419 loss)
I0226 17:31:25.516170  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.54048 (* 1 = 0.54048 loss)
I0226 17:31:25.516180  7672 sgd_solver.cpp:106] Iteration 5560, lr = 1.95677e-06
I0226 17:31:53.364786  7672 solver.cpp:229] Iteration 5570, loss = 0.961926
I0226 17:31:53.364822  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.289124 (* 1 = 0.289124 loss)
I0226 17:31:53.364835  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.71755 (* 1 = 0.71755 loss)
I0226 17:31:53.364845  7672 sgd_solver.cpp:106] Iteration 5570, lr = 1.95677e-06
I0226 17:32:21.104461  7672 solver.cpp:229] Iteration 5580, loss = 0.911509
I0226 17:32:21.104512  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.279951 (* 1 = 0.279951 loss)
I0226 17:32:21.104523  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.68346 (* 1 = 0.68346 loss)
I0226 17:32:21.104534  7672 sgd_solver.cpp:106] Iteration 5580, lr = 1.95677e-06
I0226 17:32:48.785452  7672 solver.cpp:229] Iteration 5590, loss = 0.874297
I0226 17:32:48.785497  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.23639 (* 1 = 0.23639 loss)
I0226 17:32:48.785508  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.544705 (* 1 = 0.544705 loss)
I0226 17:32:48.785519  7672 sgd_solver.cpp:106] Iteration 5590, lr = 1.95677e-06
I0226 17:33:16.516019  7672 solver.cpp:229] Iteration 5600, loss = 0.867487
I0226 17:33:16.516070  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.209209 (* 1 = 0.209209 loss)
I0226 17:33:16.516083  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.565106 (* 1 = 0.565106 loss)
I0226 17:33:16.516093  7672 sgd_solver.cpp:106] Iteration 5600, lr = 1.95677e-06
I0226 17:33:44.245529  7672 solver.cpp:229] Iteration 5610, loss = 0.848029
I0226 17:33:44.245604  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.24925 (* 1 = 0.24925 loss)
I0226 17:33:44.245620  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.565201 (* 1 = 0.565201 loss)
I0226 17:33:44.245635  7672 sgd_solver.cpp:106] Iteration 5610, lr = 1.95677e-06
I0226 17:34:12.070916  7672 solver.cpp:229] Iteration 5620, loss = 0.922406
I0226 17:34:12.070958  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.266983 (* 1 = 0.266983 loss)
I0226 17:34:12.070971  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.703748 (* 1 = 0.703748 loss)
I0226 17:34:12.070981  7672 sgd_solver.cpp:106] Iteration 5620, lr = 1.95677e-06
I0226 17:34:39.692579  7672 solver.cpp:229] Iteration 5630, loss = 0.879711
I0226 17:34:39.692631  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.209298 (* 1 = 0.209298 loss)
I0226 17:34:39.692641  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.71395 (* 1 = 0.71395 loss)
I0226 17:34:39.692663  7672 sgd_solver.cpp:106] Iteration 5630, lr = 1.95677e-06
I0226 17:35:07.481672  7672 solver.cpp:229] Iteration 5640, loss = 0.928654
I0226 17:35:07.481709  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.233139 (* 1 = 0.233139 loss)
I0226 17:35:07.481721  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.737108 (* 1 = 0.737108 loss)
I0226 17:35:07.481732  7672 sgd_solver.cpp:106] Iteration 5640, lr = 1.95677e-06
I0226 17:35:35.331404  7672 solver.cpp:229] Iteration 5650, loss = 1.03252
I0226 17:35:35.331444  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.261456 (* 1 = 0.261456 loss)
I0226 17:35:35.331455  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.819256 (* 1 = 0.819256 loss)
I0226 17:35:35.331466  7672 sgd_solver.cpp:106] Iteration 5650, lr = 1.95677e-06
I0226 17:36:03.118068  7672 solver.cpp:229] Iteration 5660, loss = 0.911393
I0226 17:36:03.118119  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.253035 (* 1 = 0.253035 loss)
I0226 17:36:03.118132  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.650537 (* 1 = 0.650537 loss)
I0226 17:36:03.118144  7672 sgd_solver.cpp:106] Iteration 5660, lr = 1.95677e-06
I0226 17:36:30.888095  7672 solver.cpp:229] Iteration 5670, loss = 0.936092
I0226 17:36:30.888134  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.246082 (* 1 = 0.246082 loss)
I0226 17:36:30.888146  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.654308 (* 1 = 0.654308 loss)
I0226 17:36:30.888157  7672 sgd_solver.cpp:106] Iteration 5670, lr = 1.95677e-06
I0226 17:36:58.571260  7672 solver.cpp:229] Iteration 5680, loss = 0.959342
I0226 17:36:58.571300  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.238164 (* 1 = 0.238164 loss)
I0226 17:36:58.571311  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.613615 (* 1 = 0.613615 loss)
I0226 17:36:58.571323  7672 sgd_solver.cpp:106] Iteration 5680, lr = 1.95677e-06
I0226 17:37:26.275310  7672 solver.cpp:229] Iteration 5690, loss = 0.971426
I0226 17:37:26.275347  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.226638 (* 1 = 0.226638 loss)
I0226 17:37:26.275358  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.601547 (* 1 = 0.601547 loss)
I0226 17:37:26.275369  7672 sgd_solver.cpp:106] Iteration 5690, lr = 1.95677e-06
I0226 17:37:54.306870  7672 solver.cpp:229] Iteration 5700, loss = 0.88014
I0226 17:37:54.306965  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.236898 (* 1 = 0.236898 loss)
I0226 17:37:54.306977  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.509359 (* 1 = 0.509359 loss)
I0226 17:37:54.306988  7672 sgd_solver.cpp:106] Iteration 5700, lr = 1.95677e-06
I0226 17:38:22.170553  7672 solver.cpp:229] Iteration 5710, loss = 0.895062
I0226 17:38:22.170605  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.288145 (* 1 = 0.288145 loss)
I0226 17:38:22.170616  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.618364 (* 1 = 0.618364 loss)
I0226 17:38:22.170627  7672 sgd_solver.cpp:106] Iteration 5710, lr = 1.95677e-06
I0226 17:38:49.888075  7672 solver.cpp:229] Iteration 5720, loss = 0.913947
I0226 17:38:49.888113  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.21712 (* 1 = 0.21712 loss)
I0226 17:38:49.888123  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.478824 (* 1 = 0.478824 loss)
I0226 17:38:49.888134  7672 sgd_solver.cpp:106] Iteration 5720, lr = 1.95677e-06
I0226 17:39:17.629004  7672 solver.cpp:229] Iteration 5730, loss = 0.915648
I0226 17:39:17.629041  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.281866 (* 1 = 0.281866 loss)
I0226 17:39:17.629052  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.638728 (* 1 = 0.638728 loss)
I0226 17:39:17.629063  7672 sgd_solver.cpp:106] Iteration 5730, lr = 1.95677e-06
I0226 17:39:45.454313  7672 solver.cpp:229] Iteration 5740, loss = 0.971869
I0226 17:39:45.454349  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.251231 (* 1 = 0.251231 loss)
I0226 17:39:45.454361  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.684897 (* 1 = 0.684897 loss)
I0226 17:39:45.454372  7672 sgd_solver.cpp:106] Iteration 5740, lr = 1.95677e-06
I0226 17:40:13.208441  7672 solver.cpp:229] Iteration 5750, loss = 0.867744
I0226 17:40:13.208493  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.260456 (* 1 = 0.260456 loss)
I0226 17:40:13.208504  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.593522 (* 1 = 0.593522 loss)
I0226 17:40:13.208514  7672 sgd_solver.cpp:106] Iteration 5750, lr = 1.95677e-06
I0226 17:40:41.118203  7672 solver.cpp:229] Iteration 5760, loss = 0.989919
I0226 17:40:41.118254  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.27048 (* 1 = 0.27048 loss)
I0226 17:40:41.118265  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.828002 (* 1 = 0.828002 loss)
I0226 17:40:41.118276  7672 sgd_solver.cpp:106] Iteration 5760, lr = 1.95677e-06
I0226 17:41:08.958158  7672 solver.cpp:229] Iteration 5770, loss = 0.931004
I0226 17:41:08.958195  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.242178 (* 1 = 0.242178 loss)
I0226 17:41:08.958206  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.649154 (* 1 = 0.649154 loss)
I0226 17:41:08.958217  7672 sgd_solver.cpp:106] Iteration 5770, lr = 1.95677e-06
I0226 17:41:36.876083  7672 solver.cpp:229] Iteration 5780, loss = 0.90996
I0226 17:41:36.876137  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.258139 (* 1 = 0.258139 loss)
I0226 17:41:36.876148  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.800895 (* 1 = 0.800895 loss)
I0226 17:41:36.876170  7672 sgd_solver.cpp:106] Iteration 5780, lr = 1.95677e-06
I0226 17:42:04.764741  7672 solver.cpp:229] Iteration 5790, loss = 0.818278
I0226 17:42:04.764780  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.2183 (* 1 = 0.2183 loss)
I0226 17:42:04.764791  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.540521 (* 1 = 0.540521 loss)
I0226 17:42:04.764801  7672 sgd_solver.cpp:106] Iteration 5790, lr = 1.95677e-06
I0226 17:42:32.576035  7672 solver.cpp:229] Iteration 5800, loss = 0.888184
I0226 17:42:32.576071  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.219576 (* 1 = 0.219576 loss)
I0226 17:42:32.576083  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.497798 (* 1 = 0.497798 loss)
I0226 17:42:32.576094  7672 sgd_solver.cpp:106] Iteration 5800, lr = 1.95677e-06
I0226 17:43:00.811437  7672 solver.cpp:229] Iteration 5810, loss = 0.941272
I0226 17:43:00.811475  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.248549 (* 1 = 0.248549 loss)
I0226 17:43:00.811487  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.651086 (* 1 = 0.651086 loss)
I0226 17:43:00.811498  7672 sgd_solver.cpp:106] Iteration 5810, lr = 1.95677e-06
I0226 17:43:28.549544  7672 solver.cpp:229] Iteration 5820, loss = 0.823448
I0226 17:43:28.549597  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.267602 (* 1 = 0.267602 loss)
I0226 17:43:28.549608  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.635705 (* 1 = 0.635705 loss)
I0226 17:43:28.549618  7672 sgd_solver.cpp:106] Iteration 5820, lr = 1.95677e-06
I0226 17:43:56.525578  7672 solver.cpp:229] Iteration 5830, loss = 0.87569
I0226 17:43:56.525632  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.241091 (* 1 = 0.241091 loss)
I0226 17:43:56.525643  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.641367 (* 1 = 0.641367 loss)
I0226 17:43:56.525655  7672 sgd_solver.cpp:106] Iteration 5830, lr = 1.95677e-06
I0226 17:44:24.669118  7672 solver.cpp:229] Iteration 5840, loss = 0.953192
I0226 17:44:24.669172  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.287337 (* 1 = 0.287337 loss)
I0226 17:44:24.669183  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.753577 (* 1 = 0.753577 loss)
I0226 17:44:24.669193  7672 sgd_solver.cpp:106] Iteration 5840, lr = 1.95677e-06
I0226 17:44:52.591224  7672 solver.cpp:229] Iteration 5850, loss = 0.848992
I0226 17:44:52.591262  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.222456 (* 1 = 0.222456 loss)
I0226 17:44:52.591274  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.481382 (* 1 = 0.481382 loss)
I0226 17:44:52.591285  7672 sgd_solver.cpp:106] Iteration 5850, lr = 1.95677e-06
I0226 17:45:20.484580  7672 solver.cpp:229] Iteration 5860, loss = 0.887606
I0226 17:45:20.484630  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.251811 (* 1 = 0.251811 loss)
I0226 17:45:20.484652  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.587011 (* 1 = 0.587011 loss)
I0226 17:45:20.484670  7672 sgd_solver.cpp:106] Iteration 5860, lr = 1.95677e-06
I0226 17:45:48.355551  7672 solver.cpp:229] Iteration 5870, loss = 0.891222
I0226 17:45:48.355618  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.257975 (* 1 = 0.257975 loss)
I0226 17:45:48.355629  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.691443 (* 1 = 0.691443 loss)
I0226 17:45:48.355640  7672 sgd_solver.cpp:106] Iteration 5870, lr = 1.95677e-06
I0226 17:46:16.239912  7672 solver.cpp:229] Iteration 5880, loss = 0.852666
I0226 17:46:16.239964  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.24573 (* 1 = 0.24573 loss)
I0226 17:46:16.239975  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.630923 (* 1 = 0.630923 loss)
I0226 17:46:16.239986  7672 sgd_solver.cpp:106] Iteration 5880, lr = 1.95677e-06
I0226 17:46:44.208575  7672 solver.cpp:229] Iteration 5890, loss = 0.941771
I0226 17:46:44.208612  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.228475 (* 1 = 0.228475 loss)
I0226 17:46:44.208623  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.580427 (* 1 = 0.580427 loss)
I0226 17:46:44.208636  7672 sgd_solver.cpp:106] Iteration 5890, lr = 1.95677e-06
I0226 17:47:12.085794  7672 solver.cpp:229] Iteration 5900, loss = 0.867199
I0226 17:47:12.085846  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.262805 (* 1 = 0.262805 loss)
I0226 17:47:12.085857  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.562318 (* 1 = 0.562318 loss)
I0226 17:47:12.085868  7672 sgd_solver.cpp:106] Iteration 5900, lr = 1.95677e-06
I0226 17:47:39.881587  7672 solver.cpp:229] Iteration 5910, loss = 0.945974
I0226 17:47:39.881639  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.277264 (* 1 = 0.277264 loss)
I0226 17:47:39.881650  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.703104 (* 1 = 0.703104 loss)
I0226 17:47:39.881661  7672 sgd_solver.cpp:106] Iteration 5910, lr = 1.95677e-06
I0226 17:48:07.750223  7672 solver.cpp:229] Iteration 5920, loss = 0.874366
I0226 17:48:07.750262  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.251942 (* 1 = 0.251942 loss)
I0226 17:48:07.750274  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.72255 (* 1 = 0.72255 loss)
I0226 17:48:07.750285  7672 sgd_solver.cpp:106] Iteration 5920, lr = 1.95677e-06
I0226 17:48:35.749022  7672 solver.cpp:229] Iteration 5930, loss = 0.918425
I0226 17:48:35.749058  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.221849 (* 1 = 0.221849 loss)
I0226 17:48:35.749070  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.589105 (* 1 = 0.589105 loss)
I0226 17:48:35.749081  7672 sgd_solver.cpp:106] Iteration 5930, lr = 1.95677e-06
I0226 17:49:03.871239  7672 solver.cpp:229] Iteration 5940, loss = 0.930545
I0226 17:49:03.871276  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.21823 (* 1 = 0.21823 loss)
I0226 17:49:03.871287  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.566127 (* 1 = 0.566127 loss)
I0226 17:49:03.871309  7672 sgd_solver.cpp:106] Iteration 5940, lr = 1.95677e-06
I0226 17:49:31.786300  7672 solver.cpp:229] Iteration 5950, loss = 0.902246
I0226 17:49:31.786351  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.255859 (* 1 = 0.255859 loss)
I0226 17:49:31.786363  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.65368 (* 1 = 0.65368 loss)
I0226 17:49:31.786373  7672 sgd_solver.cpp:106] Iteration 5950, lr = 1.95677e-06
I0226 17:49:59.664516  7672 solver.cpp:229] Iteration 5960, loss = 0.912047
I0226 17:49:59.664561  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.222131 (* 1 = 0.222131 loss)
I0226 17:49:59.664573  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.705154 (* 1 = 0.705154 loss)
I0226 17:49:59.664583  7672 sgd_solver.cpp:106] Iteration 5960, lr = 1.95677e-06
I0226 17:50:27.579242  7672 solver.cpp:229] Iteration 5970, loss = 0.94111
I0226 17:50:27.579282  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.263739 (* 1 = 0.263739 loss)
I0226 17:50:27.579293  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.650643 (* 1 = 0.650643 loss)
I0226 17:50:27.579303  7672 sgd_solver.cpp:106] Iteration 5970, lr = 1.95677e-06
I0226 17:50:55.625988  7672 solver.cpp:229] Iteration 5980, loss = 0.918872
I0226 17:50:55.626024  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.240264 (* 1 = 0.240264 loss)
I0226 17:50:55.626035  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.816338 (* 1 = 0.816338 loss)
I0226 17:50:55.626046  7672 sgd_solver.cpp:106] Iteration 5980, lr = 1.95677e-06
I0226 17:51:23.603368  7672 solver.cpp:229] Iteration 5990, loss = 0.936904
I0226 17:51:23.603416  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.280078 (* 1 = 0.280078 loss)
I0226 17:51:23.603438  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.747527 (* 1 = 0.747527 loss)
I0226 17:51:23.603456  7672 sgd_solver.cpp:106] Iteration 5990, lr = 1.95677e-06
I0226 17:51:51.540568  7672 solver.cpp:229] Iteration 6000, loss = 0.974648
I0226 17:51:51.540604  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.231912 (* 1 = 0.231912 loss)
I0226 17:51:51.540616  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.750871 (* 1 = 0.750871 loss)
I0226 17:51:51.540627  7672 sgd_solver.cpp:106] Iteration 6000, lr = 6.45734e-07
I0226 17:52:19.629876  7672 solver.cpp:229] Iteration 6010, loss = 0.919287
I0226 17:52:19.629930  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.277581 (* 1 = 0.277581 loss)
I0226 17:52:19.629941  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.718064 (* 1 = 0.718064 loss)
I0226 17:52:19.629952  7672 sgd_solver.cpp:106] Iteration 6010, lr = 6.45734e-07
I0226 17:52:47.563171  7672 solver.cpp:229] Iteration 6020, loss = 0.982751
I0226 17:52:47.563210  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.25578 (* 1 = 0.25578 loss)
I0226 17:52:47.563222  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.71841 (* 1 = 0.71841 loss)
I0226 17:52:47.563232  7672 sgd_solver.cpp:106] Iteration 6020, lr = 6.45734e-07
I0226 17:53:15.575986  7672 solver.cpp:229] Iteration 6030, loss = 0.870366
I0226 17:53:15.576030  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.230937 (* 1 = 0.230937 loss)
I0226 17:53:15.576040  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.48234 (* 1 = 0.48234 loss)
I0226 17:53:15.576051  7672 sgd_solver.cpp:106] Iteration 6030, lr = 6.45734e-07
I0226 17:53:43.619889  7672 solver.cpp:229] Iteration 6040, loss = 0.905568
I0226 17:53:43.619940  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.275224 (* 1 = 0.275224 loss)
I0226 17:53:43.619951  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.849557 (* 1 = 0.849557 loss)
I0226 17:53:43.619968  7672 sgd_solver.cpp:106] Iteration 6040, lr = 6.45734e-07
I0226 17:54:11.421540  7672 solver.cpp:229] Iteration 6050, loss = 0.867894
I0226 17:54:11.421577  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.268904 (* 1 = 0.268904 loss)
I0226 17:54:11.421589  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.567322 (* 1 = 0.567322 loss)
I0226 17:54:11.421600  7672 sgd_solver.cpp:106] Iteration 6050, lr = 6.45734e-07
I0226 17:54:39.327731  7672 solver.cpp:229] Iteration 6060, loss = 0.918203
I0226 17:54:39.327785  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.224953 (* 1 = 0.224953 loss)
I0226 17:54:39.327796  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.51317 (* 1 = 0.51317 loss)
I0226 17:54:39.327807  7672 sgd_solver.cpp:106] Iteration 6060, lr = 6.45734e-07
I0226 17:55:07.258417  7672 solver.cpp:229] Iteration 6070, loss = 0.90181
I0226 17:55:07.258468  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.27948 (* 1 = 0.27948 loss)
I0226 17:55:07.258479  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.908342 (* 1 = 0.908342 loss)
I0226 17:55:07.258489  7672 sgd_solver.cpp:106] Iteration 6070, lr = 6.45734e-07
I0226 17:55:35.095526  7672 solver.cpp:229] Iteration 6080, loss = 0.858546
I0226 17:55:35.095580  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.237015 (* 1 = 0.237015 loss)
I0226 17:55:35.095592  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.671046 (* 1 = 0.671046 loss)
I0226 17:55:35.095603  7672 sgd_solver.cpp:106] Iteration 6080, lr = 6.45734e-07
I0226 17:56:03.071830  7672 solver.cpp:229] Iteration 6090, loss = 0.929811
I0226 17:56:03.071867  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.254495 (* 1 = 0.254495 loss)
I0226 17:56:03.071880  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.675531 (* 1 = 0.675531 loss)
I0226 17:56:03.071892  7672 sgd_solver.cpp:106] Iteration 6090, lr = 6.45734e-07
I0226 17:56:31.039018  7672 solver.cpp:229] Iteration 6100, loss = 0.864854
I0226 17:56:31.039057  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.263689 (* 1 = 0.263689 loss)
I0226 17:56:31.039067  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.6725 (* 1 = 0.6725 loss)
I0226 17:56:31.039078  7672 sgd_solver.cpp:106] Iteration 6100, lr = 6.45734e-07
I0226 17:56:59.288367  7672 solver.cpp:229] Iteration 6110, loss = 0.873255
I0226 17:56:59.288404  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.22576 (* 1 = 0.22576 loss)
I0226 17:56:59.288415  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.420625 (* 1 = 0.420625 loss)
I0226 17:56:59.288426  7672 sgd_solver.cpp:106] Iteration 6110, lr = 6.45734e-07
I0226 17:57:27.171880  7672 solver.cpp:229] Iteration 6120, loss = 0.830883
I0226 17:57:27.171936  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.256885 (* 1 = 0.256885 loss)
I0226 17:57:27.171947  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.6066 (* 1 = 0.6066 loss)
I0226 17:57:27.171957  7672 sgd_solver.cpp:106] Iteration 6120, lr = 6.45734e-07
I0226 17:57:54.949287  7672 solver.cpp:229] Iteration 6130, loss = 0.894412
I0226 17:57:54.949326  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.221832 (* 1 = 0.221832 loss)
I0226 17:57:54.949337  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.637239 (* 1 = 0.637239 loss)
I0226 17:57:54.949347  7672 sgd_solver.cpp:106] Iteration 6130, lr = 6.45734e-07
I0226 17:58:22.517272  7672 solver.cpp:229] Iteration 6140, loss = 0.89839
I0226 17:58:22.517324  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.245689 (* 1 = 0.245689 loss)
I0226 17:58:22.517335  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.601429 (* 1 = 0.601429 loss)
I0226 17:58:22.517346  7672 sgd_solver.cpp:106] Iteration 6140, lr = 6.45734e-07
I0226 17:58:50.182227  7672 solver.cpp:229] Iteration 6150, loss = 0.920515
I0226 17:58:50.182265  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.216348 (* 1 = 0.216348 loss)
I0226 17:58:50.182276  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.752775 (* 1 = 0.752775 loss)
I0226 17:58:50.182286  7672 sgd_solver.cpp:106] Iteration 6150, lr = 6.45734e-07
I0226 17:59:17.959226  7672 solver.cpp:229] Iteration 6160, loss = 0.916018
I0226 17:59:17.959264  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.221265 (* 1 = 0.221265 loss)
I0226 17:59:17.959276  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.803436 (* 1 = 0.803436 loss)
I0226 17:59:17.959286  7672 sgd_solver.cpp:106] Iteration 6160, lr = 6.45734e-07
I0226 17:59:45.516077  7672 solver.cpp:229] Iteration 6170, loss = 0.976584
I0226 17:59:45.516114  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.205398 (* 1 = 0.205398 loss)
I0226 17:59:45.516125  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.587031 (* 1 = 0.587031 loss)
I0226 17:59:45.516136  7672 sgd_solver.cpp:106] Iteration 6170, lr = 6.45734e-07
I0226 18:00:13.213567  7672 solver.cpp:229] Iteration 6180, loss = 0.925226
I0226 18:00:13.213603  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.255732 (* 1 = 0.255732 loss)
I0226 18:00:13.213614  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.5627 (* 1 = 0.5627 loss)
I0226 18:00:13.213625  7672 sgd_solver.cpp:106] Iteration 6180, lr = 6.45734e-07
I0226 18:00:41.044292  7672 solver.cpp:229] Iteration 6190, loss = 0.998824
I0226 18:00:41.044328  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.243897 (* 1 = 0.243897 loss)
I0226 18:00:41.044339  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.593963 (* 1 = 0.593963 loss)
I0226 18:00:41.044350  7672 sgd_solver.cpp:106] Iteration 6190, lr = 6.45734e-07
I0226 18:01:08.706068  7672 solver.cpp:229] Iteration 6200, loss = 0.848856
I0226 18:01:08.706106  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.228828 (* 1 = 0.228828 loss)
I0226 18:01:08.706118  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.57514 (* 1 = 0.57514 loss)
I0226 18:01:08.706130  7672 sgd_solver.cpp:106] Iteration 6200, lr = 6.45734e-07
I0226 18:01:36.394377  7672 solver.cpp:229] Iteration 6210, loss = 0.960361
I0226 18:01:36.394415  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.270977 (* 1 = 0.270977 loss)
I0226 18:01:36.394428  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.710206 (* 1 = 0.710206 loss)
I0226 18:01:36.394438  7672 sgd_solver.cpp:106] Iteration 6210, lr = 6.45734e-07
I0226 18:02:04.063030  7672 solver.cpp:229] Iteration 6220, loss = 0.883312
I0226 18:02:04.063066  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.250268 (* 1 = 0.250268 loss)
I0226 18:02:04.063078  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.725757 (* 1 = 0.725757 loss)
I0226 18:02:04.063091  7672 sgd_solver.cpp:106] Iteration 6220, lr = 6.45734e-07
I0226 18:02:31.815773  7672 solver.cpp:229] Iteration 6230, loss = 0.90223
I0226 18:02:31.815811  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.224563 (* 1 = 0.224563 loss)
I0226 18:02:31.815822  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.571402 (* 1 = 0.571402 loss)
I0226 18:02:31.815832  7672 sgd_solver.cpp:106] Iteration 6230, lr = 6.45734e-07
I0226 18:02:59.508471  7672 solver.cpp:229] Iteration 6240, loss = 0.906078
I0226 18:02:59.508523  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.276642 (* 1 = 0.276642 loss)
I0226 18:02:59.508534  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.694255 (* 1 = 0.694255 loss)
I0226 18:02:59.508546  7672 sgd_solver.cpp:106] Iteration 6240, lr = 6.45734e-07
I0226 18:03:27.304378  7672 solver.cpp:229] Iteration 6250, loss = 0.953185
I0226 18:03:27.304446  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.232283 (* 1 = 0.232283 loss)
I0226 18:03:27.304457  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.584313 (* 1 = 0.584313 loss)
I0226 18:03:27.304468  7672 sgd_solver.cpp:106] Iteration 6250, lr = 6.45734e-07
I0226 18:03:55.039034  7672 solver.cpp:229] Iteration 6260, loss = 0.948651
I0226 18:03:55.039088  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.225579 (* 1 = 0.225579 loss)
I0226 18:03:55.039108  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.607463 (* 1 = 0.607463 loss)
I0226 18:03:55.039122  7672 sgd_solver.cpp:106] Iteration 6260, lr = 6.45734e-07
I0226 18:04:22.674566  7672 solver.cpp:229] Iteration 6270, loss = 0.824315
I0226 18:04:22.674602  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.206332 (* 1 = 0.206332 loss)
I0226 18:04:22.674614  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.448151 (* 1 = 0.448151 loss)
I0226 18:04:22.674625  7672 sgd_solver.cpp:106] Iteration 6270, lr = 6.45734e-07
I0226 18:04:50.336736  7672 solver.cpp:229] Iteration 6280, loss = 0.831489
I0226 18:04:50.336773  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.233473 (* 1 = 0.233473 loss)
I0226 18:04:50.336786  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.627143 (* 1 = 0.627143 loss)
I0226 18:04:50.336796  7672 sgd_solver.cpp:106] Iteration 6280, lr = 6.45734e-07
I0226 18:05:18.198554  7672 solver.cpp:229] Iteration 6290, loss = 0.974336
I0226 18:05:18.198590  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.253175 (* 1 = 0.253175 loss)
I0226 18:05:18.198601  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.775212 (* 1 = 0.775212 loss)
I0226 18:05:18.198611  7672 sgd_solver.cpp:106] Iteration 6290, lr = 6.45734e-07
I0226 18:05:45.971475  7672 solver.cpp:229] Iteration 6300, loss = 0.969486
I0226 18:05:45.971511  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.272535 (* 1 = 0.272535 loss)
I0226 18:05:45.971523  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.670575 (* 1 = 0.670575 loss)
I0226 18:05:45.971534  7672 sgd_solver.cpp:106] Iteration 6300, lr = 6.45734e-07
I0226 18:06:13.709513  7672 solver.cpp:229] Iteration 6310, loss = 0.889614
I0226 18:06:13.709568  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.220117 (* 1 = 0.220117 loss)
I0226 18:06:13.709579  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.56187 (* 1 = 0.56187 loss)
I0226 18:06:13.709590  7672 sgd_solver.cpp:106] Iteration 6310, lr = 6.45734e-07
I0226 18:06:41.470944  7672 solver.cpp:229] Iteration 6320, loss = 0.925396
I0226 18:06:41.470980  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.262554 (* 1 = 0.262554 loss)
I0226 18:06:41.470993  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.582618 (* 1 = 0.582618 loss)
I0226 18:06:41.471004  7672 sgd_solver.cpp:106] Iteration 6320, lr = 6.45734e-07
I0226 18:07:09.280180  7672 solver.cpp:229] Iteration 6330, loss = 0.854979
I0226 18:07:09.280231  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.233592 (* 1 = 0.233592 loss)
I0226 18:07:09.280243  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.651301 (* 1 = 0.651301 loss)
I0226 18:07:09.280254  7672 sgd_solver.cpp:106] Iteration 6330, lr = 6.45734e-07
I0226 18:07:37.197973  7672 solver.cpp:229] Iteration 6340, loss = 0.900422
I0226 18:07:37.198024  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.235746 (* 1 = 0.235746 loss)
I0226 18:07:37.198036  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.590492 (* 1 = 0.590492 loss)
I0226 18:07:37.198047  7672 sgd_solver.cpp:106] Iteration 6340, lr = 6.45734e-07
I0226 18:08:05.136590  7672 solver.cpp:229] Iteration 6350, loss = 0.998007
I0226 18:08:05.136626  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.291747 (* 1 = 0.291747 loss)
I0226 18:08:05.136637  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.671476 (* 1 = 0.671476 loss)
I0226 18:08:05.136648  7672 sgd_solver.cpp:106] Iteration 6350, lr = 6.45734e-07
I0226 18:08:33.025753  7672 solver.cpp:229] Iteration 6360, loss = 0.934331
I0226 18:08:33.025802  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.227012 (* 1 = 0.227012 loss)
I0226 18:08:33.025815  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.651527 (* 1 = 0.651527 loss)
I0226 18:08:33.025840  7672 sgd_solver.cpp:106] Iteration 6360, lr = 6.45734e-07
I0226 18:09:00.733340  7672 solver.cpp:229] Iteration 6370, loss = 0.848973
I0226 18:09:00.733377  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.240486 (* 1 = 0.240486 loss)
I0226 18:09:00.733388  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.609497 (* 1 = 0.609497 loss)
I0226 18:09:00.733399  7672 sgd_solver.cpp:106] Iteration 6370, lr = 6.45734e-07
I0226 18:09:28.359614  7672 solver.cpp:229] Iteration 6380, loss = 0.889981
I0226 18:09:28.359668  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.222976 (* 1 = 0.222976 loss)
I0226 18:09:28.359679  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.666082 (* 1 = 0.666082 loss)
I0226 18:09:28.359690  7672 sgd_solver.cpp:106] Iteration 6380, lr = 6.45734e-07
I0226 18:09:56.317471  7672 solver.cpp:229] Iteration 6390, loss = 0.929172
I0226 18:09:56.317509  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.252398 (* 1 = 0.252398 loss)
I0226 18:09:56.317520  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.599176 (* 1 = 0.599176 loss)
I0226 18:09:56.317531  7672 sgd_solver.cpp:106] Iteration 6390, lr = 6.45734e-07
I0226 18:10:23.967826  7672 solver.cpp:229] Iteration 6400, loss = 0.882679
I0226 18:10:23.967864  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.258304 (* 1 = 0.258304 loss)
I0226 18:10:23.967875  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.741123 (* 1 = 0.741123 loss)
I0226 18:10:23.967885  7672 sgd_solver.cpp:106] Iteration 6400, lr = 6.45734e-07
I0226 18:10:51.740231  7672 solver.cpp:229] Iteration 6410, loss = 0.91464
I0226 18:10:51.740267  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.1936 (* 1 = 0.1936 loss)
I0226 18:10:51.740279  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.649218 (* 1 = 0.649218 loss)
I0226 18:10:51.740289  7672 sgd_solver.cpp:106] Iteration 6410, lr = 6.45734e-07
I0226 18:11:19.424619  7672 solver.cpp:229] Iteration 6420, loss = 0.865299
I0226 18:11:19.424656  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.266948 (* 1 = 0.266948 loss)
I0226 18:11:19.424669  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.747853 (* 1 = 0.747853 loss)
I0226 18:11:19.424679  7672 sgd_solver.cpp:106] Iteration 6420, lr = 6.45734e-07
I0226 18:11:47.352258  7672 solver.cpp:229] Iteration 6430, loss = 0.881357
I0226 18:11:47.352296  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.269184 (* 1 = 0.269184 loss)
I0226 18:11:47.352308  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.659058 (* 1 = 0.659058 loss)
I0226 18:11:47.352319  7672 sgd_solver.cpp:106] Iteration 6430, lr = 6.45734e-07
I0226 18:12:15.190029  7672 solver.cpp:229] Iteration 6440, loss = 0.903798
I0226 18:12:15.190068  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.251398 (* 1 = 0.251398 loss)
I0226 18:12:15.190079  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.848227 (* 1 = 0.848227 loss)
I0226 18:12:15.190090  7672 sgd_solver.cpp:106] Iteration 6440, lr = 6.45734e-07
I0226 18:12:43.031085  7672 solver.cpp:229] Iteration 6450, loss = 0.860764
I0226 18:12:43.031123  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.228864 (* 1 = 0.228864 loss)
I0226 18:12:43.031134  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.592472 (* 1 = 0.592472 loss)
I0226 18:12:43.031145  7672 sgd_solver.cpp:106] Iteration 6450, lr = 6.45734e-07
I0226 18:13:10.657714  7672 solver.cpp:229] Iteration 6460, loss = 0.784933
I0226 18:13:10.657768  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.283637 (* 1 = 0.283637 loss)
I0226 18:13:10.657778  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.550618 (* 1 = 0.550618 loss)
I0226 18:13:10.657789  7672 sgd_solver.cpp:106] Iteration 6460, lr = 6.45734e-07
I0226 18:13:38.297878  7672 solver.cpp:229] Iteration 6470, loss = 0.941906
I0226 18:13:38.297915  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.203384 (* 1 = 0.203384 loss)
I0226 18:13:38.297926  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.432799 (* 1 = 0.432799 loss)
I0226 18:13:38.297937  7672 sgd_solver.cpp:106] Iteration 6470, lr = 6.45734e-07
I0226 18:14:06.158962  7672 solver.cpp:229] Iteration 6480, loss = 0.940071
I0226 18:14:06.158999  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.28912 (* 1 = 0.28912 loss)
I0226 18:14:06.159013  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.767639 (* 1 = 0.767639 loss)
I0226 18:14:06.159024  7672 sgd_solver.cpp:106] Iteration 6480, lr = 6.45734e-07
I0226 18:14:34.125483  7672 solver.cpp:229] Iteration 6490, loss = 0.909087
I0226 18:14:34.125519  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.258367 (* 1 = 0.258367 loss)
I0226 18:14:34.125530  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.749965 (* 1 = 0.749965 loss)
I0226 18:14:34.125541  7672 sgd_solver.cpp:106] Iteration 6490, lr = 6.45734e-07
I0226 18:15:01.832377  7672 solver.cpp:229] Iteration 6500, loss = 0.897779
I0226 18:15:01.832428  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.271703 (* 1 = 0.271703 loss)
I0226 18:15:01.832440  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.751852 (* 1 = 0.751852 loss)
I0226 18:15:01.832450  7672 sgd_solver.cpp:106] Iteration 6500, lr = 6.45734e-07
I0226 18:15:29.669801  7672 solver.cpp:229] Iteration 6510, loss = 0.900693
I0226 18:15:29.669853  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.265009 (* 1 = 0.265009 loss)
I0226 18:15:29.669864  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.677229 (* 1 = 0.677229 loss)
I0226 18:15:29.669875  7672 sgd_solver.cpp:106] Iteration 6510, lr = 6.45734e-07
I0226 18:15:57.528256  7672 solver.cpp:229] Iteration 6520, loss = 0.906446
I0226 18:15:57.528307  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.260957 (* 1 = 0.260957 loss)
I0226 18:15:57.528318  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.793911 (* 1 = 0.793911 loss)
I0226 18:15:57.528329  7672 sgd_solver.cpp:106] Iteration 6520, lr = 6.45734e-07
I0226 18:16:25.223872  7672 solver.cpp:229] Iteration 6530, loss = 0.982177
I0226 18:16:25.223911  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.233314 (* 1 = 0.233314 loss)
I0226 18:16:25.223922  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.646806 (* 1 = 0.646806 loss)
I0226 18:16:25.223932  7672 sgd_solver.cpp:106] Iteration 6530, lr = 6.45734e-07
I0226 18:16:53.005962  7672 solver.cpp:229] Iteration 6540, loss = 0.933414
I0226 18:16:53.006013  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.230003 (* 1 = 0.230003 loss)
I0226 18:16:53.006024  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.500112 (* 1 = 0.500112 loss)
I0226 18:16:53.006034  7672 sgd_solver.cpp:106] Iteration 6540, lr = 6.45734e-07
I0226 18:17:20.703785  7672 solver.cpp:229] Iteration 6550, loss = 0.909675
I0226 18:17:20.703821  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.216376 (* 1 = 0.216376 loss)
I0226 18:17:20.703832  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.827635 (* 1 = 0.827635 loss)
I0226 18:17:20.703843  7672 sgd_solver.cpp:106] Iteration 6550, lr = 6.45734e-07
I0226 18:17:48.419318  7672 solver.cpp:229] Iteration 6560, loss = 0.834093
I0226 18:17:48.419358  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.268013 (* 1 = 0.268013 loss)
I0226 18:17:48.419368  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.573143 (* 1 = 0.573143 loss)
I0226 18:17:48.419380  7672 sgd_solver.cpp:106] Iteration 6560, lr = 6.45734e-07
I0226 18:18:16.256338  7672 solver.cpp:229] Iteration 6570, loss = 0.870534
I0226 18:18:16.256376  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.266576 (* 1 = 0.266576 loss)
I0226 18:18:16.256386  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.756496 (* 1 = 0.756496 loss)
I0226 18:18:16.256397  7672 sgd_solver.cpp:106] Iteration 6570, lr = 6.45734e-07
I0226 18:18:43.863131  7672 solver.cpp:229] Iteration 6580, loss = 0.864801
I0226 18:18:43.863168  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.224144 (* 1 = 0.224144 loss)
I0226 18:18:43.863178  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.529639 (* 1 = 0.529639 loss)
I0226 18:18:43.863189  7672 sgd_solver.cpp:106] Iteration 6580, lr = 6.45734e-07
I0226 18:19:11.519397  7672 solver.cpp:229] Iteration 6590, loss = 0.921446
I0226 18:19:11.519433  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.232006 (* 1 = 0.232006 loss)
I0226 18:19:11.519444  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.825032 (* 1 = 0.825032 loss)
I0226 18:19:11.519455  7672 sgd_solver.cpp:106] Iteration 6590, lr = 6.45734e-07
I0226 18:19:39.296581  7672 solver.cpp:229] Iteration 6600, loss = 0.939326
I0226 18:19:39.296618  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.237449 (* 1 = 0.237449 loss)
I0226 18:19:39.296630  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.564504 (* 1 = 0.564504 loss)
I0226 18:19:39.296641  7672 sgd_solver.cpp:106] Iteration 6600, lr = 6.45734e-07
I0226 18:20:07.144472  7672 solver.cpp:229] Iteration 6610, loss = 0.901058
I0226 18:20:07.144524  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.236826 (* 1 = 0.236826 loss)
I0226 18:20:07.144536  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.612404 (* 1 = 0.612404 loss)
I0226 18:20:07.144547  7672 sgd_solver.cpp:106] Iteration 6610, lr = 6.45734e-07
I0226 18:20:34.943482  7672 solver.cpp:229] Iteration 6620, loss = 0.935672
I0226 18:20:34.943521  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.225133 (* 1 = 0.225133 loss)
I0226 18:20:34.943531  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.872372 (* 1 = 0.872372 loss)
I0226 18:20:34.943542  7672 sgd_solver.cpp:106] Iteration 6620, lr = 6.45734e-07
I0226 18:21:02.634223  7672 solver.cpp:229] Iteration 6630, loss = 0.96476
I0226 18:21:02.634263  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.233065 (* 1 = 0.233065 loss)
I0226 18:21:02.634274  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.658702 (* 1 = 0.658702 loss)
I0226 18:21:02.634284  7672 sgd_solver.cpp:106] Iteration 6630, lr = 6.45734e-07
I0226 18:21:30.520599  7672 solver.cpp:229] Iteration 6640, loss = 0.936753
I0226 18:21:30.520653  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.27605 (* 1 = 0.27605 loss)
I0226 18:21:30.520665  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.713492 (* 1 = 0.713492 loss)
I0226 18:21:30.520689  7672 sgd_solver.cpp:106] Iteration 6640, lr = 6.45734e-07
I0226 18:21:58.198549  7672 solver.cpp:229] Iteration 6650, loss = 0.919265
I0226 18:21:58.198602  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.266734 (* 1 = 0.266734 loss)
I0226 18:21:58.198613  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.684884 (* 1 = 0.684884 loss)
I0226 18:21:58.198624  7672 sgd_solver.cpp:106] Iteration 6650, lr = 6.45734e-07
I0226 18:22:25.841825  7672 solver.cpp:229] Iteration 6660, loss = 0.88954
I0226 18:22:25.841878  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.236371 (* 1 = 0.236371 loss)
I0226 18:22:25.841890  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.659032 (* 1 = 0.659032 loss)
I0226 18:22:25.841902  7672 sgd_solver.cpp:106] Iteration 6660, lr = 6.45734e-07
I0226 18:22:53.597003  7672 solver.cpp:229] Iteration 6670, loss = 0.930104
I0226 18:22:53.597052  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.256959 (* 1 = 0.256959 loss)
I0226 18:22:53.597064  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.899326 (* 1 = 0.899326 loss)
I0226 18:22:53.597075  7672 sgd_solver.cpp:106] Iteration 6670, lr = 6.45734e-07
I0226 18:23:21.480042  7672 solver.cpp:229] Iteration 6680, loss = 1.04142
I0226 18:23:21.480079  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.243962 (* 1 = 0.243962 loss)
I0226 18:23:21.480093  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.870508 (* 1 = 0.870508 loss)
I0226 18:23:21.480104  7672 sgd_solver.cpp:106] Iteration 6680, lr = 6.45734e-07
I0226 18:23:49.186394  7672 solver.cpp:229] Iteration 6690, loss = 0.866119
I0226 18:23:49.186450  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.247537 (* 1 = 0.247537 loss)
I0226 18:23:49.186462  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.611783 (* 1 = 0.611783 loss)
I0226 18:23:49.186473  7672 sgd_solver.cpp:106] Iteration 6690, lr = 6.45734e-07
I0226 18:24:16.970366  7672 solver.cpp:229] Iteration 6700, loss = 0.86935
I0226 18:24:16.970402  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.259853 (* 1 = 0.259853 loss)
I0226 18:24:16.970413  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.71251 (* 1 = 0.71251 loss)
I0226 18:24:16.970423  7672 sgd_solver.cpp:106] Iteration 6700, lr = 6.45734e-07
I0226 18:24:46.524775  7672 solver.cpp:229] Iteration 6710, loss = 0.941616
I0226 18:24:46.524819  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.271096 (* 1 = 0.271096 loss)
I0226 18:24:46.524832  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.716056 (* 1 = 0.716056 loss)
I0226 18:24:46.524842  7672 sgd_solver.cpp:106] Iteration 6710, lr = 6.45734e-07
I0226 18:25:21.129204  7672 solver.cpp:229] Iteration 6720, loss = 0.940269
I0226 18:25:21.129290  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.236512 (* 1 = 0.236512 loss)
I0226 18:25:21.129312  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.695882 (* 1 = 0.695882 loss)
I0226 18:25:21.129344  7672 sgd_solver.cpp:106] Iteration 6720, lr = 6.45734e-07
I0226 18:25:53.479841  7672 solver.cpp:229] Iteration 6730, loss = 0.875709
I0226 18:25:53.479913  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.288943 (* 1 = 0.288943 loss)
I0226 18:25:53.479935  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.537765 (* 1 = 0.537765 loss)
I0226 18:25:53.479961  7672 sgd_solver.cpp:106] Iteration 6730, lr = 6.45734e-07
I0226 18:26:22.433765  7672 solver.cpp:229] Iteration 6740, loss = 0.982507
I0226 18:26:22.433809  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.26065 (* 1 = 0.26065 loss)
I0226 18:26:22.433820  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.710318 (* 1 = 0.710318 loss)
I0226 18:26:22.433831  7672 sgd_solver.cpp:106] Iteration 6740, lr = 6.45734e-07
I0226 18:26:51.344193  7672 solver.cpp:229] Iteration 6750, loss = 0.87085
I0226 18:26:51.344238  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.25013 (* 1 = 0.25013 loss)
I0226 18:26:51.344249  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.673937 (* 1 = 0.673937 loss)
I0226 18:26:51.344260  7672 sgd_solver.cpp:106] Iteration 6750, lr = 6.45734e-07
I0226 18:27:20.387135  7672 solver.cpp:229] Iteration 6760, loss = 0.908512
I0226 18:27:20.387187  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.221462 (* 1 = 0.221462 loss)
I0226 18:27:20.387207  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.446042 (* 1 = 0.446042 loss)
I0226 18:27:20.387224  7672 sgd_solver.cpp:106] Iteration 6760, lr = 6.45734e-07
I0226 18:27:49.153957  7672 solver.cpp:229] Iteration 6770, loss = 0.922143
I0226 18:27:49.154000  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.231677 (* 1 = 0.231677 loss)
I0226 18:27:49.154011  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.652409 (* 1 = 0.652409 loss)
I0226 18:27:49.154021  7672 sgd_solver.cpp:106] Iteration 6770, lr = 6.45734e-07
I0226 18:28:17.806367  7672 solver.cpp:229] Iteration 6780, loss = 0.954429
I0226 18:28:17.806409  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.258099 (* 1 = 0.258099 loss)
I0226 18:28:17.806421  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.573786 (* 1 = 0.573786 loss)
I0226 18:28:17.806432  7672 sgd_solver.cpp:106] Iteration 6780, lr = 6.45734e-07
I0226 18:28:46.721477  7672 solver.cpp:229] Iteration 6790, loss = 0.973468
I0226 18:28:46.721519  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.263887 (* 1 = 0.263887 loss)
I0226 18:28:46.721531  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.662895 (* 1 = 0.662895 loss)
I0226 18:28:46.721544  7672 sgd_solver.cpp:106] Iteration 6790, lr = 6.45734e-07
I0226 18:29:15.531884  7672 solver.cpp:229] Iteration 6800, loss = 0.879025
I0226 18:29:15.531924  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.239648 (* 1 = 0.239648 loss)
I0226 18:29:15.531935  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.605429 (* 1 = 0.605429 loss)
I0226 18:29:15.531946  7672 sgd_solver.cpp:106] Iteration 6800, lr = 6.45734e-07
I0226 18:29:44.596297  7672 solver.cpp:229] Iteration 6810, loss = 0.914215
I0226 18:29:44.596359  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.226991 (* 1 = 0.226991 loss)
I0226 18:29:44.596370  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.640376 (* 1 = 0.640376 loss)
I0226 18:29:44.596381  7672 sgd_solver.cpp:106] Iteration 6810, lr = 6.45734e-07
I0226 18:30:13.445407  7672 solver.cpp:229] Iteration 6820, loss = 0.852624
I0226 18:30:13.445452  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.215514 (* 1 = 0.215514 loss)
I0226 18:30:13.445464  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.67378 (* 1 = 0.67378 loss)
I0226 18:30:13.445477  7672 sgd_solver.cpp:106] Iteration 6820, lr = 6.45734e-07
I0226 18:30:42.380640  7672 solver.cpp:229] Iteration 6830, loss = 0.844187
I0226 18:30:42.380692  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.187893 (* 1 = 0.187893 loss)
I0226 18:30:42.380703  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.468085 (* 1 = 0.468085 loss)
I0226 18:30:42.380714  7672 sgd_solver.cpp:106] Iteration 6830, lr = 6.45734e-07
I0226 18:31:11.227283  7672 solver.cpp:229] Iteration 6840, loss = 0.922812
I0226 18:31:11.227332  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.272362 (* 1 = 0.272362 loss)
I0226 18:31:11.227344  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.654671 (* 1 = 0.654671 loss)
I0226 18:31:11.227356  7672 sgd_solver.cpp:106] Iteration 6840, lr = 6.45734e-07
I0226 18:31:39.848682  7672 solver.cpp:229] Iteration 6850, loss = 0.886042
I0226 18:31:39.848731  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.26439 (* 1 = 0.26439 loss)
I0226 18:31:39.848748  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.735326 (* 1 = 0.735326 loss)
I0226 18:31:39.848767  7672 sgd_solver.cpp:106] Iteration 6850, lr = 6.45734e-07
I0226 18:32:08.883225  7672 solver.cpp:229] Iteration 6860, loss = 0.938775
I0226 18:32:08.883272  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.236161 (* 1 = 0.236161 loss)
I0226 18:32:08.883285  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.688434 (* 1 = 0.688434 loss)
I0226 18:32:08.883296  7672 sgd_solver.cpp:106] Iteration 6860, lr = 6.45734e-07
I0226 18:32:37.762456  7672 solver.cpp:229] Iteration 6870, loss = 0.938312
I0226 18:32:37.762493  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.249944 (* 1 = 0.249944 loss)
I0226 18:32:37.762506  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.79125 (* 1 = 0.79125 loss)
I0226 18:32:37.762516  7672 sgd_solver.cpp:106] Iteration 6870, lr = 6.45734e-07
I0226 18:33:06.606932  7672 solver.cpp:229] Iteration 6880, loss = 0.920682
I0226 18:33:06.606978  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.220488 (* 1 = 0.220488 loss)
I0226 18:33:06.606989  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.560588 (* 1 = 0.560588 loss)
I0226 18:33:06.607002  7672 sgd_solver.cpp:106] Iteration 6880, lr = 6.45734e-07
I0226 18:33:35.128290  7672 solver.cpp:229] Iteration 6890, loss = 0.886464
I0226 18:33:35.128334  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.234025 (* 1 = 0.234025 loss)
I0226 18:33:35.128346  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.704841 (* 1 = 0.704841 loss)
I0226 18:33:35.128356  7672 sgd_solver.cpp:106] Iteration 6890, lr = 6.45734e-07
I0226 18:34:03.825462  7672 solver.cpp:229] Iteration 6900, loss = 0.909562
I0226 18:34:03.825510  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.20358 (* 1 = 0.20358 loss)
I0226 18:34:03.825522  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.570422 (* 1 = 0.570422 loss)
I0226 18:34:03.825533  7672 sgd_solver.cpp:106] Iteration 6900, lr = 6.45734e-07
I0226 18:34:32.922493  7672 solver.cpp:229] Iteration 6910, loss = 0.847494
I0226 18:34:32.922538  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.246808 (* 1 = 0.246808 loss)
I0226 18:34:32.922549  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.636364 (* 1 = 0.636364 loss)
I0226 18:34:32.922560  7672 sgd_solver.cpp:106] Iteration 6910, lr = 6.45734e-07
I0226 18:35:01.899464  7672 solver.cpp:229] Iteration 6920, loss = 0.962998
I0226 18:35:01.899505  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.276883 (* 1 = 0.276883 loss)
I0226 18:35:01.899518  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.863888 (* 1 = 0.863888 loss)
I0226 18:35:01.899528  7672 sgd_solver.cpp:106] Iteration 6920, lr = 6.45734e-07
I0226 18:35:31.007808  7672 solver.cpp:229] Iteration 6930, loss = 0.960872
I0226 18:35:31.007846  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.239274 (* 1 = 0.239274 loss)
I0226 18:35:31.007858  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.977382 (* 1 = 0.977382 loss)
I0226 18:35:31.007869  7672 sgd_solver.cpp:106] Iteration 6930, lr = 6.45734e-07
I0226 18:35:59.861119  7672 solver.cpp:229] Iteration 6940, loss = 0.875497
I0226 18:35:59.861166  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.23188 (* 1 = 0.23188 loss)
I0226 18:35:59.861177  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.594722 (* 1 = 0.594722 loss)
I0226 18:35:59.861188  7672 sgd_solver.cpp:106] Iteration 6940, lr = 6.45734e-07
I0226 18:36:28.839177  7672 solver.cpp:229] Iteration 6950, loss = 0.852267
I0226 18:36:28.839222  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.236042 (* 1 = 0.236042 loss)
I0226 18:36:28.839234  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.587663 (* 1 = 0.587663 loss)
I0226 18:36:28.839246  7672 sgd_solver.cpp:106] Iteration 6950, lr = 6.45734e-07
I0226 18:36:57.705853  7672 solver.cpp:229] Iteration 6960, loss = 0.942645
I0226 18:36:57.705907  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.236578 (* 1 = 0.236578 loss)
I0226 18:36:57.705925  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.527383 (* 1 = 0.527383 loss)
I0226 18:36:57.705940  7672 sgd_solver.cpp:106] Iteration 6960, lr = 6.45734e-07
I0226 18:37:26.618681  7672 solver.cpp:229] Iteration 6970, loss = 0.915257
I0226 18:37:26.618724  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.29648 (* 1 = 0.29648 loss)
I0226 18:37:26.618736  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.668636 (* 1 = 0.668636 loss)
I0226 18:37:26.618747  7672 sgd_solver.cpp:106] Iteration 6970, lr = 6.45734e-07
I0226 18:37:55.767845  7672 solver.cpp:229] Iteration 6980, loss = 0.925061
I0226 18:37:55.767892  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.292978 (* 1 = 0.292978 loss)
I0226 18:37:55.767904  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.629172 (* 1 = 0.629172 loss)
I0226 18:37:55.767915  7672 sgd_solver.cpp:106] Iteration 6980, lr = 6.45734e-07
I0226 18:38:25.045226  7672 solver.cpp:229] Iteration 6990, loss = 0.881248
I0226 18:38:25.045274  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.248308 (* 1 = 0.248308 loss)
I0226 18:38:25.045284  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.659519 (* 1 = 0.659519 loss)
I0226 18:38:25.045296  7672 sgd_solver.cpp:106] Iteration 6990, lr = 6.45734e-07
I0226 18:38:54.227887  7672 solver.cpp:229] Iteration 7000, loss = 0.929875
I0226 18:38:54.227968  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.251804 (* 1 = 0.251804 loss)
I0226 18:38:54.227986  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.487765 (* 1 = 0.487765 loss)
I0226 18:38:54.228004  7672 sgd_solver.cpp:106] Iteration 7000, lr = 2.13092e-07
I0226 18:39:23.162464  7672 solver.cpp:229] Iteration 7010, loss = 0.885239
I0226 18:39:23.162531  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.204136 (* 1 = 0.204136 loss)
I0226 18:39:23.162560  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.468898 (* 1 = 0.468898 loss)
I0226 18:39:23.162577  7672 sgd_solver.cpp:106] Iteration 7010, lr = 2.13092e-07
I0226 18:39:51.978284  7672 solver.cpp:229] Iteration 7020, loss = 0.904218
I0226 18:39:51.978328  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.237632 (* 1 = 0.237632 loss)
I0226 18:39:51.978339  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.575587 (* 1 = 0.575587 loss)
I0226 18:39:51.978350  7672 sgd_solver.cpp:106] Iteration 7020, lr = 2.13092e-07
I0226 18:40:21.151008  7672 solver.cpp:229] Iteration 7030, loss = 0.932812
I0226 18:40:21.151052  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.271914 (* 1 = 0.271914 loss)
I0226 18:40:21.151064  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.812213 (* 1 = 0.812213 loss)
I0226 18:40:21.151075  7672 sgd_solver.cpp:106] Iteration 7030, lr = 2.13092e-07
I0226 18:40:50.155082  7672 solver.cpp:229] Iteration 7040, loss = 0.932815
I0226 18:40:50.155128  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.252042 (* 1 = 0.252042 loss)
I0226 18:40:50.155139  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.625504 (* 1 = 0.625504 loss)
I0226 18:40:50.155151  7672 sgd_solver.cpp:106] Iteration 7040, lr = 2.13092e-07
I0226 18:41:19.270550  7672 solver.cpp:229] Iteration 7050, loss = 0.919395
I0226 18:41:19.270603  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.240656 (* 1 = 0.240656 loss)
I0226 18:41:19.270615  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.501987 (* 1 = 0.501987 loss)
I0226 18:41:19.270627  7672 sgd_solver.cpp:106] Iteration 7050, lr = 2.13092e-07
I0226 18:41:48.005553  7672 solver.cpp:229] Iteration 7060, loss = 0.876468
I0226 18:41:48.005609  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.243189 (* 1 = 0.243189 loss)
I0226 18:41:48.005627  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.666035 (* 1 = 0.666035 loss)
I0226 18:41:48.005640  7672 sgd_solver.cpp:106] Iteration 7060, lr = 2.13092e-07
I0226 18:42:16.623687  7672 solver.cpp:229] Iteration 7070, loss = 0.916884
I0226 18:42:16.623729  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.273174 (* 1 = 0.273174 loss)
I0226 18:42:16.623740  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.913766 (* 1 = 0.913766 loss)
I0226 18:42:16.623751  7672 sgd_solver.cpp:106] Iteration 7070, lr = 2.13092e-07
I0226 18:42:45.557241  7672 solver.cpp:229] Iteration 7080, loss = 0.937026
I0226 18:42:45.557286  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.242648 (* 1 = 0.242648 loss)
I0226 18:42:45.557297  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.635354 (* 1 = 0.635354 loss)
I0226 18:42:45.557308  7672 sgd_solver.cpp:106] Iteration 7080, lr = 2.13092e-07
I0226 18:43:14.551335  7672 solver.cpp:229] Iteration 7090, loss = 0.836634
I0226 18:43:14.551388  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.268997 (* 1 = 0.268997 loss)
I0226 18:43:14.551401  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.777264 (* 1 = 0.777264 loss)
I0226 18:43:14.551417  7672 sgd_solver.cpp:106] Iteration 7090, lr = 2.13092e-07
I0226 18:43:44.046600  7672 solver.cpp:229] Iteration 7100, loss = 0.955598
I0226 18:43:44.046643  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.281753 (* 1 = 0.281753 loss)
I0226 18:43:44.046653  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.581719 (* 1 = 0.581719 loss)
I0226 18:43:44.046664  7672 sgd_solver.cpp:106] Iteration 7100, lr = 2.13092e-07
I0226 18:44:13.105114  7672 solver.cpp:229] Iteration 7110, loss = 0.930559
I0226 18:44:13.105166  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.251429 (* 1 = 0.251429 loss)
I0226 18:44:13.105186  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.621358 (* 1 = 0.621358 loss)
I0226 18:44:13.105204  7672 sgd_solver.cpp:106] Iteration 7110, lr = 2.13092e-07
I0226 18:44:41.945272  7672 solver.cpp:229] Iteration 7120, loss = 0.912439
I0226 18:44:41.945317  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.239132 (* 1 = 0.239132 loss)
I0226 18:44:41.945329  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.580815 (* 1 = 0.580815 loss)
I0226 18:44:41.945340  7672 sgd_solver.cpp:106] Iteration 7120, lr = 2.13092e-07
I0226 18:45:10.753870  7672 solver.cpp:229] Iteration 7130, loss = 0.915431
I0226 18:45:10.753921  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.236249 (* 1 = 0.236249 loss)
I0226 18:45:10.753933  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.570289 (* 1 = 0.570289 loss)
I0226 18:45:10.753945  7672 sgd_solver.cpp:106] Iteration 7130, lr = 2.13092e-07
I0226 18:45:39.888999  7672 solver.cpp:229] Iteration 7140, loss = 0.922008
I0226 18:45:39.889072  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.217434 (* 1 = 0.217434 loss)
I0226 18:45:39.889103  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.611687 (* 1 = 0.611687 loss)
I0226 18:45:39.889127  7672 sgd_solver.cpp:106] Iteration 7140, lr = 2.13092e-07
I0226 18:46:09.169330  7672 solver.cpp:229] Iteration 7150, loss = 0.870802
I0226 18:46:09.169385  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.249181 (* 1 = 0.249181 loss)
I0226 18:46:09.169397  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.55366 (* 1 = 0.55366 loss)
I0226 18:46:09.169416  7672 sgd_solver.cpp:106] Iteration 7150, lr = 2.13092e-07
I0226 18:46:38.895628  7672 solver.cpp:229] Iteration 7160, loss = 0.925746
I0226 18:46:38.895668  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.266204 (* 1 = 0.266204 loss)
I0226 18:46:38.895679  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.837916 (* 1 = 0.837916 loss)
I0226 18:46:38.895690  7672 sgd_solver.cpp:106] Iteration 7160, lr = 2.13092e-07
I0226 18:47:08.843534  7672 solver.cpp:229] Iteration 7170, loss = 0.926041
I0226 18:47:08.843581  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.268696 (* 1 = 0.268696 loss)
I0226 18:47:08.843592  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.790871 (* 1 = 0.790871 loss)
I0226 18:47:08.843605  7672 sgd_solver.cpp:106] Iteration 7170, lr = 2.13092e-07
I0226 18:47:38.904906  7672 solver.cpp:229] Iteration 7180, loss = 0.874569
I0226 18:47:38.904953  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.222756 (* 1 = 0.222756 loss)
I0226 18:47:38.904964  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.674938 (* 1 = 0.674938 loss)
I0226 18:47:38.904975  7672 sgd_solver.cpp:106] Iteration 7180, lr = 2.13092e-07
I0226 18:48:09.041756  7672 solver.cpp:229] Iteration 7190, loss = 0.917322
I0226 18:48:09.041817  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.259713 (* 1 = 0.259713 loss)
I0226 18:48:09.041829  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.73968 (* 1 = 0.73968 loss)
I0226 18:48:09.041841  7672 sgd_solver.cpp:106] Iteration 7190, lr = 2.13092e-07
I0226 18:48:38.976408  7672 solver.cpp:229] Iteration 7200, loss = 0.879265
I0226 18:48:38.976450  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.210565 (* 1 = 0.210565 loss)
I0226 18:48:38.976462  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.385521 (* 1 = 0.385521 loss)
I0226 18:48:38.976474  7672 sgd_solver.cpp:106] Iteration 7200, lr = 2.13092e-07
I0226 18:49:08.728420  7672 solver.cpp:229] Iteration 7210, loss = 0.944277
I0226 18:49:08.728471  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.239255 (* 1 = 0.239255 loss)
I0226 18:49:08.728487  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.635987 (* 1 = 0.635987 loss)
I0226 18:49:08.728502  7672 sgd_solver.cpp:106] Iteration 7210, lr = 2.13092e-07
I0226 18:49:38.511576  7672 solver.cpp:229] Iteration 7220, loss = 0.880147
I0226 18:49:38.511620  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.256718 (* 1 = 0.256718 loss)
I0226 18:49:38.511631  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.506631 (* 1 = 0.506631 loss)
I0226 18:49:38.511641  7672 sgd_solver.cpp:106] Iteration 7220, lr = 2.13092e-07
I0226 18:50:08.753203  7672 solver.cpp:229] Iteration 7230, loss = 0.953436
I0226 18:50:08.753275  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.305836 (* 1 = 0.305836 loss)
I0226 18:50:08.753295  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.702487 (* 1 = 0.702487 loss)
I0226 18:50:08.753314  7672 sgd_solver.cpp:106] Iteration 7230, lr = 2.13092e-07
I0226 18:50:38.923188  7672 solver.cpp:229] Iteration 7240, loss = 0.899643
I0226 18:50:38.923243  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.29546 (* 1 = 0.29546 loss)
I0226 18:50:38.923254  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.948245 (* 1 = 0.948245 loss)
I0226 18:50:38.923267  7672 sgd_solver.cpp:106] Iteration 7240, lr = 2.13092e-07
I0226 18:51:08.623507  7672 solver.cpp:229] Iteration 7250, loss = 1.01842
I0226 18:51:08.623555  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.259802 (* 1 = 0.259802 loss)
I0226 18:51:08.623567  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.920665 (* 1 = 0.920665 loss)
I0226 18:51:08.623579  7672 sgd_solver.cpp:106] Iteration 7250, lr = 2.13092e-07
I0226 18:51:38.653151  7672 solver.cpp:229] Iteration 7260, loss = 0.882967
I0226 18:51:38.653194  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.210016 (* 1 = 0.210016 loss)
I0226 18:51:38.653206  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.473204 (* 1 = 0.473204 loss)
I0226 18:51:38.653218  7672 sgd_solver.cpp:106] Iteration 7260, lr = 2.13092e-07
I0226 18:52:08.303699  7672 solver.cpp:229] Iteration 7270, loss = 0.869655
I0226 18:52:08.303742  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.276731 (* 1 = 0.276731 loss)
I0226 18:52:08.303759  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.756682 (* 1 = 0.756682 loss)
I0226 18:52:08.303776  7672 sgd_solver.cpp:106] Iteration 7270, lr = 2.13092e-07
I0226 18:52:38.202313  7672 solver.cpp:229] Iteration 7280, loss = 0.95766
I0226 18:52:38.202358  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.218507 (* 1 = 0.218507 loss)
I0226 18:52:38.202369  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.709646 (* 1 = 0.709646 loss)
I0226 18:52:38.202384  7672 sgd_solver.cpp:106] Iteration 7280, lr = 2.13092e-07
I0226 18:53:07.969395  7672 solver.cpp:229] Iteration 7290, loss = 0.883694
I0226 18:53:07.969444  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.233197 (* 1 = 0.233197 loss)
I0226 18:53:07.969461  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.837835 (* 1 = 0.837835 loss)
I0226 18:53:07.969477  7672 sgd_solver.cpp:106] Iteration 7290, lr = 2.13092e-07
I0226 18:53:37.987654  7672 solver.cpp:229] Iteration 7300, loss = 0.884092
I0226 18:53:37.987735  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.224408 (* 1 = 0.224408 loss)
I0226 18:53:37.987751  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.965762 (* 1 = 0.965762 loss)
I0226 18:53:37.987764  7672 sgd_solver.cpp:106] Iteration 7300, lr = 2.13092e-07
I0226 18:54:07.939532  7672 solver.cpp:229] Iteration 7310, loss = 0.898935
I0226 18:54:07.939581  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.256327 (* 1 = 0.256327 loss)
I0226 18:54:07.939594  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.754708 (* 1 = 0.754708 loss)
I0226 18:54:07.939605  7672 sgd_solver.cpp:106] Iteration 7310, lr = 2.13092e-07
I0226 18:54:37.850106  7672 solver.cpp:229] Iteration 7320, loss = 0.876785
I0226 18:54:37.850164  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.232094 (* 1 = 0.232094 loss)
I0226 18:54:37.850175  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.551889 (* 1 = 0.551889 loss)
I0226 18:54:37.850185  7672 sgd_solver.cpp:106] Iteration 7320, lr = 2.13092e-07
I0226 18:55:07.844525  7672 solver.cpp:229] Iteration 7330, loss = 0.906963
I0226 18:55:07.844579  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.26769 (* 1 = 0.26769 loss)
I0226 18:55:07.844597  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.527104 (* 1 = 0.527104 loss)
I0226 18:55:07.844609  7672 sgd_solver.cpp:106] Iteration 7330, lr = 2.13092e-07
I0226 18:55:38.526511  7672 solver.cpp:229] Iteration 7340, loss = 0.934326
I0226 18:55:38.526561  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.219734 (* 1 = 0.219734 loss)
I0226 18:55:38.526572  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.583336 (* 1 = 0.583336 loss)
I0226 18:55:38.526584  7672 sgd_solver.cpp:106] Iteration 7340, lr = 2.13092e-07
I0226 18:56:08.702437  7672 solver.cpp:229] Iteration 7350, loss = 0.916903
I0226 18:56:08.702491  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.24731 (* 1 = 0.24731 loss)
I0226 18:56:08.702505  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.697823 (* 1 = 0.697823 loss)
I0226 18:56:08.702517  7672 sgd_solver.cpp:106] Iteration 7350, lr = 2.13092e-07
I0226 18:56:38.423779  7672 solver.cpp:229] Iteration 7360, loss = 0.838614
I0226 18:56:38.423820  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.227281 (* 1 = 0.227281 loss)
I0226 18:56:38.423831  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.638896 (* 1 = 0.638896 loss)
I0226 18:56:38.423842  7672 sgd_solver.cpp:106] Iteration 7360, lr = 2.13092e-07
I0226 18:57:08.570125  7672 solver.cpp:229] Iteration 7370, loss = 0.901194
I0226 18:57:08.570168  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.270889 (* 1 = 0.270889 loss)
I0226 18:57:08.570179  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.621628 (* 1 = 0.621628 loss)
I0226 18:57:08.570191  7672 sgd_solver.cpp:106] Iteration 7370, lr = 2.13092e-07
I0226 18:57:38.787787  7672 solver.cpp:229] Iteration 7380, loss = 0.928067
I0226 18:57:38.787832  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.235198 (* 1 = 0.235198 loss)
I0226 18:57:38.787847  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.741748 (* 1 = 0.741748 loss)
I0226 18:57:38.787860  7672 sgd_solver.cpp:106] Iteration 7380, lr = 2.13092e-07
I0226 18:58:08.286384  7672 solver.cpp:229] Iteration 7390, loss = 0.934159
I0226 18:58:08.286434  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.261167 (* 1 = 0.261167 loss)
I0226 18:58:08.286449  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.628605 (* 1 = 0.628605 loss)
I0226 18:58:08.286463  7672 sgd_solver.cpp:106] Iteration 7390, lr = 2.13092e-07
I0226 18:58:38.122225  7672 solver.cpp:229] Iteration 7400, loss = 0.888189
I0226 18:58:38.122264  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.222662 (* 1 = 0.222662 loss)
I0226 18:58:38.122277  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.620848 (* 1 = 0.620848 loss)
I0226 18:58:38.122287  7672 sgd_solver.cpp:106] Iteration 7400, lr = 2.13092e-07
I0226 18:59:08.124123  7672 solver.cpp:229] Iteration 7410, loss = 0.890376
I0226 18:59:08.124169  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.23967 (* 1 = 0.23967 loss)
I0226 18:59:08.124181  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.499331 (* 1 = 0.499331 loss)
I0226 18:59:08.124192  7672 sgd_solver.cpp:106] Iteration 7410, lr = 2.13092e-07
I0226 18:59:38.206992  7672 solver.cpp:229] Iteration 7420, loss = 0.950759
I0226 18:59:38.207052  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.258461 (* 1 = 0.258461 loss)
I0226 18:59:38.207074  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.717808 (* 1 = 0.717808 loss)
I0226 18:59:38.207094  7672 sgd_solver.cpp:106] Iteration 7420, lr = 2.13092e-07
I0226 19:00:08.005403  7672 solver.cpp:229] Iteration 7430, loss = 0.885301
I0226 19:00:08.005446  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.249232 (* 1 = 0.249232 loss)
I0226 19:00:08.005457  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.654396 (* 1 = 0.654396 loss)
I0226 19:00:08.005468  7672 sgd_solver.cpp:106] Iteration 7430, lr = 2.13092e-07
I0226 19:00:38.369639  7672 solver.cpp:229] Iteration 7440, loss = 0.94234
I0226 19:00:38.369688  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.26812 (* 1 = 0.26812 loss)
I0226 19:00:38.369699  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.745948 (* 1 = 0.745948 loss)
I0226 19:00:38.369709  7672 sgd_solver.cpp:106] Iteration 7440, lr = 2.13092e-07
I0226 19:01:08.731544  7672 solver.cpp:229] Iteration 7450, loss = 0.874871
I0226 19:01:08.731587  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.288255 (* 1 = 0.288255 loss)
I0226 19:01:08.731602  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.672916 (* 1 = 0.672916 loss)
I0226 19:01:08.731618  7672 sgd_solver.cpp:106] Iteration 7450, lr = 2.13092e-07
I0226 19:01:39.011255  7672 solver.cpp:229] Iteration 7460, loss = 0.930781
I0226 19:01:39.011297  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.246186 (* 1 = 0.246186 loss)
I0226 19:01:39.011309  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.48175 (* 1 = 0.48175 loss)
I0226 19:01:39.011320  7672 sgd_solver.cpp:106] Iteration 7460, lr = 2.13092e-07
I0226 19:02:08.833446  7672 solver.cpp:229] Iteration 7470, loss = 0.92522
I0226 19:02:08.833506  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.269663 (* 1 = 0.269663 loss)
I0226 19:02:08.833518  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.621251 (* 1 = 0.621251 loss)
I0226 19:02:08.833528  7672 sgd_solver.cpp:106] Iteration 7470, lr = 2.13092e-07
I0226 19:02:38.667948  7672 solver.cpp:229] Iteration 7480, loss = 0.893921
I0226 19:02:38.667999  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.278351 (* 1 = 0.278351 loss)
I0226 19:02:38.668017  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.709099 (* 1 = 0.709099 loss)
I0226 19:02:38.668030  7672 sgd_solver.cpp:106] Iteration 7480, lr = 2.13092e-07
I0226 19:03:08.651374  7672 solver.cpp:229] Iteration 7490, loss = 0.962285
I0226 19:03:08.651417  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.182576 (* 1 = 0.182576 loss)
I0226 19:03:08.651432  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.864323 (* 1 = 0.864323 loss)
I0226 19:03:08.651450  7672 sgd_solver.cpp:106] Iteration 7490, lr = 2.13092e-07
I0226 19:03:38.832082  7672 solver.cpp:229] Iteration 7500, loss = 1.04731
I0226 19:03:38.832132  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.309187 (* 1 = 0.309187 loss)
I0226 19:03:38.832145  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.846725 (* 1 = 0.846725 loss)
I0226 19:03:38.832156  7672 sgd_solver.cpp:106] Iteration 7500, lr = 2.13092e-07
I0226 19:04:08.542951  7672 solver.cpp:229] Iteration 7510, loss = 0.893299
I0226 19:04:08.543012  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.247073 (* 1 = 0.247073 loss)
I0226 19:04:08.543032  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.520817 (* 1 = 0.520817 loss)
I0226 19:04:08.543057  7672 sgd_solver.cpp:106] Iteration 7510, lr = 2.13092e-07
I0226 19:04:38.652097  7672 solver.cpp:229] Iteration 7520, loss = 0.920358
I0226 19:04:38.652139  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.282353 (* 1 = 0.282353 loss)
I0226 19:04:38.652151  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.665536 (* 1 = 0.665536 loss)
I0226 19:04:38.652163  7672 sgd_solver.cpp:106] Iteration 7520, lr = 2.13092e-07
I0226 19:05:08.407826  7672 solver.cpp:229] Iteration 7530, loss = 0.900045
I0226 19:05:08.407893  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.233152 (* 1 = 0.233152 loss)
I0226 19:05:08.407917  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.5761 (* 1 = 0.5761 loss)
I0226 19:05:08.407934  7672 sgd_solver.cpp:106] Iteration 7530, lr = 2.13092e-07
I0226 19:05:38.382700  7672 solver.cpp:229] Iteration 7540, loss = 0.971382
I0226 19:05:38.382773  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.22717 (* 1 = 0.22717 loss)
I0226 19:05:38.382795  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.566755 (* 1 = 0.566755 loss)
I0226 19:05:38.382810  7672 sgd_solver.cpp:106] Iteration 7540, lr = 2.13092e-07
I0226 19:06:08.205898  7672 solver.cpp:229] Iteration 7550, loss = 0.967056
I0226 19:06:08.205948  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.243883 (* 1 = 0.243883 loss)
I0226 19:06:08.205960  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.670253 (* 1 = 0.670253 loss)
I0226 19:06:08.205974  7672 sgd_solver.cpp:106] Iteration 7550, lr = 2.13092e-07
I0226 19:06:37.958161  7672 solver.cpp:229] Iteration 7560, loss = 0.885788
I0226 19:06:37.958241  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.285522 (* 1 = 0.285522 loss)
I0226 19:06:37.958259  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.545691 (* 1 = 0.545691 loss)
I0226 19:06:37.958274  7672 sgd_solver.cpp:106] Iteration 7560, lr = 2.13092e-07
I0226 19:07:07.652894  7672 solver.cpp:229] Iteration 7570, loss = 0.957375
I0226 19:07:07.652937  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.242501 (* 1 = 0.242501 loss)
I0226 19:07:07.652950  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.669652 (* 1 = 0.669652 loss)
I0226 19:07:07.652969  7672 sgd_solver.cpp:106] Iteration 7570, lr = 2.13092e-07
I0226 19:07:37.490844  7672 solver.cpp:229] Iteration 7580, loss = 0.95041
I0226 19:07:37.490928  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.268393 (* 1 = 0.268393 loss)
I0226 19:07:37.490947  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.671951 (* 1 = 0.671951 loss)
I0226 19:07:37.490963  7672 sgd_solver.cpp:106] Iteration 7580, lr = 2.13092e-07
I0226 19:08:07.091939  7672 solver.cpp:229] Iteration 7590, loss = 0.90707
I0226 19:08:07.092005  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.248939 (* 1 = 0.248939 loss)
I0226 19:08:07.092021  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.674246 (* 1 = 0.674246 loss)
I0226 19:08:07.092032  7672 sgd_solver.cpp:106] Iteration 7590, lr = 2.13092e-07
I0226 19:08:36.840962  7672 solver.cpp:229] Iteration 7600, loss = 0.900966
I0226 19:08:36.841027  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.235942 (* 1 = 0.235942 loss)
I0226 19:08:36.841047  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.64125 (* 1 = 0.64125 loss)
I0226 19:08:36.841061  7672 sgd_solver.cpp:106] Iteration 7600, lr = 2.13092e-07
I0226 19:09:06.700755  7672 solver.cpp:229] Iteration 7610, loss = 0.902217
I0226 19:09:06.700798  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.250189 (* 1 = 0.250189 loss)
I0226 19:09:06.700817  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.577247 (* 1 = 0.577247 loss)
I0226 19:09:06.700839  7672 sgd_solver.cpp:106] Iteration 7610, lr = 2.13092e-07
I0226 19:09:36.847525  7672 solver.cpp:229] Iteration 7620, loss = 0.920164
I0226 19:09:36.847584  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.262717 (* 1 = 0.262717 loss)
I0226 19:09:36.847602  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.692455 (* 1 = 0.692455 loss)
I0226 19:09:36.847620  7672 sgd_solver.cpp:106] Iteration 7620, lr = 2.13092e-07
I0226 19:10:06.654798  7672 solver.cpp:229] Iteration 7630, loss = 0.895783
I0226 19:10:06.654855  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.240213 (* 1 = 0.240213 loss)
I0226 19:10:06.654901  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.540391 (* 1 = 0.540391 loss)
I0226 19:10:06.654918  7672 sgd_solver.cpp:106] Iteration 7630, lr = 2.13092e-07
I0226 19:10:37.017657  7672 solver.cpp:229] Iteration 7640, loss = 0.944158
I0226 19:10:37.017705  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.257298 (* 1 = 0.257298 loss)
I0226 19:10:37.017716  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.6999 (* 1 = 0.6999 loss)
I0226 19:10:37.017727  7672 sgd_solver.cpp:106] Iteration 7640, lr = 2.13092e-07
I0226 19:11:06.756707  7672 solver.cpp:229] Iteration 7650, loss = 0.900541
I0226 19:11:06.756774  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.290354 (* 1 = 0.290354 loss)
I0226 19:11:06.756800  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.77585 (* 1 = 0.77585 loss)
I0226 19:11:06.756821  7672 sgd_solver.cpp:106] Iteration 7650, lr = 2.13092e-07
I0226 19:11:36.887114  7672 solver.cpp:229] Iteration 7660, loss = 0.838241
I0226 19:11:36.887163  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.217208 (* 1 = 0.217208 loss)
I0226 19:11:36.887176  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.545666 (* 1 = 0.545666 loss)
I0226 19:11:36.887190  7672 sgd_solver.cpp:106] Iteration 7660, lr = 2.13092e-07
I0226 19:12:07.064728  7672 solver.cpp:229] Iteration 7670, loss = 0.922775
I0226 19:12:07.064792  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.217103 (* 1 = 0.217103 loss)
I0226 19:12:07.064815  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.614571 (* 1 = 0.614571 loss)
I0226 19:12:07.064837  7672 sgd_solver.cpp:106] Iteration 7670, lr = 2.13092e-07
I0226 19:12:36.952502  7672 solver.cpp:229] Iteration 7680, loss = 0.919891
I0226 19:12:36.952554  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.23194 (* 1 = 0.23194 loss)
I0226 19:12:36.952574  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.815244 (* 1 = 0.815244 loss)
I0226 19:12:36.952589  7672 sgd_solver.cpp:106] Iteration 7680, lr = 2.13092e-07
I0226 19:13:07.102190  7672 solver.cpp:229] Iteration 7690, loss = 0.889157
I0226 19:13:07.102244  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.217154 (* 1 = 0.217154 loss)
I0226 19:13:07.102259  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.493961 (* 1 = 0.493961 loss)
I0226 19:13:07.102275  7672 sgd_solver.cpp:106] Iteration 7690, lr = 2.13092e-07
I0226 19:13:36.732641  7672 solver.cpp:229] Iteration 7700, loss = 0.858729
I0226 19:13:36.732707  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.227548 (* 1 = 0.227548 loss)
I0226 19:13:36.732743  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.431525 (* 1 = 0.431525 loss)
I0226 19:13:36.732759  7672 sgd_solver.cpp:106] Iteration 7700, lr = 2.13092e-07
I0226 19:14:06.707150  7672 solver.cpp:229] Iteration 7710, loss = 0.935454
I0226 19:14:06.707206  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.290763 (* 1 = 0.290763 loss)
I0226 19:14:06.707218  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.799641 (* 1 = 0.799641 loss)
I0226 19:14:06.707229  7672 sgd_solver.cpp:106] Iteration 7710, lr = 2.13092e-07
I0226 19:14:36.545397  7672 solver.cpp:229] Iteration 7720, loss = 0.840807
I0226 19:14:36.545457  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.191163 (* 1 = 0.191163 loss)
I0226 19:14:36.545469  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.437196 (* 1 = 0.437196 loss)
I0226 19:14:36.545480  7672 sgd_solver.cpp:106] Iteration 7720, lr = 2.13092e-07
I0226 19:15:06.676358  7672 solver.cpp:229] Iteration 7730, loss = 0.884215
I0226 19:15:06.676416  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.23261 (* 1 = 0.23261 loss)
I0226 19:15:06.676436  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.682998 (* 1 = 0.682998 loss)
I0226 19:15:06.676450  7672 sgd_solver.cpp:106] Iteration 7730, lr = 2.13092e-07
I0226 19:15:36.406810  7672 solver.cpp:229] Iteration 7740, loss = 0.94212
I0226 19:15:36.406932  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.241687 (* 1 = 0.241687 loss)
I0226 19:15:36.406950  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.509314 (* 1 = 0.509314 loss)
I0226 19:15:36.406965  7672 sgd_solver.cpp:106] Iteration 7740, lr = 2.13092e-07
I0226 19:16:06.869549  7672 solver.cpp:229] Iteration 7750, loss = 0.924091
I0226 19:16:06.869594  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.24001 (* 1 = 0.24001 loss)
I0226 19:16:06.869606  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.887288 (* 1 = 0.887288 loss)
I0226 19:16:06.869617  7672 sgd_solver.cpp:106] Iteration 7750, lr = 2.13092e-07
I0226 19:16:36.773761  7672 solver.cpp:229] Iteration 7760, loss = 0.883526
I0226 19:16:36.773804  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.255731 (* 1 = 0.255731 loss)
I0226 19:16:36.773816  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.680445 (* 1 = 0.680445 loss)
I0226 19:16:36.773828  7672 sgd_solver.cpp:106] Iteration 7760, lr = 2.13092e-07
I0226 19:17:06.796766  7672 solver.cpp:229] Iteration 7770, loss = 0.897435
I0226 19:17:06.796823  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.228819 (* 1 = 0.228819 loss)
I0226 19:17:06.796842  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.610209 (* 1 = 0.610209 loss)
I0226 19:17:06.796859  7672 sgd_solver.cpp:106] Iteration 7770, lr = 2.13092e-07
I0226 19:17:36.561713  7672 solver.cpp:229] Iteration 7780, loss = 0.904325
I0226 19:17:36.561754  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.217269 (* 1 = 0.217269 loss)
I0226 19:17:36.561766  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.669675 (* 1 = 0.669675 loss)
I0226 19:17:36.561777  7672 sgd_solver.cpp:106] Iteration 7780, lr = 2.13092e-07
I0226 19:18:06.412124  7672 solver.cpp:229] Iteration 7790, loss = 0.950591
I0226 19:18:06.412196  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.25548 (* 1 = 0.25548 loss)
I0226 19:18:06.412219  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.743773 (* 1 = 0.743773 loss)
I0226 19:18:06.412236  7672 sgd_solver.cpp:106] Iteration 7790, lr = 2.13092e-07
I0226 19:18:36.280277  7672 solver.cpp:229] Iteration 7800, loss = 0.84212
I0226 19:18:36.280335  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.252002 (* 1 = 0.252002 loss)
I0226 19:18:36.280346  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.770013 (* 1 = 0.770013 loss)
I0226 19:18:36.280359  7672 sgd_solver.cpp:106] Iteration 7800, lr = 2.13092e-07
I0226 19:19:05.688727  7672 solver.cpp:229] Iteration 7810, loss = 0.941439
I0226 19:19:05.688769  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.212894 (* 1 = 0.212894 loss)
I0226 19:19:05.688781  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.778709 (* 1 = 0.778709 loss)
I0226 19:19:05.688793  7672 sgd_solver.cpp:106] Iteration 7810, lr = 2.13092e-07
I0226 19:19:34.929432  7672 solver.cpp:229] Iteration 7820, loss = 0.861322
I0226 19:19:34.929520  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.235637 (* 1 = 0.235637 loss)
I0226 19:19:34.929543  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.74471 (* 1 = 0.74471 loss)
I0226 19:19:34.929559  7672 sgd_solver.cpp:106] Iteration 7820, lr = 2.13092e-07
I0226 19:20:04.670030  7672 solver.cpp:229] Iteration 7830, loss = 0.957395
I0226 19:20:04.670085  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.265884 (* 1 = 0.265884 loss)
I0226 19:20:04.670101  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.77145 (* 1 = 0.77145 loss)
I0226 19:20:04.670112  7672 sgd_solver.cpp:106] Iteration 7830, lr = 2.13092e-07
I0226 19:20:34.366480  7672 solver.cpp:229] Iteration 7840, loss = 0.880406
I0226 19:20:34.366544  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.22261 (* 1 = 0.22261 loss)
I0226 19:20:34.366562  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.562897 (* 1 = 0.562897 loss)
I0226 19:20:34.366577  7672 sgd_solver.cpp:106] Iteration 7840, lr = 2.13092e-07
I0226 19:21:04.434319  7672 solver.cpp:229] Iteration 7850, loss = 0.854006
I0226 19:21:04.434381  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.231875 (* 1 = 0.231875 loss)
I0226 19:21:04.434396  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.848978 (* 1 = 0.848978 loss)
I0226 19:21:04.434409  7672 sgd_solver.cpp:106] Iteration 7850, lr = 2.13092e-07
I0226 19:21:34.844748  7672 solver.cpp:229] Iteration 7860, loss = 0.90843
I0226 19:21:34.844791  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.288179 (* 1 = 0.288179 loss)
I0226 19:21:34.844802  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.694411 (* 1 = 0.694411 loss)
I0226 19:21:34.844815  7672 sgd_solver.cpp:106] Iteration 7860, lr = 2.13092e-07
I0226 19:22:04.606133  7672 solver.cpp:229] Iteration 7870, loss = 0.947645
I0226 19:22:04.606174  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.22754 (* 1 = 0.22754 loss)
I0226 19:22:04.606185  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.741246 (* 1 = 0.741246 loss)
I0226 19:22:04.606196  7672 sgd_solver.cpp:106] Iteration 7870, lr = 2.13092e-07
I0226 19:22:34.551946  7672 solver.cpp:229] Iteration 7880, loss = 0.889769
I0226 19:22:34.551992  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.243722 (* 1 = 0.243722 loss)
I0226 19:22:34.552003  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.657928 (* 1 = 0.657928 loss)
I0226 19:22:34.552017  7672 sgd_solver.cpp:106] Iteration 7880, lr = 2.13092e-07
I0226 19:23:04.512512  7672 solver.cpp:229] Iteration 7890, loss = 0.858213
I0226 19:23:04.512579  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.242266 (* 1 = 0.242266 loss)
I0226 19:23:04.512594  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.627327 (* 1 = 0.627327 loss)
I0226 19:23:04.512607  7672 sgd_solver.cpp:106] Iteration 7890, lr = 2.13092e-07
I0226 19:23:34.352888  7672 solver.cpp:229] Iteration 7900, loss = 0.942995
I0226 19:23:34.352939  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.265079 (* 1 = 0.265079 loss)
I0226 19:23:34.352952  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.679886 (* 1 = 0.679886 loss)
I0226 19:23:34.352963  7672 sgd_solver.cpp:106] Iteration 7900, lr = 2.13092e-07
I0226 19:24:04.081055  7672 solver.cpp:229] Iteration 7910, loss = 0.950873
I0226 19:24:04.081106  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.243588 (* 1 = 0.243588 loss)
I0226 19:24:04.081120  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.669036 (* 1 = 0.669036 loss)
I0226 19:24:04.081131  7672 sgd_solver.cpp:106] Iteration 7910, lr = 2.13092e-07
I0226 19:24:33.788238  7672 solver.cpp:229] Iteration 7920, loss = 0.871761
I0226 19:24:33.788311  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.257052 (* 1 = 0.257052 loss)
I0226 19:24:33.788341  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.580735 (* 1 = 0.580735 loss)
I0226 19:24:33.788367  7672 sgd_solver.cpp:106] Iteration 7920, lr = 2.13092e-07
I0226 19:25:03.897686  7672 solver.cpp:229] Iteration 7930, loss = 0.853019
I0226 19:25:03.897729  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.232715 (* 1 = 0.232715 loss)
I0226 19:25:03.897743  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.480396 (* 1 = 0.480396 loss)
I0226 19:25:03.897759  7672 sgd_solver.cpp:106] Iteration 7930, lr = 2.13092e-07
I0226 19:25:33.859091  7672 solver.cpp:229] Iteration 7940, loss = 0.874684
I0226 19:25:33.859143  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.211709 (* 1 = 0.211709 loss)
I0226 19:25:33.859158  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.528384 (* 1 = 0.528384 loss)
I0226 19:25:33.859169  7672 sgd_solver.cpp:106] Iteration 7940, lr = 2.13092e-07
I0226 19:26:03.884919  7672 solver.cpp:229] Iteration 7950, loss = 0.895632
I0226 19:26:03.884979  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.212715 (* 1 = 0.212715 loss)
I0226 19:26:03.884996  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.549773 (* 1 = 0.549773 loss)
I0226 19:26:03.885015  7672 sgd_solver.cpp:106] Iteration 7950, lr = 2.13092e-07
I0226 19:26:33.898210  7672 solver.cpp:229] Iteration 7960, loss = 0.899188
I0226 19:26:33.898252  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.241627 (* 1 = 0.241627 loss)
I0226 19:26:33.898263  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.638072 (* 1 = 0.638072 loss)
I0226 19:26:33.898274  7672 sgd_solver.cpp:106] Iteration 7960, lr = 2.13092e-07
I0226 19:27:03.807859  7672 solver.cpp:229] Iteration 7970, loss = 0.937042
I0226 19:27:03.807914  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.236446 (* 1 = 0.236446 loss)
I0226 19:27:03.807925  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.61018 (* 1 = 0.61018 loss)
I0226 19:27:03.807940  7672 sgd_solver.cpp:106] Iteration 7970, lr = 2.13092e-07
I0226 19:27:34.005661  7672 solver.cpp:229] Iteration 7980, loss = 0.914055
I0226 19:27:34.005704  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.220685 (* 1 = 0.220685 loss)
I0226 19:27:34.005717  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.548838 (* 1 = 0.548838 loss)
I0226 19:27:34.005729  7672 sgd_solver.cpp:106] Iteration 7980, lr = 2.13092e-07
I0226 19:28:04.079463  7672 solver.cpp:229] Iteration 7990, loss = 0.832499
I0226 19:28:04.079504  7672 solver.cpp:245]     Train net output #0: loss-Constrain = 0.243499 (* 1 = 0.243499 loss)
I0226 19:28:04.079515  7672 solver.cpp:245]     Train net output #1: loss-Seed = 0.678647 (* 1 = 0.678647 loss)
I0226 19:28:04.079526  7672 sgd_solver.cpp:106] Iteration 7990, lr = 2.13092e-07
I0226 19:28:30.941083  7672 solver.cpp:456] Snapshotting to binary proto file models/model-s_iter_8000.caffemodel
I0226 19:28:35.729535  7672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/model-s_iter_8000.solverstate
I0226 19:28:38.387765  7672 solver.cpp:318] Iteration 8000, loss = 0.955367
I0226 19:28:38.387806  7672 solver.cpp:323] Optimization Done.
done solving
UNIQUESTRING 2
/media/ssd1/austin/Point-DSRG/deeplab-public-ver2/python
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0226 19:28:48.005173 31022 net.cpp:49] Initializing net from parameters:
name: "DSRG"
input: "images"
input_dim: 1
input_dim: 3
input_dim: 321
input_dim: 321
state {
  phase: TEST
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "images"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    pad: 1
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    pad: 1
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    pad: 1
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    dilation: 2
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    dilation: 2
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    dilation: 2
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "pool5a"
  type: "Pooling"
  bottom: "pool5"
  top: "pool5a"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "fc6_1"
  type: "Convolution"
  bottom: "pool5a"
  top: "fc6_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    pad: 6
    kernel_size: 3
    dilation: 6
  }
}
layer {
  name: "relu6_1"
  type: "ReLU"
  bottom: "fc6_1"
  top: "fc6_1"
}
layer {
  name: "drop6_1"
  type: "Dropout"
  bottom: "fc6_1"
  top: "fc6_1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7_1"
  type: "Convolution"
  bottom: "fc6_1"
  top: "fc7_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    kernel_size: 1
  }
}
layer {
  name: "relu7_1"
  type: "ReLU"
  bottom: "fc7_1"
  top: "fc7_1"
}
layer {
  name: "drop7_1"
  type: "Dropout"
  bottom: "fc7_1"
  top: "fc7_1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8-SEC_1"
  type: "Convolution"
  bottom: "fc7_1"
  top: "fc8-SEC_1"
  param {
    lr_mult: 10
    decay_mult: 1
  }
  param {
    lr_mult: 20
    decay_mult: 0
  }
  convolution_param {
    num_output: 21
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fc6_2"
  type: "Convolution"
  bottom: "pool5a"
  top: "fc6_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    pad: 12
    kernel_size: 3
    dilation: 12
  }
}
layer {
  name: "relu6_2"
  type: "ReLU"
  bottom: "fc6_2"
  top: "fc6_2"
}
layer {
  name: "drop6_2"
  type: "Dropout"
  bottom: "fc6_2"
  top: "fc6_2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7_2"
  type: "Convolution"
  bottom: "fc6_2"
  top: "fc7_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    kernel_size: 1
  }
}
layer {
  name: "relu7_2"
  type: "ReLU"
  bottom: "fc7_2"
  top: "fc7_2"
}
layer {
  name: "drop7_2"
  type: "Dropout"
  bottom: "fc7_2"
  top: "fc7_2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8-SEC_2"
  type: "Convolution"
  bottom: "fc7_2"
  top: "fc8-SEC_2"
  param {
    lr_mult: 10
    decay_mult: 1
  }
  param {
    lr_mult: 20
    decay_mult: 0
  }
  convolution_param {
    num_output: 21
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fc6_3"
  type: "Convolution"
  bottom: "pool5a"
  top: "fc6_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    pad: 18
    kernel_size: 3
    dilation: 18
  }
}
layer {
  name: "relu6_3"
  type: "ReLU"
  bottom: "fc6_3"
  top: "fc6_3"
}
layer {
  name: "drop6_3"
  type: "Dropout"
  bottom: "fc6_3"
  top: "fc6_3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7_3"
  type: "Convolution"
  bottom: "fc6_3"
  top: "fc7_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    kernel_size: 1
  }
}
layer {
  name: "relu7_3"
  type: "ReLU"
  bottom: "fc7_3"
  top: "fc7_3"
}
layer {
  name: "drop7_3"
  type: "Dropout"
  bottom: "fc7_3"
  top: "fc7_3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8-SEC_3"
  type: "Convolution"
  bottom: "fc7_3"
  top: "fc8-SEC_3"
  param {
    lr_mult: 10
    decay_mult: 1
  }
  param {
    lr_mult: 20
    decay_mult: 0
  }
  convolution_param {
    num_output: 21
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fc6_4"
  type: "Convolution"
  bottom: "pool5a"
  top: "fc6_4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    pad: 24
    kernel_size: 3
    dilation: 24
  }
}
layer {
  name: "relu6_4"
  type: "ReLU"
  bottom: "fc6_4"
  top: "fc6_4"
}
layer {
  name: "drop6_4"
  type: "Dropout"
  bottom: "fc6_4"
  top: "fc6_4"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7_4"
  type: "Convolution"
  bottom: "fc6_4"
  top: "fc7_4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    kernel_size: 1
  }
}
layer {
  name: "relu7_4"
  type: "ReLU"
  bottom: "fc7_4"
  top: "fc7_4"
}
layer {
  name: "drop7_4"
  type: "Dropout"
  bottom: "fc7_4"
  top: "fc7_4"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8-SEC_4"
  type: "Convolution"
  bottom: "fc7_4"
  top: "fc8-SEC_4"
  param {
    lr_mult: 10
    decay_mult: 1
  }
  param {
    lr_mult: 20
    decay_mult: 0
  }
  convolution_param {
    num_output: 21
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fc8-SEC"
  type: "Eltwise"
  bottom: "fc8-SEC_1"
  bottom: "fc8-SEC_2"
  bottom: "fc8-SEC_3"
  bottom: "fc8-SEC_4"
  top: "fc8-SEC"
  eltwise_param {
    operation: SUM
  }
}
I0226 19:28:48.008256 31022 net.cpp:413] Input 0 -> images
I0226 19:28:48.153630 31022 layer_factory.hpp:77] Creating layer conv1_1
I0226 19:28:48.153687 31022 net.cpp:106] Creating Layer conv1_1
I0226 19:28:48.153697 31022 net.cpp:454] conv1_1 <- images
I0226 19:28:48.153710 31022 net.cpp:411] conv1_1 -> conv1_1
I0226 19:28:48.166636 31022 net.cpp:150] Setting up conv1_1
I0226 19:28:48.166692 31022 net.cpp:157] Top shape: 1 64 321 321 (6594624)
I0226 19:28:48.166704 31022 net.cpp:165] Memory required for data: 26378496
I0226 19:28:48.166740 31022 layer_factory.hpp:77] Creating layer relu1_1
I0226 19:28:48.166766 31022 net.cpp:106] Creating Layer relu1_1
I0226 19:28:48.166779 31022 net.cpp:454] relu1_1 <- conv1_1
I0226 19:28:48.166810 31022 net.cpp:397] relu1_1 -> conv1_1 (in-place)
I0226 19:28:48.166837 31022 net.cpp:150] Setting up relu1_1
I0226 19:28:48.166854 31022 net.cpp:157] Top shape: 1 64 321 321 (6594624)
I0226 19:28:48.166867 31022 net.cpp:165] Memory required for data: 52756992
I0226 19:28:48.166903 31022 layer_factory.hpp:77] Creating layer conv1_2
I0226 19:28:48.166930 31022 net.cpp:106] Creating Layer conv1_2
I0226 19:28:48.166945 31022 net.cpp:454] conv1_2 <- conv1_1
I0226 19:28:48.166963 31022 net.cpp:411] conv1_2 -> conv1_2
I0226 19:28:48.181720 31022 net.cpp:150] Setting up conv1_2
I0226 19:28:48.181776 31022 net.cpp:157] Top shape: 1 64 321 321 (6594624)
I0226 19:28:48.181792 31022 net.cpp:165] Memory required for data: 79135488
I0226 19:28:48.181820 31022 layer_factory.hpp:77] Creating layer relu1_2
I0226 19:28:48.181850 31022 net.cpp:106] Creating Layer relu1_2
I0226 19:28:48.181879 31022 net.cpp:454] relu1_2 <- conv1_2
I0226 19:28:48.181898 31022 net.cpp:397] relu1_2 -> conv1_2 (in-place)
I0226 19:28:48.181931 31022 net.cpp:150] Setting up relu1_2
I0226 19:28:48.181952 31022 net.cpp:157] Top shape: 1 64 321 321 (6594624)
I0226 19:28:48.181967 31022 net.cpp:165] Memory required for data: 105513984
I0226 19:28:48.181990 31022 layer_factory.hpp:77] Creating layer pool1
I0226 19:28:48.182021 31022 net.cpp:106] Creating Layer pool1
I0226 19:28:48.182035 31022 net.cpp:454] pool1 <- conv1_2
I0226 19:28:48.182054 31022 net.cpp:411] pool1 -> pool1
I0226 19:28:48.182142 31022 net.cpp:150] Setting up pool1
I0226 19:28:48.182165 31022 net.cpp:157] Top shape: 1 64 161 161 (1658944)
I0226 19:28:48.182179 31022 net.cpp:165] Memory required for data: 112149760
I0226 19:28:48.182193 31022 layer_factory.hpp:77] Creating layer conv2_1
I0226 19:28:48.182215 31022 net.cpp:106] Creating Layer conv2_1
I0226 19:28:48.182229 31022 net.cpp:454] conv2_1 <- pool1
I0226 19:28:48.182248 31022 net.cpp:411] conv2_1 -> conv2_1
I0226 19:28:48.182798 31022 net.cpp:150] Setting up conv2_1
I0226 19:28:48.182826 31022 net.cpp:157] Top shape: 1 128 161 161 (3317888)
I0226 19:28:48.182840 31022 net.cpp:165] Memory required for data: 125421312
I0226 19:28:48.182863 31022 layer_factory.hpp:77] Creating layer relu2_1
I0226 19:28:48.182906 31022 net.cpp:106] Creating Layer relu2_1
I0226 19:28:48.182924 31022 net.cpp:454] relu2_1 <- conv2_1
I0226 19:28:48.182941 31022 net.cpp:397] relu2_1 -> conv2_1 (in-place)
I0226 19:28:48.182961 31022 net.cpp:150] Setting up relu2_1
I0226 19:28:48.182979 31022 net.cpp:157] Top shape: 1 128 161 161 (3317888)
I0226 19:28:48.182993 31022 net.cpp:165] Memory required for data: 138692864
I0226 19:28:48.183007 31022 layer_factory.hpp:77] Creating layer conv2_2
I0226 19:28:48.183030 31022 net.cpp:106] Creating Layer conv2_2
I0226 19:28:48.183050 31022 net.cpp:454] conv2_2 <- conv2_1
I0226 19:28:48.183066 31022 net.cpp:411] conv2_2 -> conv2_2
I0226 19:28:48.183750 31022 net.cpp:150] Setting up conv2_2
I0226 19:28:48.183776 31022 net.cpp:157] Top shape: 1 128 161 161 (3317888)
I0226 19:28:48.183790 31022 net.cpp:165] Memory required for data: 151964416
I0226 19:28:48.183809 31022 layer_factory.hpp:77] Creating layer relu2_2
I0226 19:28:48.183831 31022 net.cpp:106] Creating Layer relu2_2
I0226 19:28:48.183848 31022 net.cpp:454] relu2_2 <- conv2_2
I0226 19:28:48.183866 31022 net.cpp:397] relu2_2 -> conv2_2 (in-place)
I0226 19:28:48.183883 31022 net.cpp:150] Setting up relu2_2
I0226 19:28:48.183900 31022 net.cpp:157] Top shape: 1 128 161 161 (3317888)
I0226 19:28:48.183928 31022 net.cpp:165] Memory required for data: 165235968
I0226 19:28:48.183941 31022 layer_factory.hpp:77] Creating layer pool2
I0226 19:28:48.183959 31022 net.cpp:106] Creating Layer pool2
I0226 19:28:48.183974 31022 net.cpp:454] pool2 <- conv2_2
I0226 19:28:48.183992 31022 net.cpp:411] pool2 -> pool2
I0226 19:28:48.184067 31022 net.cpp:150] Setting up pool2
I0226 19:28:48.184089 31022 net.cpp:157] Top shape: 1 128 81 81 (839808)
I0226 19:28:48.184103 31022 net.cpp:165] Memory required for data: 168595200
I0226 19:28:48.184120 31022 layer_factory.hpp:77] Creating layer conv3_1
I0226 19:28:48.184144 31022 net.cpp:106] Creating Layer conv3_1
I0226 19:28:48.184164 31022 net.cpp:454] conv3_1 <- pool2
I0226 19:28:48.184180 31022 net.cpp:411] conv3_1 -> conv3_1
I0226 19:28:48.216424 31022 net.cpp:150] Setting up conv3_1
I0226 19:28:48.216500 31022 net.cpp:157] Top shape: 1 256 81 81 (1679616)
I0226 19:28:48.216516 31022 net.cpp:165] Memory required for data: 175313664
I0226 19:28:48.216544 31022 layer_factory.hpp:77] Creating layer relu3_1
I0226 19:28:48.216567 31022 net.cpp:106] Creating Layer relu3_1
I0226 19:28:48.216583 31022 net.cpp:454] relu3_1 <- conv3_1
I0226 19:28:48.216599 31022 net.cpp:397] relu3_1 -> conv3_1 (in-place)
I0226 19:28:48.216621 31022 net.cpp:150] Setting up relu3_1
I0226 19:28:48.216635 31022 net.cpp:157] Top shape: 1 256 81 81 (1679616)
I0226 19:28:48.216648 31022 net.cpp:165] Memory required for data: 182032128
I0226 19:28:48.216660 31022 layer_factory.hpp:77] Creating layer conv3_2
I0226 19:28:48.216683 31022 net.cpp:106] Creating Layer conv3_2
I0226 19:28:48.216704 31022 net.cpp:454] conv3_2 <- conv3_1
I0226 19:28:48.216719 31022 net.cpp:411] conv3_2 -> conv3_2
I0226 19:28:48.221477 31022 net.cpp:150] Setting up conv3_2
I0226 19:28:48.221527 31022 net.cpp:157] Top shape: 1 256 81 81 (1679616)
I0226 19:28:48.221544 31022 net.cpp:165] Memory required for data: 188750592
I0226 19:28:48.221565 31022 layer_factory.hpp:77] Creating layer relu3_2
I0226 19:28:48.221585 31022 net.cpp:106] Creating Layer relu3_2
I0226 19:28:48.221599 31022 net.cpp:454] relu3_2 <- conv3_2
I0226 19:28:48.221616 31022 net.cpp:397] relu3_2 -> conv3_2 (in-place)
I0226 19:28:48.221638 31022 net.cpp:150] Setting up relu3_2
I0226 19:28:48.221654 31022 net.cpp:157] Top shape: 1 256 81 81 (1679616)
I0226 19:28:48.221668 31022 net.cpp:165] Memory required for data: 195469056
I0226 19:28:48.221683 31022 layer_factory.hpp:77] Creating layer conv3_3
I0226 19:28:48.221710 31022 net.cpp:106] Creating Layer conv3_3
I0226 19:28:48.221726 31022 net.cpp:454] conv3_3 <- conv3_2
I0226 19:28:48.221746 31022 net.cpp:411] conv3_3 -> conv3_3
I0226 19:28:48.226285 31022 net.cpp:150] Setting up conv3_3
I0226 19:28:48.226332 31022 net.cpp:157] Top shape: 1 256 81 81 (1679616)
I0226 19:28:48.226347 31022 net.cpp:165] Memory required for data: 202187520
I0226 19:28:48.226370 31022 layer_factory.hpp:77] Creating layer relu3_3
I0226 19:28:48.226389 31022 net.cpp:106] Creating Layer relu3_3
I0226 19:28:48.226404 31022 net.cpp:454] relu3_3 <- conv3_3
I0226 19:28:48.226421 31022 net.cpp:397] relu3_3 -> conv3_3 (in-place)
I0226 19:28:48.226444 31022 net.cpp:150] Setting up relu3_3
I0226 19:28:48.226460 31022 net.cpp:157] Top shape: 1 256 81 81 (1679616)
I0226 19:28:48.226475 31022 net.cpp:165] Memory required for data: 208905984
I0226 19:28:48.226490 31022 layer_factory.hpp:77] Creating layer pool3
I0226 19:28:48.226514 31022 net.cpp:106] Creating Layer pool3
I0226 19:28:48.226539 31022 net.cpp:454] pool3 <- conv3_3
I0226 19:28:48.226559 31022 net.cpp:411] pool3 -> pool3
I0226 19:28:48.226641 31022 net.cpp:150] Setting up pool3
I0226 19:28:48.226665 31022 net.cpp:157] Top shape: 1 256 41 41 (430336)
I0226 19:28:48.226677 31022 net.cpp:165] Memory required for data: 210627328
I0226 19:28:48.226691 31022 layer_factory.hpp:77] Creating layer conv4_1
I0226 19:28:48.226716 31022 net.cpp:106] Creating Layer conv4_1
I0226 19:28:48.226729 31022 net.cpp:454] conv4_1 <- pool3
I0226 19:28:48.226752 31022 net.cpp:411] conv4_1 -> conv4_1
I0226 19:28:48.233167 31022 net.cpp:150] Setting up conv4_1
I0226 19:28:48.233213 31022 net.cpp:157] Top shape: 1 512 41 41 (860672)
I0226 19:28:48.233227 31022 net.cpp:165] Memory required for data: 214070016
I0226 19:28:48.233254 31022 layer_factory.hpp:77] Creating layer relu4_1
I0226 19:28:48.233273 31022 net.cpp:106] Creating Layer relu4_1
I0226 19:28:48.233287 31022 net.cpp:454] relu4_1 <- conv4_1
I0226 19:28:48.233305 31022 net.cpp:397] relu4_1 -> conv4_1 (in-place)
I0226 19:28:48.233325 31022 net.cpp:150] Setting up relu4_1
I0226 19:28:48.233340 31022 net.cpp:157] Top shape: 1 512 41 41 (860672)
I0226 19:28:48.233351 31022 net.cpp:165] Memory required for data: 217512704
I0226 19:28:48.233363 31022 layer_factory.hpp:77] Creating layer conv4_2
I0226 19:28:48.233384 31022 net.cpp:106] Creating Layer conv4_2
I0226 19:28:48.233397 31022 net.cpp:454] conv4_2 <- conv4_1
I0226 19:28:48.233412 31022 net.cpp:411] conv4_2 -> conv4_2
I0226 19:28:48.240947 31022 net.cpp:150] Setting up conv4_2
I0226 19:28:48.240977 31022 net.cpp:157] Top shape: 1 512 41 41 (860672)
I0226 19:28:48.240984 31022 net.cpp:165] Memory required for data: 220955392
I0226 19:28:48.241005 31022 layer_factory.hpp:77] Creating layer relu4_2
I0226 19:28:48.241019 31022 net.cpp:106] Creating Layer relu4_2
I0226 19:28:48.241027 31022 net.cpp:454] relu4_2 <- conv4_2
I0226 19:28:48.241039 31022 net.cpp:397] relu4_2 -> conv4_2 (in-place)
I0226 19:28:48.241052 31022 net.cpp:150] Setting up relu4_2
I0226 19:28:48.241061 31022 net.cpp:157] Top shape: 1 512 41 41 (860672)
I0226 19:28:48.241070 31022 net.cpp:165] Memory required for data: 224398080
I0226 19:28:48.241077 31022 layer_factory.hpp:77] Creating layer conv4_3
I0226 19:28:48.241091 31022 net.cpp:106] Creating Layer conv4_3
I0226 19:28:48.241098 31022 net.cpp:454] conv4_3 <- conv4_2
I0226 19:28:48.241111 31022 net.cpp:411] conv4_3 -> conv4_3
I0226 19:28:48.247308 31022 net.cpp:150] Setting up conv4_3
I0226 19:28:48.247337 31022 net.cpp:157] Top shape: 1 512 41 41 (860672)
I0226 19:28:48.247345 31022 net.cpp:165] Memory required for data: 227840768
I0226 19:28:48.247359 31022 layer_factory.hpp:77] Creating layer relu4_3
I0226 19:28:48.247371 31022 net.cpp:106] Creating Layer relu4_3
I0226 19:28:48.247381 31022 net.cpp:454] relu4_3 <- conv4_3
I0226 19:28:48.247393 31022 net.cpp:397] relu4_3 -> conv4_3 (in-place)
I0226 19:28:48.247407 31022 net.cpp:150] Setting up relu4_3
I0226 19:28:48.247416 31022 net.cpp:157] Top shape: 1 512 41 41 (860672)
I0226 19:28:48.247424 31022 net.cpp:165] Memory required for data: 231283456
I0226 19:28:48.247432 31022 layer_factory.hpp:77] Creating layer pool4
I0226 19:28:48.247443 31022 net.cpp:106] Creating Layer pool4
I0226 19:28:48.247452 31022 net.cpp:454] pool4 <- conv4_3
I0226 19:28:48.247462 31022 net.cpp:411] pool4 -> pool4
I0226 19:28:48.247509 31022 net.cpp:150] Setting up pool4
I0226 19:28:48.247524 31022 net.cpp:157] Top shape: 1 512 41 41 (860672)
I0226 19:28:48.247545 31022 net.cpp:165] Memory required for data: 234726144
I0226 19:28:48.247552 31022 layer_factory.hpp:77] Creating layer conv5_1
I0226 19:28:48.247568 31022 net.cpp:106] Creating Layer conv5_1
I0226 19:28:48.247576 31022 net.cpp:454] conv5_1 <- pool4
I0226 19:28:48.247589 31022 net.cpp:411] conv5_1 -> conv5_1
I0226 19:28:48.253214 31022 net.cpp:150] Setting up conv5_1
I0226 19:28:48.253238 31022 net.cpp:157] Top shape: 1 512 41 41 (860672)
I0226 19:28:48.253247 31022 net.cpp:165] Memory required for data: 238168832
I0226 19:28:48.253259 31022 layer_factory.hpp:77] Creating layer relu5_1
I0226 19:28:48.253269 31022 net.cpp:106] Creating Layer relu5_1
I0226 19:28:48.253278 31022 net.cpp:454] relu5_1 <- conv5_1
I0226 19:28:48.253288 31022 net.cpp:397] relu5_1 -> conv5_1 (in-place)
I0226 19:28:48.253301 31022 net.cpp:150] Setting up relu5_1
I0226 19:28:48.253309 31022 net.cpp:157] Top shape: 1 512 41 41 (860672)
I0226 19:28:48.253317 31022 net.cpp:165] Memory required for data: 241611520
I0226 19:28:48.253324 31022 layer_factory.hpp:77] Creating layer conv5_2
I0226 19:28:48.253340 31022 net.cpp:106] Creating Layer conv5_2
I0226 19:28:48.253347 31022 net.cpp:454] conv5_2 <- conv5_1
I0226 19:28:48.253356 31022 net.cpp:411] conv5_2 -> conv5_2
I0226 19:28:48.258822 31022 net.cpp:150] Setting up conv5_2
I0226 19:28:48.258850 31022 net.cpp:157] Top shape: 1 512 41 41 (860672)
I0226 19:28:48.258858 31022 net.cpp:165] Memory required for data: 245054208
I0226 19:28:48.258869 31022 layer_factory.hpp:77] Creating layer relu5_2
I0226 19:28:48.258891 31022 net.cpp:106] Creating Layer relu5_2
I0226 19:28:48.258899 31022 net.cpp:454] relu5_2 <- conv5_2
I0226 19:28:48.258909 31022 net.cpp:397] relu5_2 -> conv5_2 (in-place)
I0226 19:28:48.258920 31022 net.cpp:150] Setting up relu5_2
I0226 19:28:48.258929 31022 net.cpp:157] Top shape: 1 512 41 41 (860672)
I0226 19:28:48.258936 31022 net.cpp:165] Memory required for data: 248496896
I0226 19:28:48.258944 31022 layer_factory.hpp:77] Creating layer conv5_3
I0226 19:28:48.258960 31022 net.cpp:106] Creating Layer conv5_3
I0226 19:28:48.258966 31022 net.cpp:454] conv5_3 <- conv5_2
I0226 19:28:48.258976 31022 net.cpp:411] conv5_3 -> conv5_3
I0226 19:28:48.264387 31022 net.cpp:150] Setting up conv5_3
I0226 19:28:48.264410 31022 net.cpp:157] Top shape: 1 512 41 41 (860672)
I0226 19:28:48.264418 31022 net.cpp:165] Memory required for data: 251939584
I0226 19:28:48.264430 31022 layer_factory.hpp:77] Creating layer relu5_3
I0226 19:28:48.264443 31022 net.cpp:106] Creating Layer relu5_3
I0226 19:28:48.264451 31022 net.cpp:454] relu5_3 <- conv5_3
I0226 19:28:48.264466 31022 net.cpp:397] relu5_3 -> conv5_3 (in-place)
I0226 19:28:48.264477 31022 net.cpp:150] Setting up relu5_3
I0226 19:28:48.264485 31022 net.cpp:157] Top shape: 1 512 41 41 (860672)
I0226 19:28:48.264492 31022 net.cpp:165] Memory required for data: 255382272
I0226 19:28:48.264499 31022 layer_factory.hpp:77] Creating layer pool5
I0226 19:28:48.264509 31022 net.cpp:106] Creating Layer pool5
I0226 19:28:48.264518 31022 net.cpp:454] pool5 <- conv5_3
I0226 19:28:48.264526 31022 net.cpp:411] pool5 -> pool5
I0226 19:28:48.264573 31022 net.cpp:150] Setting up pool5
I0226 19:28:48.264585 31022 net.cpp:157] Top shape: 1 512 41 41 (860672)
I0226 19:28:48.264592 31022 net.cpp:165] Memory required for data: 258824960
I0226 19:28:48.264600 31022 layer_factory.hpp:77] Creating layer pool5a
I0226 19:28:48.264608 31022 net.cpp:106] Creating Layer pool5a
I0226 19:28:48.264616 31022 net.cpp:454] pool5a <- pool5
I0226 19:28:48.264626 31022 net.cpp:411] pool5a -> pool5a
I0226 19:28:48.264654 31022 net.cpp:150] Setting up pool5a
I0226 19:28:48.264663 31022 net.cpp:157] Top shape: 1 512 41 41 (860672)
I0226 19:28:48.264672 31022 net.cpp:165] Memory required for data: 262267648
I0226 19:28:48.264678 31022 layer_factory.hpp:77] Creating layer pool5a_pool5a_0_split
I0226 19:28:48.264699 31022 net.cpp:106] Creating Layer pool5a_pool5a_0_split
I0226 19:28:48.264708 31022 net.cpp:454] pool5a_pool5a_0_split <- pool5a
I0226 19:28:48.264719 31022 net.cpp:411] pool5a_pool5a_0_split -> pool5a_pool5a_0_split_0
I0226 19:28:48.264729 31022 net.cpp:411] pool5a_pool5a_0_split -> pool5a_pool5a_0_split_1
I0226 19:28:48.264739 31022 net.cpp:411] pool5a_pool5a_0_split -> pool5a_pool5a_0_split_2
I0226 19:28:48.264748 31022 net.cpp:411] pool5a_pool5a_0_split -> pool5a_pool5a_0_split_3
I0226 19:28:48.264812 31022 net.cpp:150] Setting up pool5a_pool5a_0_split
I0226 19:28:48.264825 31022 net.cpp:157] Top shape: 1 512 41 41 (860672)
I0226 19:28:48.264834 31022 net.cpp:157] Top shape: 1 512 41 41 (860672)
I0226 19:28:48.264842 31022 net.cpp:157] Top shape: 1 512 41 41 (860672)
I0226 19:28:48.264849 31022 net.cpp:157] Top shape: 1 512 41 41 (860672)
I0226 19:28:48.264858 31022 net.cpp:165] Memory required for data: 276038400
I0226 19:28:48.264866 31022 layer_factory.hpp:77] Creating layer fc6_1
I0226 19:28:48.264880 31022 net.cpp:106] Creating Layer fc6_1
I0226 19:28:48.264889 31022 net.cpp:454] fc6_1 <- pool5a_pool5a_0_split_0
I0226 19:28:48.264900 31022 net.cpp:411] fc6_1 -> fc6_1
I0226 19:28:48.275640 31022 net.cpp:150] Setting up fc6_1
I0226 19:28:48.275676 31022 net.cpp:157] Top shape: 1 1024 41 41 (1721344)
I0226 19:28:48.275684 31022 net.cpp:165] Memory required for data: 282923776
I0226 19:28:48.275697 31022 layer_factory.hpp:77] Creating layer relu6_1
I0226 19:28:48.275717 31022 net.cpp:106] Creating Layer relu6_1
I0226 19:28:48.275727 31022 net.cpp:454] relu6_1 <- fc6_1
I0226 19:28:48.275738 31022 net.cpp:397] relu6_1 -> fc6_1 (in-place)
I0226 19:28:48.275751 31022 net.cpp:150] Setting up relu6_1
I0226 19:28:48.275760 31022 net.cpp:157] Top shape: 1 1024 41 41 (1721344)
I0226 19:28:48.275768 31022 net.cpp:165] Memory required for data: 289809152
I0226 19:28:48.275774 31022 layer_factory.hpp:77] Creating layer drop6_1
I0226 19:28:48.275792 31022 net.cpp:106] Creating Layer drop6_1
I0226 19:28:48.275802 31022 net.cpp:454] drop6_1 <- fc6_1
I0226 19:28:48.275810 31022 net.cpp:397] drop6_1 -> fc6_1 (in-place)
I0226 19:28:48.275842 31022 net.cpp:150] Setting up drop6_1
I0226 19:28:48.275852 31022 net.cpp:157] Top shape: 1 1024 41 41 (1721344)
I0226 19:28:48.275859 31022 net.cpp:165] Memory required for data: 296694528
I0226 19:28:48.275867 31022 layer_factory.hpp:77] Creating layer fc7_1
I0226 19:28:48.275883 31022 net.cpp:106] Creating Layer fc7_1
I0226 19:28:48.275892 31022 net.cpp:454] fc7_1 <- fc6_1
I0226 19:28:48.275900 31022 net.cpp:411] fc7_1 -> fc7_1
I0226 19:28:48.278643 31022 net.cpp:150] Setting up fc7_1
I0226 19:28:48.278668 31022 net.cpp:157] Top shape: 1 1024 41 41 (1721344)
I0226 19:28:48.278676 31022 net.cpp:165] Memory required for data: 303579904
I0226 19:28:48.278687 31022 layer_factory.hpp:77] Creating layer relu7_1
I0226 19:28:48.278698 31022 net.cpp:106] Creating Layer relu7_1
I0226 19:28:48.278707 31022 net.cpp:454] relu7_1 <- fc7_1
I0226 19:28:48.278718 31022 net.cpp:397] relu7_1 -> fc7_1 (in-place)
I0226 19:28:48.278729 31022 net.cpp:150] Setting up relu7_1
I0226 19:28:48.278738 31022 net.cpp:157] Top shape: 1 1024 41 41 (1721344)
I0226 19:28:48.278745 31022 net.cpp:165] Memory required for data: 310465280
I0226 19:28:48.278753 31022 layer_factory.hpp:77] Creating layer drop7_1
I0226 19:28:48.278762 31022 net.cpp:106] Creating Layer drop7_1
I0226 19:28:48.278769 31022 net.cpp:454] drop7_1 <- fc7_1
I0226 19:28:48.278779 31022 net.cpp:397] drop7_1 -> fc7_1 (in-place)
I0226 19:28:48.278808 31022 net.cpp:150] Setting up drop7_1
I0226 19:28:48.278818 31022 net.cpp:157] Top shape: 1 1024 41 41 (1721344)
I0226 19:28:48.278825 31022 net.cpp:165] Memory required for data: 317350656
I0226 19:28:48.278832 31022 layer_factory.hpp:77] Creating layer fc8-SEC_1
I0226 19:28:48.278847 31022 net.cpp:106] Creating Layer fc8-SEC_1
I0226 19:28:48.278856 31022 net.cpp:454] fc8-SEC_1 <- fc7_1
I0226 19:28:48.278867 31022 net.cpp:411] fc8-SEC_1 -> fc8-SEC_1
I0226 19:28:48.279830 31022 net.cpp:150] Setting up fc8-SEC_1
I0226 19:28:48.279850 31022 net.cpp:157] Top shape: 1 21 41 41 (35301)
I0226 19:28:48.279857 31022 net.cpp:165] Memory required for data: 317491860
I0226 19:28:48.279867 31022 layer_factory.hpp:77] Creating layer fc6_2
I0226 19:28:48.279882 31022 net.cpp:106] Creating Layer fc6_2
I0226 19:28:48.279891 31022 net.cpp:454] fc6_2 <- pool5a_pool5a_0_split_1
I0226 19:28:48.279903 31022 net.cpp:411] fc6_2 -> fc6_2
I0226 19:28:48.290462 31022 net.cpp:150] Setting up fc6_2
I0226 19:28:48.290488 31022 net.cpp:157] Top shape: 1 1024 41 41 (1721344)
I0226 19:28:48.290495 31022 net.cpp:165] Memory required for data: 324377236
I0226 19:28:48.290515 31022 layer_factory.hpp:77] Creating layer relu6_2
I0226 19:28:48.290527 31022 net.cpp:106] Creating Layer relu6_2
I0226 19:28:48.290535 31022 net.cpp:454] relu6_2 <- fc6_2
I0226 19:28:48.290545 31022 net.cpp:397] relu6_2 -> fc6_2 (in-place)
I0226 19:28:48.290556 31022 net.cpp:150] Setting up relu6_2
I0226 19:28:48.290565 31022 net.cpp:157] Top shape: 1 1024 41 41 (1721344)
I0226 19:28:48.290571 31022 net.cpp:165] Memory required for data: 331262612
I0226 19:28:48.290580 31022 layer_factory.hpp:77] Creating layer drop6_2
I0226 19:28:48.290591 31022 net.cpp:106] Creating Layer drop6_2
I0226 19:28:48.290598 31022 net.cpp:454] drop6_2 <- fc6_2
I0226 19:28:48.290606 31022 net.cpp:397] drop6_2 -> fc6_2 (in-place)
I0226 19:28:48.290634 31022 net.cpp:150] Setting up drop6_2
I0226 19:28:48.290647 31022 net.cpp:157] Top shape: 1 1024 41 41 (1721344)
I0226 19:28:48.290653 31022 net.cpp:165] Memory required for data: 338147988
I0226 19:28:48.290660 31022 layer_factory.hpp:77] Creating layer fc7_2
I0226 19:28:48.290674 31022 net.cpp:106] Creating Layer fc7_2
I0226 19:28:48.290681 31022 net.cpp:454] fc7_2 <- fc6_2
I0226 19:28:48.290690 31022 net.cpp:411] fc7_2 -> fc7_2
I0226 19:28:48.293457 31022 net.cpp:150] Setting up fc7_2
I0226 19:28:48.293481 31022 net.cpp:157] Top shape: 1 1024 41 41 (1721344)
I0226 19:28:48.293489 31022 net.cpp:165] Memory required for data: 345033364
I0226 19:28:48.293500 31022 layer_factory.hpp:77] Creating layer relu7_2
I0226 19:28:48.293511 31022 net.cpp:106] Creating Layer relu7_2
I0226 19:28:48.293519 31022 net.cpp:454] relu7_2 <- fc7_2
I0226 19:28:48.293530 31022 net.cpp:397] relu7_2 -> fc7_2 (in-place)
I0226 19:28:48.293542 31022 net.cpp:150] Setting up relu7_2
I0226 19:28:48.293550 31022 net.cpp:157] Top shape: 1 1024 41 41 (1721344)
I0226 19:28:48.293557 31022 net.cpp:165] Memory required for data: 351918740
I0226 19:28:48.293565 31022 layer_factory.hpp:77] Creating layer drop7_2
I0226 19:28:48.293575 31022 net.cpp:106] Creating Layer drop7_2
I0226 19:28:48.293581 31022 net.cpp:454] drop7_2 <- fc7_2
I0226 19:28:48.293592 31022 net.cpp:397] drop7_2 -> fc7_2 (in-place)
I0226 19:28:48.293622 31022 net.cpp:150] Setting up drop7_2
I0226 19:28:48.293632 31022 net.cpp:157] Top shape: 1 1024 41 41 (1721344)
I0226 19:28:48.293639 31022 net.cpp:165] Memory required for data: 358804116
I0226 19:28:48.293646 31022 layer_factory.hpp:77] Creating layer fc8-SEC_2
I0226 19:28:48.293661 31022 net.cpp:106] Creating Layer fc8-SEC_2
I0226 19:28:48.293669 31022 net.cpp:454] fc8-SEC_2 <- fc7_2
I0226 19:28:48.293681 31022 net.cpp:411] fc8-SEC_2 -> fc8-SEC_2
I0226 19:28:48.294152 31022 net.cpp:150] Setting up fc8-SEC_2
I0226 19:28:48.294167 31022 net.cpp:157] Top shape: 1 21 41 41 (35301)
I0226 19:28:48.294174 31022 net.cpp:165] Memory required for data: 358945320
I0226 19:28:48.294185 31022 layer_factory.hpp:77] Creating layer fc6_3
I0226 19:28:48.294198 31022 net.cpp:106] Creating Layer fc6_3
I0226 19:28:48.294207 31022 net.cpp:454] fc6_3 <- pool5a_pool5a_0_split_2
I0226 19:28:48.294217 31022 net.cpp:411] fc6_3 -> fc6_3
I0226 19:28:48.304770 31022 net.cpp:150] Setting up fc6_3
I0226 19:28:48.304806 31022 net.cpp:157] Top shape: 1 1024 41 41 (1721344)
I0226 19:28:48.304814 31022 net.cpp:165] Memory required for data: 365830696
I0226 19:28:48.304826 31022 layer_factory.hpp:77] Creating layer relu6_3
I0226 19:28:48.304841 31022 net.cpp:106] Creating Layer relu6_3
I0226 19:28:48.304849 31022 net.cpp:454] relu6_3 <- fc6_3
I0226 19:28:48.304862 31022 net.cpp:397] relu6_3 -> fc6_3 (in-place)
I0226 19:28:48.304874 31022 net.cpp:150] Setting up relu6_3
I0226 19:28:48.304883 31022 net.cpp:157] Top shape: 1 1024 41 41 (1721344)
I0226 19:28:48.304890 31022 net.cpp:165] Memory required for data: 372716072
I0226 19:28:48.304898 31022 layer_factory.hpp:77] Creating layer drop6_3
I0226 19:28:48.304908 31022 net.cpp:106] Creating Layer drop6_3
I0226 19:28:48.304914 31022 net.cpp:454] drop6_3 <- fc6_3
I0226 19:28:48.304924 31022 net.cpp:397] drop6_3 -> fc6_3 (in-place)
I0226 19:28:48.304955 31022 net.cpp:150] Setting up drop6_3
I0226 19:28:48.304965 31022 net.cpp:157] Top shape: 1 1024 41 41 (1721344)
I0226 19:28:48.304971 31022 net.cpp:165] Memory required for data: 379601448
I0226 19:28:48.304978 31022 layer_factory.hpp:77] Creating layer fc7_3
I0226 19:28:48.304992 31022 net.cpp:106] Creating Layer fc7_3
I0226 19:28:48.305001 31022 net.cpp:454] fc7_3 <- fc6_3
I0226 19:28:48.305011 31022 net.cpp:411] fc7_3 -> fc7_3
I0226 19:28:48.307754 31022 net.cpp:150] Setting up fc7_3
I0226 19:28:48.307780 31022 net.cpp:157] Top shape: 1 1024 41 41 (1721344)
I0226 19:28:48.307787 31022 net.cpp:165] Memory required for data: 386486824
I0226 19:28:48.307799 31022 layer_factory.hpp:77] Creating layer relu7_3
I0226 19:28:48.307811 31022 net.cpp:106] Creating Layer relu7_3
I0226 19:28:48.307819 31022 net.cpp:454] relu7_3 <- fc7_3
I0226 19:28:48.307828 31022 net.cpp:397] relu7_3 -> fc7_3 (in-place)
I0226 19:28:48.307839 31022 net.cpp:150] Setting up relu7_3
I0226 19:28:48.307847 31022 net.cpp:157] Top shape: 1 1024 41 41 (1721344)
I0226 19:28:48.307854 31022 net.cpp:165] Memory required for data: 393372200
I0226 19:28:48.307862 31022 layer_factory.hpp:77] Creating layer drop7_3
I0226 19:28:48.307873 31022 net.cpp:106] Creating Layer drop7_3
I0226 19:28:48.307881 31022 net.cpp:454] drop7_3 <- fc7_3
I0226 19:28:48.307890 31022 net.cpp:397] drop7_3 -> fc7_3 (in-place)
I0226 19:28:48.307921 31022 net.cpp:150] Setting up drop7_3
I0226 19:28:48.307931 31022 net.cpp:157] Top shape: 1 1024 41 41 (1721344)
I0226 19:28:48.307938 31022 net.cpp:165] Memory required for data: 400257576
I0226 19:28:48.307945 31022 layer_factory.hpp:77] Creating layer fc8-SEC_3
I0226 19:28:48.307960 31022 net.cpp:106] Creating Layer fc8-SEC_3
I0226 19:28:48.307968 31022 net.cpp:454] fc8-SEC_3 <- fc7_3
I0226 19:28:48.307978 31022 net.cpp:411] fc8-SEC_3 -> fc8-SEC_3
I0226 19:28:48.308465 31022 net.cpp:150] Setting up fc8-SEC_3
I0226 19:28:48.308482 31022 net.cpp:157] Top shape: 1 21 41 41 (35301)
I0226 19:28:48.308490 31022 net.cpp:165] Memory required for data: 400398780
I0226 19:28:48.308501 31022 layer_factory.hpp:77] Creating layer fc6_4
I0226 19:28:48.308513 31022 net.cpp:106] Creating Layer fc6_4
I0226 19:28:48.308522 31022 net.cpp:454] fc6_4 <- pool5a_pool5a_0_split_3
I0226 19:28:48.308532 31022 net.cpp:411] fc6_4 -> fc6_4
I0226 19:28:48.319511 31022 net.cpp:150] Setting up fc6_4
I0226 19:28:48.319546 31022 net.cpp:157] Top shape: 1 1024 41 41 (1721344)
I0226 19:28:48.319555 31022 net.cpp:165] Memory required for data: 407284156
I0226 19:28:48.319569 31022 layer_factory.hpp:77] Creating layer relu6_4
I0226 19:28:48.319582 31022 net.cpp:106] Creating Layer relu6_4
I0226 19:28:48.319592 31022 net.cpp:454] relu6_4 <- fc6_4
I0226 19:28:48.319605 31022 net.cpp:397] relu6_4 -> fc6_4 (in-place)
I0226 19:28:48.319619 31022 net.cpp:150] Setting up relu6_4
I0226 19:28:48.319628 31022 net.cpp:157] Top shape: 1 1024 41 41 (1721344)
I0226 19:28:48.319634 31022 net.cpp:165] Memory required for data: 414169532
I0226 19:28:48.319641 31022 layer_factory.hpp:77] Creating layer drop6_4
I0226 19:28:48.319653 31022 net.cpp:106] Creating Layer drop6_4
I0226 19:28:48.319659 31022 net.cpp:454] drop6_4 <- fc6_4
I0226 19:28:48.319669 31022 net.cpp:397] drop6_4 -> fc6_4 (in-place)
I0226 19:28:48.319701 31022 net.cpp:150] Setting up drop6_4
I0226 19:28:48.319711 31022 net.cpp:157] Top shape: 1 1024 41 41 (1721344)
I0226 19:28:48.319718 31022 net.cpp:165] Memory required for data: 421054908
I0226 19:28:48.319725 31022 layer_factory.hpp:77] Creating layer fc7_4
I0226 19:28:48.319739 31022 net.cpp:106] Creating Layer fc7_4
I0226 19:28:48.319749 31022 net.cpp:454] fc7_4 <- fc6_4
I0226 19:28:48.319761 31022 net.cpp:411] fc7_4 -> fc7_4
I0226 19:28:48.322504 31022 net.cpp:150] Setting up fc7_4
I0226 19:28:48.322530 31022 net.cpp:157] Top shape: 1 1024 41 41 (1721344)
I0226 19:28:48.322537 31022 net.cpp:165] Memory required for data: 427940284
I0226 19:28:48.322548 31022 layer_factory.hpp:77] Creating layer relu7_4
I0226 19:28:48.322561 31022 net.cpp:106] Creating Layer relu7_4
I0226 19:28:48.322568 31022 net.cpp:454] relu7_4 <- fc7_4
I0226 19:28:48.322578 31022 net.cpp:397] relu7_4 -> fc7_4 (in-place)
I0226 19:28:48.322590 31022 net.cpp:150] Setting up relu7_4
I0226 19:28:48.322598 31022 net.cpp:157] Top shape: 1 1024 41 41 (1721344)
I0226 19:28:48.322605 31022 net.cpp:165] Memory required for data: 434825660
I0226 19:28:48.322613 31022 layer_factory.hpp:77] Creating layer drop7_4
I0226 19:28:48.322623 31022 net.cpp:106] Creating Layer drop7_4
I0226 19:28:48.322631 31022 net.cpp:454] drop7_4 <- fc7_4
I0226 19:28:48.322640 31022 net.cpp:397] drop7_4 -> fc7_4 (in-place)
I0226 19:28:48.322674 31022 net.cpp:150] Setting up drop7_4
I0226 19:28:48.322683 31022 net.cpp:157] Top shape: 1 1024 41 41 (1721344)
I0226 19:28:48.322690 31022 net.cpp:165] Memory required for data: 441711036
I0226 19:28:48.322697 31022 layer_factory.hpp:77] Creating layer fc8-SEC_4
I0226 19:28:48.322712 31022 net.cpp:106] Creating Layer fc8-SEC_4
I0226 19:28:48.322721 31022 net.cpp:454] fc8-SEC_4 <- fc7_4
I0226 19:28:48.322731 31022 net.cpp:411] fc8-SEC_4 -> fc8-SEC_4
I0226 19:28:48.323228 31022 net.cpp:150] Setting up fc8-SEC_4
I0226 19:28:48.323245 31022 net.cpp:157] Top shape: 1 21 41 41 (35301)
I0226 19:28:48.323252 31022 net.cpp:165] Memory required for data: 441852240
I0226 19:28:48.323261 31022 layer_factory.hpp:77] Creating layer fc8-SEC
I0226 19:28:48.323280 31022 net.cpp:106] Creating Layer fc8-SEC
I0226 19:28:48.323288 31022 net.cpp:454] fc8-SEC <- fc8-SEC_1
I0226 19:28:48.323297 31022 net.cpp:454] fc8-SEC <- fc8-SEC_2
I0226 19:28:48.323305 31022 net.cpp:454] fc8-SEC <- fc8-SEC_3
I0226 19:28:48.323312 31022 net.cpp:454] fc8-SEC <- fc8-SEC_4
I0226 19:28:48.323321 31022 net.cpp:411] fc8-SEC -> fc8-SEC
I0226 19:28:48.323359 31022 net.cpp:150] Setting up fc8-SEC
I0226 19:28:48.323371 31022 net.cpp:157] Top shape: 1 21 41 41 (35301)
I0226 19:28:48.323379 31022 net.cpp:165] Memory required for data: 441993444
I0226 19:28:48.323385 31022 net.cpp:228] fc8-SEC does not need backward computation.
I0226 19:28:48.323393 31022 net.cpp:228] fc8-SEC_4 does not need backward computation.
I0226 19:28:48.323400 31022 net.cpp:228] drop7_4 does not need backward computation.
I0226 19:28:48.323407 31022 net.cpp:228] relu7_4 does not need backward computation.
I0226 19:28:48.323415 31022 net.cpp:228] fc7_4 does not need backward computation.
I0226 19:28:48.323421 31022 net.cpp:228] drop6_4 does not need backward computation.
I0226 19:28:48.323427 31022 net.cpp:228] relu6_4 does not need backward computation.
I0226 19:28:48.323434 31022 net.cpp:228] fc6_4 does not need backward computation.
I0226 19:28:48.323441 31022 net.cpp:228] fc8-SEC_3 does not need backward computation.
I0226 19:28:48.323449 31022 net.cpp:228] drop7_3 does not need backward computation.
I0226 19:28:48.323457 31022 net.cpp:228] relu7_3 does not need backward computation.
I0226 19:28:48.323465 31022 net.cpp:228] fc7_3 does not need backward computation.
I0226 19:28:48.323472 31022 net.cpp:228] drop6_3 does not need backward computation.
I0226 19:28:48.323479 31022 net.cpp:228] relu6_3 does not need backward computation.
I0226 19:28:48.323487 31022 net.cpp:228] fc6_3 does not need backward computation.
I0226 19:28:48.323493 31022 net.cpp:228] fc8-SEC_2 does not need backward computation.
I0226 19:28:48.323501 31022 net.cpp:228] drop7_2 does not need backward computation.
I0226 19:28:48.323508 31022 net.cpp:228] relu7_2 does not need backward computation.
I0226 19:28:48.323515 31022 net.cpp:228] fc7_2 does not need backward computation.
I0226 19:28:48.323523 31022 net.cpp:228] drop6_2 does not need backward computation.
I0226 19:28:48.323530 31022 net.cpp:228] relu6_2 does not need backward computation.
I0226 19:28:48.323537 31022 net.cpp:228] fc6_2 does not need backward computation.
I0226 19:28:48.323544 31022 net.cpp:228] fc8-SEC_1 does not need backward computation.
I0226 19:28:48.323552 31022 net.cpp:228] drop7_1 does not need backward computation.
I0226 19:28:48.323559 31022 net.cpp:228] relu7_1 does not need backward computation.
I0226 19:28:48.323566 31022 net.cpp:228] fc7_1 does not need backward computation.
I0226 19:28:48.323573 31022 net.cpp:228] drop6_1 does not need backward computation.
I0226 19:28:48.323580 31022 net.cpp:228] relu6_1 does not need backward computation.
I0226 19:28:48.323586 31022 net.cpp:228] fc6_1 does not need backward computation.
I0226 19:28:48.323595 31022 net.cpp:228] pool5a_pool5a_0_split does not need backward computation.
I0226 19:28:48.323603 31022 net.cpp:228] pool5a does not need backward computation.
I0226 19:28:48.323611 31022 net.cpp:228] pool5 does not need backward computation.
I0226 19:28:48.323618 31022 net.cpp:228] relu5_3 does not need backward computation.
I0226 19:28:48.323626 31022 net.cpp:228] conv5_3 does not need backward computation.
I0226 19:28:48.323632 31022 net.cpp:228] relu5_2 does not need backward computation.
I0226 19:28:48.323640 31022 net.cpp:228] conv5_2 does not need backward computation.
I0226 19:28:48.323647 31022 net.cpp:228] relu5_1 does not need backward computation.
I0226 19:28:48.323654 31022 net.cpp:228] conv5_1 does not need backward computation.
I0226 19:28:48.323662 31022 net.cpp:228] pool4 does not need backward computation.
I0226 19:28:48.323669 31022 net.cpp:228] relu4_3 does not need backward computation.
I0226 19:28:48.323676 31022 net.cpp:228] conv4_3 does not need backward computation.
I0226 19:28:48.323684 31022 net.cpp:228] relu4_2 does not need backward computation.
I0226 19:28:48.323690 31022 net.cpp:228] conv4_2 does not need backward computation.
I0226 19:28:48.323698 31022 net.cpp:228] relu4_1 does not need backward computation.
I0226 19:28:48.323704 31022 net.cpp:228] conv4_1 does not need backward computation.
I0226 19:28:48.323712 31022 net.cpp:228] pool3 does not need backward computation.
I0226 19:28:48.323721 31022 net.cpp:228] relu3_3 does not need backward computation.
I0226 19:28:48.323729 31022 net.cpp:228] conv3_3 does not need backward computation.
I0226 19:28:48.323735 31022 net.cpp:228] relu3_2 does not need backward computation.
I0226 19:28:48.323742 31022 net.cpp:228] conv3_2 does not need backward computation.
I0226 19:28:48.323750 31022 net.cpp:228] relu3_1 does not need backward computation.
I0226 19:28:48.323757 31022 net.cpp:228] conv3_1 does not need backward computation.
I0226 19:28:48.323765 31022 net.cpp:228] pool2 does not need backward computation.
I0226 19:28:48.323772 31022 net.cpp:228] relu2_2 does not need backward computation.
I0226 19:28:48.323779 31022 net.cpp:228] conv2_2 does not need backward computation.
I0226 19:28:48.323786 31022 net.cpp:228] relu2_1 does not need backward computation.
I0226 19:28:48.323793 31022 net.cpp:228] conv2_1 does not need backward computation.
I0226 19:28:48.323801 31022 net.cpp:228] pool1 does not need backward computation.
I0226 19:28:48.323808 31022 net.cpp:228] relu1_2 does not need backward computation.
I0226 19:28:48.323815 31022 net.cpp:228] conv1_2 does not need backward computation.
I0226 19:28:48.323822 31022 net.cpp:228] relu1_1 does not need backward computation.
I0226 19:28:48.323829 31022 net.cpp:228] conv1_1 does not need backward computation.
I0226 19:28:48.323837 31022 net.cpp:270] This network produces output fc8-SEC
I0226 19:28:48.323879 31022 net.cpp:283] Network initialization done.
I0226 19:28:49.946231 31022 net.cpp:816] Ignoring source layer Input
I0226 19:28:49.946264 31022 net.cpp:816] Ignoring source layer Annotation
I0226 19:28:49.946272 31022 net.cpp:816] Ignoring source layer images_Annotation_2_split
I0226 19:28:49.976377 31022 net.cpp:816] Ignoring source layer Softmax
I0226 19:28:49.976408 31022 net.cpp:816] Ignoring source layer fc8-SEC-Softmax_Softmax_0_split
I0226 19:28:49.976415 31022 net.cpp:816] Ignoring source layer CRF
I0226 19:28:49.976423 31022 net.cpp:816] Ignoring source layer update-seed
I0226 19:28:49.976429 31022 net.cpp:816] Ignoring source layer loss-Seed
I0226 19:28:49.976436 31022 net.cpp:816] Ignoring source layer loss-Constrain
0 2007_000032
1 2007_000039
/home/austin/.virtualenvs/pdsrg/local/lib/python2.7/site-packages/scipy/ndimage/interpolation.py:568: UserWarning: From scipy 0.13.0, the output shape of zoom() is calculated with round() instead of int() - for these inputs the size of the returned array has changed.
  "the returned array has changed.", UserWarning)
2 2007_000063
3 2007_000068
4 2007_000121
5 2007_000170
6 2007_000241
7 2007_000243
8 2007_000250
9 2007_000256
10 2007_000333
11 2007_000363
12 2007_000364
13 2007_000392
14 2007_000480
15 2007_000504
16 2007_000515
17 2007_000528
18 2007_000549
19 2007_000584
20 2007_000645
21 2007_000648
22 2007_000713
23 2007_000720
24 2007_000733
25 2007_000738
26 2007_000768
27 2007_000793
28 2007_000822
29 2007_000836
30 2007_000876
31 2007_000904
32 2007_001027
33 2007_001073
34 2007_001149
35 2007_001185
36 2007_001225
37 2007_001340
38 2007_001397
39 2007_001416
40 2007_001420
41 2007_001439
42 2007_001487
43 2007_001595
44 2007_001602
45 2007_001609
46 2007_001698
47 2007_001704
48 2007_001709
49 2007_001724
50 2007_001764
51 2007_001825
52 2007_001834
53 2007_001857
54 2007_001872
55 2007_001901
56 2007_001917
57 2007_001960
58 2007_002024
59 2007_002055
60 2007_002088
61 2007_002099
62 2007_002105
63 2007_002107
64 2007_002120
65 2007_002142
66 2007_002198
67 2007_002212
68 2007_002216
69 2007_002227
70 2007_002234
71 2007_002273
72 2007_002281
73 2007_002293
74 2007_002361
75 2007_002368
76 2007_002370
77 2007_002403
78 2007_002462
79 2007_002488
80 2007_002545
81 2007_002611
82 2007_002639
83 2007_002668
84 2007_002669
85 2007_002760
86 2007_002789
87 2007_002845
88 2007_002895
89 2007_002896
90 2007_002914
91 2007_002953
92 2007_002954
93 2007_002967
94 2007_003000
95 2007_003118
96 2007_003178
97 2007_003189
98 2007_003190
99 2007_003191
100 2007_003205
101 2007_003207
102 2007_003251
103 2007_003267
104 2007_003286
105 2007_003330
106 2007_003431
107 2007_003451
108 2007_003525
109 2007_003529
110 2007_003541
111 2007_003565
112 2007_003580
113 2007_003593
114 2007_003604
115 2007_003668
116 2007_003715
117 2007_003778
118 2007_003788
119 2007_003815
120 2007_003876
121 2007_003889
122 2007_003910
123 2007_004003
124 2007_004009
125 2007_004065
126 2007_004081
127 2007_004166
128 2007_004289
129 2007_004291
130 2007_004328
131 2007_004423
132 2007_004459
133 2007_004476
134 2007_004481
135 2007_004500
136 2007_004537
137 2007_004627
138 2007_004663
139 2007_004705
140 2007_004707
141 2007_004768
142 2007_004769
143 2007_004810
144 2007_004830
145 2007_004841
146 2007_004948
147 2007_004951
148 2007_004988
149 2007_004998
150 2007_005043
151 2007_005064
152 2007_005086
153 2007_005124
154 2007_005130
155 2007_005144
156 2007_005210
157 2007_005212
158 2007_005227
159 2007_005248
160 2007_005262
161 2007_005264
162 2007_005266
163 2007_005273
164 2007_005314
165 2007_005360
166 2007_005368
167 2007_005430
168 2007_005647
169 2007_005688
170 2007_005702
171 2007_005790
172 2007_005797
173 2007_005859
174 2007_005878
175 2007_005902
176 2007_005951
177 2007_005988
178 2007_005989
179 2007_006004
180 2007_006066
181 2007_006134
182 2007_006136
183 2007_006151
184 2007_006212
185 2007_006232
186 2007_006254
187 2007_006281
188 2007_006303
189 2007_006317
190 2007_006400
191 2007_006409
192 2007_006445
193 2007_006477
194 2007_006483
195 2007_006490
196 2007_006530
197 2007_006581
198 2007_006585
199 2007_006605
200 2007_006615
201 2007_006641
202 2007_006660
203 2007_006661
204 2007_006673
205 2007_006699
206 2007_006704
207 2007_006803
208 2007_006832
209 2007_006865
210 2007_006899
211 2007_006900
212 2007_006944
213 2007_007003
214 2007_007021
215 2007_007048
216 2007_007098
217 2007_007154
218 2007_007230
219 2007_007250
220 2007_007355
221 2007_007387
222 2007_007398
223 2007_007415
224 2007_007432
225 2007_007447
226 2007_007480
227 2007_007481
228 2007_007523
229 2007_007530
230 2007_007585
231 2007_007591
232 2007_007621
233 2007_007649
234 2007_007698
235 2007_007726
236 2007_007772
237 2007_007773
238 2007_007783
239 2007_007878
240 2007_007890
241 2007_007891
242 2007_007902
243 2007_007908
244 2007_007930
245 2007_007947
246 2007_007948
247 2007_008043
248 2007_008072
249 2007_008085
250 2007_008140
251 2007_008142
252 2007_008203
253 2007_008218
254 2007_008219
255 2007_008307
256 2007_008403
257 2007_008407
258 2007_008468
259 2007_008526
260 2007_008571
261 2007_008575
262 2007_008714
263 2007_008764
264 2007_008778
265 2007_008801
266 2007_008821
267 2007_008927
268 2007_008932
269 2007_008945
270 2007_008948
271 2007_008994
272 2007_009030
273 2007_009052
274 2007_009082
275 2007_009139
276 2007_009209
277 2007_009216
278 2007_009295
279 2007_009322
280 2007_009327
281 2007_009348
282 2007_009422
283 2007_009435
284 2007_009436
285 2007_009464
286 2007_009527
287 2007_009533
288 2007_009550
289 2007_009554
290 2007_009580
291 2007_009594
292 2007_009597
293 2007_009605
294 2007_009607
295 2007_009618
296 2007_009630
297 2007_009649
298 2007_009665
299 2007_009709
300 2007_009724
301 2007_009759
302 2007_009779
303 2007_009788
304 2007_009807
305 2007_009832
306 2007_009889
307 2007_009899
308 2007_009901
309 2007_009947
310 2007_009950
311 2008_000002
312 2008_000003
313 2008_000007
314 2008_000008
315 2008_000015
316 2008_000019
317 2008_000023
318 2008_000026
319 2008_000027
320 2008_000028
321 2008_000032
322 2008_000033
323 2008_000034
324 2008_000036
325 2008_000041
326 2008_000042
327 2008_000043
328 2008_000045
329 2008_000050
330 2008_000051
331 2008_000052
332 2008_000053
333 2008_000054
334 2008_000056
335 2008_000059
336 2008_000060
337 2008_000062
338 2008_000064
339 2008_000066
340 2008_000067
341 2008_000070
342 2008_000074
343 2008_000076
344 2008_000078
345 2008_000082
346 2008_000084
347 2008_000085
348 2008_000089
349 2008_000090
350 2008_000093
351 2008_000095
352 2008_000096
353 2008_000097
354 2008_000099
355 2008_000103
356 2008_000105
357 2008_000109
358 2008_000112
359 2008_000115
360 2008_000116
361 2008_000119
362 2008_000128
363 2008_000131
364 2008_000132
365 2008_000133
366 2008_000134
367 2008_000138
368 2008_000140
369 2008_000141
370 2008_000142
371 2008_000143
372 2008_000144
373 2008_000145
374 2008_000148
375 2008_000154
376 2008_000162
377 2008_000163
378 2008_000174
379 2008_000176
380 2008_000177
381 2008_000181
382 2008_000183
383 2008_000185
384 2008_000187
385 2008_000188
386 2008_000189
387 2008_000190
388 2008_000191
389 2008_000192
390 2008_000194
391 2008_000195
392 2008_000196
393 2008_000197
394 2008_000199
395 2008_000202
396 2008_000203
397 2008_000204
398 2008_000207
399 2008_000217
400 2008_000219
401 2008_000222
402 2008_000226
403 2008_000227
404 2008_000235
405 2008_000236
406 2008_000237
407 2008_000238
408 2008_000243
409 2008_000244
410 2008_000246
411 2008_000251
412 2008_000252
413 2008_000253
414 2008_000255
415 2008_000257
416 2008_000259
417 2008_000260
418 2008_000261
419 2008_000262
420 2008_000264
421 2008_000266
422 2008_000268
423 2008_000272
424 2008_000273
425 2008_000274
426 2008_000275
427 2008_000277
428 2008_000278
429 2008_000281
430 2008_000283
431 2008_000284
432 2008_000287
433 2008_000289
434 2008_000290
435 2008_000291
436 2008_000297
437 2008_000298
438 2008_000304
439 2008_000305
440 2008_000306
441 2008_000307
442 2008_000309
443 2008_000311
444 2008_000313
445 2008_000315
446 2008_000316
447 2008_000318
448 2008_000321
449 2008_000328
450 2008_000330
451 2008_000335
452 2008_000336
453 2008_000338
454 2008_000339
455 2008_000340
456 2008_000342
457 2008_000343
458 2008_000346
459 2008_000348
460 2008_000350
461 2008_000354
462 2008_000356
463 2008_000358
464 2008_000361
465 2008_000364
466 2008_000365
467 2008_000367
468 2008_000371
469 2008_000373
470 2008_000376
471 2008_000378
472 2008_000380
473 2008_000381
474 2008_000382
475 2008_000383
476 2008_000392
477 2008_000393
478 2008_000397
479 2008_000398
480 2008_000399
481 2008_000400
482 2008_000403
483 2008_000405
484 2008_000406
485 2008_000407
486 2008_000408
487 2008_000413
488 2008_000414
489 2008_000415
490 2008_000416
491 2008_000418
492 2008_000419
493 2008_000421
494 2008_000422
495 2008_000423
496 2008_000424
497 2008_000426
498 2008_000428
499 2008_000432
500 2008_000435
501 2008_000436
502 2008_000437
503 2008_000442
504 2008_000443
505 2008_000445
506 2008_000446
507 2008_000447
508 2008_000448
509 2008_000452
510 2008_000455
511 2008_000457
512 2008_000461
513 2008_000465
514 2008_000470
515 2008_000471
516 2008_000472
517 2008_000473
518 2008_000475
519 2008_000480
520 2008_000481
521 2008_000488
522 2008_000489
523 2008_000491
524 2008_000492
525 2008_000493
526 2008_000495
527 2008_000496
528 2008_000498
529 2008_000499
530 2008_000502
531 2008_000505
532 2008_000511
533 2008_000512
534 2008_000514
535 2008_000515
536 2008_000516
537 2008_000522
538 2008_000527
539 2008_000531
540 2008_000532
541 2008_000535
542 2008_000536
543 2008_000540
544 2008_000541
545 2008_000544
546 2008_000545
547 2008_000547
548 2008_000548
549 2008_000552
550 2008_000553
551 2008_000558
552 2008_000559
553 2008_000561
554 2008_000562
555 2008_000563
556 2008_000564
557 2008_000566
558 2008_000567
559 2008_000568
560 2008_000569
561 2008_000572
562 2008_000578
563 2008_000579
564 2008_000581
565 2008_000583
566 2008_000584
567 2008_000585
568 2008_000588
569 2008_000595
570 2008_000599
571 2008_000605
572 2008_000607
573 2008_000609
574 2008_000613
575 2008_000614
576 2008_000615
577 2008_000619
578 2008_000620
579 2008_000622
580 2008_000623
581 2008_000626
582 2008_000628
583 2008_000629
584 2008_000634
585 2008_000636
586 2008_000640
587 2008_000641
588 2008_000645
589 2008_000646
590 2008_000647
591 2008_000648
592 2008_000650
593 2008_000652
594 2008_000655
595 2008_000656
596 2008_000659
597 2008_000660
598 2008_000669
599 2008_000670
600 2008_000672
601 2008_000674
602 2008_000676
603 2008_000677
604 2008_000678
605 2008_000683
606 2008_000689
607 2008_000690
608 2008_000691
609 2008_000694
610 2008_000695
611 2008_000696
612 2008_000697
613 2008_000699
614 2008_000703
615 2008_000704
616 2008_000705
617 2008_000706
618 2008_000711
619 2008_000714
620 2008_000716
621 2008_000719
622 2008_000721
623 2008_000723
624 2008_000724
625 2008_000726
626 2008_000727
627 2008_000729
628 2008_000732
629 2008_000733
630 2008_000734
631 2008_000737
632 2008_000740
633 2008_000742
634 2008_000745
635 2008_000748
636 2008_000753
637 2008_000756
638 2008_000758
639 2008_000760
640 2008_000761
641 2008_000764
642 2008_000769
643 2008_000775
644 2008_000776
645 2008_000777
646 2008_000778
647 2008_000780
648 2008_000783
649 2008_000785
650 2008_000787
651 2008_000788
652 2008_000790
653 2008_000792
654 2008_000793
655 2008_000796
656 2008_000798
657 2008_000801
658 2008_000803
659 2008_000804
660 2008_000806
661 2008_000808
662 2008_000814
663 2008_000815
664 2008_000817
665 2008_000824
666 2008_000825
667 2008_000828
668 2008_000829
669 2008_000832
670 2008_000833
671 2008_000834
672 2008_000835
673 2008_000837
674 2008_000839
675 2008_000841
676 2008_000842
677 2008_000844
678 2008_000847
679 2008_000851
680 2008_000854
681 2008_000857
682 2008_000858
683 2008_000860
684 2008_000861
685 2008_000864
686 2008_000867
687 2008_000868
688 2008_000870
689 2008_000873
690 2008_000875
691 2008_000876
692 2008_000878
693 2008_000880
694 2008_000881
695 2008_000883
696 2008_000884
697 2008_000885
698 2008_000887
699 2008_000897
700 2008_000899
701 2008_000901
702 2008_000902
703 2008_000904
704 2008_000905
705 2008_000908
706 2008_000910
707 2008_000912
708 2008_000914
709 2008_000915
710 2008_000916
711 2008_000917
712 2008_000922
713 2008_000923
714 2008_000924
715 2008_000928
716 2008_000931
717 2008_000934
718 2008_000936
719 2008_000939
720 2008_000940
721 2008_000941
722 2008_000942
723 2008_000944
724 2008_000950
725 2008_000952
726 2008_000953
727 2008_000956
728 2008_000957
729 2008_000959
730 2008_000960
731 2008_000964
732 2008_000965
733 2008_000970
734 2008_000971
735 2008_000972
736 2008_000973
737 2008_000976
738 2008_000979
739 2008_000981
740 2008_000982
741 2008_000984
742 2008_000985
743 2008_000987
744 2008_000993
745 2008_000999
746 2008_001004
747 2008_001007
748 2008_001009
749 2008_001012
750 2008_001018
751 2008_001020
752 2008_001021
753 2008_001022
754 2008_001023
755 2008_001024
756 2008_001026
757 2008_001030
758 2008_001031
759 2008_001034
760 2008_001035
761 2008_001036
762 2008_001039
763 2008_001041
764 2008_001042
765 2008_001046
766 2008_001047
767 2008_001048
768 2008_001052
769 2008_001054
770 2008_001055
771 2008_001056
772 2008_001057
773 2008_001060
774 2008_001062
775 2008_001063
776 2008_001066
777 2008_001068
778 2008_001071
779 2008_001073
780 2008_001075
781 2008_001077
782 2008_001080
783 2008_001081
784 2008_001083
785 2008_001089
786 2008_001090
787 2008_001092
788 2008_001098
789 2008_001099
790 2008_001104
791 2008_001105
792 2008_001106
793 2008_001111
794 2008_001112
795 2008_001113
796 2008_001114
797 2008_001115
798 2008_001118
799 2008_001119
800 2008_001120
801 2008_001121
802 2008_001122
803 2008_001130
804 2008_001133
805 2008_001134
806 2008_001136
807 2008_001137
808 2008_001139
809 2008_001140
810 2008_001142
811 2008_001143
812 2008_001147
813 2008_001154
814 2008_001155
815 2008_001158
816 2008_001159
817 2008_001160
818 2008_001161
819 2008_001164
820 2008_001166
821 2008_001167
822 2008_001168
823 2008_001169
824 2008_001171
825 2008_001177
826 2008_001182
827 2008_001183
828 2008_001185
829 2008_001188
830 2008_001189
831 2008_001190
832 2008_001192
833 2008_001194
834 2008_001196
835 2008_001199
836 2008_001202
837 2008_001203
838 2008_001205
839 2008_001206
840 2008_001208
841 2008_001210
842 2008_001215
843 2008_001218
844 2008_001219
845 2008_001220
846 2008_001221
847 2008_001223
848 2008_001225
849 2008_001226
850 2008_001227
851 2008_001230
852 2008_001235
853 2008_001236
854 2008_001238
855 2008_001241
856 2008_001245
857 2008_001248
858 2008_001255
859 2008_001257
860 2008_001262
861 2008_001263
862 2008_001264
863 2008_001267
864 2008_001271
865 2008_001272
866 2008_001274
867 2008_001275
868 2008_001278
869 2008_001284
870 2008_001285
871 2008_001290
872 2008_001294
873 2008_001296
874 2008_001299
875 2008_001301
876 2008_001302
877 2008_001304
878 2008_001306
879 2008_001307
880 2008_001310
881 2008_001312
882 2008_001314
883 2008_001318
884 2008_001320
885 2008_001322
886 2008_001325
887 2008_001329
888 2008_001333
889 2008_001334
890 2008_001335
891 2008_001336
892 2008_001338
893 2008_001340
894 2008_001344
895 2008_001346
896 2008_001349
897 2008_001350
898 2008_001351
899 2008_001353
900 2008_001356
901 2008_001357
902 2008_001358
903 2008_001359
904 2008_001366
905 2008_001367
906 2008_001369
907 2008_001373
908 2008_001374
909 2008_001375
910 2008_001376
911 2008_001380
912 2008_001382
913 2008_001383
914 2008_001385
915 2008_001387
916 2008_001388
917 2008_001389
918 2008_001390
919 2008_001391
920 2008_001395
921 2008_001399
922 2008_001401
923 2008_001402
924 2008_001405
925 2008_001406
926 2008_001408
927 2008_001410
928 2008_001413
929 2008_001414
930 2008_001415
931 2008_001419
932 2008_001420
933 2008_001427
934 2008_001428
935 2008_001429
936 2008_001430
937 2008_001431
938 2008_001432
939 2008_001434
940 2008_001436
941 2008_001437
942 2008_001440
943 2008_001444
944 2008_001445
945 2008_001446
946 2008_001448
947 2008_001451
948 2008_001454
949 2008_001455
950 2008_001456
951 2008_001460
952 2008_001461
953 2008_001462
954 2008_001464
955 2008_001466
956 2008_001467
957 2008_001468
958 2008_001470
959 2008_001475
960 2008_001479
961 2008_001481
962 2008_001482
963 2008_001486
964 2008_001488
965 2008_001493
966 2008_001494
967 2008_001495
968 2008_001498
969 2008_001500
970 2008_001501
971 2008_001503
972 2008_001510
973 2008_001516
974 2008_001520
975 2008_001522
976 2008_001523
977 2008_001525
978 2008_001527
979 2008_001529
980 2008_001533
981 2008_001534
982 2008_001536
983 2008_001538
984 2008_001539
985 2008_001540
986 2008_001541
987 2008_001542
988 2008_001543
989 2008_001544
990 2008_001549
991 2008_001550
992 2008_001551
993 2008_001553
994 2008_001563
995 2008_001564
996 2008_001566
997 2008_001574
998 2008_001575
999 2008_001576
1000 2008_001577
1001 2008_001582
1002 2008_001586
1003 2008_001589
1004 2008_001590
1005 2008_001591
1006 2008_001592
1007 2008_001593
1008 2008_001594
1009 2008_001596
1010 2008_001598
1011 2008_001601
1012 2008_001602
1013 2008_001605
1014 2008_001607
1015 2008_001609
1016 2008_001610
1017 2008_001613
1018 2008_001615
1019 2008_001617
1020 2008_001619
1021 2008_001620
1022 2008_001622
1023 2008_001624
1024 2008_001625
1025 2008_001626
1026 2008_001631
1027 2008_001632
1028 2008_001636
1029 2008_001638
1030 2008_001641
1031 2008_001643
1032 2008_001645
1033 2008_001648
1034 2008_001649
1035 2008_001652
1036 2008_001653
1037 2008_001655
1038 2008_001659
1039 2008_001660
1040 2008_001661
1041 2008_001663
1042 2008_001666
1043 2008_001667
1044 2008_001668
1045 2008_001669
1046 2008_001670
1047 2008_001673
1048 2008_001676
1049 2008_001679
1050 2008_001680
1051 2008_001681
1052 2008_001690
1053 2008_001691
1054 2008_001692
1055 2008_001694
1056 2008_001697
1057 2008_001699
1058 2008_001702
1059 2008_001704
1060 2008_001706
1061 2008_001708
1062 2008_001709
1063 2008_001710
1064 2008_001712
1065 2008_001716
1066 2008_001717
1067 2008_001719
1068 2008_001722
1069 2008_001723
1070 2008_001724
1071 2008_001727
1072 2008_001729
1073 2008_001730
1074 2008_001731
1075 2008_001735
1076 2008_001736
1077 2008_001737
1078 2008_001741
1079 2008_001742
1080 2008_001744
1081 2008_001745
1082 2008_001746
1083 2008_001750
1084 2008_001751
1085 2008_001757
1086 2008_001758
1087 2008_001761
1088 2008_001763
1089 2008_001764
1090 2008_001765
1091 2008_001769
1092 2008_001770
1093 2008_001772
1094 2008_001773
1095 2008_001774
1096 2008_001775
1097 2008_001781
1098 2008_001782
1099 2008_001783
1100 2008_001784
1101 2008_001787
1102 2008_001789
1103 2008_001791
1104 2008_001792
1105 2008_001797
1106 2008_001801
1107 2008_001802
1108 2008_001805
1109 2008_001806
1110 2008_001808
1111 2008_001809
1112 2008_001810
1113 2008_001811
1114 2008_001812
1115 2008_001813
1116 2008_001814
1117 2008_001815
1118 2008_001816
1119 2008_001820
1120 2008_001823
1121 2008_001825
1122 2008_001829
1123 2008_001830
1124 2008_001832
1125 2008_001834
1126 2008_001836
1127 2008_001837
1128 2008_001838
1129 2008_001841
1130 2008_001842
1131 2008_001843
1132 2008_001845
1133 2008_001849
1134 2008_001850
1135 2008_001852
1136 2008_001854
1137 2008_001856
1138 2008_001858
1139 2008_001860
1140 2008_001862
1141 2008_001863
1142 2008_001865
1143 2008_001866
1144 2008_001867
1145 2008_001869
1146 2008_001871
1147 2008_001872
1148 2008_001876
1149 2008_001880
1150 2008_001881
1151 2008_001882
1152 2008_001888
1153 2008_001894
1154 2008_001896
1155 2008_001899
1156 2008_001903
1157 2008_001905
1158 2008_001907
1159 2008_001908
1160 2008_001909
1161 2008_001910
1162 2008_001911
1163 2008_001914
1164 2008_001919
1165 2008_001920
1166 2008_001921
1167 2008_001926
1168 2008_001928
1169 2008_001929
1170 2008_001930
1171 2008_001932
1172 2008_001934
1173 2008_001937
1174 2008_001941
1175 2008_001945
1176 2008_001946
1177 2008_001947
1178 2008_001951
1179 2008_001955
1180 2008_001956
1181 2008_001957
1182 2008_001958
1183 2008_001961
1184 2008_001965
1185 2008_001967
1186 2008_001969
1187 2008_001970
1188 2008_001977
1189 2008_001978
1190 2008_001979
1191 2008_001980
1192 2008_001982
1193 2008_001985
1194 2008_001986
1195 2008_001987
1196 2008_001989
1197 2008_001997
1198 2008_001998
1199 2008_002000
1200 2008_002001
1201 2008_002002
1202 2008_002003
1203 2008_002004
1204 2008_002005
1205 2008_002007
1206 2008_002009
1207 2008_002011
1208 2008_002013
1209 2008_002017
1210 2008_002021
1211 2008_002023
1212 2008_002026
1213 2008_002031
1214 2008_002032
1215 2008_002033
1216 2008_002035
1217 2008_002036
1218 2008_002037
1219 2008_002039
1220 2008_002042
1221 2008_002045
1222 2008_002046
1223 2008_002047
1224 2008_002052
1225 2008_002056
1226 2008_002058
1227 2008_002061
1228 2008_002062
1229 2008_002064
1230 2008_002066
1231 2008_002067
1232 2008_002069
1233 2008_002071
1234 2008_002073
1235 2008_002079
1236 2008_002080
1237 2008_002082
1238 2008_002084
1239 2008_002086
1240 2008_002088
1241 2008_002092
1242 2008_002093
1243 2008_002094
1244 2008_002096
1245 2008_002098
1246 2008_002099
1247 2008_002103
1248 2008_002107
1249 2008_002112
1250 2008_002113
1251 2008_002114
1252 2008_002115
1253 2008_002116
1254 2008_002117
1255 2008_002118
1256 2008_002119
1257 2008_002123
1258 2008_002124
1259 2008_002129
1260 2008_002131
1261 2008_002132
1262 2008_002138
1263 2008_002140
1264 2008_002144
1265 2008_002145
1266 2008_002146
1267 2008_002148
1268 2008_002150
1269 2008_002151
1270 2008_002153
1271 2008_002155
1272 2008_002156
1273 2008_002158
1274 2008_002160
1275 2008_002162
1276 2008_002167
1277 2008_002169
1278 2008_002172
1279 2008_002175
1280 2008_002176
1281 2008_002177
1282 2008_002179
1283 2008_002181
1284 2008_002182
1285 2008_002185
1286 2008_002191
1287 2008_002193
1288 2008_002194
1289 2008_002195
1290 2008_002197
1291 2008_002198
1292 2008_002199
1293 2008_002200
1294 2008_002201
1295 2008_002202
1296 2008_002204
1297 2008_002206
1298 2008_002207
1299 2008_002208
1300 2008_002209
1301 2008_002210
1302 2008_002215
1303 2008_002218
1304 2008_002220
1305 2008_002221
1306 2008_002222
1307 2008_002223
1308 2008_002225
1309 2008_002227
1310 2008_002229
1311 2008_002231
1312 2008_002234
1313 2008_002236
1314 2008_002243
1315 2008_002244
1316 2008_002247
1317 2008_002248
1318 2008_002250
1319 2008_002251
1320 2008_002255
1321 2008_002258
1322 2008_002259
1323 2008_002262
1324 2008_002267
1325 2008_002270
1326 2008_002272
1327 2008_002278
1328 2008_002279
1329 2008_002280
1330 2008_002281
1331 2008_002283
1332 2008_002288
1333 2008_002292
1334 2008_002293
1335 2008_002294
1336 2008_002296
1337 2008_002298
1338 2008_002299
1339 2008_002304
1340 2008_002305
1341 2008_002307
1342 2008_002311
1343 2008_002312
1344 2008_002314
1345 2008_002317
1346 2008_002321
1347 2008_002322
1348 2008_002324
1349 2008_002325
1350 2008_002327
1351 2008_002328
1352 2008_002329
1353 2008_002330
1354 2008_002331
1355 2008_002335
1356 2008_002338
1357 2008_002340
1358 2008_002343
1359 2008_002344
1360 2008_002347
1361 2008_002349
1362 2008_002350
1363 2008_002356
1364 2008_002357
1365 2008_002359
1366 2008_002361
1367 2008_002362
1368 2008_002365
1369 2008_002366
1370 2008_002368
1371 2008_002369
1372 2008_002370
1373 2008_002372
1374 2008_002374
1375 2008_002377
1376 2008_002378
1377 2008_002384
1378 2008_002389
1379 2008_002395
1380 2008_002399
1381 2008_002401
1382 2008_002403
1383 2008_002404
1384 2008_002405
1385 2008_002408
1386 2008_002410
1387 2008_002411
1388 2008_002412
1389 2008_002414
1390 2008_002418
1391 2008_002419
1392 2008_002422
1393 2008_002424
1394 2008_002425
1395 2008_002428
1396 2008_002430
1397 2008_002434
1398 2008_002436
1399 2008_002437
1400 2008_002438
1401 2008_002439
1402 2008_002441
1403 2008_002442
1404 2008_002444
1405 2008_002445
1406 2008_002446
1407 2008_002448
1408 2008_002451
1409 2008_002452
1410 2008_002454
1411 2008_002456
1412 2008_002457
1413 2008_002458
1414 2008_002459
1415 2008_002461
1416 2008_002465
1417 2008_002466
1418 2008_002470
1419 2008_002471
1420 2008_002473
1421 2008_002477
1422 2008_002481
1423 2008_002482
1424 2008_002483
1425 2008_002484
1426 2008_002485
1427 2008_002487
1428 2008_002491
1429 2008_002494
1430 2008_002499
1431 2008_002501
1432 2008_002502
1433 2008_002506
1434 2008_002508
1435 2008_002509
1436 2008_002510
1437 2008_002512
1438 2008_002514
1439 2008_002515
1440 2008_002523
1441 2008_002524
1442 2008_002526
1443 2008_002527
1444 2008_002533
1445 2008_002540
1446 2008_002541
1447 2008_002542
1448 2008_002543
1449 2008_002547
1450 2008_002549
1451 2008_002551
1452 2008_002555
1453 2008_002558
1454 2008_002562
1455 2008_002564
1456 2008_002566
1457 2008_002567
1458 2008_002568
1459 2008_002574
1460 2008_002575
1461 2008_002576
1462 2008_002578
1463 2008_002579
1464 2008_002583
1465 2008_002584
1466 2008_002589
1467 2008_002590
1468 2008_002597
1469 2008_002598
1470 2008_002599
1471 2008_002601
1472 2008_002603
1473 2008_002606
1474 2008_002610
1475 2008_002612
1476 2008_002613
1477 2008_002616
1478 2008_002621
1479 2008_002622
1480 2008_002624
1481 2008_002625
1482 2008_002631
1483 2008_002634
1484 2008_002638
1485 2008_002639
1486 2008_002640
1487 2008_002641
1488 2008_002643
1489 2008_002645
1490 2008_002647
1491 2008_002649
1492 2008_002650
1493 2008_002652
1494 2008_002653
1495 2008_002662
1496 2008_002665
1497 2008_002666
1498 2008_002668
1499 2008_002670
1500 2008_002672
1501 2008_002673
1502 2008_002674
1503 2008_002675
1504 2008_002676
1505 2008_002677
1506 2008_002678
1507 2008_002679
1508 2008_002682
1509 2008_002684
1510 2008_002686
1511 2008_002687
1512 2008_002696
1513 2008_002697
1514 2008_002698
1515 2008_002700
1516 2008_002701
1517 2008_002704
1518 2008_002705
1519 2008_002709
1520 2008_002710
1521 2008_002712
1522 2008_002714
1523 2008_002715
1524 2008_002716
1525 2008_002718
1526 2008_002719
1527 2008_002720
1528 2008_002725
1529 2008_002728
1530 2008_002730
1531 2008_002732
1532 2008_002733
1533 2008_002735
1534 2008_002736
1535 2008_002738
1536 2008_002741
1537 2008_002746
1538 2008_002749
1539 2008_002750
1540 2008_002751
1541 2008_002752
1542 2008_002753
1543 2008_002756
1544 2008_002758
1545 2008_002760
1546 2008_002762
1547 2008_002766
1548 2008_002767
1549 2008_002768
1550 2008_002772
1551 2008_002773
1552 2008_002774
1553 2008_002776
1554 2008_002783
1555 2008_002784
1556 2008_002787
1557 2008_002789
1558 2008_002791
1559 2008_002792
1560 2008_002793
1561 2008_002794
1562 2008_002795
1563 2008_002801
1564 2008_002804
1565 2008_002806
1566 2008_002808
1567 2008_002809
1568 2008_002811
1569 2008_002813
1570 2008_002814
1571 2008_002817
1572 2008_002820
1573 2008_002823
1574 2008_002826
1575 2008_002829
1576 2008_002830
1577 2008_002831
1578 2008_002834
1579 2008_002838
1580 2008_002842
1581 2008_002843
1582 2008_002845
1583 2008_002847
1584 2008_002848
1585 2008_002850
1586 2008_002852
1587 2008_002854
1588 2008_002856
1589 2008_002857
1590 2008_002860
1591 2008_002866
1592 2008_002868
1593 2008_002869
1594 2008_002870
1595 2008_002872
1596 2008_002873
1597 2008_002875
1598 2008_002876
1599 2008_002879
1600 2008_002880
1601 2008_002882
1602 2008_002883
1603 2008_002885
1604 2008_002887
1605 2008_002890
1606 2008_002891
1607 2008_002892
1608 2008_002894
1609 2008_002897
1610 2008_002899
1611 2008_002903
1612 2008_002906
1613 2008_002908
1614 2008_002909
1615 2008_002910
1616 2008_002913
1617 2008_002916
1618 2008_002917
1619 2008_002920
1620 2008_002922
1621 2008_002926
1622 2008_002930
1623 2008_002931
1624 2008_002932
1625 2008_002943
1626 2008_002946
1627 2008_002947
1628 2008_002948
1629 2008_002951
1630 2008_002954
1631 2008_002955
1632 2008_002956
1633 2008_002957
1634 2008_002960
1635 2008_002961
1636 2008_002965
1637 2008_002966
1638 2008_002968
1639 2008_002970
1640 2008_002971
1641 2008_002972
1642 2008_002973
1643 2008_002977
1644 2008_002983
1645 2008_002984
1646 2008_002985
1647 2008_002988
1648 2008_002992
1649 2008_002993
1650 2008_002997
1651 2008_002999
1652 2008_003001
1653 2008_003005
1654 2008_003008
1655 2008_003013
1656 2008_003015
1657 2008_003017
1658 2008_003018
1659 2008_003020
1660 2008_003021
1661 2008_003022
1662 2008_003023
1663 2008_003025
1664 2008_003030
1665 2008_003039
1666 2008_003041
1667 2008_003043
1668 2008_003045
1669 2008_003048
1670 2008_003049
1671 2008_003051
1672 2008_003052
1673 2008_003053
1674 2008_003055
1675 2008_003056
1676 2008_003057
1677 2008_003059
1678 2008_003060
1679 2008_003061
1680 2008_003062
1681 2008_003063
1682 2008_003065
1683 2008_003067
1684 2008_003068
1685 2008_003072
1686 2008_003073
1687 2008_003075
1688 2008_003079
1689 2008_003081
1690 2008_003082
1691 2008_003083
1692 2008_003087
1693 2008_003088
1694 2008_003089
1695 2008_003090
1696 2008_003093
1697 2008_003094
1698 2008_003095
1699 2008_003099
1700 2008_003100
1701 2008_003101
1702 2008_003104
1703 2008_003106
1704 2008_003107
1705 2008_003112
1706 2008_003114
1707 2008_003120
1708 2008_003122
1709 2008_003127
1710 2008_003128
1711 2008_003132
1712 2008_003133
1713 2008_003134
1714 2008_003136
1715 2008_003140
1716 2008_003143
1717 2008_003144
1718 2008_003146
1719 2008_003147
1720 2008_003151
1721 2008_003152
1722 2008_003154
1723 2008_003157
1724 2008_003160
1725 2008_003161
1726 2008_003167
1727 2008_003168
1728 2008_003170
1729 2008_003178
1730 2008_003180
1731 2008_003181
1732 2008_003182
1733 2008_003186
1734 2008_003187
1735 2008_003189
1736 2008_003191
1737 2008_003193
1738 2008_003196
1739 2008_003200
1740 2008_003202
1741 2008_003203
1742 2008_003205
1743 2008_003208
1744 2008_003209
1745 2008_003211
1746 2008_003213
1747 2008_003220
1748 2008_003222
1749 2008_003224
1750 2008_003225
1751 2008_003228
1752 2008_003231
1753 2008_003232
1754 2008_003239
1755 2008_003242
1756 2008_003244
1757 2008_003245
1758 2008_003248
1759 2008_003249
1760 2008_003251
1761 2008_003252
1762 2008_003255
1763 2008_003256
1764 2008_003261
1765 2008_003263
1766 2008_003264
1767 2008_003265
1768 2008_003266
1769 2008_003269
1770 2008_003271
1771 2008_003272
1772 2008_003275
1773 2008_003276
1774 2008_003277
1775 2008_003278
1776 2008_003280
1777 2008_003283
1778 2008_003286
1779 2008_003287
1780 2008_003288
1781 2008_003289
1782 2008_003290
1783 2008_003291
1784 2008_003295
1785 2008_003297
1786 2008_003300
1787 2008_003302
1788 2008_003303
1789 2008_003304
1790 2008_003305
1791 2008_003311
1792 2008_003313
1793 2008_003316
1794 2008_003318
1795 2008_003320
1796 2008_003321
1797 2008_003323
1798 2008_003326
1799 2008_003329
1800 2008_003331
1801 2008_003334
1802 2008_003335
1803 2008_003336
1804 2008_003338
1805 2008_003342
1806 2008_003343
1807 2008_003344
1808 2008_003347
1809 2008_003348
1810 2008_003350
1811 2008_003351
1812 2008_003359
1813 2008_003360
1814 2008_003361
1815 2008_003362
1816 2008_003373
1817 2008_003374
1818 2008_003378
1819 2008_003380
1820 2008_003381
1821 2008_003382
1822 2008_003384
1823 2008_003386
1824 2008_003393
1825 2008_003394
1826 2008_003395
1827 2008_003402
1828 2008_003405
1829 2008_003406
1830 2008_003407
1831 2008_003409
1832 2008_003414
1833 2008_003415
1834 2008_003417
1835 2008_003418
1836 2008_003420
1837 2008_003423
1838 2008_003424
1839 2008_003426
1840 2008_003429
1841 2008_003430
1842 2008_003432
1843 2008_003433
1844 2008_003434
1845 2008_003435
1846 2008_003437
1847 2008_003439
1848 2008_003442
1849 2008_003443
1850 2008_003447
1851 2008_003448
1852 2008_003449
1853 2008_003452
1854 2008_003453
1855 2008_003458
1856 2008_003462
1857 2008_003463
1858 2008_003464
1859 2008_003466
1860 2008_003467
1861 2008_003469
1862 2008_003472
1863 2008_003475
1864 2008_003478
1865 2008_003479
1866 2008_003480
1867 2008_003482
1868 2008_003483
1869 2008_003484
1870 2008_003485
1871 2008_003488
1872 2008_003489
1873 2008_003493
1874 2008_003496
1875 2008_003497
1876 2008_003498
1877 2008_003500
1878 2008_003501
1879 2008_003504
1880 2008_003507
1881 2008_003510
1882 2008_003514
1883 2008_003515
1884 2008_003519
1885 2008_003520
1886 2008_003521
1887 2008_003522
1888 2008_003523
1889 2008_003524
1890 2008_003526
1891 2008_003531
1892 2008_003533
1893 2008_003534
1894 2008_003542
1895 2008_003544
1896 2008_003545
1897 2008_003547
1898 2008_003552
1899 2008_003557
1900 2008_003559
1901 2008_003560
1902 2008_003562
1903 2008_003565
1904 2008_003571
1905 2008_003572
1906 2008_003575
1907 2008_003578
1908 2008_003579
1909 2008_003580
1910 2008_003582
1911 2008_003585
1912 2008_003587
1913 2008_003589
1914 2008_003590
1915 2008_003591
1916 2008_003592
1917 2008_003593
1918 2008_003596
1919 2008_003598
1920 2008_003604
1921 2008_003607
1922 2008_003608
1923 2008_003609
1924 2008_003610
1925 2008_003611
1926 2008_003613
1927 2008_003617
1928 2008_003618
1929 2008_003619
1930 2008_003622
1931 2008_003624
1932 2008_003626
1933 2008_003629
1934 2008_003635
1935 2008_003636
1936 2008_003637
1937 2008_003638
1938 2008_003645
1939 2008_003647
1940 2008_003650
1941 2008_003652
1942 2008_003653
1943 2008_003655
1944 2008_003658
1945 2008_003659
1946 2008_003662
1947 2008_003665
1948 2008_003667
1949 2008_003671
1950 2008_003672
1951 2008_003673
1952 2008_003674
1953 2008_003675
1954 2008_003677
1955 2008_003680
1956 2008_003681
1957 2008_003682
1958 2008_003683
1959 2008_003684
1960 2008_003685
1961 2008_003688
1962 2008_003689
1963 2008_003691
1964 2008_003694
1965 2008_003697
1966 2008_003701
1967 2008_003703
1968 2008_003704
1969 2008_003706
1970 2008_003707
1971 2008_003712
1972 2008_003718
1973 2008_003719
1974 2008_003720
1975 2008_003721
1976 2008_003722
1977 2008_003726
1978 2008_003729
1979 2008_003732
1980 2008_003737
1981 2008_003743
1982 2008_003744
1983 2008_003745
1984 2008_003746
1985 2008_003748
1986 2008_003749
1987 2008_003753
1988 2008_003754
1989 2008_003755
1990 2008_003756
1991 2008_003761
1992 2008_003762
1993 2008_003763
1994 2008_003764
1995 2008_003766
1996 2008_003767
1997 2008_003768
1998 2008_003769
1999 2008_003772
2000 2008_003773
2001 2008_003774
2002 2008_003775
2003 2008_003776
2004 2008_003779
2005 2008_003780
2006 2008_003781
2007 2008_003788
2008 2008_003789
2009 2008_003791
2010 2008_003793
2011 2008_003794
2012 2008_003796
2013 2008_003799
2014 2008_003800
2015 2008_003801
2016 2008_003802
2017 2008_003805
2018 2008_003811
2019 2008_003812
2020 2008_003813
2021 2008_003814
2022 2008_003815
2023 2008_003819
2024 2008_003820
2025 2008_003825
2026 2008_003826
2027 2008_003827
2028 2008_003829
2029 2008_003830
2030 2008_003831
2031 2008_003835
2032 2008_003838
2033 2008_003840
2034 2008_003841
2035 2008_003843
2036 2008_003844
2037 2008_003847
2038 2008_003849
2039 2008_003852
2040 2008_003854
2041 2008_003860
2042 2008_003864
2043 2008_003866
2044 2008_003868
2045 2008_003870
2046 2008_003871
2047 2008_003873
2048 2008_003881
2049 2008_003882
2050 2008_003883
2051 2008_003884
2052 2008_003888
2053 2008_003891
2054 2008_003892
2055 2008_003894
2056 2008_003904
2057 2008_003905
2058 2008_003908
2059 2008_003913
2060 2008_003914
2061 2008_003915
2062 2008_003916
2063 2008_003920
2064 2008_003921
2065 2008_003922
2066 2008_003924
2067 2008_003925
2068 2008_003929
2069 2008_003932
2070 2008_003933
2071 2008_003939
2072 2008_003940
2073 2008_003941
2074 2008_003942
2075 2008_003943
2076 2008_003944
2077 2008_003945
2078 2008_003947
2079 2008_003948
2080 2008_003951
2081 2008_003956
2082 2008_003958
2083 2008_003962
2084 2008_003965
2085 2008_003967
2086 2008_003969
2087 2008_003970
2088 2008_003971
2089 2008_003974
2090 2008_003975
2091 2008_003978
2092 2008_003983
2093 2008_003984
2094 2008_003985
2095 2008_003986
2096 2008_003988
2097 2008_003992
2098 2008_003995
2099 2008_003996
2100 2008_003997
2101 2008_003998
2102 2008_004002
2103 2008_004003
2104 2008_004004
2105 2008_004006
2106 2008_004007
2107 2008_004008
2108 2008_004014
2109 2008_004015
2110 2008_004016
2111 2008_004017
2112 2008_004018
2113 2008_004020
2114 2008_004021
2115 2008_004022
2116 2008_004024
2117 2008_004026
2118 2008_004027
2119 2008_004030
2120 2008_004036
2121 2008_004037
2122 2008_004040
2123 2008_004042
2124 2008_004044
2125 2008_004045
2126 2008_004046
2127 2008_004048
2128 2008_004053
2129 2008_004054
2130 2008_004055
2131 2008_004056
2132 2008_004058
2133 2008_004064
2134 2008_004066
2135 2008_004071
2136 2008_004074
2137 2008_004075
2138 2008_004076
2139 2008_004077
2140 2008_004080
2141 2008_004081
2142 2008_004084
2143 2008_004087
2144 2008_004088
2145 2008_004090
2146 2008_004092
2147 2008_004093
2148 2008_004097
2149 2008_004100
2150 2008_004102
2151 2008_004103
2152 2008_004105
2153 2008_004106
2154 2008_004110
2155 2008_004112
2156 2008_004113
2157 2008_004119
2158 2008_004120
2159 2008_004121
2160 2008_004122
2161 2008_004123
2162 2008_004124
2163 2008_004125
2164 2008_004126
2165 2008_004127
2166 2008_004130
2167 2008_004134
2168 2008_004135
2169 2008_004137
2170 2008_004138
2171 2008_004142
2172 2008_004145
2173 2008_004147
2174 2008_004148
2175 2008_004155
2176 2008_004161
2177 2008_004163
2178 2008_004165
2179 2008_004166
2180 2008_004171
2181 2008_004174
2182 2008_004176
2183 2008_004178
2184 2008_004182
2185 2008_004188
2186 2008_004189
2187 2008_004190
2188 2008_004195
2189 2008_004196
2190 2008_004198
2191 2008_004201
2192 2008_004203
2193 2008_004205
2194 2008_004208
2195 2008_004213
2196 2008_004214
2197 2008_004216
2198 2008_004217
2199 2008_004218
2200 2008_004221
2201 2008_004224
2202 2008_004230
2203 2008_004231
2204 2008_004232
2205 2008_004234
2206 2008_004235
2207 2008_004239
2208 2008_004242
2209 2008_004243
2210 2008_004245
2211 2008_004246
2212 2008_004247
2213 2008_004251
2214 2008_004257
2215 2008_004258
2216 2008_004259
2217 2008_004263
2218 2008_004265
2219 2008_004269
2220 2008_004270
2221 2008_004271
2222 2008_004273
2223 2008_004274
2224 2008_004276
2225 2008_004278
2226 2008_004280
2227 2008_004284
2228 2008_004287
2229 2008_004288
2230 2008_004289
2231 2008_004290
2232 2008_004291
2233 2008_004292
2234 2008_004293
2235 2008_004296
2236 2008_004297
2237 2008_004301
2238 2008_004303
2239 2008_004306
2240 2008_004307
2241 2008_004308
2242 2008_004312
2243 2008_004313
2244 2008_004314
2245 2008_004317
2246 2008_004318
2247 2008_004319
2248 2008_004321
2249 2008_004324
2250 2008_004325
2251 2008_004326
2252 2008_004327
2253 2008_004328
2254 2008_004330
2255 2008_004333
2256 2008_004342
2257 2008_004344
2258 2008_004347
2259 2008_004348
2260 2008_004353
2261 2008_004354
2262 2008_004357
2263 2008_004358
2264 2008_004361
2265 2008_004362
2266 2008_004365
2267 2008_004371
2268 2008_004372
2269 2008_004374
2270 2008_004378
2271 2008_004380
2272 2008_004384
2273 2008_004385
2274 2008_004387
2275 2008_004389
2276 2008_004391
2277 2008_004394
2278 2008_004398
2279 2008_004402
2280 2008_004403
2281 2008_004406
2282 2008_004408
2283 2008_004410
2284 2008_004411
2285 2008_004412
2286 2008_004414
2287 2008_004416
2288 2008_004417
2289 2008_004418
2290 2008_004419
2291 2008_004422
2292 2008_004425
2293 2008_004426
2294 2008_004427
2295 2008_004428
2296 2008_004430
2297 2008_004431
2298 2008_004435
2299 2008_004436
2300 2008_004438
2301 2008_004439
2302 2008_004441
2303 2008_004443
2304 2008_004445
2305 2008_004450
2306 2008_004452
2307 2008_004455
2308 2008_004457
2309 2008_004458
2310 2008_004459
2311 2008_004460
2312 2008_004462
2313 2008_004464
2314 2008_004469
2315 2008_004470
2316 2008_004471
2317 2008_004476
2318 2008_004478
2319 2008_004479
2320 2008_004480
2321 2008_004482
2322 2008_004487
2323 2008_004488
2324 2008_004490
2325 2008_004492
2326 2008_004493
2327 2008_004497
2328 2008_004498
2329 2008_004499
2330 2008_004501
2331 2008_004502
2332 2008_004504
2333 2008_004505
2334 2008_004506
2335 2008_004510
2336 2008_004512
2337 2008_004513
2338 2008_004515
2339 2008_004519
2340 2008_004520
2341 2008_004522
2342 2008_004525
2343 2008_004526
2344 2008_004528
2345 2008_004532
2346 2008_004533
2347 2008_004534
2348 2008_004538
2349 2008_004539
2350 2008_004540
2351 2008_004541
2352 2008_004544
2353 2008_004545
2354 2008_004546
2355 2008_004547
2356 2008_004549
2357 2008_004550
2358 2008_004551
2359 2008_004553
2360 2008_004554
2361 2008_004559
2362 2008_004564
2363 2008_004567
2364 2008_004568
2365 2008_004570
2366 2008_004574
2367 2008_004579
2368 2008_004581
2369 2008_004583
2370 2008_004584
2371 2008_004585
2372 2008_004588
2373 2008_004589
2374 2008_004590
2375 2008_004592
2376 2008_004593
2377 2008_004599
2378 2008_004602
2379 2008_004603
2380 2008_004605
2381 2008_004606
2382 2008_004607
2383 2008_004611
2384 2008_004613
2385 2008_004614
2386 2008_004615
2387 2008_004616
2388 2008_004617
2389 2008_004619
2390 2008_004620
2391 2008_004629
2392 2008_004630
2393 2008_004631
2394 2008_004632
2395 2008_004633
2396 2008_004634
2397 2008_004635
2398 2008_004636
2399 2008_004640
2400 2008_004646
2401 2008_004647
2402 2008_004648
2403 2008_004649
2404 2008_004653
2405 2008_004661
2406 2008_004662
2407 2008_004663
2408 2008_004665
2409 2008_004666
2410 2008_004667
2411 2008_004668
2412 2008_004670
2413 2008_004671
2414 2008_004672
2415 2008_004677
2416 2008_004678
2417 2008_004679
2418 2008_004684
2419 2008_004688
2420 2008_004689
2421 2008_004690
2422 2008_004692
2423 2008_004695
2424 2008_004696
2425 2008_004697
2426 2008_004702
2427 2008_004703
2428 2008_004706
2429 2008_004707
2430 2008_004711
2431 2008_004713
2432 2008_004718
2433 2008_004719
2434 2008_004720
2435 2008_004722
2436 2008_004725
2437 2008_004726
2438 2008_004729
2439 2008_004730
2440 2008_004732
2441 2008_004736
2442 2008_004739
2443 2008_004740
2444 2008_004742
2445 2008_004745
2446 2008_004749
2447 2008_004750
2448 2008_004752
2449 2008_004756
2450 2008_004760
2451 2008_004763
2452 2008_004764
2453 2008_004766
2454 2008_004767
2455 2008_004768
2456 2008_004770
2457 2008_004771
2458 2008_004774
2459 2008_004776
2460 2008_004777
2461 2008_004778
2462 2008_004781
2463 2008_004783
2464 2008_004784
2465 2008_004786
2466 2008_004794
2467 2008_004795
2468 2008_004797
2469 2008_004802
2470 2008_004804
2471 2008_004805
2472 2008_004807
2473 2008_004808
2474 2008_004812
2475 2008_004814
2476 2008_004819
2477 2008_004821
2478 2008_004822
2479 2008_004825
2480 2008_004827
2481 2008_004832
2482 2008_004833
2483 2008_004834
2484 2008_004837
2485 2008_004838
2486 2008_004841
2487 2008_004844
2488 2008_004845
2489 2008_004847
2490 2008_004849
2491 2008_004850
2492 2008_004851
2493 2008_004852
2494 2008_004856
2495 2008_004858
2496 2008_004862
2497 2008_004866
2498 2008_004868
2499 2008_004869
2500 2008_004872
2501 2008_004873
2502 2008_004874
2503 2008_004875
2504 2008_004876
2505 2008_004881
2506 2008_004885
2507 2008_004887
2508 2008_004892
2509 2008_004893
2510 2008_004894
2511 2008_004896
2512 2008_004898
2513 2008_004899
2514 2008_004900
2515 2008_004904
2516 2008_004907
2517 2008_004908
2518 2008_004911
2519 2008_004914
2520 2008_004917
2521 2008_004920
2522 2008_004921
2523 2008_004923
2524 2008_004926
2525 2008_004930
2526 2008_004931
2527 2008_004933
2528 2008_004934
2529 2008_004935
2530 2008_004937
2531 2008_004938
2532 2008_004940
2533 2008_004942
2534 2008_004945
2535 2008_004946
2536 2008_004948
2537 2008_004950
2538 2008_004955
2539 2008_004961
2540 2008_004964
2541 2008_004966
2542 2008_004967
2543 2008_004968
2544 2008_004969
2545 2008_004970
2546 2008_004973
2547 2008_004974
2548 2008_004975
2549 2008_004976
2550 2008_004977
2551 2008_004979
2552 2008_004981
2553 2008_004982
2554 2008_004983
2555 2008_004984
2556 2008_004985
2557 2008_004990
2558 2008_004991
2559 2008_004998
2560 2008_005000
2561 2008_005001
2562 2008_005003
2563 2008_005006
2564 2008_005008
2565 2008_005010
2566 2008_005013
2567 2008_005015
2568 2008_005016
2569 2008_005023
2570 2008_005032
2571 2008_005033
2572 2008_005035
2573 2008_005036
2574 2008_005037
2575 2008_005040
2576 2008_005042
2577 2008_005043
2578 2008_005045
2579 2008_005046
2580 2008_005051
2581 2008_005054
2582 2008_005055
2583 2008_005057
2584 2008_005061
2585 2008_005063
2586 2008_005064
2587 2008_005065
2588 2008_005066
2589 2008_005068
2590 2008_005070
2591 2008_005071
2592 2008_005072
2593 2008_005074
2594 2008_005078
2595 2008_005080
2596 2008_005081
2597 2008_005082
2598 2008_005084
2599 2008_005085
2600 2008_005088
2601 2008_005090
2602 2008_005092
2603 2008_005094
2604 2008_005096
2605 2008_005098
2606 2008_005101
2607 2008_005107
2608 2008_005108
2609 2008_005109
2610 2008_005110
2611 2008_005111
2612 2008_005114
2613 2008_005115
2614 2008_005117
2615 2008_005123
2616 2008_005127
2617 2008_005132
2618 2008_005133
2619 2008_005134
2620 2008_005136
2621 2008_005137
2622 2008_005139
2623 2008_005140
2624 2008_005146
2625 2008_005147
2626 2008_005150
2627 2008_005151
2628 2008_005156
2629 2008_005159
2630 2008_005160
2631 2008_005166
2632 2008_005167
2633 2008_005168
2634 2008_005171
2635 2008_005174
2636 2008_005178
2637 2008_005181
2638 2008_005182
2639 2008_005185
2640 2008_005186
2641 2008_005190
2642 2008_005191
2643 2008_005193
2644 2008_005194
2645 2008_005196
2646 2008_005201
2647 2008_005204
2648 2008_005205
2649 2008_005208
2650 2008_005209
2651 2008_005213
2652 2008_005214
2653 2008_005215
2654 2008_005216
2655 2008_005218
2656 2008_005220
2657 2008_005221
2658 2008_005231
2659 2008_005233
2660 2008_005234
2661 2008_005235
2662 2008_005236
2663 2008_005240
2664 2008_005243
2665 2008_005244
2666 2008_005247
2667 2008_005248
2668 2008_005250
2669 2008_005251
2670 2008_005252
2671 2008_005253
2672 2008_005255
2673 2008_005257
2674 2008_005260
2675 2008_005261
2676 2008_005266
2677 2008_005269
2678 2008_005270
2679 2008_005271
2680 2008_005272
2681 2008_005276
2682 2008_005277
2683 2008_005279
2684 2008_005281
2685 2008_005282
2686 2008_005283
2687 2008_005288
2688 2008_005294
2689 2008_005295
2690 2008_005296
2691 2008_005297
2692 2008_005300
2693 2008_005303
2694 2008_005304
2695 2008_005309
2696 2008_005310
2697 2008_005313
2698 2008_005315
2699 2008_005316
2700 2008_005319
2701 2008_005321
2702 2008_005323
2703 2008_005324
2704 2008_005325
2705 2008_005327
2706 2008_005329
2707 2008_005331
2708 2008_005333
2709 2008_005335
2710 2008_005336
2711 2008_005337
2712 2008_005342
2713 2008_005345
2714 2008_005346
2715 2008_005347
2716 2008_005348
2717 2008_005349
2718 2008_005350
2719 2008_005354
2720 2008_005356
2721 2008_005357
2722 2008_005359
2723 2008_005360
2724 2008_005361
2725 2008_005362
2726 2008_005363
2727 2008_005365
2728 2008_005367
2729 2008_005369
2730 2008_005373
2731 2008_005374
2732 2008_005375
2733 2008_005376
2734 2008_005378
2735 2008_005379
2736 2008_005380
2737 2008_005382
2738 2008_005386
2739 2008_005393
2740 2008_005395
2741 2008_005396
2742 2008_005400
2743 2008_005404
2744 2008_005405
2745 2008_005406
2746 2008_005408
2747 2008_005412
2748 2008_005414
2749 2008_005415
2750 2008_005417
2751 2008_005421
2752 2008_005423
2753 2008_005427
2754 2008_005429
2755 2008_005431
2756 2008_005436
2757 2008_005443
2758 2008_005444
2759 2008_005446
2760 2008_005447
2761 2008_005449
2762 2008_005451
2763 2008_005455
2764 2008_005456
2765 2008_005460
2766 2008_005463
2767 2008_005465
2768 2008_005467
2769 2008_005469
2770 2008_005472
2771 2008_005473
2772 2008_005477
2773 2008_005480
2774 2008_005484
2775 2008_005485
2776 2008_005490
2777 2008_005491
2778 2008_005494
2779 2008_005496
2780 2008_005498
2781 2008_005500
2782 2008_005501
2783 2008_005502
2784 2008_005504
2785 2008_005505
2786 2008_005507
2787 2008_005510
2788 2008_005511
2789 2008_005512
2790 2008_005514
2791 2008_005517
2792 2008_005519
2793 2008_005521
2794 2008_005522
2795 2008_005523
2796 2008_005526
2797 2008_005527
2798 2008_005530
2799 2008_005531
2800 2008_005534
2801 2008_005536
2802 2008_005538
2803 2008_005541
2804 2008_005548
2805 2008_005549
2806 2008_005550
2807 2008_005552
2808 2008_005553
2809 2008_005558
2810 2008_005560
2811 2008_005561
2812 2008_005563
2813 2008_005564
2814 2008_005566
2815 2008_005567
2816 2008_005569
2817 2008_005570
2818 2008_005572
2819 2008_005573
2820 2008_005574
2821 2008_005582
2822 2008_005584
2823 2008_005588
2824 2008_005589
2825 2008_005591
2826 2008_005593
2827 2008_005599
2828 2008_005600
2829 2008_005601
2830 2008_005603
2831 2008_005608
2832 2008_005609
2833 2008_005610
2834 2008_005611
2835 2008_005612
2836 2008_005614
2837 2008_005616
2838 2008_005618
2839 2008_005623
2840 2008_005625
2841 2008_005626
2842 2008_005627
2843 2008_005631
2844 2008_005634
2845 2008_005635
2846 2008_005636
2847 2008_005638
2848 2008_005639
2849 2008_005641
2850 2008_005643
2851 2008_005646
2852 2008_005649
2853 2008_005650
2854 2008_005652
2855 2008_005653
2856 2008_005656
2857 2008_005657
2858 2008_005660
2859 2008_005663
2860 2008_005664
2861 2008_005668
2862 2008_005673
2863 2008_005675
2864 2008_005677
2865 2008_005678
2866 2008_005679
2867 2008_005681
2868 2008_005682
2869 2008_005683
2870 2008_005685
2871 2008_005686
2872 2008_005687
2873 2008_005695
2874 2008_005698
2875 2008_005699
2876 2008_005701
2877 2008_005702
2878 2008_005703
2879 2008_005705
2880 2008_005706
2881 2008_005707
2882 2008_005713
2883 2008_005714
2884 2008_005716
2885 2008_005719
2886 2008_005720
2887 2008_005721
2888 2008_005724
2889 2008_005726
2890 2008_005728
2891 2008_005732
2892 2008_005734
2893 2008_005735
2894 2008_005736
2895 2008_005737
2896 2008_005739
2897 2008_005742
2898 2008_005747
2899 2008_005748
2900 2008_005750
2901 2008_005752
2902 2008_005757
2903 2008_005758
2904 2008_005761
2905 2008_005763
2906 2008_005764
2907 2008_005767
2908 2008_005768
2909 2008_005770
2910 2008_005774
2911 2008_005777
2912 2008_005779
2913 2008_005780
2914 2008_005788
2915 2008_005790
2916 2008_005791
2917 2008_005792
2918 2008_005794
2919 2008_005796
2920 2008_005798
2921 2008_005800
2922 2008_005801
2923 2008_005803
2924 2008_005805
2925 2008_005808
2926 2008_005810
2927 2008_005816
2928 2008_005817
2929 2008_005818
2930 2008_005821
2931 2008_005822
2932 2008_005823
2933 2008_005825
2934 2008_005831
2935 2008_005832
2936 2008_005834
2937 2008_005838
2938 2008_005839
2939 2008_005843
2940 2008_005845
2941 2008_005846
2942 2008_005847
2943 2008_005848
2944 2008_005850
2945 2008_005853
2946 2008_005855
2947 2008_005856
2948 2008_005857
2949 2008_005860
2950 2008_005863
2951 2008_005865
2952 2008_005867
2953 2008_005869
2954 2008_005871
2955 2008_005873
2956 2008_005874
2957 2008_005875
2958 2008_005877
2959 2008_005878
2960 2008_005881
2961 2008_005882
2962 2008_005883
2963 2008_005884
2964 2008_005889
2965 2008_005890
2966 2008_005891
2967 2008_005893
2968 2008_005897
2969 2008_005898
2970 2008_005902
2971 2008_005903
2972 2008_005907
2973 2008_005914
2974 2008_005916
2975 2008_005918
2976 2008_005921
2977 2008_005923
2978 2008_005924
2979 2008_005926
2980 2008_005928
2981 2008_005929
2982 2008_005933
2983 2008_005934
2984 2008_005935
2985 2008_005936
2986 2008_005937
2987 2008_005938
2988 2008_005939
2989 2008_005943
2990 2008_005945
2991 2008_005953
2992 2008_005954
2993 2008_005956
2994 2008_005957
2995 2008_005959
2996 2008_005960
2997 2008_005962
2998 2008_005964
2999 2008_005967
3000 2008_005968
3001 2008_005970
3002 2008_005972
3003 2008_005975
3004 2008_005976
3005 2008_005977
3006 2008_005978
3007 2008_005979
3008 2008_005980
3009 2008_005982
3010 2008_005984
3011 2008_005987
3012 2008_005989
3013 2008_005991
3014 2008_005997
3015 2008_006000
3016 2008_006002
3017 2008_006004
3018 2008_006007
3019 2008_006010
3020 2008_006014
3021 2008_006017
3022 2008_006020
3023 2008_006021
3024 2008_006024
3025 2008_006027
3026 2008_006028
3027 2008_006031
3028 2008_006032
3029 2008_006037
3030 2008_006038
3031 2008_006039
3032 2008_006041
3033 2008_006042
3034 2008_006045
3035 2008_006046
3036 2008_006047
3037 2008_006049
3038 2008_006050
3039 2008_006052
3040 2008_006058
3041 2008_006059
3042 2008_006062
3043 2008_006064
3044 2008_006065
3045 2008_006067
3046 2008_006068
3047 2008_006070
3048 2008_006071
3049 2008_006072
3050 2008_006074
3051 2008_006076
3052 2008_006078
3053 2008_006081
3054 2008_006082
3055 2008_006085
3056 2008_006087
3057 2008_006088
3058 2008_006090
3059 2008_006092
3060 2008_006094
3061 2008_006096
3062 2008_006099
3063 2008_006100
3064 2008_006102
3065 2008_006104
3066 2008_006109
3067 2008_006111
3068 2008_006112
3069 2008_006113
3070 2008_006117
3071 2008_006119
3072 2008_006120
3073 2008_006121
3074 2008_006124
3075 2008_006128
3076 2008_006129
3077 2008_006133
3078 2008_006135
3079 2008_006136
3080 2008_006140
3081 2008_006144
3082 2008_006145
3083 2008_006147
3084 2008_006148
3085 2008_006151
3086 2008_006152
3087 2008_006154
3088 2008_006158
3089 2008_006163
3090 2008_006164
3091 2008_006166
3092 2008_006169
3093 2008_006170
3094 2008_006175
3095 2008_006178
3096 2008_006179
3097 2008_006181
3098 2008_006182
3099 2008_006185
3100 2008_006186
3101 2008_006188
3102 2008_006190
3103 2008_006192
3104 2008_006194
3105 2008_006195
3106 2008_006200
3107 2008_006203
3108 2008_006205
3109 2008_006207
3110 2008_006210
3111 2008_006211
3112 2008_006213
3113 2008_006215
3114 2008_006218
3115 2008_006220
3116 2008_006221
3117 2008_006222
3118 2008_006224
3119 2008_006225
3120 2008_006227
3121 2008_006232
3122 2008_006233
3123 2008_006234
3124 2008_006235
3125 2008_006239
3126 2008_006240
3127 2008_006242
3128 2008_006244
3129 2008_006249
3130 2008_006250
3131 2008_006253
3132 2008_006256
3133 2008_006257
3134 2008_006258
3135 2008_006262
3136 2008_006265
3137 2008_006267
3138 2008_006269
3139 2008_006271
3140 2008_006272
3141 2008_006273
3142 2008_006276
3143 2008_006280
3144 2008_006281
3145 2008_006282
3146 2008_006285
3147 2008_006288
3148 2008_006289
3149 2008_006290
3150 2008_006294
3151 2008_006295
3152 2008_006298
3153 2008_006300
3154 2008_006303
3155 2008_006307
3156 2008_006310
3157 2008_006311
3158 2008_006315
3159 2008_006316
3160 2008_006317
3161 2008_006320
3162 2008_006323
3163 2008_006329
3164 2008_006330
3165 2008_006331
3166 2008_006335
3167 2008_006336
3168 2008_006337
3169 2008_006339
3170 2008_006345
3171 2008_006347
3172 2008_006349
3173 2008_006350
3174 2008_006351
3175 2008_006353
3176 2008_006355
3177 2008_006356
3178 2008_006359
3179 2008_006361
3180 2008_006362
3181 2008_006364
3182 2008_006365
3183 2008_006366
3184 2008_006368
3185 2008_006369
3186 2008_006370
3187 2008_006373
3188 2008_006376
3189 2008_006377
3190 2008_006382
3191 2008_006384
3192 2008_006386
3193 2008_006387
3194 2008_006389
3195 2008_006390
3196 2008_006392
3197 2008_006394
3198 2008_006397
3199 2008_006400
3200 2008_006401
3201 2008_006403
3202 2008_006404
3203 2008_006407
3204 2008_006409
3205 2008_006410
3206 2008_006416
3207 2008_006417
3208 2008_006419
3209 2008_006421
3210 2008_006424
3211 2008_006425
3212 2008_006427
3213 2008_006429
3214 2008_006430
3215 2008_006432
3216 2008_006433
3217 2008_006434
3218 2008_006436
3219 2008_006438
3220 2008_006441
3221 2008_006447
3222 2008_006448
3223 2008_006449
3224 2008_006452
3225 2008_006458
3226 2008_006461
3227 2008_006462
3228 2008_006463
3229 2008_006467
3230 2008_006470
3231 2008_006474
3232 2008_006475
3233 2008_006477
3234 2008_006481
3235 2008_006482
3236 2008_006483
3237 2008_006487
3238 2008_006488
3239 2008_006489
3240 2008_006490
3241 2008_006491
3242 2008_006496
3243 2008_006497
3244 2008_006500
3245 2008_006502
3246 2008_006503
3247 2008_006509
3248 2008_006511
3249 2008_006512
3250 2008_006517
3251 2008_006519
3252 2008_006520
3253 2008_006522
3254 2008_006524
3255 2008_006530
3256 2008_006534
3257 2008_006538
3258 2008_006543
3259 2008_006546
3260 2008_006547
3261 2008_006548
3262 2008_006549
3263 2008_006558
3264 2008_006561
3265 2008_006562
3266 2008_006564
3267 2008_006566
3268 2008_006567
3269 2008_006568
3270 2008_006570
3271 2008_006576
3272 2008_006578
3273 2008_006579
3274 2008_006585
3275 2008_006586
3276 2008_006587
3277 2008_006588
3278 2008_006591
3279 2008_006598
3280 2008_006599
3281 2008_006600
3282 2008_006602
3283 2008_006604
3284 2008_006605
3285 2008_006606
3286 2008_006609
3287 2008_006610
3288 2008_006611
3289 2008_006613
3290 2008_006614
3291 2008_006616
3292 2008_006617
3293 2008_006619
3294 2008_006621
3295 2008_006623
3296 2008_006624
3297 2008_006625
3298 2008_006626
3299 2008_006629
3300 2008_006631
3301 2008_006634
3302 2008_006635
3303 2008_006637
3304 2008_006638
3305 2008_006641
3306 2008_006642
3307 2008_006645
3308 2008_006646
3309 2008_006649
3310 2008_006650
3311 2008_006654
3312 2008_006655
3313 2008_006656
3314 2008_006657
3315 2008_006660
3316 2008_006662
3317 2008_006663
3318 2008_006665
3319 2008_006667
3320 2008_006668
3321 2008_006671
3322 2008_006677
3323 2008_006682
3324 2008_006684
3325 2008_006686
3326 2008_006690
3327 2008_006691
3328 2008_006692
3329 2008_006694
3330 2008_006696
3331 2008_006701
3332 2008_006705
3333 2008_006708
3334 2008_006710
3335 2008_006712
3336 2008_006714
3337 2008_006715
3338 2008_006716
3339 2008_006717
3340 2008_006718
3341 2008_006719
3342 2008_006724
3343 2008_006728
3344 2008_006730
3345 2008_006731
3346 2008_006732
3347 2008_006733
3348 2008_006737
3349 2008_006743
3350 2008_006746
3351 2008_006747
3352 2008_006748
3353 2008_006750
3354 2008_006751
3355 2008_006753
3356 2008_006758
3357 2008_006761
3358 2008_006762
3359 2008_006764
3360 2008_006765
3361 2008_006767
3362 2008_006773
3363 2008_006774
3364 2008_006776
3365 2008_006777
3366 2008_006778
3367 2008_006779
3368 2008_006781
3369 2008_006785
3370 2008_006792
3371 2008_006793
3372 2008_006796
3373 2008_006797
3374 2008_006798
3375 2008_006800
3376 2008_006802
3377 2008_006807
3378 2008_006808
3379 2008_006810
3380 2008_006811
3381 2008_006813
3382 2008_006815
3383 2008_006816
3384 2008_006817
3385 2008_006818
3386 2008_006819
3387 2008_006820
3388 2008_006824
3389 2008_006825
3390 2008_006827
3391 2008_006828
3392 2008_006831
3393 2008_006832
3394 2008_006833
3395 2008_006834
3396 2008_006837
3397 2008_006839
3398 2008_006841
3399 2008_006843
3400 2008_006844
3401 2008_006847
3402 2008_006849
3403 2008_006855
3404 2008_006857
3405 2008_006863
3406 2008_006864
3407 2008_006865
3408 2008_006868
3409 2008_006870
3410 2008_006872
3411 2008_006873
3412 2008_006877
3413 2008_006879
3414 2008_006880
3415 2008_006881
3416 2008_006882
3417 2008_006885
3418 2008_006889
3419 2008_006890
3420 2008_006892
3421 2008_006896
3422 2008_006898
3423 2008_006900
3424 2008_006902
3425 2008_006903
3426 2008_006904
3427 2008_006907
3428 2008_006908
3429 2008_006909
3430 2008_006910
3431 2008_006912
3432 2008_006919
3433 2008_006920
3434 2008_006921
3435 2008_006923
3436 2008_006924
3437 2008_006925
3438 2008_006926
3439 2008_006933
3440 2008_006936
3441 2008_006939
3442 2008_006941
3443 2008_006944
3444 2008_006946
3445 2008_006948
3446 2008_006949
3447 2008_006950
3448 2008_006951
3449 2008_006952
3450 2008_006953
3451 2008_006954
3452 2008_006956
3453 2008_006959
3454 2008_006960
3455 2008_006961
3456 2008_006962
3457 2008_006965
3458 2008_006967
3459 2008_006968
3460 2008_006969
3461 2008_006973
3462 2008_006979
3463 2008_006980
3464 2008_006987
3465 2008_006989
3466 2008_006991
3467 2008_006992
3468 2008_006997
3469 2008_006998
3470 2008_006999
3471 2008_007003
3472 2008_007004
3473 2008_007006
3474 2008_007009
3475 2008_007010
3476 2008_007011
3477 2008_007012
3478 2008_007014
3479 2008_007019
3480 2008_007021
3481 2008_007022
3482 2008_007026
3483 2008_007028
3484 2008_007030
3485 2008_007032
3486 2008_007034
3487 2008_007038
3488 2008_007039
3489 2008_007042
3490 2008_007043
3491 2008_007045
3492 2008_007050
3493 2008_007054
3494 2008_007056
3495 2008_007057
3496 2008_007058
3497 2008_007059
3498 2008_007060
3499 2008_007061
3500 2008_007064
3501 2008_007067
3502 2008_007069
3503 2008_007070
3504 2008_007073
3505 2008_007075
3506 2008_007076
3507 2008_007081
3508 2008_007082
3509 2008_007084
3510 2008_007085
3511 2008_007086
3512 2008_007090
3513 2008_007091
3514 2008_007095
3515 2008_007097
3516 2008_007098
3517 2008_007101
3518 2008_007103
3519 2008_007105
3520 2008_007106
3521 2008_007108
3522 2008_007112
3523 2008_007114
3524 2008_007115
3525 2008_007118
3526 2008_007119
3527 2008_007124
3528 2008_007129
3529 2008_007130
3530 2008_007131
3531 2008_007133
3532 2008_007134
3533 2008_007138
3534 2008_007142
3535 2008_007145
3536 2008_007146
3537 2008_007147
3538 2008_007151
3539 2008_007156
3540 2008_007161
3541 2008_007163
3542 2008_007164
3543 2008_007165
3544 2008_007166
3545 2008_007167
3546 2008_007168
3547 2008_007169
3548 2008_007171
3549 2008_007176
3550 2008_007179
3551 2008_007181
3552 2008_007182
3553 2008_007184
3554 2008_007185
3555 2008_007187
3556 2008_007188
3557 2008_007189
3558 2008_007190
3559 2008_007195
3560 2008_007196
3561 2008_007197
3562 2008_007201
3563 2008_007205
3564 2008_007207
3565 2008_007208
3566 2008_007211
3567 2008_007214
3568 2008_007216
3569 2008_007217
3570 2008_007218
3571 2008_007221
3572 2008_007222
3573 2008_007223
3574 2008_007225
3575 2008_007226
3576 2008_007227
3577 2008_007229
3578 2008_007231
3579 2008_007236
3580 2008_007237
3581 2008_007239
3582 2008_007241
3583 2008_007242
3584 2008_007245
3585 2008_007246
3586 2008_007247
3587 2008_007250
3588 2008_007252
3589 2008_007254
3590 2008_007256
3591 2008_007260
3592 2008_007261
3593 2008_007264
3594 2008_007265
3595 2008_007266
3596 2008_007274
3597 2008_007277
3598 2008_007279
3599 2008_007280
3600 2008_007281
3601 2008_007282
3602 2008_007285
3603 2008_007286
3604 2008_007287
3605 2008_007289
3606 2008_007291
3607 2008_007293
3608 2008_007295
3609 2008_007298
3610 2008_007305
3611 2008_007307
3612 2008_007311
3613 2008_007312
3614 2008_007313
3615 2008_007314
3616 2008_007317
3617 2008_007319
3618 2008_007320
3619 2008_007321
3620 2008_007323
3621 2008_007324
3622 2008_007325
3623 2008_007327
3624 2008_007332
3625 2008_007334
3626 2008_007335
3627 2008_007336
3628 2008_007339
3629 2008_007344
3630 2008_007346
3631 2008_007348
3632 2008_007352
3633 2008_007353
3634 2008_007355
3635 2008_007356
3636 2008_007357
3637 2008_007358
3638 2008_007361
3639 2008_007363
3640 2008_007364
3641 2008_007374
3642 2008_007375
3643 2008_007382
3644 2008_007383
3645 2008_007384
3646 2008_007388
3647 2008_007389
3648 2008_007390
3649 2008_007393
3650 2008_007394
3651 2008_007397
3652 2008_007398
3653 2008_007403
3654 2008_007404
3655 2008_007409
3656 2008_007410
3657 2008_007415
3658 2008_007417
3659 2008_007421
3660 2008_007423
3661 2008_007424
3662 2008_007425
3663 2008_007428
3664 2008_007430
3665 2008_007431
3666 2008_007432
3667 2008_007433
3668 2008_007434
3669 2008_007435
3670 2008_007438
3671 2008_007441
3672 2008_007442
3673 2008_007443
3674 2008_007444
3675 2008_007446
3676 2008_007448
3677 2008_007452
3678 2008_007455
3679 2008_007456
3680 2008_007458
3681 2008_007459
3682 2008_007461
3683 2008_007465
3684 2008_007466
3685 2008_007469
3686 2008_007470
3687 2008_007471
3688 2008_007472
3689 2008_007473
3690 2008_007476
3691 2008_007477
3692 2008_007478
3693 2008_007480
3694 2008_007485
3695 2008_007486
3696 2008_007488
3697 2008_007491
3698 2008_007494
3699 2008_007496
3700 2008_007500
3701 2008_007501
3702 2008_007504
3703 2008_007509
3704 2008_007510
3705 2008_007511
3706 2008_007514
3707 2008_007515
3708 2008_007519
3709 2008_007521
3710 2008_007524
3711 2008_007525
3712 2008_007528
3713 2008_007529
3714 2008_007531
3715 2008_007533
3716 2008_007534
3717 2008_007536
3718 2008_007537
3719 2008_007538
3720 2008_007544
3721 2008_007546
3722 2008_007556
3723 2008_007558
3724 2008_007559
3725 2008_007561
3726 2008_007565
3727 2008_007567
3728 2008_007573
3729 2008_007574
3730 2008_007576
3731 2008_007579
3732 2008_007581
3733 2008_007583
3734 2008_007584
3735 2008_007585
3736 2008_007586
3737 2008_007587
3738 2008_007588
3739 2008_007589
3740 2008_007591
3741 2008_007593
3742 2008_007594
3743 2008_007595
3744 2008_007597
3745 2008_007599
3746 2008_007604
3747 2008_007608
3748 2008_007610
3749 2008_007611
3750 2008_007612
3751 2008_007613
3752 2008_007617
3753 2008_007618
3754 2008_007621
3755 2008_007623
3756 2008_007625
3757 2008_007629
3758 2008_007630
3759 2008_007632
3760 2008_007635
3761 2008_007640
3762 2008_007641
3763 2008_007643
3764 2008_007646
3765 2008_007648
3766 2008_007649
3767 2008_007653
3768 2008_007656
3769 2008_007660
3770 2008_007661
3771 2008_007662
3772 2008_007664
3773 2008_007665
3774 2008_007666
3775 2008_007668
3776 2008_007669
3777 2008_007673
3778 2008_007676
3779 2008_007682
3780 2008_007683
3781 2008_007685
3782 2008_007688
3783 2008_007690
3784 2008_007691
3785 2008_007692
3786 2008_007693
3787 2008_007694
3788 2008_007696
3789 2008_007697
3790 2008_007698
3791 2008_007701
3792 2008_007702
3793 2008_007704
3794 2008_007706
3795 2008_007709
3796 2008_007710
3797 2008_007714
3798 2008_007716
3799 2008_007717
3800 2008_007719
3801 2008_007724
3802 2008_007726
3803 2008_007729
3804 2008_007730
3805 2008_007733
3806 2008_007735
3807 2008_007736
3808 2008_007739
3809 2008_007741
3810 2008_007742
3811 2008_007745
3812 2008_007746
3813 2008_007748
3814 2008_007749
3815 2008_007750
3816 2008_007752
3817 2008_007755
3818 2008_007757
3819 2008_007758
3820 2008_007759
3821 2008_007760
3822 2008_007761
3823 2008_007764
3824 2008_007766
3825 2008_007768
3826 2008_007770
3827 2008_007777
3828 2008_007779
3829 2008_007780
3830 2008_007781
3831 2008_007786
3832 2008_007787
3833 2008_007788
3834 2008_007789
3835 2008_007791
3836 2008_007793
3837 2008_007794
3838 2008_007798
3839 2008_007805
3840 2008_007806
3841 2008_007812
3842 2008_007816
3843 2008_007817
3844 2008_007819
3845 2008_007823
3846 2008_007825
3847 2008_007827
3848 2008_007829
3849 2008_007831
3850 2008_007833
3851 2008_007835
3852 2008_007837
3853 2008_007839
3854 2008_007840
3855 2008_007841
3856 2008_007842
3857 2008_007843
3858 2008_007848
3859 2008_007850
3860 2008_007852
3861 2008_007853
3862 2008_007854
3863 2008_007855
3864 2008_007858
3865 2008_007861
3866 2008_007864
3867 2008_007869
3868 2008_007870
3869 2008_007871
3870 2008_007872
3871 2008_007873
3872 2008_007875
3873 2008_007877
3874 2008_007879
3875 2008_007882
3876 2008_007883
3877 2008_007884
3878 2008_007887
3879 2008_007888
3880 2008_007890
3881 2008_007891
3882 2008_007893
3883 2008_007895
3884 2008_007897
3885 2008_007902
3886 2008_007904
3887 2008_007907
3888 2008_007909
3889 2008_007912
3890 2008_007913
3891 2008_007914
3892 2008_007915
3893 2008_007916
3894 2008_007917
3895 2008_007918
3896 2008_007922
3897 2008_007923
3898 2008_007928
3899 2008_007931
3900 2008_007932
3901 2008_007933
3902 2008_007935
3903 2008_007936
3904 2008_007937
3905 2008_007938
3906 2008_007940
3907 2008_007941
3908 2008_007942
3909 2008_007947
3910 2008_007948
3911 2008_007949
3912 2008_007950
3913 2008_007953
3914 2008_007954
3915 2008_007955
3916 2008_007962
3917 2008_007964
3918 2008_007966
3919 2008_007969
3920 2008_007970
3921 2008_007973
3922 2008_007975
3923 2008_007977
3924 2008_007981
3925 2008_007985
3926 2008_007986
3927 2008_007987
3928 2008_007988
3929 2008_007989
3930 2008_007990
3931 2008_007993
3932 2008_007997
3933 2008_007998
3934 2008_007999
3935 2008_008001
3936 2008_008002
3937 2008_008004
3938 2008_008007
3939 2008_008011
3940 2008_008012
3941 2008_008018
3942 2008_008020
3943 2008_008021
3944 2008_008022
3945 2008_008024
3946 2008_008025
3947 2008_008028
3948 2008_008029
3949 2008_008031
3950 2008_008034
3951 2008_008037
3952 2008_008040
3953 2008_008043
3954 2008_008044
3955 2008_008048
3956 2008_008052
3957 2008_008055
3958 2008_008057
3959 2008_008058
3960 2008_008064
3961 2008_008066
3962 2008_008069
3963 2008_008070
3964 2008_008072
3965 2008_008073
3966 2008_008074
3967 2008_008075
3968 2008_008080
3969 2008_008083
3970 2008_008084
3971 2008_008086
3972 2008_008091
3973 2008_008093
3974 2008_008095
3975 2008_008096
3976 2008_008097
3977 2008_008098
3978 2008_008105
3979 2008_008106
3980 2008_008109
3981 2008_008112
3982 2008_008113
3983 2008_008115
3984 2008_008116
3985 2008_008120
3986 2008_008121
3987 2008_008122
3988 2008_008123
3989 2008_008125
3990 2008_008130
3991 2008_008132
3992 2008_008134
3993 2008_008141
3994 2008_008145
3995 2008_008146
3996 2008_008147
3997 2008_008148
3998 2008_008150
3999 2008_008152
4000 2008_008154
4001 2008_008155
4002 2008_008162
4003 2008_008166
4004 2008_008169
4005 2008_008170
4006 2008_008175
4007 2008_008176
4008 2008_008177
4009 2008_008179
4010 2008_008180
4011 2008_008184
4012 2008_008185
4013 2008_008190
4014 2008_008191
4015 2008_008192
4016 2008_008193
4017 2008_008194
4018 2008_008197
4019 2008_008199
4020 2008_008200
4021 2008_008203
4022 2008_008206
4023 2008_008208
4024 2008_008210
4025 2008_008211
4026 2008_008212
4027 2008_008215
4028 2008_008217
4029 2008_008218
4030 2008_008220
4031 2008_008223
4032 2008_008224
4033 2008_008227
4034 2008_008229
4035 2008_008231
4036 2008_008232
4037 2008_008233
4038 2008_008234
4039 2008_008235
4040 2008_008237
4041 2008_008241
4042 2008_008242
4043 2008_008246
4044 2008_008254
4045 2008_008257
4046 2008_008262
4047 2008_008263
4048 2008_008266
4049 2008_008269
4050 2008_008271
4051 2008_008272
4052 2008_008274
4053 2008_008275
4054 2008_008276
4055 2008_008279
4056 2008_008281
4057 2008_008284
4058 2008_008287
4059 2008_008288
4060 2008_008292
4061 2008_008294
4062 2008_008297
4063 2008_008300
4064 2008_008302
4065 2008_008307
4066 2008_008309
4067 2008_008310
4068 2008_008313
4069 2008_008314
4070 2008_008315
4071 2008_008318
4072 2008_008319
4073 2008_008320
4074 2008_008321
4075 2008_008322
4076 2008_008323
4077 2008_008324
4078 2008_008325
4079 2008_008330
4080 2008_008331
4081 2008_008336
4082 2008_008337
4083 2008_008338
4084 2008_008341
4085 2008_008342
4086 2008_008343
4087 2008_008344
4088 2008_008345
4089 2008_008346
4090 2008_008347
4091 2008_008354
4092 2008_008356
4093 2008_008357
4094 2008_008359
4095 2008_008363
4096 2008_008364
4097 2008_008365
4098 2008_008366
4099 2008_008368
4100 2008_008370
4101 2008_008373
4102 2008_008376
4103 2008_008377
4104 2008_008379
4105 2008_008380
4106 2008_008382
4107 2008_008384
4108 2008_008387
4109 2008_008388
4110 2008_008395
4111 2008_008402
4112 2008_008403
4113 2008_008404
4114 2008_008406
4115 2008_008410
4116 2008_008411
4117 2008_008416
4118 2008_008423
4119 2008_008428
4120 2008_008429
4121 2008_008431
4122 2008_008432
4123 2008_008433
4124 2008_008435
4125 2008_008437
4126 2008_008439
4127 2008_008440
4128 2008_008443
4129 2008_008444
4130 2008_008446
4131 2008_008447
4132 2008_008450
4133 2008_008453
4134 2008_008455
4135 2008_008461
4136 2008_008462
4137 2008_008464
4138 2008_008466
4139 2008_008467
4140 2008_008470
4141 2008_008474
4142 2008_008476
4143 2008_008479
4144 2008_008480
4145 2008_008482
4146 2008_008487
4147 2008_008488
4148 2008_008490
4149 2008_008496
4150 2008_008497
4151 2008_008500
4152 2008_008501
4153 2008_008506
4154 2008_008507
4155 2008_008508
4156 2008_008511
4157 2008_008512
4158 2008_008517
4159 2008_008519
4160 2008_008521
4161 2008_008522
4162 2008_008524
4163 2008_008525
4164 2008_008526
4165 2008_008527
4166 2008_008528
4167 2008_008530
4168 2008_008531
4169 2008_008533
4170 2008_008536
4171 2008_008537
4172 2008_008538
4173 2008_008541
4174 2008_008544
4175 2008_008545
4176 2008_008546
4177 2008_008547
4178 2008_008549
4179 2008_008550
4180 2008_008552
4181 2008_008554
4182 2008_008560
4183 2008_008564
4184 2008_008567
4185 2008_008570
4186 2008_008572
4187 2008_008574
4188 2008_008578
4189 2008_008579
4190 2008_008583
4191 2008_008585
4192 2008_008588
4193 2008_008589
4194 2008_008590
4195 2008_008591
4196 2008_008593
4197 2008_008595
4198 2008_008598
4199 2008_008600
4200 2008_008601
4201 2008_008606
4202 2008_008607
4203 2008_008608
4204 2008_008611
4205 2008_008613
4206 2008_008615
4207 2008_008616
4208 2008_008617
4209 2008_008618
4210 2008_008619
4211 2008_008621
4212 2008_008622
4213 2008_008623
4214 2008_008624
4215 2008_008628
4216 2008_008632
4217 2008_008635
4218 2008_008636
4219 2008_008637
4220 2008_008641
4221 2008_008642
4222 2008_008649
4223 2008_008652
4224 2008_008654
4225 2008_008658
4226 2008_008659
4227 2008_008662
4228 2008_008665
4229 2008_008666
4230 2008_008668
4231 2008_008671
4232 2008_008673
4233 2008_008674
4234 2008_008675
4235 2008_008676
4236 2008_008679
4237 2008_008681
4238 2008_008683
4239 2008_008684
4240 2008_008685
4241 2008_008689
4242 2008_008690
4243 2008_008691
4244 2008_008694
4245 2008_008695
4246 2008_008696
4247 2008_008697
4248 2008_008700
4249 2008_008701
4250 2008_008705
4251 2008_008706
4252 2008_008707
4253 2008_008708
4254 2008_008713
4255 2008_008714
4256 2008_008717
4257 2008_008718
4258 2008_008719
4259 2008_008724
4260 2008_008725
4261 2008_008726
4262 2008_008732
4263 2008_008735
4264 2008_008739
4265 2008_008744
4266 2008_008745
4267 2008_008748
4268 2008_008749
4269 2008_008751
4270 2008_008753
4271 2008_008755
4272 2008_008757
4273 2008_008765
4274 2008_008767
4275 2008_008770
4276 2008_008772
4277 2008_008773
4278 2009_000001
4279 2009_000002
4280 2009_000006
4281 2009_000009
4282 2009_000010
4283 2009_000011
4284 2009_000014
4285 2009_000015
4286 2009_000016
4287 2009_000017
4288 2009_000021
4289 2009_000026
4290 2009_000027
4291 2009_000028
4292 2009_000029
4293 2009_000030
4294 2009_000035
4295 2009_000040
4296 2009_000041
4297 2009_000042
4298 2009_000045
4299 2009_000051
4300 2009_000052
4301 2009_000054
4302 2009_000055
4303 2009_000056
4304 2009_000058
4305 2009_000059
4306 2009_000060
4307 2009_000063
4308 2009_000066
4309 2009_000067
4310 2009_000068
4311 2009_000072
4312 2009_000073
4313 2009_000078
4314 2009_000082
4315 2009_000084
4316 2009_000085
4317 2009_000088
4318 2009_000089
4319 2009_000090
4320 2009_000091
4321 2009_000093
4322 2009_000097
4323 2009_000100
4324 2009_000102
4325 2009_000103
4326 2009_000104
4327 2009_000105
4328 2009_000109
4329 2009_000119
4330 2009_000120
4331 2009_000122
4332 2009_000124
4333 2009_000128
4334 2009_000130
4335 2009_000131
4336 2009_000132
4337 2009_000133
4338 2009_000135
4339 2009_000137
4340 2009_000140
4341 2009_000141
4342 2009_000142
4343 2009_000145
4344 2009_000146
4345 2009_000150
4346 2009_000151
4347 2009_000157
4348 2009_000158
4349 2009_000159
4350 2009_000160
4351 2009_000161
4352 2009_000164
4353 2009_000165
4354 2009_000168
4355 2009_000169
4356 2009_000171
4357 2009_000176
4358 2009_000177
4359 2009_000181
4360 2009_000182
4361 2009_000183
4362 2009_000184
4363 2009_000188
4364 2009_000189
4365 2009_000192
4366 2009_000195
4367 2009_000197
4368 2009_000198
4369 2009_000199
4370 2009_000203
4371 2009_000206
4372 2009_000209
4373 2009_000212
4374 2009_000214
4375 2009_000216
4376 2009_000217
4377 2009_000218
4378 2009_000223
4379 2009_000225
4380 2009_000227
4381 2009_000229
4382 2009_000232
4383 2009_000233
4384 2009_000237
4385 2009_000239
4386 2009_000244
4387 2009_000247
4388 2009_000248
4389 2009_000249
4390 2009_000250
4391 2009_000251
4392 2009_000253
4393 2009_000254
4394 2009_000257
4395 2009_000260
4396 2009_000268
4397 2009_000276
4398 2009_000277
4399 2009_000280
4400 2009_000282
4401 2009_000283
4402 2009_000284
4403 2009_000285
4404 2009_000286
4405 2009_000287
4406 2009_000288
4407 2009_000289
4408 2009_000290
4409 2009_000291
4410 2009_000293
4411 2009_000297
4412 2009_000298
4413 2009_000300
4414 2009_000303
4415 2009_000304
4416 2009_000305
4417 2009_000308
4418 2009_000312
4419 2009_000316
4420 2009_000317
4421 2009_000320
4422 2009_000321
4423 2009_000322
4424 2009_000327
4425 2009_000328
4426 2009_000330
4427 2009_000336
4428 2009_000337
4429 2009_000339
4430 2009_000340
4431 2009_000341
4432 2009_000342
4433 2009_000343
4434 2009_000344
4435 2009_000347
4436 2009_000350
4437 2009_000356
4438 2009_000366
4439 2009_000367
4440 2009_000370
4441 2009_000375
4442 2009_000377
4443 2009_000378
4444 2009_000379
4445 2009_000385
4446 2009_000389
4447 2009_000390
4448 2009_000393
4449 2009_000397
4450 2009_000398
4451 2009_000399
4452 2009_000400
4453 2009_000402
4454 2009_000405
4455 2009_000408
4456 2009_000409
4457 2009_000410
4458 2009_000411
4459 2009_000414
4460 2009_000416
4461 2009_000417
4462 2009_000419
4463 2009_000420
4464 2009_000422
4465 2009_000430
4466 2009_000435
4467 2009_000438
4468 2009_000439
4469 2009_000443
4470 2009_000444
4471 2009_000445
4472 2009_000449
4473 2009_000452
4474 2009_000453
4475 2009_000454
4476 2009_000456
4477 2009_000461
4478 2009_000463
4479 2009_000464
4480 2009_000466
4481 2009_000471
4482 2009_000472
4483 2009_000474
4484 2009_000476
4485 2009_000477
4486 2009_000483
4487 2009_000486
4488 2009_000491
4489 2009_000493
4490 2009_000494
4491 2009_000496
4492 2009_000499
4493 2009_000500
4494 2009_000501
4495 2009_000502
4496 2009_000503
4497 2009_000504
4498 2009_000505
4499 2009_000511
4500 2009_000512
4501 2009_000513
4502 2009_000515
4503 2009_000516
4504 2009_000519
4505 2009_000522
4506 2009_000525
4507 2009_000526
4508 2009_000527
4509 2009_000529
4510 2009_000532
4511 2009_000535
4512 2009_000536
4513 2009_000539
4514 2009_000542
4515 2009_000544
4516 2009_000545
4517 2009_000546
4518 2009_000547
4519 2009_000549
4520 2009_000550
4521 2009_000552
4522 2009_000553
4523 2009_000557
4524 2009_000558
4525 2009_000559
4526 2009_000560
4527 2009_000562
4528 2009_000563
4529 2009_000565
4530 2009_000566
4531 2009_000567
4532 2009_000568
4533 2009_000574
4534 2009_000575
4535 2009_000576
4536 2009_000577
4537 2009_000579
4538 2009_000585
4539 2009_000586
4540 2009_000590
4541 2009_000591
4542 2009_000592
4543 2009_000593
4544 2009_000595
4545 2009_000597
4546 2009_000599
4547 2009_000600
4548 2009_000602
4549 2009_000603
4550 2009_000604
4551 2009_000606
4552 2009_000611
4553 2009_000614
4554 2009_000615
4555 2009_000617
4556 2009_000624
4557 2009_000625
4558 2009_000626
4559 2009_000629
4560 2009_000631
4561 2009_000632
4562 2009_000634
4563 2009_000635
4564 2009_000636
4565 2009_000637
4566 2009_000638
4567 2009_000642
4568 2009_000647
4569 2009_000648
4570 2009_000651
4571 2009_000653
4572 2009_000655
4573 2009_000658
4574 2009_000661
4575 2009_000662
4576 2009_000663
4577 2009_000670
4578 2009_000672
4579 2009_000674
4580 2009_000676
4581 2009_000677
4582 2009_000679
4583 2009_000681
4584 2009_000683
4585 2009_000684
4586 2009_000686
4587 2009_000689
4588 2009_000690
4589 2009_000691
4590 2009_000692
4591 2009_000694
4592 2009_000695
4593 2009_000696
4594 2009_000702
4595 2009_000708
4596 2009_000709
4597 2009_000718
4598 2009_000719
4599 2009_000720
4600 2009_000722
4601 2009_000724
4602 2009_000725
4603 2009_000726
4604 2009_000734
4605 2009_000737
4606 2009_000741
4607 2009_000742
4608 2009_000744
4609 2009_000745
4610 2009_000746
4611 2009_000748
4612 2009_000750
4613 2009_000752
4614 2009_000755
4615 2009_000756
4616 2009_000757
4617 2009_000758
4618 2009_000759
4619 2009_000760
4620 2009_000762
4621 2009_000763
4622 2009_000768
4623 2009_000770
4624 2009_000774
4625 2009_000777
4626 2009_000778
4627 2009_000779
4628 2009_000782
4629 2009_000783
4630 2009_000789
4631 2009_000790
4632 2009_000791
4633 2009_000793
4634 2009_000794
4635 2009_000796
4636 2009_000797
4637 2009_000801
4638 2009_000804
4639 2009_000805
4640 2009_000811
4641 2009_000812
4642 2009_000815
4643 2009_000816
4644 2009_000817
4645 2009_000820
4646 2009_000821
4647 2009_000823
4648 2009_000824
4649 2009_000829
4650 2009_000830
4651 2009_000831
4652 2009_000833
4653 2009_000834
4654 2009_000837
4655 2009_000843
4656 2009_000846
4657 2009_000848
4658 2009_000849
4659 2009_000851
4660 2009_000852
4661 2009_000854
4662 2009_000856
4663 2009_000858
4664 2009_000862
4665 2009_000865
4666 2009_000867
4667 2009_000869
4668 2009_000871
4669 2009_000874
4670 2009_000882
4671 2009_000886
4672 2009_000887
4673 2009_000889
4674 2009_000890
4675 2009_000894
4676 2009_000895
4677 2009_000896
4678 2009_000897
4679 2009_000898
4680 2009_000899
4681 2009_000901
4682 2009_000902
4683 2009_000904
4684 2009_000906
4685 2009_000909
4686 2009_000910
4687 2009_000915
4688 2009_000920
4689 2009_000923
4690 2009_000925
4691 2009_000926
4692 2009_000927
4693 2009_000928
4694 2009_000930
4695 2009_000932
4696 2009_000934
4697 2009_000937
4698 2009_000938
4699 2009_000939
4700 2009_000945
4701 2009_000948
4702 2009_000953
4703 2009_000954
4704 2009_000955
4705 2009_000958
4706 2009_000960
4707 2009_000961
4708 2009_000962
4709 2009_000966
4710 2009_000967
4711 2009_000969
4712 2009_000970
4713 2009_000971
4714 2009_000973
4715 2009_000974
4716 2009_000975
4717 2009_000979
4718 2009_000980
4719 2009_000981
4720 2009_000985
4721 2009_000987
4722 2009_000990
4723 2009_000992
4724 2009_000995
4725 2009_000996
4726 2009_001000
4727 2009_001002
4728 2009_001006
4729 2009_001007
4730 2009_001009
4731 2009_001011
4732 2009_001012
4733 2009_001013
4734 2009_001016
4735 2009_001019
4736 2009_001021
4737 2009_001024
4738 2009_001026
4739 2009_001027
4740 2009_001028
4741 2009_001030
4742 2009_001036
4743 2009_001037
4744 2009_001038
4745 2009_001040
4746 2009_001042
4747 2009_001044
4748 2009_001052
4749 2009_001054
4750 2009_001055
4751 2009_001056
4752 2009_001057
4753 2009_001059
4754 2009_001061
4755 2009_001069
4756 2009_001070
4757 2009_001075
4758 2009_001078
4759 2009_001079
4760 2009_001081
4761 2009_001083
4762 2009_001084
4763 2009_001085
4764 2009_001090
4765 2009_001091
4766 2009_001094
4767 2009_001095
4768 2009_001096
4769 2009_001097
4770 2009_001098
4771 2009_001100
4772 2009_001102
4773 2009_001103
4774 2009_001104
4775 2009_001105
4776 2009_001106
4777 2009_001107
4778 2009_001110
4779 2009_001111
4780 2009_001113
4781 2009_001117
4782 2009_001118
4783 2009_001120
4784 2009_001121
4785 2009_001124
4786 2009_001126
4787 2009_001128
4788 2009_001129
4789 2009_001133
4790 2009_001134
4791 2009_001135
4792 2009_001137
4793 2009_001138
4794 2009_001139
4795 2009_001140
4796 2009_001145
4797 2009_001146
4798 2009_001147
4799 2009_001148
4800 2009_001151
4801 2009_001152
4802 2009_001153
4803 2009_001154
4804 2009_001155
4805 2009_001159
4806 2009_001163
4807 2009_001164
4808 2009_001166
4809 2009_001172
4810 2009_001177
4811 2009_001180
4812 2009_001181
4813 2009_001184
4814 2009_001188
4815 2009_001190
4816 2009_001192
4817 2009_001195
4818 2009_001196
4819 2009_001197
4820 2009_001198
4821 2009_001199
4822 2009_001201
4823 2009_001203
4824 2009_001205
4825 2009_001206
4826 2009_001207
4827 2009_001208
4828 2009_001212
4829 2009_001216
4830 2009_001217
4831 2009_001221
4832 2009_001224
4833 2009_001225
4834 2009_001227
4835 2009_001229
4836 2009_001230
4837 2009_001236
4838 2009_001237
4839 2009_001238
4840 2009_001241
4841 2009_001242
4842 2009_001243
4843 2009_001245
4844 2009_001249
4845 2009_001251
4846 2009_001252
4847 2009_001253
4848 2009_001254
4849 2009_001257
4850 2009_001259
4851 2009_001260
4852 2009_001263
4853 2009_001264
4854 2009_001266
4855 2009_001268
4856 2009_001270
4857 2009_001271
4858 2009_001279
4859 2009_001282
4860 2009_001283
4861 2009_001285
4862 2009_001286
4863 2009_001288
4864 2009_001289
4865 2009_001291
4866 2009_001301
4867 2009_001303
4868 2009_001305
4869 2009_001306
4870 2009_001308
4871 2009_001309
4872 2009_001311
4873 2009_001312
4874 2009_001313
4875 2009_001316
4876 2009_001319
4877 2009_001320
4878 2009_001321
4879 2009_001322
4880 2009_001323
4881 2009_001326
4882 2009_001327
4883 2009_001328
4884 2009_001329
4885 2009_001339
4886 2009_001343
4887 2009_001344
4888 2009_001345
4889 2009_001348
4890 2009_001349
4891 2009_001350
4892 2009_001354
4893 2009_001355
4894 2009_001357
4895 2009_001359
4896 2009_001360
4897 2009_001361
4898 2009_001364
4899 2009_001366
4900 2009_001367
4901 2009_001368
4902 2009_001369
4903 2009_001370
4904 2009_001371
4905 2009_001372
4906 2009_001374
4907 2009_001375
4908 2009_001376
4909 2009_001384
4910 2009_001385
4911 2009_001387
4912 2009_001388
4913 2009_001389
4914 2009_001390
4915 2009_001393
4916 2009_001395
4917 2009_001397
4918 2009_001398
4919 2009_001403
4920 2009_001406
4921 2009_001407
4922 2009_001409
4923 2009_001412
4924 2009_001413
4925 2009_001414
4926 2009_001417
4927 2009_001419
4928 2009_001422
4929 2009_001424
4930 2009_001426
4931 2009_001427
4932 2009_001431
4933 2009_001434
4934 2009_001435
4935 2009_001437
4936 2009_001440
4937 2009_001443
4938 2009_001444
4939 2009_001446
4940 2009_001447
4941 2009_001448
4942 2009_001449
4943 2009_001450
4944 2009_001452
4945 2009_001453
4946 2009_001456
4947 2009_001457
4948 2009_001462
4949 2009_001463
4950 2009_001466
4951 2009_001468
4952 2009_001470
4953 2009_001472
4954 2009_001474
4955 2009_001475
4956 2009_001476
4957 2009_001479
4958 2009_001480
4959 2009_001481
4960 2009_001484
4961 2009_001490
4962 2009_001493
4963 2009_001494
4964 2009_001498
4965 2009_001500
4966 2009_001501
4967 2009_001502
4968 2009_001507
4969 2009_001508
4970 2009_001509
4971 2009_001514
4972 2009_001516
4973 2009_001517
4974 2009_001518
4975 2009_001519
4976 2009_001521
4977 2009_001522
4978 2009_001526
4979 2009_001534
4980 2009_001537
4981 2009_001538
4982 2009_001539
4983 2009_001541
4984 2009_001542
4985 2009_001544
4986 2009_001546
4987 2009_001549
4988 2009_001550
4989 2009_001553
4990 2009_001554
4991 2009_001555
4992 2009_001558
4993 2009_001562
4994 2009_001566
4995 2009_001567
4996 2009_001568
4997 2009_001570
4998 2009_001575
4999 2009_001577
5000 2009_001581
5001 2009_001585
5002 2009_001587
5003 2009_001589
5004 2009_001590
5005 2009_001591
5006 2009_001593
5007 2009_001594
5008 2009_001595
5009 2009_001598
5010 2009_001602
5011 2009_001605
5012 2009_001606
5013 2009_001608
5014 2009_001611
5015 2009_001612
5016 2009_001614
5017 2009_001615
5018 2009_001617
5019 2009_001618
5020 2009_001621
5021 2009_001623
5022 2009_001625
5023 2009_001627
5024 2009_001631
5025 2009_001633
5026 2009_001635
5027 2009_001636
5028 2009_001638
5029 2009_001640
5030 2009_001642
5031 2009_001643
5032 2009_001645
5033 2009_001646
5034 2009_001648
5035 2009_001651
5036 2009_001653
5037 2009_001657
5038 2009_001660
5039 2009_001664
5040 2009_001667
5041 2009_001670
5042 2009_001671
5043 2009_001673
5044 2009_001674
5045 2009_001675
5046 2009_001676
5047 2009_001677
5048 2009_001678
5049 2009_001682
5050 2009_001689
5051 2009_001690
5052 2009_001693
5053 2009_001695
5054 2009_001696
5055 2009_001699
5056 2009_001704
5057 2009_001705
5058 2009_001706
5059 2009_001707
5060 2009_001709
5061 2009_001713
5062 2009_001715
5063 2009_001719
5064 2009_001720
5065 2009_001723
5066 2009_001724
5067 2009_001732
5068 2009_001733
5069 2009_001734
5070 2009_001735
5071 2009_001738
5072 2009_001740
5073 2009_001741
5074 2009_001743
5075 2009_001744
5076 2009_001746
5077 2009_001747
5078 2009_001749
5079 2009_001750
5080 2009_001751
5081 2009_001752
5082 2009_001754
5083 2009_001755
5084 2009_001758
5085 2009_001759
5086 2009_001764
5087 2009_001767
5088 2009_001770
5089 2009_001774
5090 2009_001778
5091 2009_001779
5092 2009_001780
5093 2009_001781
5094 2009_001782
5095 2009_001783
5096 2009_001784
5097 2009_001792
5098 2009_001794
5099 2009_001798
5100 2009_001799
5101 2009_001800
5102 2009_001801
5103 2009_001802
5104 2009_001805
5105 2009_001806
5106 2009_001807
5107 2009_001809
5108 2009_001810
5109 2009_001811
5110 2009_001812
5111 2009_001817
5112 2009_001820
5113 2009_001822
5114 2009_001823
5115 2009_001825
5116 2009_001826
5117 2009_001827
5118 2009_001828
5119 2009_001830
5120 2009_001831
5121 2009_001833
5122 2009_001835
5123 2009_001837
5124 2009_001839
5125 2009_001840
5126 2009_001846
5127 2009_001847
5128 2009_001848
5129 2009_001852
5130 2009_001853
5131 2009_001856
5132 2009_001858
5133 2009_001861
5134 2009_001864
5135 2009_001865
5136 2009_001867
5137 2009_001868
5138 2009_001869
5139 2009_001871
5140 2009_001873
5141 2009_001874
5142 2009_001875
5143 2009_001881
5144 2009_001884
5145 2009_001885
5146 2009_001888
5147 2009_001890
5148 2009_001894
5149 2009_001897
5150 2009_001898
5151 2009_001902
5152 2009_001904
5153 2009_001905
5154 2009_001906
5155 2009_001907
5156 2009_001908
5157 2009_001909
5158 2009_001910
5159 2009_001911
5160 2009_001916
5161 2009_001917
5162 2009_001922
5163 2009_001926
5164 2009_001927
5165 2009_001929
5166 2009_001931
5167 2009_001933
5168 2009_001934
5169 2009_001937
5170 2009_001940
5171 2009_001945
5172 2009_001948
5173 2009_001949
5174 2009_001952
5175 2009_001959
5176 2009_001960
5177 2009_001961
5178 2009_001962
5179 2009_001964
5180 2009_001965
5181 2009_001967
5182 2009_001971
5183 2009_001972
5184 2009_001973
5185 2009_001975
5186 2009_001976
5187 2009_001977
5188 2009_001979
5189 2009_001980
5190 2009_001984
5191 2009_001988
5192 2009_001990
5193 2009_001994
5194 2009_001997
5195 2009_001999
5196 2009_002000
5197 2009_002001
5198 2009_002002
5199 2009_002003
5200 2009_002008
5201 2009_002009
5202 2009_002010
5203 2009_002011
5204 2009_002019
5205 2009_002024
5206 2009_002031
5207 2009_002037
5208 2009_002039
5209 2009_002040
5210 2009_002044
5211 2009_002046
5212 2009_002052
5213 2009_002053
5214 2009_002054
5215 2009_002055
5216 2009_002056
5217 2009_002057
5218 2009_002058
5219 2009_002060
5220 2009_002061
5221 2009_002064
5222 2009_002066
5223 2009_002072
5224 2009_002073
5225 2009_002077
5226 2009_002078
5227 2009_002083
5228 2009_002086
5229 2009_002087
5230 2009_002088
5231 2009_002089
5232 2009_002093
5233 2009_002096
5234 2009_002098
5235 2009_002099
5236 2009_002103
5237 2009_002104
5238 2009_002105
5239 2009_002107
5240 2009_002110
5241 2009_002111
5242 2009_002112
5243 2009_002116
5244 2009_002117
5245 2009_002118
5246 2009_002119
5247 2009_002120
5248 2009_002123
5249 2009_002126
5250 2009_002127
5251 2009_002128
5252 2009_002129
5253 2009_002131
5254 2009_002133
5255 2009_002136
5256 2009_002137
5257 2009_002139
5258 2009_002141
5259 2009_002144
5260 2009_002145
5261 2009_002146
5262 2009_002147
5263 2009_002149
5264 2009_002151
5265 2009_002152
5266 2009_002153
5267 2009_002169
5268 2009_002173
5269 2009_002175
5270 2009_002176
5271 2009_002177
5272 2009_002180
5273 2009_002182
5274 2009_002191
5275 2009_002192
5276 2009_002193
5277 2009_002194
5278 2009_002197
5279 2009_002198
5280 2009_002199
5281 2009_002203
5282 2009_002204
5283 2009_002205
5284 2009_002208
5285 2009_002211
5286 2009_002212
5287 2009_002214
5288 2009_002215
5289 2009_002216
5290 2009_002219
5291 2009_002222
5292 2009_002225
5293 2009_002226
5294 2009_002228
5295 2009_002229
5296 2009_002230
5297 2009_002231
5298 2009_002232
5299 2009_002235
5300 2009_002236
5301 2009_002240
5302 2009_002242
5303 2009_002245
5304 2009_002252
5305 2009_002253
5306 2009_002254
5307 2009_002256
5308 2009_002257
5309 2009_002258
5310 2009_002259
5311 2009_002262
5312 2009_002264
5313 2009_002267
5314 2009_002271
5315 2009_002272
5316 2009_002273
5317 2009_002274
5318 2009_002281
5319 2009_002282
5320 2009_002285
5321 2009_002286
5322 2009_002289
5323 2009_002297
5324 2009_002298
5325 2009_002299
5326 2009_002301
5327 2009_002302
5328 2009_002305
5329 2009_002306
5330 2009_002308
5331 2009_002311
5332 2009_002312
5333 2009_002314
5334 2009_002319
5335 2009_002324
5336 2009_002325
5337 2009_002326
5338 2009_002328
5339 2009_002331
5340 2009_002333
5341 2009_002335
5342 2009_002338
5343 2009_002339
5344 2009_002343
5345 2009_002348
5346 2009_002349
5347 2009_002350
5348 2009_002352
5349 2009_002358
5350 2009_002360
5351 2009_002362
5352 2009_002363
5353 2009_002370
5354 2009_002371
5355 2009_002373
5356 2009_002374
5357 2009_002376
5358 2009_002377
5359 2009_002380
5360 2009_002381
5361 2009_002386
5362 2009_002387
5363 2009_002388
5364 2009_002391
5365 2009_002393
5366 2009_002397
5367 2009_002398
5368 2009_002399
5369 2009_002400
5370 2009_002401
5371 2009_002404
5372 2009_002406
5373 2009_002407
5374 2009_002408
5375 2009_002409
5376 2009_002414
5377 2009_002416
5378 2009_002419
5379 2009_002420
5380 2009_002422
5381 2009_002423
5382 2009_002424
5383 2009_002425
5384 2009_002429
5385 2009_002431
5386 2009_002432
5387 2009_002433
5388 2009_002434
5389 2009_002436
5390 2009_002438
5391 2009_002439
5392 2009_002441
5393 2009_002443
5394 2009_002444
5395 2009_002448
5396 2009_002449
5397 2009_002452
5398 2009_002453
5399 2009_002456
5400 2009_002457
5401 2009_002460
5402 2009_002464
5403 2009_002465
5404 2009_002470
5405 2009_002471
5406 2009_002472
5407 2009_002474
5408 2009_002475
5409 2009_002476
5410 2009_002477
5411 2009_002488
5412 2009_002499
5413 2009_002500
5414 2009_002504
5415 2009_002505
5416 2009_002506
5417 2009_002510
5418 2009_002512
5419 2009_002514
5420 2009_002515
5421 2009_002517
5422 2009_002518
5423 2009_002519
5424 2009_002522
5425 2009_002523
5426 2009_002524
5427 2009_002525
5428 2009_002530
5429 2009_002531
5430 2009_002532
5431 2009_002536
5432 2009_002537
5433 2009_002542
5434 2009_002543
5435 2009_002546
5436 2009_002552
5437 2009_002553
5438 2009_002556
5439 2009_002557
5440 2009_002558
5441 2009_002559
5442 2009_002561
5443 2009_002563
5444 2009_002565
5445 2009_002566
5446 2009_002567
5447 2009_002569
5448 2009_002570
5449 2009_002577
5450 2009_002579
5451 2009_002580
5452 2009_002585
5453 2009_002586
5454 2009_002588
5455 2009_002592
5456 2009_002595
5457 2009_002597
5458 2009_002599
5459 2009_002605
5460 2009_002607
5461 2009_002608
5462 2009_002609
5463 2009_002611
5464 2009_002612
5465 2009_002613
5466 2009_002614
5467 2009_002615
5468 2009_002616
5469 2009_002620
5470 2009_002621
5471 2009_002624
5472 2009_002625
5473 2009_002626
5474 2009_002628
5475 2009_002629
5476 2009_002632
5477 2009_002634
5478 2009_002645
5479 2009_002648
5480 2009_002652
5481 2009_002662
5482 2009_002663
5483 2009_002665
5484 2009_002667
5485 2009_002668
5486 2009_002669
5487 2009_002670
5488 2009_002671
5489 2009_002672
5490 2009_002673
5491 2009_002674
5492 2009_002675
5493 2009_002676
5494 2009_002681
5495 2009_002683
5496 2009_002684
5497 2009_002685
5498 2009_002687
5499 2009_002688
5500 2009_002689
5501 2009_002695
5502 2009_002697
5503 2009_002698
5504 2009_002703
5505 2009_002704
5506 2009_002705
5507 2009_002708
5508 2009_002710
5509 2009_002711
5510 2009_002712
5511 2009_002713
5512 2009_002714
5513 2009_002715
5514 2009_002717
5515 2009_002719
5516 2009_002725
5517 2009_002728
5518 2009_002733
5519 2009_002734
5520 2009_002739
5521 2009_002741
5522 2009_002743
5523 2009_002744
5524 2009_002746
5525 2009_002750
5526 2009_002752
5527 2009_002754
5528 2009_002755
5529 2009_002758
5530 2009_002759
5531 2009_002762
5532 2009_002763
5533 2009_002764
5534 2009_002765
5535 2009_002770
5536 2009_002772
5537 2009_002774
5538 2009_002777
5539 2009_002778
5540 2009_002779
5541 2009_002780
5542 2009_002784
5543 2009_002785
5544 2009_002789
5545 2009_002790
5546 2009_002791
5547 2009_002792
5548 2009_002798
5549 2009_002799
5550 2009_002800
5551 2009_002803
5552 2009_002806
5553 2009_002807
5554 2009_002809
5555 2009_002813
5556 2009_002814
5557 2009_002816
5558 2009_002817
5559 2009_002820
5560 2009_002824
5561 2009_002827
5562 2009_002830
5563 2009_002831
5564 2009_002833
5565 2009_002835
5566 2009_002836
5567 2009_002837
5568 2009_002838
5569 2009_002841
5570 2009_002842
5571 2009_002843
5572 2009_002844
5573 2009_002845
5574 2009_002847
5575 2009_002849
5576 2009_002850
5577 2009_002851
5578 2009_002853
5579 2009_002855
5580 2009_002862
5581 2009_002865
5582 2009_002867
5583 2009_002869
5584 2009_002872
5585 2009_002876
5586 2009_002877
5587 2009_002879
5588 2009_002882
5589 2009_002883
5590 2009_002885
5591 2009_002890
5592 2009_002893
5593 2009_002894
5594 2009_002897
5595 2009_002898
5596 2009_002901
5597 2009_002902
5598 2009_002908
5599 2009_002910
5600 2009_002912
5601 2009_002914
5602 2009_002917
5603 2009_002918
5604 2009_002920
5605 2009_002921
5606 2009_002925
5607 2009_002932
5608 2009_002933
5609 2009_002935
5610 2009_002937
5611 2009_002938
5612 2009_002940
5613 2009_002941
5614 2009_002946
5615 2009_002947
5616 2009_002952
5617 2009_002954
5618 2009_002955
5619 2009_002957
5620 2009_002958
5621 2009_002960
5622 2009_002961
5623 2009_002962
5624 2009_002967
5625 2009_002970
5626 2009_002971
5627 2009_002972
5628 2009_002976
5629 2009_002977
5630 2009_002978
5631 2009_002980
5632 2009_002983
5633 2009_002984
5634 2009_002985
5635 2009_002986
5636 2009_002988
5637 2009_002993
5638 2009_002995
5639 2009_002998
5640 2009_002999
5641 2009_003000
5642 2009_003002
5643 2009_003006
5644 2009_003007
5645 2009_003010
5646 2009_003012
5647 2009_003013
5648 2009_003018
5649 2009_003019
5650 2009_003020
5651 2009_003022
5652 2009_003023
5653 2009_003031
5654 2009_003032
5655 2009_003033
5656 2009_003034
5657 2009_003035
5658 2009_003039
5659 2009_003042
5660 2009_003044
5661 2009_003052
5662 2009_003053
5663 2009_003054
5664 2009_003056
5665 2009_003058
5666 2009_003064
5667 2009_003066
5668 2009_003067
5669 2009_003068
5670 2009_003070
5671 2009_003074
5672 2009_003075
5673 2009_003076
5674 2009_003077
5675 2009_003078
5676 2009_003082
5677 2009_003083
5678 2009_003087
5679 2009_003088
5680 2009_003089
5681 2009_003090
5682 2009_003091
5683 2009_003093
5684 2009_003095
5685 2009_003097
5686 2009_003098
5687 2009_003107
5688 2009_003108
5689 2009_003109
5690 2009_003110
5691 2009_003114
5692 2009_003115
5693 2009_003116
5694 2009_003118
5695 2009_003122
5696 2009_003125
5697 2009_003126
5698 2009_003127
5699 2009_003128
5700 2009_003129
5701 2009_003130
5702 2009_003132
5703 2009_003136
5704 2009_003138
5705 2009_003140
5706 2009_003142
5707 2009_003143
5708 2009_003144
5709 2009_003146
5710 2009_003147
5711 2009_003150
5712 2009_003151
5713 2009_003153
5714 2009_003154
5715 2009_003155
5716 2009_003156
5717 2009_003157
5718 2009_003164
5719 2009_003165
5720 2009_003166
5721 2009_003168
5722 2009_003172
5723 2009_003173
5724 2009_003175
5725 2009_003183
5726 2009_003185
5727 2009_003187
5728 2009_003189
5729 2009_003191
5730 2009_003194
5731 2009_003198
5732 2009_003199
5733 2009_003200
5734 2009_003201
5735 2009_003204
5736 2009_003208
5737 2009_003209
5738 2009_003212
5739 2009_003214
5740 2009_003218
5741 2009_003219
5742 2009_003222
5743 2009_003225
5744 2009_003229
5745 2009_003230
5746 2009_003232
5747 2009_003233
5748 2009_003234
5749 2009_003238
5750 2009_003247
5751 2009_003249
5752 2009_003251
5753 2009_003253
5754 2009_003254
5755 2009_003255
5756 2009_003257
5757 2009_003259
5758 2009_003261
5759 2009_003262
5760 2009_003265
5761 2009_003266
5762 2009_003267
5763 2009_003271
5764 2009_003272
5765 2009_003276
5766 2009_003277
5767 2009_003278
5768 2009_003282
5769 2009_003284
5770 2009_003285
5771 2009_003288
5772 2009_003290
5773 2009_003294
5774 2009_003297
5775 2009_003300
5776 2009_003301
5777 2009_003305
5778 2009_003309
5779 2009_003310
5780 2009_003312
5781 2009_003315
5782 2009_003316
5783 2009_003317
5784 2009_003320
5785 2009_003326
5786 2009_003333
5787 2009_003338
5788 2009_003340
5789 2009_003345
5790 2009_003346
5791 2009_003347
5792 2009_003348
5793 2009_003349
5794 2009_003350
5795 2009_003351
5796 2009_003352
5797 2009_003353
5798 2009_003360
5799 2009_003361
5800 2009_003363
5801 2009_003365
5802 2009_003367
5803 2009_003369
5804 2009_003372
5805 2009_003373
5806 2009_003375
5807 2009_003376
5808 2009_003377
5809 2009_003379
5810 2009_003380
5811 2009_003381
5812 2009_003383
5813 2009_003384
5814 2009_003385
5815 2009_003386
5816 2009_003394
5817 2009_003395
5818 2009_003396
5819 2009_003399
5820 2009_003400
5821 2009_003402
5822 2009_003407
5823 2009_003409
5824 2009_003411
5825 2009_003415
5826 2009_003416
5827 2009_003417
5828 2009_003419
5829 2009_003422
5830 2009_003425
5831 2009_003430
5832 2009_003431
5833 2009_003436
5834 2009_003440
5835 2009_003441
5836 2009_003443
5837 2009_003445
5838 2009_003446
5839 2009_003447
5840 2009_003453
5841 2009_003454
5842 2009_003455
5843 2009_003456
5844 2009_003457
5845 2009_003458
5846 2009_003459
5847 2009_003460
5848 2009_003461
5849 2009_003462
5850 2009_003467
5851 2009_003468
5852 2009_003469
5853 2009_003476
5854 2009_003482
5855 2009_003487
5856 2009_003488
5857 2009_003489
5858 2009_003490
5859 2009_003491
5860 2009_003492
5861 2009_003497
5862 2009_003499
5863 2009_003500
5864 2009_003508
5865 2009_003509
5866 2009_003510
5867 2009_003511
5868 2009_003513
5869 2009_003519
5870 2009_003520
5871 2009_003521
5872 2009_003522
5873 2009_003524
5874 2009_003528
5875 2009_003530
5876 2009_003531
5877 2009_003533
5878 2009_003534
5879 2009_003537
5880 2009_003538
5881 2009_003539
5882 2009_003540
5883 2009_003541
5884 2009_003543
5885 2009_003544
5886 2009_003545
5887 2009_003546
5888 2009_003554
5889 2009_003555
5890 2009_003560
5891 2009_003562
5892 2009_003563
5893 2009_003565
5894 2009_003566
5895 2009_003571
5896 2009_003572
5897 2009_003577
5898 2009_003581
5899 2009_003583
5900 2009_003588
5901 2009_003592
5902 2009_003594
5903 2009_003598
5904 2009_003600
5905 2009_003601
5906 2009_003605
5907 2009_003606
5908 2009_003608
5909 2009_003609
5910 2009_003612
5911 2009_003613
5912 2009_003614
5913 2009_003618
5914 2009_003624
5915 2009_003626
5916 2009_003627
5917 2009_003629
5918 2009_003633
5919 2009_003634
5920 2009_003635
5921 2009_003636
5922 2009_003638
5923 2009_003639
5924 2009_003642
5925 2009_003644
5926 2009_003646
5927 2009_003647
5928 2009_003650
5929 2009_003652
5930 2009_003654
5931 2009_003655
5932 2009_003656
5933 2009_003657
5934 2009_003660
5935 2009_003663
5936 2009_003664
5937 2009_003667
5938 2009_003668
5939 2009_003669
5940 2009_003671
5941 2009_003677
5942 2009_003679
5943 2009_003683
5944 2009_003685
5945 2009_003686
5946 2009_003688
5947 2009_003689
5948 2009_003690
5949 2009_003694
5950 2009_003695
5951 2009_003697
5952 2009_003698
5953 2009_003702
5954 2009_003704
5955 2009_003705
5956 2009_003708
5957 2009_003709
5958 2009_003710
5959 2009_003711
5960 2009_003713
5961 2009_003714
5962 2009_003717
5963 2009_003718
5964 2009_003720
5965 2009_003722
5966 2009_003725
5967 2009_003732
5968 2009_003734
5969 2009_003735
5970 2009_003736
5971 2009_003738
5972 2009_003739
5973 2009_003743
5974 2009_003747
5975 2009_003751
5976 2009_003752
5977 2009_003753
5978 2009_003757
5979 2009_003758
5980 2009_003759
5981 2009_003760
5982 2009_003765
5983 2009_003768
5984 2009_003775
5985 2009_003776
5986 2009_003781
5987 2009_003783
5988 2009_003784
5989 2009_003785
5990 2009_003786
5991 2009_003790
5992 2009_003793
5993 2009_003795
5994 2009_003799
5995 2009_003800
5996 2009_003801
5997 2009_003802
5998 2009_003808
5999 2009_003813
6000 2009_003814
6001 2009_003815
6002 2009_003816
6003 2009_003818
6004 2009_003819
6005 2009_003820
6006 2009_003821
6007 2009_003822
6008 2009_003825
6009 2009_003827
6010 2009_003829
6011 2009_003832
6012 2009_003835
6013 2009_003836
6014 2009_003837
6015 2009_003838
6016 2009_003840
6017 2009_003843
6018 2009_003846
6019 2009_003847
6020 2009_003848
6021 2009_003852
6022 2009_003855
6023 2009_003860
6024 2009_003863
6025 2009_003865
6026 2009_003867
6027 2009_003870
6028 2009_003873
6029 2009_003874
6030 2009_003879
6031 2009_003883
6032 2009_003884
6033 2009_003888
6034 2009_003892
6035 2009_003896
6036 2009_003897
6037 2009_003899
6038 2009_003900
6039 2009_003901
6040 2009_003902
6041 2009_003905
6042 2009_003908
6043 2009_003911
6044 2009_003912
6045 2009_003913
6046 2009_003914
6047 2009_003916
6048 2009_003920
6049 2009_003921
6050 2009_003922
6051 2009_003929
6052 2009_003933
6053 2009_003936
6054 2009_003942
6055 2009_003944
6056 2009_003947
6057 2009_003950
6058 2009_003951
6059 2009_003955
6060 2009_003956
6061 2009_003958
6062 2009_003961
6063 2009_003962
6064 2009_003965
6065 2009_003966
6066 2009_003969
6067 2009_003973
6068 2009_003974
6069 2009_003975
6070 2009_003976
6071 2009_003977
6072 2009_003982
6073 2009_003985
6074 2009_003986
6075 2009_003992
6076 2009_003993
6077 2009_003994
6078 2009_003995
6079 2009_004001
6080 2009_004002
6081 2009_004004
6082 2009_004005
6083 2009_004007
6084 2009_004012
6085 2009_004016
6086 2009_004018
6087 2009_004019
6088 2009_004020
6089 2009_004022
6090 2009_004023
6091 2009_004025
6092 2009_004031
6093 2009_004032
6094 2009_004034
6095 2009_004037
6096 2009_004038
6097 2009_004040
6098 2009_004042
6099 2009_004044
6100 2009_004050
6101 2009_004051
6102 2009_004052
6103 2009_004055
6104 2009_004058
6105 2009_004062
6106 2009_004069
6107 2009_004073
6108 2009_004074
6109 2009_004075
6110 2009_004076
6111 2009_004078
6112 2009_004082
6113 2009_004083
6114 2009_004085
6115 2009_004088
6116 2009_004091
6117 2009_004092
6118 2009_004093
6119 2009_004094
6120 2009_004095
6121 2009_004096
6122 2009_004100
6123 2009_004102
6124 2009_004103
6125 2009_004105
6126 2009_004108
6127 2009_004109
6128 2009_004111
6129 2009_004112
6130 2009_004113
6131 2009_004117
6132 2009_004118
6133 2009_004121
6134 2009_004122
6135 2009_004124
6136 2009_004126
6137 2009_004128
6138 2009_004129
6139 2009_004131
6140 2009_004133
6141 2009_004134
6142 2009_004138
6143 2009_004139
6144 2009_004141
6145 2009_004142
6146 2009_004148
6147 2009_004150
6148 2009_004152
6149 2009_004154
6150 2009_004157
6151 2009_004159
6152 2009_004161
6153 2009_004162
6154 2009_004163
6155 2009_004164
6156 2009_004165
6157 2009_004166
6158 2009_004168
6159 2009_004169
6160 2009_004170
6161 2009_004171
6162 2009_004174
6163 2009_004175
6164 2009_004176
6165 2009_004177
6166 2009_004178
6167 2009_004179
6168 2009_004180
6169 2009_004181
6170 2009_004183
6171 2009_004186
6172 2009_004187
6173 2009_004188
6174 2009_004191
6175 2009_004193
6176 2009_004197
6177 2009_004199
6178 2009_004200
6179 2009_004201
6180 2009_004202
6181 2009_004203
6182 2009_004205
6183 2009_004207
6184 2009_004210
6185 2009_004211
6186 2009_004212
6187 2009_004213
6188 2009_004218
6189 2009_004222
6190 2009_004224
6191 2009_004225
6192 2009_004227
6193 2009_004228
6194 2009_004229
6195 2009_004231
6196 2009_004232
6197 2009_004233
6198 2009_004234
6199 2009_004241
6200 2009_004243
6201 2009_004244
6202 2009_004249
6203 2009_004258
6204 2009_004261
6205 2009_004262
6206 2009_004263
6207 2009_004264
6208 2009_004271
6209 2009_004272
6210 2009_004273
6211 2009_004274
6212 2009_004276
6213 2009_004277
6214 2009_004278
6215 2009_004279
6216 2009_004283
6217 2009_004284
6218 2009_004285
6219 2009_004289
6220 2009_004290
6221 2009_004291
6222 2009_004295
6223 2009_004300
6224 2009_004301
6225 2009_004303
6226 2009_004307
6227 2009_004308
6228 2009_004309
6229 2009_004312
6230 2009_004315
6231 2009_004316
6232 2009_004317
6233 2009_004319
6234 2009_004322
6235 2009_004323
6236 2009_004327
6237 2009_004328
6238 2009_004329
6239 2009_004332
6240 2009_004334
6241 2009_004336
6242 2009_004338
6243 2009_004340
6244 2009_004341
6245 2009_004346
6246 2009_004347
6247 2009_004350
6248 2009_004351
6249 2009_004357
6250 2009_004358
6251 2009_004359
6252 2009_004361
6253 2009_004364
6254 2009_004366
6255 2009_004368
6256 2009_004369
6257 2009_004370
6258 2009_004371
6259 2009_004374
6260 2009_004375
6261 2009_004377
6262 2009_004382
6263 2009_004383
6264 2009_004390
6265 2009_004392
6266 2009_004394
6267 2009_004397
6268 2009_004399
6269 2009_004403
6270 2009_004404
6271 2009_004406
6272 2009_004409
6273 2009_004410
6274 2009_004411
6275 2009_004414
6276 2009_004417
6277 2009_004419
6278 2009_004424
6279 2009_004425
6280 2009_004426
6281 2009_004429
6282 2009_004432
6283 2009_004434
6284 2009_004435
6285 2009_004436
6286 2009_004438
6287 2009_004440
6288 2009_004442
6289 2009_004444
6290 2009_004445
6291 2009_004446
6292 2009_004448
6293 2009_004449
6294 2009_004451
6295 2009_004452
6296 2009_004453
6297 2009_004454
6298 2009_004456
6299 2009_004457
6300 2009_004464
6301 2009_004465
6302 2009_004468
6303 2009_004471
6304 2009_004475
6305 2009_004477
6306 2009_004478
6307 2009_004479
6308 2009_004483
6309 2009_004486
6310 2009_004492
6311 2009_004499
6312 2009_004501
6313 2009_004502
6314 2009_004503
6315 2009_004508
6316 2009_004511
6317 2009_004513
6318 2009_004514
6319 2009_004518
6320 2009_004519
6321 2009_004524
6322 2009_004525
6323 2009_004527
6324 2009_004529
6325 2009_004530
6326 2009_004532
6327 2009_004535
6328 2009_004536
6329 2009_004537
6330 2009_004539
6331 2009_004542
6332 2009_004543
6333 2009_004545
6334 2009_004547
6335 2009_004548
6336 2009_004551
6337 2009_004552
6338 2009_004554
6339 2009_004556
6340 2009_004557
6341 2009_004559
6342 2009_004560
6343 2009_004561
6344 2009_004562
6345 2009_004565
6346 2009_004567
6347 2009_004570
6348 2009_004571
6349 2009_004572
6350 2009_004580
6351 2009_004582
6352 2009_004587
6353 2009_004588
6354 2009_004593
6355 2009_004598
6356 2009_004601
6357 2009_004606
6358 2009_004607
6359 2009_004614
6360 2009_004616
6361 2009_004619
6362 2009_004620
6363 2009_004623
6364 2009_004624
6365 2009_004625
6366 2009_004626
6367 2009_004628
6368 2009_004629
6369 2009_004630
6370 2009_004631
6371 2009_004634
6372 2009_004639
6373 2009_004642
6374 2009_004643
6375 2009_004645
6376 2009_004647
6377 2009_004648
6378 2009_004651
6379 2009_004652
6380 2009_004655
6381 2009_004656
6382 2009_004661
6383 2009_004662
6384 2009_004664
6385 2009_004667
6386 2009_004669
6387 2009_004670
6388 2009_004671
6389 2009_004674
6390 2009_004677
6391 2009_004679
6392 2009_004681
6393 2009_004683
6394 2009_004684
6395 2009_004686
6396 2009_004688
6397 2009_004694
6398 2009_004697
6399 2009_004701
6400 2009_004705
6401 2009_004706
6402 2009_004708
6403 2009_004709
6404 2009_004710
6405 2009_004713
6406 2009_004716
6407 2009_004718
6408 2009_004719
6409 2009_004720
6410 2009_004723
6411 2009_004728
6412 2009_004731
6413 2009_004734
6414 2009_004737
6415 2009_004744
6416 2009_004745
6417 2009_004746
6418 2009_004749
6419 2009_004754
6420 2009_004756
6421 2009_004758
6422 2009_004759
6423 2009_004760
6424 2009_004761
6425 2009_004763
6426 2009_004764
6427 2009_004765
6428 2009_004766
6429 2009_004768
6430 2009_004769
6431 2009_004771
6432 2009_004772
6433 2009_004779
6434 2009_004780
6435 2009_004781
6436 2009_004782
6437 2009_004784
6438 2009_004786
6439 2009_004787
6440 2009_004790
6441 2009_004794
6442 2009_004796
6443 2009_004797
6444 2009_004798
6445 2009_004804
6446 2009_004805
6447 2009_004806
6448 2009_004812
6449 2009_004813
6450 2009_004815
6451 2009_004817
6452 2009_004822
6453 2009_004823
6454 2009_004824
6455 2009_004828
6456 2009_004829
6457 2009_004830
6458 2009_004831
6459 2009_004834
6460 2009_004836
6461 2009_004839
6462 2009_004841
6463 2009_004845
6464 2009_004846
6465 2009_004847
6466 2009_004849
6467 2009_004855
6468 2009_004856
6469 2009_004857
6470 2009_004858
6471 2009_004865
6472 2009_004868
6473 2009_004869
6474 2009_004871
6475 2009_004872
6476 2009_004874
6477 2009_004876
6478 2009_004877
6479 2009_004880
6480 2009_004885
6481 2009_004887
6482 2009_004888
6483 2009_004889
6484 2009_004890
6485 2009_004897
6486 2009_004898
6487 2009_004899
6488 2009_004901
6489 2009_004902
6490 2009_004903
6491 2009_004904
6492 2009_004905
6493 2009_004907
6494 2009_004913
6495 2009_004914
6496 2009_004917
6497 2009_004919
6498 2009_004921
6499 2009_004922
6500 2009_004926
6501 2009_004929
6502 2009_004930
6503 2009_004933
6504 2009_004934
6505 2009_004939
6506 2009_004940
6507 2009_004943
6508 2009_004944
6509 2009_004945
6510 2009_004946
6511 2009_004947
6512 2009_004953
6513 2009_004956
6514 2009_004958
6515 2009_004959
6516 2009_004961
6517 2009_004962
6518 2009_004965
6519 2009_004971
6520 2009_004974
6521 2009_004975
6522 2009_004977
6523 2009_004979
6524 2009_004980
6525 2009_004982
6526 2009_004983
6527 2009_004984
6528 2009_004986
6529 2009_004988
6530 2009_004990
6531 2009_004996
6532 2009_004999
6533 2009_005000
6534 2009_005001
6535 2009_005005
6536 2009_005006
6537 2009_005008
6538 2009_005015
6539 2009_005016
6540 2009_005019
6541 2009_005024
6542 2009_005025
6543 2009_005030
6544 2009_005031
6545 2009_005033
6546 2009_005035
6547 2009_005036
6548 2009_005037
6549 2009_005040
6550 2009_005042
6551 2009_005044
6552 2009_005045
6553 2009_005051
6554 2009_005055
6555 2009_005056
6556 2009_005057
6557 2009_005060
6558 2009_005061
6559 2009_005062
6560 2009_005064
6561 2009_005068
6562 2009_005069
6563 2009_005070
6564 2009_005073
6565 2009_005075
6566 2009_005076
6567 2009_005080
6568 2009_005081
6569 2009_005082
6570 2009_005083
6571 2009_005084
6572 2009_005085
6573 2009_005086
6574 2009_005094
6575 2009_005095
6576 2009_005098
6577 2009_005102
6578 2009_005103
6579 2009_005104
6580 2009_005107
6581 2009_005111
6582 2009_005114
6583 2009_005118
6584 2009_005119
6585 2009_005120
6586 2009_005126
6587 2009_005127
6588 2009_005128
6589 2009_005130
6590 2009_005131
6591 2009_005133
6592 2009_005140
6593 2009_005141
6594 2009_005142
6595 2009_005144
6596 2009_005145
6597 2009_005147
6598 2009_005149
6599 2009_005150
6600 2009_005152
6601 2009_005153
6602 2009_005154
6603 2009_005155
6604 2009_005160
6605 2009_005161
6606 2009_005162
6607 2009_005163
6608 2009_005165
6609 2009_005168
6610 2009_005170
6611 2009_005171
6612 2009_005172
6613 2009_005177
6614 2009_005178
6615 2009_005181
6616 2009_005183
6617 2009_005185
6618 2009_005191
6619 2009_005193
6620 2009_005194
6621 2009_005198
6622 2009_005201
6623 2009_005202
6624 2009_005203
6625 2009_005204
6626 2009_005205
6627 2009_005210
6628 2009_005211
6629 2009_005215
6630 2009_005216
6631 2009_005218
6632 2009_005221
6633 2009_005222
6634 2009_005225
6635 2009_005229
6636 2009_005232
6637 2009_005234
6638 2009_005236
6639 2009_005239
6640 2009_005240
6641 2009_005242
6642 2009_005246
6643 2009_005247
6644 2009_005251
6645 2009_005256
6646 2009_005257
6647 2009_005263
6648 2009_005265
6649 2009_005267
6650 2009_005268
6651 2009_005269
6652 2009_005272
6653 2009_005278
6654 2009_005279
6655 2009_005282
6656 2009_005286
6657 2009_005287
6658 2009_005288
6659 2009_005292
6660 2009_005293
6661 2009_005294
6662 2009_005299
6663 2009_005300
6664 2009_005303
6665 2009_005307
6666 2009_005308
6667 2009_005309
6668 2009_005310
6669 2009_005311
6670 2010_000001
6671 2010_000002
6672 2010_000009
6673 2010_000014
6674 2010_000015
6675 2010_000018
6676 2010_000023
6677 2010_000024
6678 2010_000026
6679 2010_000027
6680 2010_000031
6681 2010_000033
6682 2010_000035
6683 2010_000036
6684 2010_000043
6685 2010_000045
6686 2010_000048
6687 2010_000050
6688 2010_000052
6689 2010_000053
6690 2010_000054
6691 2010_000055
6692 2010_000056
6693 2010_000061
6694 2010_000063
6695 2010_000067
6696 2010_000069
6697 2010_000071
6698 2010_000072
6699 2010_000073
6700 2010_000074
6701 2010_000075
6702 2010_000076
6703 2010_000079
6704 2010_000080
6705 2010_000082
6706 2010_000085
6707 2010_000088
6708 2010_000089
6709 2010_000090
6710 2010_000091
6711 2010_000095
6712 2010_000097
6713 2010_000098
6714 2010_000099
6715 2010_000103
6716 2010_000109
6717 2010_000111
6718 2010_000113
6719 2010_000114
6720 2010_000117
6721 2010_000118
6722 2010_000120
6723 2010_000124
6724 2010_000127
6725 2010_000131
6726 2010_000132
6727 2010_000133
6728 2010_000136
6729 2010_000137
6730 2010_000138
6731 2010_000139
6732 2010_000140
6733 2010_000141
6734 2010_000145
6735 2010_000148
6736 2010_000151
6737 2010_000152
6738 2010_000157
6739 2010_000162
6740 2010_000165
6741 2010_000169
6742 2010_000170
6743 2010_000172
6744 2010_000175
6745 2010_000177
6746 2010_000178
6747 2010_000182
6748 2010_000183
6749 2010_000184
6750 2010_000187
6751 2010_000189
6752 2010_000190
6753 2010_000194
6754 2010_000195
6755 2010_000196
6756 2010_000197
6757 2010_000198
6758 2010_000199
6759 2010_000202
6760 2010_000203
6761 2010_000204
6762 2010_000209
6763 2010_000211
6764 2010_000213
6765 2010_000218
6766 2010_000222
6767 2010_000224
6768 2010_000227
6769 2010_000229
6770 2010_000233
6771 2010_000234
6772 2010_000244
6773 2010_000245
6774 2010_000246
6775 2010_000247
6776 2010_000248
6777 2010_000249
6778 2010_000250
6779 2010_000254
6780 2010_000255
6781 2010_000260
6782 2010_000261
6783 2010_000262
6784 2010_000263
6785 2010_000264
6786 2010_000266
6787 2010_000269
6788 2010_000270
6789 2010_000273
6790 2010_000276
6791 2010_000279
6792 2010_000283
6793 2010_000285
6794 2010_000286
6795 2010_000291
6796 2010_000293
6797 2010_000295
6798 2010_000296
6799 2010_000299
6800 2010_000302
6801 2010_000303
6802 2010_000307
6803 2010_000308
6804 2010_000310
6805 2010_000312
6806 2010_000313
6807 2010_000317
6808 2010_000320
6809 2010_000321
6810 2010_000323
6811 2010_000324
6812 2010_000325
6813 2010_000327
6814 2010_000329
6815 2010_000336
6816 2010_000337
6817 2010_000344
6818 2010_000347
6819 2010_000352
6820 2010_000356
6821 2010_000358
6822 2010_000361
6823 2010_000362
6824 2010_000370
6825 2010_000371
6826 2010_000374
6827 2010_000375
6828 2010_000376
6829 2010_000377
6830 2010_000379
6831 2010_000381
6832 2010_000382
6833 2010_000384
6834 2010_000386
6835 2010_000388
6836 2010_000389
6837 2010_000390
6838 2010_000392
6839 2010_000393
6840 2010_000394
6841 2010_000395
6842 2010_000399
6843 2010_000401
6844 2010_000404
6845 2010_000406
6846 2010_000409
6847 2010_000413
6848 2010_000415
6849 2010_000418
6850 2010_000419
6851 2010_000420
6852 2010_000431
6853 2010_000432
6854 2010_000433
6855 2010_000435
6856 2010_000436
6857 2010_000437
6858 2010_000439
6859 2010_000442
6860 2010_000444
6861 2010_000446
6862 2010_000447
6863 2010_000448
6864 2010_000449
6865 2010_000453
6866 2010_000456
6867 2010_000458
6868 2010_000459
6869 2010_000461
6870 2010_000462
6871 2010_000463
6872 2010_000465
6873 2010_000466
6874 2010_000468
6875 2010_000469
6876 2010_000470
6877 2010_000473
6878 2010_000474
6879 2010_000475
6880 2010_000477
6881 2010_000480
6882 2010_000483
6883 2010_000484
6884 2010_000485
6885 2010_000488
6886 2010_000490
6887 2010_000492
6888 2010_000493
6889 2010_000495
6890 2010_000497
6891 2010_000498
6892 2010_000500
6893 2010_000503
6894 2010_000506
6895 2010_000508
6896 2010_000510
6897 2010_000511
6898 2010_000513
6899 2010_000515
6900 2010_000519
6901 2010_000522
6902 2010_000524
6903 2010_000526
6904 2010_000527
6905 2010_000534
6906 2010_000536
6907 2010_000537
6908 2010_000538
6909 2010_000541
6910 2010_000545
6911 2010_000547
6912 2010_000548
6913 2010_000549
6914 2010_000553
6915 2010_000556
6916 2010_000557
6917 2010_000561
6918 2010_000562
6919 2010_000564
6920 2010_000567
6921 2010_000568
6922 2010_000571
6923 2010_000574
6924 2010_000576
6925 2010_000577
6926 2010_000578
6927 2010_000581
6928 2010_000582
6929 2010_000583
6930 2010_000586
6931 2010_000588
6932 2010_000590
6933 2010_000591
6934 2010_000601
6935 2010_000602
6936 2010_000603
6937 2010_000604
6938 2010_000608
6939 2010_000613
6940 2010_000616
6941 2010_000617
6942 2010_000621
6943 2010_000624
6944 2010_000626
6945 2010_000630
6946 2010_000632
6947 2010_000633
6948 2010_000635
6949 2010_000641
6950 2010_000644
6951 2010_000645
6952 2010_000646
6953 2010_000647
6954 2010_000648
6955 2010_000651
6956 2010_000655
6957 2010_000658
6958 2010_000661
6959 2010_000664
6960 2010_000665
6961 2010_000667
6962 2010_000669
6963 2010_000671
6964 2010_000674
6965 2010_000675
6966 2010_000678
6967 2010_000681
6968 2010_000685
6969 2010_000687
6970 2010_000688
6971 2010_000689
6972 2010_000691
6973 2010_000692
6974 2010_000694
6975 2010_000695
6976 2010_000697
6977 2010_000702
6978 2010_000705
6979 2010_000707
6980 2010_000710
6981 2010_000711
6982 2010_000712
6983 2010_000715
6984 2010_000716
6985 2010_000717
6986 2010_000721
6987 2010_000722
6988 2010_000723
6989 2010_000726
6990 2010_000727
6991 2010_000729
6992 2010_000731
6993 2010_000735
6994 2010_000737
6995 2010_000739
6996 2010_000740
6997 2010_000743
6998 2010_000744
6999 2010_000746
7000 2010_000747
7001 2010_000748
7002 2010_000749
7003 2010_000754
7004 2010_000759
7005 2010_000760
7006 2010_000761
7007 2010_000765
7008 2010_000769
7009 2010_000770
7010 2010_000771
7011 2010_000772
7012 2010_000773
7013 2010_000778
7014 2010_000782
7015 2010_000785
7016 2010_000786
7017 2010_000787
7018 2010_000791
7019 2010_000792
7020 2010_000797
7021 2010_000799
7022 2010_000800
7023 2010_000802
7024 2010_000803
7025 2010_000805
7026 2010_000806
7027 2010_000807
7028 2010_000808
7029 2010_000810
7030 2010_000811
7031 2010_000815
7032 2010_000821
7033 2010_000822
7034 2010_000828
7035 2010_000829
7036 2010_000830
7037 2010_000831
7038 2010_000837
7039 2010_000838
7040 2010_000842
7041 2010_000846
7042 2010_000847
7043 2010_000849
7044 2010_000855
7045 2010_000860
7046 2010_000862
7047 2010_000863
7048 2010_000865
7049 2010_000866
7050 2010_000870
7051 2010_000871
7052 2010_000872
7053 2010_000875
7054 2010_000876
7055 2010_000879
7056 2010_000883
7057 2010_000885
7058 2010_000887
7059 2010_000889
7060 2010_000891
7061 2010_000893
7062 2010_000897
7063 2010_000898
7064 2010_000899
7065 2010_000908
7066 2010_000910
7067 2010_000912
7068 2010_000914
7069 2010_000915
7070 2010_000920
7071 2010_000922
7072 2010_000923
7073 2010_000926
7074 2010_000927
7075 2010_000928
7076 2010_000931
7077 2010_000938
7078 2010_000942
7079 2010_000944
7080 2010_000945
7081 2010_000947
7082 2010_000948
7083 2010_000954
7084 2010_000955
7085 2010_000956
7086 2010_000959
7087 2010_000968
7088 2010_000970
7089 2010_000971
7090 2010_000973
7091 2010_000974
7092 2010_000975
7093 2010_000978
7094 2010_000979
7095 2010_000981
7096 2010_000983
7097 2010_000984
7098 2010_000986
7099 2010_000989
7100 2010_000991
7101 2010_000993
7102 2010_000994
7103 2010_000995
7104 2010_000996
7105 2010_001002
7106 2010_001006
7107 2010_001008
7108 2010_001009
7109 2010_001012
7110 2010_001013
7111 2010_001021
7112 2010_001023
7113 2010_001025
7114 2010_001030
7115 2010_001032
7116 2010_001039
7117 2010_001042
7118 2010_001043
7119 2010_001044
7120 2010_001049
7121 2010_001051
7122 2010_001052
7123 2010_001054
7124 2010_001057
7125 2010_001063
7126 2010_001066
7127 2010_001074
7128 2010_001076
7129 2010_001077
7130 2010_001080
7131 2010_001082
7132 2010_001085
7133 2010_001087
7134 2010_001089
7135 2010_001092
7136 2010_001094
7137 2010_001098
7138 2010_001099
7139 2010_001100
7140 2010_001103
7141 2010_001105
7142 2010_001106
7143 2010_001107
7144 2010_001109
7145 2010_001110
7146 2010_001111
7147 2010_001112
7148 2010_001113
7149 2010_001117
7150 2010_001118
7151 2010_001119
7152 2010_001120
7153 2010_001121
7154 2010_001123
7155 2010_001125
7156 2010_001126
7157 2010_001127
7158 2010_001130
7159 2010_001131
7160 2010_001134
7161 2010_001139
7162 2010_001140
7163 2010_001142
7164 2010_001143
7165 2010_001148
7166 2010_001152
7167 2010_001154
7168 2010_001158
7169 2010_001159
7170 2010_001160
7171 2010_001163
7172 2010_001164
7173 2010_001172
7174 2010_001175
7175 2010_001177
7176 2010_001179
7177 2010_001181
7178 2010_001183
7179 2010_001184
7180 2010_001185
7181 2010_001188
7182 2010_001189
7183 2010_001192
7184 2010_001193
7185 2010_001195
7186 2010_001199
7187 2010_001201
7188 2010_001204
7189 2010_001205
7190 2010_001210
7191 2010_001211
7192 2010_001212
7193 2010_001214
7194 2010_001215
7195 2010_001216
7196 2010_001218
7197 2010_001219
7198 2010_001220
7199 2010_001224
7200 2010_001225
7201 2010_001229
7202 2010_001234
7203 2010_001237
7204 2010_001240
7205 2010_001241
7206 2010_001242
7207 2010_001245
7208 2010_001247
7209 2010_001250
7210 2010_001253
7211 2010_001254
7212 2010_001257
7213 2010_001261
7214 2010_001263
7215 2010_001270
7216 2010_001271
7217 2010_001272
7218 2010_001273
7219 2010_001274
7220 2010_001275
7221 2010_001277
7222 2010_001279
7223 2010_001282
7224 2010_001286
7225 2010_001287
7226 2010_001288
7227 2010_001289
7228 2010_001291
7229 2010_001293
7230 2010_001294
7231 2010_001301
7232 2010_001305
7233 2010_001310
7234 2010_001311
7235 2010_001312
7236 2010_001315
7237 2010_001317
7238 2010_001320
7239 2010_001321
7240 2010_001325
7241 2010_001326
7242 2010_001328
7243 2010_001329
7244 2010_001333
7245 2010_001337
7246 2010_001338
7247 2010_001339
7248 2010_001343
7249 2010_001344
7250 2010_001347
7251 2010_001355
7252 2010_001356
7253 2010_001357
7254 2010_001360
7255 2010_001361
7256 2010_001363
7257 2010_001364
7258 2010_001366
7259 2010_001370
7260 2010_001372
7261 2010_001374
7262 2010_001382
7263 2010_001383
7264 2010_001385
7265 2010_001386
7266 2010_001390
7267 2010_001394
7268 2010_001395
7269 2010_001397
7270 2010_001399
7271 2010_001401
7272 2010_001402
7273 2010_001405
7274 2010_001406
7275 2010_001407
7276 2010_001408
7277 2010_001410
7278 2010_001411
7279 2010_001412
7280 2010_001413
7281 2010_001417
7282 2010_001418
7283 2010_001421
7284 2010_001422
7285 2010_001425
7286 2010_001426
7287 2010_001430
7288 2010_001431
7289 2010_001432
7290 2010_001433
7291 2010_001434
7292 2010_001435
7293 2010_001441
7294 2010_001449
7295 2010_001450
7296 2010_001452
7297 2010_001453
7298 2010_001455
7299 2010_001456
7300 2010_001457
7301 2010_001458
7302 2010_001461
7303 2010_001463
7304 2010_001464
7305 2010_001465
7306 2010_001468
7307 2010_001472
7308 2010_001473
7309 2010_001478
7310 2010_001479
7311 2010_001480
7312 2010_001481
7313 2010_001486
7314 2010_001487
7315 2010_001497
7316 2010_001499
7317 2010_001501
7318 2010_001502
7319 2010_001503
7320 2010_001505
7321 2010_001511
7322 2010_001514
7323 2010_001515
7324 2010_001516
7325 2010_001518
7326 2010_001520
7327 2010_001525
7328 2010_001528
7329 2010_001529
7330 2010_001533
7331 2010_001535
7332 2010_001536
7333 2010_001537
7334 2010_001539
7335 2010_001540
7336 2010_001543
7337 2010_001544
7338 2010_001547
7339 2010_001548
7340 2010_001550
7341 2010_001551
7342 2010_001552
7343 2010_001555
7344 2010_001560
7345 2010_001561
7346 2010_001562
7347 2010_001569
7348 2010_001571
7349 2010_001572
7350 2010_001574
7351 2010_001576
7352 2010_001580
7353 2010_001583
7354 2010_001584
7355 2010_001586
7356 2010_001587
7357 2010_001590
7358 2010_001592
7359 2010_001594
7360 2010_001595
7361 2010_001596
7362 2010_001599
7363 2010_001601
7364 2010_001602
7365 2010_001603
7366 2010_001606
7367 2010_001607
7368 2010_001608
7369 2010_001614
7370 2010_001618
7371 2010_001619
7372 2010_001625
7373 2010_001626
7374 2010_001630
7375 2010_001633
7376 2010_001635
7377 2010_001636
7378 2010_001637
7379 2010_001638
7380 2010_001640
7381 2010_001644
7382 2010_001645
7383 2010_001647
7384 2010_001649
7385 2010_001650
7386 2010_001652
7387 2010_001659
7388 2010_001660
7389 2010_001665
7390 2010_001668
7391 2010_001669
7392 2010_001671
7393 2010_001674
7394 2010_001675
7395 2010_001676
7396 2010_001679
7397 2010_001680
7398 2010_001682
7399 2010_001685
7400 2010_001687
7401 2010_001689
7402 2010_001690
7403 2010_001694
7404 2010_001697
7405 2010_001698
7406 2010_001700
7407 2010_001705
7408 2010_001706
7409 2010_001709
7410 2010_001710
7411 2010_001712
7412 2010_001715
7413 2010_001717
7414 2010_001718
7415 2010_001719
7416 2010_001720
7417 2010_001726
7418 2010_001729
7419 2010_001731
7420 2010_001732
7421 2010_001737
7422 2010_001739
7423 2010_001743
7424 2010_001744
7425 2010_001746
7426 2010_001747
7427 2010_001748
7428 2010_001749
7429 2010_001753
7430 2010_001754
7431 2010_001756
7432 2010_001757
7433 2010_001759
7434 2010_001760
7435 2010_001762
7436 2010_001763
7437 2010_001771
7438 2010_001776
7439 2010_001777
7440 2010_001780
7441 2010_001783
7442 2010_001784
7443 2010_001785
7444 2010_001787
7445 2010_001788
7446 2010_001794
7447 2010_001795
7448 2010_001796
7449 2010_001797
7450 2010_001801
7451 2010_001803
7452 2010_001806
7453 2010_001807
7454 2010_001808
7455 2010_001810
7456 2010_001814
7457 2010_001817
7458 2010_001819
7459 2010_001821
7460 2010_001823
7461 2010_001827
7462 2010_001828
7463 2010_001829
7464 2010_001837
7465 2010_001838
7466 2010_001841
7467 2010_001842
7468 2010_001843
7469 2010_001845
7470 2010_001846
7471 2010_001849
7472 2010_001850
7473 2010_001852
7474 2010_001853
7475 2010_001856
7476 2010_001857
7477 2010_001858
7478 2010_001860
7479 2010_001863
7480 2010_001864
7481 2010_001868
7482 2010_001869
7483 2010_001870
7484 2010_001877
7485 2010_001881
7486 2010_001884
7487 2010_001885
7488 2010_001891
7489 2010_001892
7490 2010_001893
7491 2010_001896
7492 2010_001899
7493 2010_001904
7494 2010_001907
7495 2010_001911
7496 2010_001916
7497 2010_001918
7498 2010_001919
7499 2010_001921
7500 2010_001922
7501 2010_001923
7502 2010_001924
7503 2010_001927
7504 2010_001929
7505 2010_001931
7506 2010_001933
7507 2010_001934
7508 2010_001937
7509 2010_001938
7510 2010_001939
7511 2010_001940
7512 2010_001941
7513 2010_001944
7514 2010_001948
7515 2010_001950
7516 2010_001954
7517 2010_001957
7518 2010_001960
7519 2010_001967
7520 2010_001968
7521 2010_001970
7522 2010_001973
7523 2010_001974
7524 2010_001976
7525 2010_001978
7526 2010_001979
7527 2010_001980
7528 2010_001981
7529 2010_001982
7530 2010_001986
7531 2010_001987
7532 2010_001988
7533 2010_001992
7534 2010_001993
7535 2010_001994
7536 2010_001998
7537 2010_002000
7538 2010_002002
7539 2010_002005
7540 2010_002006
7541 2010_002015
7542 2010_002018
7543 2010_002019
7544 2010_002020
7545 2010_002022
7546 2010_002023
7547 2010_002026
7548 2010_002029
7549 2010_002032
7550 2010_002037
7551 2010_002039
7552 2010_002040
7553 2010_002041
7554 2010_002042
7555 2010_002044
7556 2010_002045
7557 2010_002046
7558 2010_002047
7559 2010_002048
7560 2010_002050
7561 2010_002054
7562 2010_002055
7563 2010_002057
7564 2010_002058
7565 2010_002060
7566 2010_002065
7567 2010_002067
7568 2010_002068
7569 2010_002070
7570 2010_002073
7571 2010_002080
7572 2010_002085
7573 2010_002086
7574 2010_002089
7575 2010_002094
7576 2010_002095
7577 2010_002096
7578 2010_002097
7579 2010_002098
7580 2010_002100
7581 2010_002102
7582 2010_002104
7583 2010_002105
7584 2010_002107
7585 2010_002113
7586 2010_002117
7587 2010_002118
7588 2010_002121
7589 2010_002124
7590 2010_002127
7591 2010_002128
7592 2010_002129
7593 2010_002130
7594 2010_002132
7595 2010_002133
7596 2010_002136
7597 2010_002138
7598 2010_002139
7599 2010_002143
7600 2010_002149
7601 2010_002152
7602 2010_002154
7603 2010_002166
7604 2010_002167
7605 2010_002168
7606 2010_002172
7607 2010_002175
7608 2010_002176
7609 2010_002177
7610 2010_002179
7611 2010_002180
7612 2010_002181
7613 2010_002182
7614 2010_002183
7615 2010_002185
7616 2010_002187
7617 2010_002191
7618 2010_002192
7619 2010_002193
7620 2010_002194
7621 2010_002195
7622 2010_002199
7623 2010_002203
7624 2010_002204
7625 2010_002207
7626 2010_002208
7627 2010_002211
7628 2010_002213
7629 2010_002215
7630 2010_002216
7631 2010_002218
7632 2010_002219
7633 2010_002220
7634 2010_002221
7635 2010_002223
7636 2010_002224
7637 2010_002226
7638 2010_002227
7639 2010_002229
7640 2010_002236
7641 2010_002242
7642 2010_002243
7643 2010_002244
7644 2010_002245
7645 2010_002247
7646 2010_002248
7647 2010_002254
7648 2010_002255
7649 2010_002261
7650 2010_002263
7651 2010_002269
7652 2010_002274
7653 2010_002276
7654 2010_002278
7655 2010_002279
7656 2010_002283
7657 2010_002286
7658 2010_002287
7659 2010_002289
7660 2010_002294
7661 2010_002295
7662 2010_002299
7663 2010_002301
7664 2010_002303
7665 2010_002307
7666 2010_002309
7667 2010_002312
7668 2010_002313
7669 2010_002315
7670 2010_002316
7671 2010_002318
7672 2010_002319
7673 2010_002320
7674 2010_002321
7675 2010_002326
7676 2010_002327
7677 2010_002332
7678 2010_002333
7679 2010_002337
7680 2010_002338
7681 2010_002340
7682 2010_002346
7683 2010_002349
7684 2010_002353
7685 2010_002354
7686 2010_002356
7687 2010_002357
7688 2010_002363
7689 2010_002364
7690 2010_002365
7691 2010_002366
7692 2010_002368
7693 2010_002369
7694 2010_002370
7695 2010_002371
7696 2010_002373
7697 2010_002374
7698 2010_002378
7699 2010_002379
7700 2010_002382
7701 2010_002383
7702 2010_002387
7703 2010_002388
7704 2010_002391
7705 2010_002392
7706 2010_002393
7707 2010_002398
7708 2010_002399
7709 2010_002400
7710 2010_002402
7711 2010_002405
7712 2010_002406
7713 2010_002408
7714 2010_002409
7715 2010_002410
7716 2010_002413
7717 2010_002418
7718 2010_002420
7719 2010_002424
7720 2010_002425
7721 2010_002427
7722 2010_002429
7723 2010_002431
7724 2010_002435
7725 2010_002436
7726 2010_002438
7727 2010_002439
7728 2010_002440
7729 2010_002445
7730 2010_002446
7731 2010_002448
7732 2010_002449
7733 2010_002452
7734 2010_002455
7735 2010_002456
7736 2010_002457
7737 2010_002458
7738 2010_002459
7739 2010_002460
7740 2010_002461
7741 2010_002462
7742 2010_002468
7743 2010_002469
7744 2010_002472
7745 2010_002475
7746 2010_002479
7747 2010_002482
7748 2010_002484
7749 2010_002485
7750 2010_002487
7751 2010_002492
7752 2010_002496
7753 2010_002497
7754 2010_002498
7755 2010_002499
7756 2010_002501
7757 2010_002504
7758 2010_002507
7759 2010_002509
7760 2010_002510
7761 2010_002513
7762 2010_002516
7763 2010_002518
7764 2010_002520
7765 2010_002526
7766 2010_002527
7767 2010_002529
7768 2010_002532
7769 2010_002533
7770 2010_002534
7771 2010_002537
7772 2010_002539
7773 2010_002542
7774 2010_002543
7775 2010_002547
7776 2010_002551
7777 2010_002552
7778 2010_002553
7779 2010_002556
7780 2010_002561
7781 2010_002562
7782 2010_002565
7783 2010_002567
7784 2010_002569
7785 2010_002570
7786 2010_002573
7787 2010_002575
7788 2010_002577
7789 2010_002578
7790 2010_002579
7791 2010_002580
7792 2010_002582
7793 2010_002583
7794 2010_002586
7795 2010_002587
7796 2010_002589
7797 2010_002592
7798 2010_002594
7799 2010_002597
7800 2010_002598
7801 2010_002601
7802 2010_002602
7803 2010_002603
7804 2010_002605
7805 2010_002614
7806 2010_002615
7807 2010_002616
7808 2010_002618
7809 2010_002620
7810 2010_002621
7811 2010_002624
7812 2010_002625
7813 2010_002626
7814 2010_002628
7815 2010_002629
7816 2010_002631
7817 2010_002632
7818 2010_002638
7819 2010_002639
7820 2010_002642
7821 2010_002644
7822 2010_002645
7823 2010_002647
7824 2010_002652
7825 2010_002653
7826 2010_002654
7827 2010_002656
7828 2010_002659
7829 2010_002660
7830 2010_002661
7831 2010_002662
7832 2010_002665
7833 2010_002666
7834 2010_002667
7835 2010_002668
7836 2010_002674
7837 2010_002675
7838 2010_002676
7839 2010_002678
7840 2010_002679
7841 2010_002684
7842 2010_002686
7843 2010_002688
7844 2010_002692
7845 2010_002695
7846 2010_002696
7847 2010_002697
7848 2010_002702
7849 2010_002704
7850 2010_002705
7851 2010_002708
7852 2010_002710
7853 2010_002713
7854 2010_002714
7855 2010_002716
7856 2010_002720
7857 2010_002721
7858 2010_002722
7859 2010_002723
7860 2010_002725
7861 2010_002728
7862 2010_002729
7863 2010_002733
7864 2010_002734
7865 2010_002736
7866 2010_002737
7867 2010_002740
7868 2010_002741
7869 2010_002742
7870 2010_002746
7871 2010_002747
7872 2010_002750
7873 2010_002752
7874 2010_002754
7875 2010_002758
7876 2010_002759
7877 2010_002760
7878 2010_002767
7879 2010_002770
7880 2010_002771
7881 2010_002772
7882 2010_002774
7883 2010_002775
7884 2010_002778
7885 2010_002779
7886 2010_002780
7887 2010_002781
7888 2010_002783
7889 2010_002786
7890 2010_002789
7891 2010_002790
7892 2010_002791
7893 2010_002793
7894 2010_002794
7895 2010_002797
7896 2010_002801
7897 2010_002803
7898 2010_002805
7899 2010_002807
7900 2010_002808
7901 2010_002811
7902 2010_002813
7903 2010_002814
7904 2010_002815
7905 2010_002816
7906 2010_002817
7907 2010_002820
7908 2010_002821
7909 2010_002822
7910 2010_002824
7911 2010_002827
7912 2010_002830
7913 2010_002831
7914 2010_002834
7915 2010_002838
7916 2010_002839
7917 2010_002840
7918 2010_002841
7919 2010_002843
7920 2010_002844
7921 2010_002845
7922 2010_002851
7923 2010_002853
7924 2010_002854
7925 2010_002855
7926 2010_002856
7927 2010_002857
7928 2010_002858
7929 2010_002860
7930 2010_002864
7931 2010_002865
7932 2010_002870
7933 2010_002871
7934 2010_002873
7935 2010_002876
7936 2010_002877
7937 2010_002879
7938 2010_002880
7939 2010_002881
7940 2010_002884
7941 2010_002887
7942 2010_002891
7943 2010_002892
7944 2010_002896
7945 2010_002899
7946 2010_002901
7947 2010_002903
7948 2010_002905
7949 2010_002907
7950 2010_002909
7951 2010_002914
7952 2010_002915
7953 2010_002917
7954 2010_002924
7955 2010_002927
7956 2010_002930
7957 2010_002931
7958 2010_002935
7959 2010_002937
7960 2010_002938
7961 2010_002940
7962 2010_002941
7963 2010_002946
7964 2010_002947
7965 2010_002948
7966 2010_002954
7967 2010_002955
7968 2010_002956
7969 2010_002958
7970 2010_002960
7971 2010_002962
7972 2010_002965
7973 2010_002972
7974 2010_002973
7975 2010_002976
7976 2010_002978
7977 2010_002979
7978 2010_002980
7979 2010_002982
7980 2010_002985
7981 2010_002987
7982 2010_002990
7983 2010_002991
7984 2010_002993
7985 2010_002995
7986 2010_003002
7987 2010_003003
7988 2010_003007
7989 2010_003010
7990 2010_003011
7991 2010_003013
7992 2010_003015
7993 2010_003016
7994 2010_003017
7995 2010_003019
7996 2010_003024
7997 2010_003025
7998 2010_003027
7999 2010_003028
8000 2010_003032
8001 2010_003034
8002 2010_003035
8003 2010_003037
8004 2010_003040
8005 2010_003043
8006 2010_003044
8007 2010_003047
8008 2010_003050
8009 2010_003051
8010 2010_003053
8011 2010_003054
8012 2010_003055
8013 2010_003056
8014 2010_003057
8015 2010_003062
8016 2010_003067
8017 2010_003071
8018 2010_003072
8019 2010_003074
8020 2010_003077
8021 2010_003078
8022 2010_003081
8023 2010_003082
8024 2010_003084
8025 2010_003086
8026 2010_003088
8027 2010_003091
8028 2010_003092
8029 2010_003093
8030 2010_003094
8031 2010_003097
8032 2010_003098
8033 2010_003101
8034 2010_003102
8035 2010_003103
8036 2010_003106
8037 2010_003107
8038 2010_003108
8039 2010_003112
8040 2010_003114
8041 2010_003115
8042 2010_003117
8043 2010_003119
8044 2010_003120
8045 2010_003122
8046 2010_003129
8047 2010_003133
8048 2010_003135
8049 2010_003137
8050 2010_003138
8051 2010_003139
8052 2010_003143
8053 2010_003146
8054 2010_003147
8055 2010_003148
8056 2010_003149
8057 2010_003151
8058 2010_003153
8059 2010_003154
8060 2010_003156
8061 2010_003157
8062 2010_003159
8063 2010_003160
8064 2010_003162
8065 2010_003169
8066 2010_003170
8067 2010_003173
8068 2010_003174
8069 2010_003176
8070 2010_003179
8071 2010_003185
8072 2010_003186
8073 2010_003190
8074 2010_003191
8075 2010_003192
8076 2010_003197
8077 2010_003199
8078 2010_003200
8079 2010_003201
8080 2010_003203
8081 2010_003204
8082 2010_003206
8083 2010_003212
8084 2010_003214
8085 2010_003218
8086 2010_003219
8087 2010_003220
8088 2010_003222
8089 2010_003223
8090 2010_003227
8091 2010_003230
8092 2010_003232
8093 2010_003233
8094 2010_003236
8095 2010_003238
8096 2010_003240
8097 2010_003241
8098 2010_003244
8099 2010_003248
8100 2010_003249
8101 2010_003250
8102 2010_003251
8103 2010_003252
8104 2010_003253
8105 2010_003255
8106 2010_003256
8107 2010_003257
8108 2010_003259
8109 2010_003260
8110 2010_003263
8111 2010_003264
8112 2010_003269
8113 2010_003270
8114 2010_003274
8115 2010_003278
8116 2010_003279
8117 2010_003280
8118 2010_003283
8119 2010_003285
8120 2010_003287
8121 2010_003290
8122 2010_003291
8123 2010_003297
8124 2010_003299
8125 2010_003300
8126 2010_003301
8127 2010_003303
8128 2010_003304
8129 2010_003305
8130 2010_003309
8131 2010_003314
8132 2010_003316
8133 2010_003321
8134 2010_003326
8135 2010_003329
8136 2010_003331
8137 2010_003332
8138 2010_003333
8139 2010_003335
8140 2010_003337
8141 2010_003341
8142 2010_003342
8143 2010_003343
8144 2010_003344
8145 2010_003345
8146 2010_003350
8147 2010_003351
8148 2010_003353
8149 2010_003355
8150 2010_003358
8151 2010_003361
8152 2010_003366
8153 2010_003367
8154 2010_003368
8155 2010_003370
8156 2010_003371
8157 2010_003372
8158 2010_003374
8159 2010_003375
8160 2010_003376
8161 2010_003379
8162 2010_003380
8163 2010_003383
8164 2010_003384
8165 2010_003385
8166 2010_003390
8167 2010_003391
8168 2010_003395
8169 2010_003397
8170 2010_003398
8171 2010_003400
8172 2010_003401
8173 2010_003405
8174 2010_003406
8175 2010_003411
8176 2010_003415
8177 2010_003419
8178 2010_003421
8179 2010_003427
8180 2010_003429
8181 2010_003432
8182 2010_003435
8183 2010_003436
8184 2010_003437
8185 2010_003439
8186 2010_003450
8187 2010_003451
8188 2010_003458
8189 2010_003461
8190 2010_003465
8191 2010_003467
8192 2010_003469
8193 2010_003470
8194 2010_003474
8195 2010_003477
8196 2010_003478
8197 2010_003479
8198 2010_003481
8199 2010_003482
8200 2010_003483
8201 2010_003488
8202 2010_003490
8203 2010_003491
8204 2010_003493
8205 2010_003496
8206 2010_003497
8207 2010_003503
8208 2010_003507
8209 2010_003508
8210 2010_003509
8211 2010_003512
8212 2010_003513
8213 2010_003520
8214 2010_003522
8215 2010_003526
8216 2010_003527
8217 2010_003529
8218 2010_003534
8219 2010_003535
8220 2010_003537
8221 2010_003538
8222 2010_003539
8223 2010_003540
8224 2010_003546
8225 2010_003549
8226 2010_003551
8227 2010_003554
8228 2010_003556
8229 2010_003559
8230 2010_003560
8231 2010_003561
8232 2010_003562
8233 2010_003563
8234 2010_003567
8235 2010_003568
8236 2010_003569
8237 2010_003573
8238 2010_003574
8239 2010_003576
8240 2010_003579
8241 2010_003582
8242 2010_003585
8243 2010_003588
8244 2010_003592
8245 2010_003594
8246 2010_003598
8247 2010_003599
8248 2010_003601
8249 2010_003603
8250 2010_003604
8251 2010_003605
8252 2010_003608
8253 2010_003609
8254 2010_003610
8255 2010_003612
8256 2010_003613
8257 2010_003618
8258 2010_003625
8259 2010_003628
8260 2010_003629
8261 2010_003630
8262 2010_003632
8263 2010_003634
8264 2010_003635
8265 2010_003640
8266 2010_003641
8267 2010_003643
8268 2010_003644
8269 2010_003645
8270 2010_003648
8271 2010_003649
8272 2010_003651
8273 2010_003653
8274 2010_003655
8275 2010_003656
8276 2010_003659
8277 2010_003664
8278 2010_003665
8279 2010_003667
8280 2010_003670
8281 2010_003671
8282 2010_003672
8283 2010_003673
8284 2010_003674
8285 2010_003677
8286 2010_003679
8287 2010_003680
8288 2010_003686
8289 2010_003687
8290 2010_003688
8291 2010_003689
8292 2010_003690
8293 2010_003695
8294 2010_003696
8295 2010_003701
8296 2010_003703
8297 2010_003709
8298 2010_003714
8299 2010_003717
8300 2010_003719
8301 2010_003721
8302 2010_003723
8303 2010_003724
8304 2010_003725
8305 2010_003728
8306 2010_003729
8307 2010_003730
8308 2010_003731
8309 2010_003734
8310 2010_003735
8311 2010_003736
8312 2010_003737
8313 2010_003742
8314 2010_003743
8315 2010_003744
8316 2010_003745
8317 2010_003747
8318 2010_003752
8319 2010_003754
8320 2010_003755
8321 2010_003757
8322 2010_003761
8323 2010_003762
8324 2010_003770
8325 2010_003773
8326 2010_003774
8327 2010_003779
8328 2010_003784
8329 2010_003788
8330 2010_003789
8331 2010_003791
8332 2010_003792
8333 2010_003798
8334 2010_003799
8335 2010_003800
8336 2010_003801
8337 2010_003804
8338 2010_003805
8339 2010_003806
8340 2010_003807
8341 2010_003811
8342 2010_003815
8343 2010_003816
8344 2010_003818
8345 2010_003821
8346 2010_003822
8347 2010_003823
8348 2010_003825
8349 2010_003826
8350 2010_003828
8351 2010_003837
8352 2010_003844
8353 2010_003845
8354 2010_003847
8355 2010_003848
8356 2010_003852
8357 2010_003855
8358 2010_003856
8359 2010_003857
8360 2010_003859
8361 2010_003860
8362 2010_003861
8363 2010_003863
8364 2010_003864
8365 2010_003865
8366 2010_003871
8367 2010_003874
8368 2010_003875
8369 2010_003877
8370 2010_003878
8371 2010_003879
8372 2010_003884
8373 2010_003887
8374 2010_003890
8375 2010_003891
8376 2010_003892
8377 2010_003893
8378 2010_003894
8379 2010_003897
8380 2010_003898
8381 2010_003899
8382 2010_003900
8383 2010_003906
8384 2010_003910
8385 2010_003911
8386 2010_003914
8387 2010_003919
8388 2010_003920
8389 2010_003925
8390 2010_003928
8391 2010_003929
8392 2010_003931
8393 2010_003933
8394 2010_003936
8395 2010_003937
8396 2010_003938
8397 2010_003939
8398 2010_003942
8399 2010_003943
8400 2010_003944
8401 2010_003945
8402 2010_003949
8403 2010_003950
8404 2010_003954
8405 2010_003955
8406 2010_003957
8407 2010_003958
8408 2010_003961
8409 2010_003966
8410 2010_003970
8411 2010_003974
8412 2010_003976
8413 2010_003980
8414 2010_003981
8415 2010_003982
8416 2010_003983
8417 2010_003987
8418 2010_003988
8419 2010_003994
8420 2010_003995
8421 2010_003996
8422 2010_003999
8423 2010_004002
8424 2010_004005
8425 2010_004006
8426 2010_004007
8427 2010_004008
8428 2010_004009
8429 2010_004014
8430 2010_004017
8431 2010_004021
8432 2010_004023
8433 2010_004025
8434 2010_004026
8435 2010_004027
8436 2010_004028
8437 2010_004029
8438 2010_004030
8439 2010_004031
8440 2010_004033
8441 2010_004036
8442 2010_004037
8443 2010_004043
8444 2010_004045
8445 2010_004048
8446 2010_004050
8447 2010_004052
8448 2010_004053
8449 2010_004054
8450 2010_004059
8451 2010_004060
8452 2010_004061
8453 2010_004062
8454 2010_004064
8455 2010_004065
8456 2010_004066
8457 2010_004067
8458 2010_004069
8459 2010_004071
8460 2010_004072
8461 2010_004073
8462 2010_004074
8463 2010_004075
8464 2010_004081
8465 2010_004084
8466 2010_004088
8467 2010_004089
8468 2010_004092
8469 2010_004094
8470 2010_004095
8471 2010_004096
8472 2010_004102
8473 2010_004105
8474 2010_004107
8475 2010_004108
8476 2010_004109
8477 2010_004111
8478 2010_004116
8479 2010_004118
8480 2010_004119
8481 2010_004121
8482 2010_004123
8483 2010_004124
8484 2010_004125
8485 2010_004129
8486 2010_004130
8487 2010_004133
8488 2010_004137
8489 2010_004138
8490 2010_004139
8491 2010_004140
8492 2010_004141
8493 2010_004143
8494 2010_004144
8495 2010_004145
8496 2010_004148
8497 2010_004154
8498 2010_004157
8499 2010_004160
8500 2010_004161
8501 2010_004162
8502 2010_004163
8503 2010_004168
8504 2010_004171
8505 2010_004172
8506 2010_004173
8507 2010_004175
8508 2010_004178
8509 2010_004179
8510 2010_004180
8511 2010_004182
8512 2010_004184
8513 2010_004186
8514 2010_004187
8515 2010_004188
8516 2010_004191
8517 2010_004193
8518 2010_004197
8519 2010_004198
8520 2010_004201
8521 2010_004204
8522 2010_004207
8523 2010_004209
8524 2010_004210
8525 2010_004211
8526 2010_004216
8527 2010_004222
8528 2010_004223
8529 2010_004224
8530 2010_004225
8531 2010_004227
8532 2010_004228
8533 2010_004229
8534 2010_004230
8535 2010_004231
8536 2010_004238
8537 2010_004239
8538 2010_004242
8539 2010_004244
8540 2010_004247
8541 2010_004248
8542 2010_004249
8543 2010_004252
8544 2010_004253
8545 2010_004254
8546 2010_004256
8547 2010_004257
8548 2010_004258
8549 2010_004259
8550 2010_004263
8551 2010_004264
8552 2010_004271
8553 2010_004275
8554 2010_004276
8555 2010_004278
8556 2010_004279
8557 2010_004280
8558 2010_004282
8559 2010_004283
8560 2010_004286
8561 2010_004288
8562 2010_004289
8563 2010_004290
8564 2010_004291
8565 2010_004295
8566 2010_004296
8567 2010_004297
8568 2010_004301
8569 2010_004304
8570 2010_004306
8571 2010_004307
8572 2010_004311
8573 2010_004312
8574 2010_004313
8575 2010_004318
8576 2010_004325
8577 2010_004327
8578 2010_004332
8579 2010_004333
8580 2010_004335
8581 2010_004336
8582 2010_004339
8583 2010_004341
8584 2010_004344
8585 2010_004345
8586 2010_004346
8587 2010_004349
8588 2010_004350
8589 2010_004351
8590 2010_004352
8591 2010_004357
8592 2010_004358
8593 2010_004360
8594 2010_004361
8595 2010_004362
8596 2010_004363
8597 2010_004365
8598 2010_004366
8599 2010_004367
8600 2010_004368
8601 2010_004370
8602 2010_004371
8603 2010_004373
8604 2010_004374
8605 2010_004380
8606 2010_004385
8607 2010_004387
8608 2010_004390
8609 2010_004391
8610 2010_004400
8611 2010_004402
8612 2010_004404
8613 2010_004409
8614 2010_004412
8615 2010_004415
8616 2010_004417
8617 2010_004420
8618 2010_004422
8619 2010_004425
8620 2010_004428
8621 2010_004429
8622 2010_004431
8623 2010_004436
8624 2010_004439
8625 2010_004441
8626 2010_004445
8627 2010_004447
8628 2010_004448
8629 2010_004450
8630 2010_004451
8631 2010_004455
8632 2010_004456
8633 2010_004457
8634 2010_004459
8635 2010_004460
8636 2010_004461
8637 2010_004466
8638 2010_004467
8639 2010_004469
8640 2010_004475
8641 2010_004476
8642 2010_004477
8643 2010_004478
8644 2010_004481
8645 2010_004483
8646 2010_004484
8647 2010_004486
8648 2010_004488
8649 2010_004491
8650 2010_004492
8651 2010_004493
8652 2010_004499
8653 2010_004501
8654 2010_004503
8655 2010_004505
8656 2010_004506
8657 2010_004509
8658 2010_004511
8659 2010_004514
8660 2010_004515
8661 2010_004517
8662 2010_004518
8663 2010_004521
8664 2010_004523
8665 2010_004533
8666 2010_004536
8667 2010_004537
8668 2010_004540
8669 2010_004542
8670 2010_004545
8671 2010_004546
8672 2010_004553
8673 2010_004554
8674 2010_004557
8675 2010_004558
8676 2010_004560
8677 2010_004561
8678 2010_004567
8679 2010_004569
8680 2010_004570
8681 2010_004573
8682 2010_004575
8683 2010_004576
8684 2010_004577
8685 2010_004581
8686 2010_004584
8687 2010_004585
8688 2010_004586
8689 2010_004588
8690 2010_004591
8691 2010_004592
8692 2010_004594
8693 2010_004596
8694 2010_004597
8695 2010_004598
8696 2010_004601
8697 2010_004604
8698 2010_004609
8699 2010_004616
8700 2010_004618
8701 2010_004620
8702 2010_004621
8703 2010_004624
8704 2010_004625
8705 2010_004627
8706 2010_004629
8707 2010_004631
8708 2010_004634
8709 2010_004637
8710 2010_004638
8711 2010_004642
8712 2010_004646
8713 2010_004654
8714 2010_004655
8715 2010_004656
8716 2010_004657
8717 2010_004659
8718 2010_004660
8719 2010_004661
8720 2010_004665
8721 2010_004666
8722 2010_004667
8723 2010_004669
8724 2010_004672
8725 2010_004676
8726 2010_004677
8727 2010_004679
8728 2010_004680
8729 2010_004681
8730 2010_004683
8731 2010_004686
8732 2010_004690
8733 2010_004691
8734 2010_004692
8735 2010_004694
8736 2010_004696
8737 2010_004698
8738 2010_004703
8739 2010_004704
8740 2010_004708
8741 2010_004710
8742 2010_004712
8743 2010_004714
8744 2010_004717
8745 2010_004721
8746 2010_004722
8747 2010_004726
8748 2010_004728
8749 2010_004729
8750 2010_004730
8751 2010_004733
8752 2010_004735
8753 2010_004738
8754 2010_004741
8755 2010_004743
8756 2010_004747
8757 2010_004748
8758 2010_004749
8759 2010_004750
8760 2010_004751
8761 2010_004753
8762 2010_004756
8763 2010_004760
8764 2010_004765
8765 2010_004766
8766 2010_004768
8767 2010_004770
8768 2010_004773
8769 2010_004775
8770 2010_004777
8771 2010_004778
8772 2010_004779
8773 2010_004782
8774 2010_004785
8775 2010_004786
8776 2010_004791
8777 2010_004792
8778 2010_004793
8779 2010_004797
8780 2010_004804
8781 2010_004805
8782 2010_004806
8783 2010_004807
8784 2010_004808
8785 2010_004809
8786 2010_004812
8787 2010_004813
8788 2010_004816
8789 2010_004817
8790 2010_004821
8791 2010_004822
8792 2010_004824
8793 2010_004826
8794 2010_004829
8795 2010_004830
8796 2010_004832
8797 2010_004836
8798 2010_004838
8799 2010_004841
8800 2010_004844
8801 2010_004847
8802 2010_004848
8803 2010_004849
8804 2010_004852
8805 2010_004854
8806 2010_004855
8807 2010_004865
8808 2010_004866
8809 2010_004868
8810 2010_004871
8811 2010_004874
8812 2010_004877
8813 2010_004878
8814 2010_004879
8815 2010_004888
8816 2010_004889
8817 2010_004890
8818 2010_004891
8819 2010_004894
8820 2010_004896
8821 2010_004900
8822 2010_004901
8823 2010_004903
8824 2010_004906
8825 2010_004908
8826 2010_004909
8827 2010_004910
8828 2010_004913
8829 2010_004916
8830 2010_004917
8831 2010_004918
8832 2010_004919
8833 2010_004921
8834 2010_004922
8835 2010_004928
8836 2010_004930
8837 2010_004931
8838 2010_004933
8839 2010_004937
8840 2010_004938
8841 2010_004942
8842 2010_004943
8843 2010_004944
8844 2010_004945
8845 2010_004948
8846 2010_004950
8847 2010_004952
8848 2010_004953
8849 2010_004954
8850 2010_004957
8851 2010_004959
8852 2010_004960
8853 2010_004962
8854 2010_004963
8855 2010_004966
8856 2010_004967
8857 2010_004968
8858 2010_004970
8859 2010_004971
8860 2010_004973
8861 2010_004974
8862 2010_004982
8863 2010_004983
8864 2010_004987
8865 2010_004989
8866 2010_004991
8867 2010_004992
8868 2010_004995
8869 2010_004997
8870 2010_004998
8871 2010_005000
8872 2010_005002
8873 2010_005005
8874 2010_005006
8875 2010_005008
8876 2010_005011
8877 2010_005016
8878 2010_005017
8879 2010_005018
8880 2010_005019
8881 2010_005022
8882 2010_005023
8883 2010_005026
8884 2010_005028
8885 2010_005031
8886 2010_005033
8887 2010_005035
8888 2010_005041
8889 2010_005042
8890 2010_005044
8891 2010_005048
8892 2010_005049
8893 2010_005052
8894 2010_005053
8895 2010_005054
8896 2010_005055
8897 2010_005059
8898 2010_005060
8899 2010_005061
8900 2010_005062
8901 2010_005064
8902 2010_005066
8903 2010_005068
8904 2010_005071
8905 2010_005072
8906 2010_005075
8907 2010_005079
8908 2010_005080
8909 2010_005082
8910 2010_005083
8911 2010_005087
8912 2010_005090
8913 2010_005093
8914 2010_005094
8915 2010_005096
8916 2010_005098
8917 2010_005099
8918 2010_005100
8919 2010_005101
8920 2010_005106
8921 2010_005107
8922 2010_005109
8923 2010_005110
8924 2010_005111
8925 2010_005115
8926 2010_005116
8927 2010_005119
8928 2010_005120
8929 2010_005123
8930 2010_005127
8931 2010_005128
8932 2010_005129
8933 2010_005130
8934 2010_005133
8935 2010_005134
8936 2010_005136
8937 2010_005138
8938 2010_005141
8939 2010_005143
8940 2010_005147
8941 2010_005148
8942 2010_005149
8943 2010_005152
8944 2010_005155
8945 2010_005158
8946 2010_005161
8947 2010_005164
8948 2010_005167
8949 2010_005169
8950 2010_005170
8951 2010_005182
8952 2010_005183
8953 2010_005184
8954 2010_005185
8955 2010_005188
8956 2010_005190
8957 2010_005192
8958 2010_005193
8959 2010_005198
8960 2010_005199
8961 2010_005201
8962 2010_005202
8963 2010_005208
8964 2010_005211
8965 2010_005213
8966 2010_005215
8967 2010_005216
8968 2010_005217
8969 2010_005222
8970 2010_005223
8971 2010_005224
8972 2010_005226
8973 2010_005229
8974 2010_005230
8975 2010_005232
8976 2010_005236
8977 2010_005238
8978 2010_005239
8979 2010_005242
8980 2010_005243
8981 2010_005246
8982 2010_005250
8983 2010_005253
8984 2010_005257
8985 2010_005258
8986 2010_005260
8987 2010_005261
8988 2010_005264
8989 2010_005266
8990 2010_005268
8991 2010_005270
8992 2010_005272
8993 2010_005273
8994 2010_005274
8995 2010_005275
8996 2010_005276
8997 2010_005277
8998 2010_005279
8999 2010_005285
9000 2010_005287
9001 2010_005292
9002 2010_005293
9003 2010_005297
9004 2010_005299
9005 2010_005301
9006 2010_005303
9007 2010_005306
9008 2010_005308
9009 2010_005309
9010 2010_005310
9011 2010_005312
9012 2010_005314
9013 2010_005317
9014 2010_005318
9015 2010_005320
9016 2010_005323
9017 2010_005327
9018 2010_005330
9019 2010_005331
9020 2010_005332
9021 2010_005338
9022 2010_005340
9023 2010_005345
9024 2010_005346
9025 2010_005349
9026 2010_005350
9027 2010_005352
9028 2010_005359
9029 2010_005361
9030 2010_005364
9031 2010_005365
9032 2010_005369
9033 2010_005371
9034 2010_005372
9035 2010_005374
9036 2010_005375
9037 2010_005376
9038 2010_005377
9039 2010_005379
9040 2010_005382
9041 2010_005384
9042 2010_005385
9043 2010_005386
9044 2010_005388
9045 2010_005389
9046 2010_005391
9047 2010_005393
9048 2010_005394
9049 2010_005398
9050 2010_005403
9051 2010_005405
9052 2010_005406
9053 2010_005408
9054 2010_005409
9055 2010_005410
9056 2010_005414
9057 2010_005415
9058 2010_005416
9059 2010_005417
9060 2010_005419
9061 2010_005424
9062 2010_005425
9063 2010_005426
9064 2010_005429
9065 2010_005434
9066 2010_005437
9067 2010_005441
9068 2010_005442
9069 2010_005450
9070 2010_005452
9071 2010_005455
9072 2010_005456
9073 2010_005457
9074 2010_005458
9075 2010_005462
9076 2010_005463
9077 2010_005466
9078 2010_005467
9079 2010_005468
9080 2010_005471
9081 2010_005472
9082 2010_005474
9083 2010_005475
9084 2010_005480
9085 2010_005482
9086 2010_005483
9087 2010_005484
9088 2010_005489
9089 2010_005491
9090 2010_005492
9091 2010_005493
9092 2010_005494
9093 2010_005497
9094 2010_005498
9095 2010_005500
9096 2010_005502
9097 2010_005505
9098 2010_005506
9099 2010_005511
9100 2010_005512
9101 2010_005513
9102 2010_005514
9103 2010_005515
9104 2010_005516
9105 2010_005518
9106 2010_005519
9107 2010_005522
9108 2010_005527
9109 2010_005532
9110 2010_005535
9111 2010_005536
9112 2010_005538
9113 2010_005540
9114 2010_005542
9115 2010_005543
9116 2010_005546
9117 2010_005548
9118 2010_005551
9119 2010_005556
9120 2010_005557
9121 2010_005559
9122 2010_005561
9123 2010_005562
9124 2010_005565
9125 2010_005566
9126 2010_005567
9127 2010_005570
9128 2010_005571
9129 2010_005572
9130 2010_005573
9131 2010_005576
9132 2010_005578
9133 2010_005584
9134 2010_005585
9135 2010_005586
9136 2010_005587
9137 2010_005588
9138 2010_005591
9139 2010_005592
9140 2010_005593
9141 2010_005594
9142 2010_005595
9143 2010_005596
9144 2010_005597
9145 2010_005601
9146 2010_005603
9147 2010_005604
9148 2010_005608
9149 2010_005610
9150 2010_005612
9151 2010_005614
9152 2010_005615
9153 2010_005619
9154 2010_005620
9155 2010_005625
9156 2010_005627
9157 2010_005628
9158 2010_005629
9159 2010_005632
9160 2010_005635
9161 2010_005636
9162 2010_005637
9163 2010_005640
9164 2010_005643
9165 2010_005646
9166 2010_005647
9167 2010_005651
9168 2010_005652
9169 2010_005654
9170 2010_005657
9171 2010_005658
9172 2010_005663
9173 2010_005665
9174 2010_005666
9175 2010_005668
9176 2010_005669
9177 2010_005670
9178 2010_005671
9179 2010_005672
9180 2010_005676
9181 2010_005678
9182 2010_005681
9183 2010_005683
9184 2010_005684
9185 2010_005688
9186 2010_005692
9187 2010_005696
9188 2010_005697
9189 2010_005700
9190 2010_005712
9191 2010_005715
9192 2010_005716
9193 2010_005721
9194 2010_005723
9195 2010_005725
9196 2010_005731
9197 2010_005732
9198 2010_005733
9199 2010_005734
9200 2010_005735
9201 2010_005736
9202 2010_005738
9203 2010_005740
9204 2010_005744
9205 2010_005746
9206 2010_005747
9207 2010_005748
9208 2010_005750
9209 2010_005752
9210 2010_005753
9211 2010_005755
9212 2010_005756
9213 2010_005758
9214 2010_005761
9215 2010_005763
9216 2010_005764
9217 2010_005767
9218 2010_005768
9219 2010_005770
9220 2010_005775
9221 2010_005776
9222 2010_005777
9223 2010_005780
9224 2010_005782
9225 2010_005784
9226 2010_005785
9227 2010_005791
9228 2010_005794
9229 2010_005796
9230 2010_005800
9231 2010_005804
9232 2010_005805
9233 2010_005806
9234 2010_005807
9235 2010_005810
9236 2010_005815
9237 2010_005816
9238 2010_005817
9239 2010_005820
9240 2010_005821
9241 2010_005823
9242 2010_005824
9243 2010_005825
9244 2010_005826
9245 2010_005827
9246 2010_005830
9247 2010_005833
9248 2010_005835
9249 2010_005836
9250 2010_005837
9251 2010_005838
9252 2010_005840
9253 2010_005841
9254 2010_005843
9255 2010_005845
9256 2010_005847
9257 2010_005848
9258 2010_005849
9259 2010_005853
9260 2010_005855
9261 2010_005865
9262 2010_005867
9263 2010_005868
9264 2010_005870
9265 2010_005874
9266 2010_005875
9267 2010_005876
9268 2010_005882
9269 2010_005883
9270 2010_005884
9271 2010_005885
9272 2010_005886
9273 2010_005891
9274 2010_005892
9275 2010_005894
9276 2010_005896
9277 2010_005897
9278 2010_005898
9279 2010_005901
9280 2010_005903
9281 2010_005904
9282 2010_005906
9283 2010_005907
9284 2010_005909
9285 2010_005914
9286 2010_005919
9287 2010_005921
9288 2010_005927
9289 2010_005928
9290 2010_005929
9291 2010_005930
9292 2010_005932
9293 2010_005934
9294 2010_005935
9295 2010_005936
9296 2010_005937
9297 2010_005938
9298 2010_005942
9299 2010_005943
9300 2010_005948
9301 2010_005949
9302 2010_005951
9303 2010_005952
9304 2010_005953
9305 2010_005954
9306 2010_005958
9307 2010_005959
9308 2010_005960
9309 2010_005967
9310 2010_005968
9311 2010_005972
9312 2010_005973
9313 2010_005974
9314 2010_005975
9315 2010_005976
9316 2010_005978
9317 2010_005980
9318 2010_005981
9319 2010_005982
9320 2010_005984
9321 2010_005985
9322 2010_005986
9323 2010_005987
9324 2010_005993
9325 2010_005995
9326 2010_005996
9327 2010_005997
9328 2010_005998
9329 2010_006000
9330 2010_006004
9331 2010_006009
9332 2010_006010
9333 2010_006011
9334 2010_006012
9335 2010_006015
9336 2010_006021
9337 2010_006023
9338 2010_006025
9339 2010_006028
9340 2010_006031
9341 2010_006032
9342 2010_006033
9343 2010_006035
9344 2010_006037
9345 2010_006040
9346 2010_006041
9347 2010_006042
9348 2010_006050
9349 2010_006051
9350 2010_006056
9351 2010_006057
9352 2010_006058
9353 2010_006061
9354 2010_006062
9355 2010_006063
9356 2010_006066
9357 2010_006067
9358 2010_006073
9359 2010_006076
9360 2010_006078
9361 2010_006079
9362 2010_006082
9363 2010_006084
9364 2010_006086
9365 2011_000002
9366 2011_000003
9367 2011_000006
9368 2011_000007
9369 2011_000009
9370 2011_000010
9371 2011_000012
9372 2011_000016
9373 2011_000017
9374 2011_000022
9375 2011_000025
9376 2011_000027
9377 2011_000030
9378 2011_000034
9379 2011_000036
9380 2011_000037
9381 2011_000038
9382 2011_000041
9383 2011_000043
9384 2011_000044
9385 2011_000048
9386 2011_000052
9387 2011_000053
9388 2011_000057
9389 2011_000058
9390 2011_000060
9391 2011_000061
9392 2011_000065
9393 2011_000068
9394 2011_000069
9395 2011_000071
9396 2011_000072
9397 2011_000076
9398 2011_000077
9399 2011_000082
9400 2011_000083
9401 2011_000084
9402 2011_000086
9403 2011_000087
9404 2011_000090
9405 2011_000094
9406 2011_000095
9407 2011_000096
9408 2011_000098
9409 2011_000102
9410 2011_000103
9411 2011_000105
9412 2011_000108
9413 2011_000109
9414 2011_000114
9415 2011_000116
9416 2011_000122
9417 2011_000124
9418 2011_000128
9419 2011_000129
9420 2011_000130
9421 2011_000137
9422 2011_000138
9423 2011_000142
9424 2011_000145
9425 2011_000146
9426 2011_000147
9427 2011_000149
9428 2011_000152
9429 2011_000161
9430 2011_000162
9431 2011_000163
9432 2011_000165
9433 2011_000166
9434 2011_000176
9435 2011_000180
9436 2011_000181
9437 2011_000182
9438 2011_000192
9439 2011_000194
9440 2011_000195
9441 2011_000196
9442 2011_000197
9443 2011_000202
9444 2011_000206
9445 2011_000208
9446 2011_000210
9447 2011_000213
9448 2011_000214
9449 2011_000216
9450 2011_000219
9451 2011_000220
9452 2011_000221
9453 2011_000222
9454 2011_000224
9455 2011_000228
9456 2011_000229
9457 2011_000232
9458 2011_000233
9459 2011_000241
9460 2011_000243
9461 2011_000246
9462 2011_000249
9463 2011_000250
9464 2011_000252
9465 2011_000253
9466 2011_000257
9467 2011_000258
9468 2011_000267
9469 2011_000268
9470 2011_000269
9471 2011_000273
9472 2011_000276
9473 2011_000277
9474 2011_000278
9475 2011_000282
9476 2011_000285
9477 2011_000286
9478 2011_000288
9479 2011_000290
9480 2011_000293
9481 2011_000297
9482 2011_000299
9483 2011_000304
9484 2011_000305
9485 2011_000307
9486 2011_000309
9487 2011_000314
9488 2011_000315
9489 2011_000317
9490 2011_000319
9491 2011_000320
9492 2011_000321
9493 2011_000322
9494 2011_000324
9495 2011_000329
9496 2011_000332
9497 2011_000342
9498 2011_000343
9499 2011_000344
9500 2011_000345
9501 2011_000346
9502 2011_000347
9503 2011_000359
9504 2011_000361
9505 2011_000362
9506 2011_000364
9507 2011_000369
9508 2011_000370
9509 2011_000374
9510 2011_000375
9511 2011_000376
9512 2011_000379
9513 2011_000382
9514 2011_000383
9515 2011_000386
9516 2011_000388
9517 2011_000391
9518 2011_000392
9519 2011_000397
9520 2011_000398
9521 2011_000399
9522 2011_000400
9523 2011_000404
9524 2011_000408
9525 2011_000413
9526 2011_000416
9527 2011_000418
9528 2011_000420
9529 2011_000426
9530 2011_000427
9531 2011_000428
9532 2011_000432
9533 2011_000434
9534 2011_000442
9535 2011_000444
9536 2011_000445
9537 2011_000449
9538 2011_000450
9539 2011_000453
9540 2011_000454
9541 2011_000457
9542 2011_000465
9543 2011_000468
9544 2011_000469
9545 2011_000471
9546 2011_000474
9547 2011_000475
9548 2011_000477
9549 2011_000485
9550 2011_000487
9551 2011_000491
9552 2011_000492
9553 2011_000494
9554 2011_000496
9555 2011_000498
9556 2011_000499
9557 2011_000502
9558 2011_000505
9559 2011_000509
9560 2011_000511
9561 2011_000513
9562 2011_000514
9563 2011_000518
9564 2011_000519
9565 2011_000520
9566 2011_000530
9567 2011_000531
9568 2011_000534
9569 2011_000538
9570 2011_000541
9571 2011_000542
9572 2011_000550
9573 2011_000551
9574 2011_000554
9575 2011_000556
9576 2011_000557
9577 2011_000558
9578 2011_000559
9579 2011_000560
9580 2011_000565
9581 2011_000567
9582 2011_000569
9583 2011_000572
9584 2011_000573
9585 2011_000575
9586 2011_000577
9587 2011_000578
9588 2011_000579
9589 2011_000586
9590 2011_000589
9591 2011_000592
9592 2011_000594
9593 2011_000596
9594 2011_000600
9595 2011_000608
9596 2011_000609
9597 2011_000612
9598 2011_000622
9599 2011_000627
9600 2011_000628
9601 2011_000629
9602 2011_000630
9603 2011_000631
9604 2011_000634
9605 2011_000637
9606 2011_000641
9607 2011_000642
9608 2011_000646
9609 2011_000651
9610 2011_000652
9611 2011_000655
9612 2011_000656
9613 2011_000657
9614 2011_000666
9615 2011_000673
9616 2011_000675
9617 2011_000679
9618 2011_000682
9619 2011_000683
9620 2011_000684
9621 2011_000685
9622 2011_000688
9623 2011_000689
9624 2011_000690
9625 2011_000692
9626 2011_000698
9627 2011_000701
9628 2011_000703
9629 2011_000704
9630 2011_000709
9631 2011_000711
9632 2011_000713
9633 2011_000718
9634 2011_000724
9635 2011_000725
9636 2011_000731
9637 2011_000734
9638 2011_000743
9639 2011_000744
9640 2011_000745
9641 2011_000748
9642 2011_000749
9643 2011_000753
9644 2011_000755
9645 2011_000758
9646 2011_000759
9647 2011_000763
9648 2011_000765
9649 2011_000767
9650 2011_000768
9651 2011_000769
9652 2011_000770
9653 2011_000771
9654 2011_000772
9655 2011_000774
9656 2011_000778
9657 2011_000784
9658 2011_000785
9659 2011_000788
9660 2011_000790
9661 2011_000791
9662 2011_000793
9663 2011_000800
9664 2011_000804
9665 2011_000806
9666 2011_000815
9667 2011_000819
9668 2011_000820
9669 2011_000823
9670 2011_000824
9671 2011_000827
9672 2011_000828
9673 2011_000829
9674 2011_000831
9675 2011_000834
9676 2011_000837
9677 2011_000839
9678 2011_000840
9679 2011_000845
9680 2011_000847
9681 2011_000848
9682 2011_000850
9683 2011_000851
9684 2011_000853
9685 2011_000855
9686 2011_000858
9687 2011_000859
9688 2011_000872
9689 2011_000875
9690 2011_000882
9691 2011_000885
9692 2011_000887
9693 2011_000893
9694 2011_000895
9695 2011_000897
9696 2011_000898
9697 2011_000899
9698 2011_000901
9699 2011_000908
9700 2011_000909
9701 2011_000917
9702 2011_000919
9703 2011_000920
9704 2011_000922
9705 2011_000927
9706 2011_000930
9707 2011_000932
9708 2011_000933
9709 2011_000934
9710 2011_000940
9711 2011_000944
9712 2011_000947
9713 2011_000950
9714 2011_000951
9715 2011_000954
9716 2011_000957
9717 2011_000961
9718 2011_000965
9719 2011_000973
9720 2011_000975
9721 2011_000977
9722 2011_000979
9723 2011_000981
9724 2011_000982
9725 2011_000983
9726 2011_000986
9727 2011_000987
9728 2011_000990
9729 2011_000991
9730 2011_000996
9731 2011_000997
9732 2011_000999
9733 2011_001001
9734 2011_001004
9735 2011_001008
9736 2011_001009
9737 2011_001010
9738 2011_001011
9739 2011_001015
9740 2011_001016
9741 2011_001019
9742 2011_001022
9743 2011_001023
9744 2011_001025
9745 2011_001027
9746 2011_001028
9747 2011_001029
9748 2011_001030
9749 2011_001031
9750 2011_001032
9751 2011_001033
9752 2011_001034
9753 2011_001036
9754 2011_001040
9755 2011_001044
9756 2011_001052
9757 2011_001054
9758 2011_001055
9759 2011_001056
9760 2011_001058
9761 2011_001062
9762 2011_001066
9763 2011_001073
9764 2011_001079
9765 2011_001080
9766 2011_001081
9767 2011_001084
9768 2011_001086
9769 2011_001091
9770 2011_001093
9771 2011_001097
9772 2011_001100
9773 2011_001105
9774 2011_001106
9775 2011_001107
9776 2011_001111
9777 2011_001116
9778 2011_001117
9779 2011_001123
9780 2011_001124
9781 2011_001126
9782 2011_001127
9783 2011_001128
9784 2011_001133
9785 2011_001134
9786 2011_001135
9787 2011_001136
9788 2011_001137
9789 2011_001138
9790 2011_001139
9791 2011_001144
9792 2011_001146
9793 2011_001149
9794 2011_001150
9795 2011_001152
9796 2011_001153
9797 2011_001158
9798 2011_001160
9799 2011_001163
9800 2011_001166
9801 2011_001167
9802 2011_001168
9803 2011_001169
9804 2011_001173
9805 2011_001175
9806 2011_001176
9807 2011_001188
9808 2011_001189
9809 2011_001192
9810 2011_001193
9811 2011_001198
9812 2011_001201
9813 2011_001203
9814 2011_001208
9815 2011_001211
9816 2011_001213
9817 2011_001215
9818 2011_001216
9819 2011_001217
9820 2011_001220
9821 2011_001221
9822 2011_001223
9823 2011_001226
9824 2011_001227
9825 2011_001229
9826 2011_001238
9827 2011_001240
9828 2011_001245
9829 2011_001246
9830 2011_001251
9831 2011_001252
9832 2011_001253
9833 2011_001254
9834 2011_001255
9835 2011_001257
9836 2011_001259
9837 2011_001260
9838 2011_001261
9839 2011_001264
9840 2011_001266
9841 2011_001270
9842 2011_001271
9843 2011_001272
9844 2011_001277
9845 2011_001282
9846 2011_001283
9847 2011_001284
9848 2011_001285
9849 2011_001286
9850 2011_001288
9851 2011_001290
9852 2011_001295
9853 2011_001302
9854 2011_001304
9855 2011_001305
9856 2011_001310
9857 2011_001311
9858 2011_001315
9859 2011_001318
9860 2011_001319
9861 2011_001320
9862 2011_001323
9863 2011_001326
9864 2011_001327
9865 2011_001329
9866 2011_001330
9867 2011_001333
9868 2011_001335
9869 2011_001336
9870 2011_001337
9871 2011_001354
9872 2011_001355
9873 2011_001357
9874 2011_001360
9875 2011_001366
9876 2011_001369
9877 2011_001370
9878 2011_001373
9879 2011_001375
9880 2011_001381
9881 2011_001382
9882 2011_001384
9883 2011_001387
9884 2011_001388
9885 2011_001389
9886 2011_001390
9887 2011_001394
9888 2011_001399
9889 2011_001400
9890 2011_001402
9891 2011_001404
9892 2011_001406
9893 2011_001411
9894 2011_001412
9895 2011_001414
9896 2011_001422
9897 2011_001424
9898 2011_001432
9899 2011_001440
9900 2011_001441
9901 2011_001449
9902 2011_001451
9903 2011_001455
9904 2011_001456
9905 2011_001463
9906 2011_001464
9907 2011_001466
9908 2011_001467
9909 2011_001471
9910 2011_001475
9911 2011_001476
9912 2011_001479
9913 2011_001480
9914 2011_001498
9915 2011_001501
9916 2011_001503
9917 2011_001505
9918 2011_001507
9919 2011_001508
9920 2011_001510
9921 2011_001514
9922 2011_001518
9923 2011_001519
9924 2011_001521
9925 2011_001524
9926 2011_001525
9927 2011_001526
9928 2011_001531
9929 2011_001535
9930 2011_001536
9931 2011_001537
9932 2011_001538
9933 2011_001541
9934 2011_001542
9935 2011_001544
9936 2011_001547
9937 2011_001549
9938 2011_001557
9939 2011_001558
9940 2011_001560
9941 2011_001566
9942 2011_001568
9943 2011_001571
9944 2011_001572
9945 2011_001573
9946 2011_001582
9947 2011_001586
9948 2011_001591
9949 2011_001592
9950 2011_001596
9951 2011_001599
9952 2011_001600
9953 2011_001602
9954 2011_001605
9955 2011_001606
9956 2011_001608
9957 2011_001611
9958 2011_001612
9959 2011_001616
9960 2011_001618
9961 2011_001620
9962 2011_001621
9963 2011_001622
9964 2011_001625
9965 2011_001628
9966 2011_001629
9967 2011_001632
9968 2011_001641
9969 2011_001643
9970 2011_001647
9971 2011_001649
9972 2011_001650
9973 2011_001652
9974 2011_001653
9975 2011_001655
9976 2011_001656
9977 2011_001662
9978 2011_001663
9979 2011_001666
9980 2011_001671
9981 2011_001673
9982 2011_001678
9983 2011_001679
9984 2011_001689
9985 2011_001691
9986 2011_001693
9987 2011_001694
9988 2011_001695
9989 2011_001698
9990 2011_001699
9991 2011_001700
9992 2011_001705
9993 2011_001707
9994 2011_001710
9995 2011_001712
9996 2011_001715
9997 2011_001716
9998 2011_001719
9999 2011_001720
10000 2011_001727
10001 2011_001730
10002 2011_001732
10003 2011_001733
10004 2011_001739
10005 2011_001740
10006 2011_001741
10007 2011_001747
10008 2011_001751
10009 2011_001753
10010 2011_001754
10011 2011_001755
10012 2011_001757
10013 2011_001764
10014 2011_001765
10015 2011_001766
10016 2011_001769
10017 2011_001771
10018 2011_001776
10019 2011_001779
10020 2011_001785
10021 2011_001789
10022 2011_001790
10023 2011_001791
10024 2011_001796
10025 2011_001799
10026 2011_001800
10027 2011_001801
10028 2011_001805
10029 2011_001806
10030 2011_001810
10031 2011_001811
10032 2011_001815
10033 2011_001819
10034 2011_001820
10035 2011_001822
10036 2011_001824
10037 2011_001825
10038 2011_001826
10039 2011_001827
10040 2011_001833
10041 2011_001834
10042 2011_001837
10043 2011_001840
10044 2011_001841
10045 2011_001842
10046 2011_001845
10047 2011_001847
10048 2011_001854
10049 2011_001855
10050 2011_001856
10051 2011_001858
10052 2011_001866
10053 2011_001870
10054 2011_001871
10055 2011_001872
10056 2011_001873
10057 2011_001875
10058 2011_001876
10059 2011_001877
10060 2011_001884
10061 2011_001885
10062 2011_001886
10063 2011_001889
10064 2011_001891
10065 2011_001893
10066 2011_001895
10067 2011_001896
10068 2011_001900
10069 2011_001901
10070 2011_001902
10071 2011_001904
10072 2011_001906
10073 2011_001911
10074 2011_001914
10075 2011_001919
10076 2011_001920
10077 2011_001922
10078 2011_001924
10079 2011_001926
10080 2011_001927
10081 2011_001928
10082 2011_001929
10083 2011_001930
10084 2011_001932
10085 2011_001937
10086 2011_001938
10087 2011_001941
10088 2011_001942
10089 2011_001944
10090 2011_001945
10091 2011_001946
10092 2011_001949
10093 2011_001950
10094 2011_001951
10095 2011_001952
10096 2011_001956
10097 2011_001959
10098 2011_001961
10099 2011_001962
10100 2011_001964
10101 2011_001966
10102 2011_001967
10103 2011_001971
10104 2011_001972
10105 2011_001974
10106 2011_001975
10107 2011_001977
10108 2011_001980
10109 2011_001982
10110 2011_001986
10111 2011_001987
10112 2011_001989
10113 2011_001991
10114 2011_002003
10115 2011_002004
10116 2011_002005
10117 2011_002006
10118 2011_002012
10119 2011_002016
10120 2011_002018
10121 2011_002019
10122 2011_002021
10123 2011_002022
10124 2011_002027
10125 2011_002031
10126 2011_002033
10127 2011_002034
10128 2011_002036
10129 2011_002038
10130 2011_002039
10131 2011_002042
10132 2011_002044
10133 2011_002045
10134 2011_002046
10135 2011_002047
10136 2011_002049
10137 2011_002050
10138 2011_002053
10139 2011_002055
10140 2011_002062
10141 2011_002063
10142 2011_002073
10143 2011_002074
10144 2011_002079
10145 2011_002085
10146 2011_002088
10147 2011_002091
10148 2011_002093
10149 2011_002096
10150 2011_002097
10151 2011_002100
10152 2011_002102
10153 2011_002105
10154 2011_002106
10155 2011_002107
10156 2011_002108
10157 2011_002109
10158 2011_002111
10159 2011_002113
10160 2011_002114
10161 2011_002116
10162 2011_002119
10163 2011_002128
10164 2011_002131
10165 2011_002132
10166 2011_002134
10167 2011_002135
10168 2011_002137
10169 2011_002142
10170 2011_002143
10171 2011_002144
10172 2011_002147
10173 2011_002148
10174 2011_002149
10175 2011_002154
10176 2011_002158
10177 2011_002159
10178 2011_002160
10179 2011_002163
10180 2011_002167
10181 2011_002169
10182 2011_002173
10183 2011_002174
10184 2011_002177
10185 2011_002179
10186 2011_002184
10187 2011_002185
10188 2011_002186
10189 2011_002189
10190 2011_002192
10191 2011_002193
10192 2011_002211
10193 2011_002215
10194 2011_002218
10195 2011_002221
10196 2011_002222
10197 2011_002224
10198 2011_002227
10199 2011_002228
10200 2011_002230
10201 2011_002234
10202 2011_002236
10203 2011_002237
10204 2011_002239
10205 2011_002241
10206 2011_002245
10207 2011_002246
10208 2011_002248
10209 2011_002251
10210 2011_002252
10211 2011_002253
10212 2011_002260
10213 2011_002265
10214 2011_002268
10215 2011_002269
10216 2011_002270
10217 2011_002272
10218 2011_002273
10219 2011_002276
10220 2011_002278
10221 2011_002280
10222 2011_002281
10223 2011_002284
10224 2011_002291
10225 2011_002292
10226 2011_002294
10227 2011_002300
10228 2011_002301
10229 2011_002303
10230 2011_002312
10231 2011_002318
10232 2011_002324
10233 2011_002325
10234 2011_002330
10235 2011_002335
10236 2011_002341
10237 2011_002346
10238 2011_002347
10239 2011_002348
10240 2011_002350
10241 2011_002357
10242 2011_002359
10243 2011_002365
10244 2011_002366
10245 2011_002380
10246 2011_002381
10247 2011_002384
10248 2011_002385
10249 2011_002386
10250 2011_002387
10251 2011_002388
10252 2011_002389
10253 2011_002393
10254 2011_002394
10255 2011_002395
10256 2011_002396
10257 2011_002397
10258 2011_002398
10259 2011_002402
10260 2011_002406
10261 2011_002407
10262 2011_002409
10263 2011_002410
10264 2011_002413
10265 2011_002414
10266 2011_002418
10267 2011_002420
10268 2011_002421
10269 2011_002422
10270 2011_002429
10271 2011_002433
10272 2011_002435
10273 2011_002436
10274 2011_002443
10275 2011_002447
10276 2011_002448
10277 2011_002455
10278 2011_002457
10279 2011_002458
10280 2011_002459
10281 2011_002460
10282 2011_002461
10283 2011_002462
10284 2011_002463
10285 2011_002464
10286 2011_002470
10287 2011_002474
10288 2011_002476
10289 2011_002479
10290 2011_002482
10291 2011_002484
10292 2011_002488
10293 2011_002490
10294 2011_002491
10295 2011_002492
10296 2011_002494
10297 2011_002495
10298 2011_002503
10299 2011_002504
10300 2011_002505
10301 2011_002507
10302 2011_002511
10303 2011_002514
10304 2011_002516
10305 2011_002519
10306 2011_002520
10307 2011_002526
10308 2011_002528
10309 2011_002531
10310 2011_002533
10311 2011_002536
10312 2011_002542
10313 2011_002543
10314 2011_002551
10315 2011_002552
10316 2011_002553
10317 2011_002554
10318 2011_002555
10319 2011_002556
10320 2011_002558
10321 2011_002559
10322 2011_002560
10323 2011_002561
10324 2011_002566
10325 2011_002567
10326 2011_002568
10327 2011_002571
10328 2011_002579
10329 2011_002582
10330 2011_002583
10331 2011_002584
10332 2011_002585
10333 2011_002588
10334 2011_002590
10335 2011_002594
10336 2011_002598
10337 2011_002605
10338 2011_002606
10339 2011_002609
10340 2011_002610
10341 2011_002612
10342 2011_002614
10343 2011_002616
10344 2011_002617
10345 2011_002618
10346 2011_002620
10347 2011_002624
10348 2011_002629
10349 2011_002631
10350 2011_002636
10351 2011_002638
10352 2011_002639
10353 2011_002640
10354 2011_002649
10355 2011_002650
10356 2011_002652
10357 2011_002656
10358 2011_002657
10359 2011_002658
10360 2011_002661
10361 2011_002664
10362 2011_002673
10363 2011_002674
10364 2011_002676
10365 2011_002677
10366 2011_002678
10367 2011_002687
10368 2011_002694
10369 2011_002697
10370 2011_002699
10371 2011_002706
10372 2011_002709
10373 2011_002714
10374 2011_002715
10375 2011_002717
10376 2011_002719
10377 2011_002724
10378 2011_002725
10379 2011_002726
10380 2011_002738
10381 2011_002740
10382 2011_002742
10383 2011_002748
10384 2011_002750
10385 2011_002751
10386 2011_002752
10387 2011_002756
10388 2011_002760
10389 2011_002765
10390 2011_002767
10391 2011_002770
10392 2011_002772
10393 2011_002775
10394 2011_002776
10395 2011_002779
10396 2011_002780
10397 2011_002782
10398 2011_002784
10399 2011_002786
10400 2011_002790
10401 2011_002795
10402 2011_002796
10403 2011_002798
10404 2011_002802
10405 2011_002803
10406 2011_002805
10407 2011_002808
10408 2011_002810
10409 2011_002811
10410 2011_002814
10411 2011_002817
10412 2011_002818
10413 2011_002821
10414 2011_002823
10415 2011_002826
10416 2011_002830
10417 2011_002831
10418 2011_002833
10419 2011_002834
10420 2011_002838
10421 2011_002841
10422 2011_002842
10423 2011_002851
10424 2011_002852
10425 2011_002854
10426 2011_002864
10427 2011_002867
10428 2011_002868
10429 2011_002870
10430 2011_002871
10431 2011_002872
10432 2011_002873
10433 2011_002880
10434 2011_002881
10435 2011_002883
10436 2011_002884
10437 2011_002887
10438 2011_002889
10439 2011_002890
10440 2011_002897
10441 2011_002900
10442 2011_002908
10443 2011_002911
10444 2011_002912
10445 2011_002913
10446 2011_002916
10447 2011_002917
10448 2011_002920
10449 2011_002921
10450 2011_002924
10451 2011_002925
10452 2011_002927
10453 2011_002930
10454 2011_002932
10455 2011_002933
10456 2011_002935
10457 2011_002937
10458 2011_002940
10459 2011_002942
10460 2011_002943
10461 2011_002944
10462 2011_002947
10463 2011_002949
10464 2011_002953
10465 2011_002956
10466 2011_002958
10467 2011_002962
10468 2011_002965
10469 2011_002966
10470 2011_002967
10471 2011_002969
10472 2011_002970
10473 2011_002971
10474 2011_002974
10475 2011_002978
10476 2011_002979
10477 2011_002983
10478 2011_002985
10479 2011_002987
10480 2011_002988
10481 2011_002992
10482 2011_002994
10483 2011_002999
10484 2011_003002
10485 2011_003005
10486 2011_003010
10487 2011_003012
10488 2011_003013
10489 2011_003016
10490 2011_003020
10491 2011_003023
10492 2011_003025
10493 2011_003027
10494 2011_003028
10495 2011_003029
10496 2011_003034
10497 2011_003038
10498 2011_003039
10499 2011_003041
10500 2011_003043
10501 2011_003044
10502 2011_003047
10503 2011_003048
10504 2011_003049
10505 2011_003050
10506 2011_003054
10507 2011_003057
10508 2011_003059
10509 2011_003063
10510 2011_003065
10511 2011_003066
10512 2011_003073
10513 2011_003074
10514 2011_003076
10515 2011_003078
10516 2011_003079
10517 2011_003081
10518 2011_003086
10519 2011_003089
10520 2011_003091
10521 2011_003097
10522 2011_003109
10523 2011_003111
10524 2011_003115
10525 2011_003121
10526 2011_003124
10527 2011_003132
10528 2011_003134
10529 2011_003138
10530 2011_003141
10531 2011_003148
10532 2011_003149
10533 2011_003150
10534 2011_003151
10535 2011_003152
10536 2011_003154
10537 2011_003158
10538 2011_003159
10539 2011_003162
10540 2011_003163
10541 2011_003166
10542 2011_003167
10543 2011_003168
10544 2011_003169
10545 2011_003171
10546 2011_003176
10547 2011_003177
10548 2011_003183
10549 2011_003184
10550 2011_003185
10551 2011_003187
10552 2011_003188
10553 2011_003192
10554 2011_003194
10555 2011_003201
10556 2011_003211
10557 2011_003212
10558 2011_003213
10559 2011_003216
10560 2011_003220
10561 2011_003223
10562 2011_003228
10563 2011_003230
10564 2011_003232
10565 2011_003236
10566 2011_003238
10567 2011_003242
10568 2011_003244
10569 2011_003246
10570 2011_003247
10571 2011_003253
10572 2011_003254
10573 2011_003255
10574 2011_003259
10575 2011_003260
10576 2011_003261
10577 2011_003262
10578 2011_003269
10579 2011_003274
10580 2011_003275
10581 2011_003276
UNIQUESTRING 3
/media/ssd1/austin/Point-DSRG/deeplab-public-ver2/python
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0227 04:34:42.832412 20800 solver.cpp:48] Initializing solver from parameters:
train_net: "train-f.prototxt"
base_lr: 0.001
display: 20
max_iter: 20000
lr_policy: "poly"
power: 0.9
momentum: 0.9
weight_decay: 0.0005
snapshot: 10000
snapshot_prefix: "models/model-f"
solver_mode: GPU
random_seed: 0
average_loss: 20
I0227 04:34:42.833884 20800 solver.cpp:81] Creating training net from train_net file: train-f.prototxt
I0227 04:34:42.836472 20800 net.cpp:49] Initializing net from parameters:
name: "DSRG"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Python"
  top: "images"
  top: "label"
  include {
    phase: TRAIN
  }
  python_param {
    module: "pylayers.layer"
    layer: "ImageSegDataLayer"
    param_str: "{\'batch_size\':10 ,\'root_folder\': \'/media/ssd1/austin/datasets/VOC/VOCdevkit/VOC2012/\' ,\'mean\': (104.0, 117.0, 123.0), \'source\': \'list/train.txt\', \'mirror\': True, \'crop_size\': (321, 321)}"
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "images"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    pad: 1
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    pad: 1
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    pad: 1
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    dilation: 2
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    dilation: 2
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    dilation: 2
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "pool5a"
  type: "Pooling"
  bottom: "pool5"
  top: "pool5a"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "fc6_1"
  type: "Convolution"
  bottom: "pool5a"
  top: "fc6_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    pad: 6
    kernel_size: 3
    dilation: 6
  }
}
layer {
  name: "relu6_1"
  type: "ReLU"
  bottom: "fc6_1"
  top: "fc6_1"
}
layer {
  name: "drop6_1"
  type: "Dropout"
  bottom: "fc6_1"
  top: "fc6_1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7_1"
  type: "Convolution"
  bottom: "fc6_1"
  top: "fc7_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    kernel_size: 1
  }
}
layer {
  name: "relu7_1"
  type: "ReLU"
  bottom: "fc7_1"
  top: "fc7_1"
}
layer {
  name: "drop7_1"
  type: "Dropout"
  bottom: "fc7_1"
  top: "fc7_1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8-SEC_1"
  type: "Convolution"
  bottom: "fc7_1"
  top: "fc8-SEC_1"
  param {
    lr_mult: 10
    decay_mult: 1
  }
  param {
    lr_mult: 20
    decay_mult: 0
  }
  convolution_param {
    num_output: 21
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fc6_2"
  type: "Convolution"
  bottom: "pool5a"
  top: "fc6_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    pad: 12
    kernel_size: 3
    dilation: 12
  }
}
layer {
  name: "relu6_2"
  type: "ReLU"
  bottom: "fc6_2"
  top: "fc6_2"
}
layer {
  name: "drop6_2"
  type: "Dropout"
  bottom: "fc6_2"
  top: "fc6_2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7_2"
  type: "Convolution"
  bottom: "fc6_2"
  top: "fc7_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    kernel_size: 1
  }
}
layer {
  name: "relu7_2"
  type: "ReLU"
  bottom: "fc7_2"
  top: "fc7_2"
}
layer {
  name: "drop7_2"
  type: "Dropout"
  bottom: "fc7_2"
  top: "fc7_2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8-SEC_2"
  type: "Convolution"
  bottom: "fc7_2"
  top: "fc8-SEC_2"
  param {
    lr_mult: 10
    decay_mult: 1
  }
  param {
    lr_mult: 20
    decay_mult: 0
  }
  convolution_param {
    num_output: 21
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fc6_3"
  type: "Convolution"
  bottom: "pool5a"
  top: "fc6_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    pad: 18
    kernel_size: 3
    dilation: 18
  }
}
layer {
  name: "relu6_3"
  type: "ReLU"
  bottom: "fc6_3"
  top: "fc6_3"
}
layer {
  name: "drop6_3"
  type: "Dropout"
  bottom: "fc6_3"
  top: "fc6_3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7_3"
  type: "Convolution"
  bottom: "fc6_3"
  top: "fc7_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    kernel_size: 1
  }
}
layer {
  name: "relu7_3"
  type: "ReLU"
  bottom: "fc7_3"
  top: "fc7_3"
}
layer {
  name: "drop7_3"
  type: "Dropout"
  bottom: "fc7_3"
  top: "fc7_3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8-SEC_3"
  type: "Convolution"
  bottom: "fc7_3"
  top: "fc8-SEC_3"
  param {
    lr_mult: 10
    decay_mult: 1
  }
  param {
    lr_mult: 20
    decay_mult: 0
  }
  convolution_param {
    num_output: 21
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fc6_4"
  type: "Convolution"
  bottom: "pool5a"
  top: "fc6_4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    pad: 24
    kernel_size: 3
    dilation: 24
  }
}
layer {
  name: "relu6_4"
  type: "ReLU"
  bottom: "fc6_4"
  top: "fc6_4"
}
layer {
  name: "drop6_4"
  type: "Dropout"
  bottom: "fc6_4"
  top: "fc6_4"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7_4"
  type: "Convolution"
  bottom: "fc6_4"
  top: "fc7_4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    kernel_size: 1
  }
}
layer {
  name: "relu7_4"
  type: "ReLU"
  bottom: "fc7_4"
  top: "fc7_4"
}
layer {
  name: "drop7_4"
  type: "Dropout"
  bottom: "fc7_4"
  top: "fc7_4"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8-SEC_4"
  type: "Convolution"
  bottom: "fc7_4"
  top: "fc8-SEC_4"
  param {
    lr_mult: 10
    decay_mult: 1
  }
  param {
    lr_mult: 20
    decay_mult: 0
  }
  convolution_param {
    num_output: 21
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fc8-SEC"
  type: "Eltwise"
  bottom: "fc8-SEC_1"
  bottom: "fc8-SEC_2"
  bottom: "fc8-SEC_3"
  bottom: "fc8-SEC_4"
  top: "fc8-SEC"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "label_shrink"
  type: "Interp"
  bottom: "label"
  top: "label_shrink"
  interp_param {
    shrink_factor: 8
    pad_beg: 0
    pad_end: 0
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8-SEC"
  bottom: "label_shrink"
  loss_weight: 1
  include {
    phase: TRAIN
  }
  loss_param {
    ignore_label: 255
  }
}
layer {
  name: "accuracy"
  type: "SegAccuracy"
  bottom: "fc8-SEC"
  bottom: "label_shrink"
  top: "accuracy"
  seg_accuracy_param {
    ignore_label: 255
  }
}
I0227 04:34:42.837687 20800 layer_factory.hpp:77] Creating layer data
I0227 04:34:43.791553 20800 net.cpp:106] Creating Layer data
I0227 04:34:43.791621 20800 net.cpp:411] data -> images
I0227 04:34:43.791662 20800 net.cpp:411] data -> label
BatchLoader initialized with 10582 images
ImageSegDataLayer initialized for split: list/train.txt, with bs: 10, im_shape: (321, 321).
I0227 04:34:43.821753 20800 net.cpp:150] Setting up data
I0227 04:34:43.821772 20800 net.cpp:157] Top shape: 10 3 321 321 (3091230)
I0227 04:34:43.821782 20800 net.cpp:157] Top shape: 10 1 321 321 (1030410)
I0227 04:34:43.821789 20800 net.cpp:165] Memory required for data: 16486560
I0227 04:34:43.821797 20800 layer_factory.hpp:77] Creating layer conv1_1
I0227 04:34:43.821815 20800 net.cpp:106] Creating Layer conv1_1
I0227 04:34:43.821822 20800 net.cpp:454] conv1_1 <- images
I0227 04:34:43.821832 20800 net.cpp:411] conv1_1 -> conv1_1
I0227 04:34:43.824815 20800 net.cpp:150] Setting up conv1_1
I0227 04:34:43.824837 20800 net.cpp:157] Top shape: 10 64 321 321 (65946240)
I0227 04:34:43.824846 20800 net.cpp:165] Memory required for data: 280271520
I0227 04:34:43.824867 20800 layer_factory.hpp:77] Creating layer relu1_1
I0227 04:34:43.824879 20800 net.cpp:106] Creating Layer relu1_1
I0227 04:34:43.824885 20800 net.cpp:454] relu1_1 <- conv1_1
I0227 04:34:43.824894 20800 net.cpp:397] relu1_1 -> conv1_1 (in-place)
I0227 04:34:43.824906 20800 net.cpp:150] Setting up relu1_1
I0227 04:34:43.824914 20800 net.cpp:157] Top shape: 10 64 321 321 (65946240)
I0227 04:34:43.824920 20800 net.cpp:165] Memory required for data: 544056480
I0227 04:34:43.824926 20800 layer_factory.hpp:77] Creating layer conv1_2
I0227 04:34:43.824936 20800 net.cpp:106] Creating Layer conv1_2
I0227 04:34:43.824942 20800 net.cpp:454] conv1_2 <- conv1_1
I0227 04:34:43.824950 20800 net.cpp:411] conv1_2 -> conv1_2
I0227 04:34:43.830606 20800 net.cpp:150] Setting up conv1_2
I0227 04:34:43.830644 20800 net.cpp:157] Top shape: 10 64 321 321 (65946240)
I0227 04:34:43.830652 20800 net.cpp:165] Memory required for data: 807841440
I0227 04:34:43.830664 20800 layer_factory.hpp:77] Creating layer relu1_2
I0227 04:34:43.830677 20800 net.cpp:106] Creating Layer relu1_2
I0227 04:34:43.830684 20800 net.cpp:454] relu1_2 <- conv1_2
I0227 04:34:43.830693 20800 net.cpp:397] relu1_2 -> conv1_2 (in-place)
I0227 04:34:43.830701 20800 net.cpp:150] Setting up relu1_2
I0227 04:34:43.830709 20800 net.cpp:157] Top shape: 10 64 321 321 (65946240)
I0227 04:34:43.830714 20800 net.cpp:165] Memory required for data: 1071626400
I0227 04:34:43.830720 20800 layer_factory.hpp:77] Creating layer pool1
I0227 04:34:43.830731 20800 net.cpp:106] Creating Layer pool1
I0227 04:34:43.830739 20800 net.cpp:454] pool1 <- conv1_2
I0227 04:34:43.830745 20800 net.cpp:411] pool1 -> pool1
I0227 04:34:43.830785 20800 net.cpp:150] Setting up pool1
I0227 04:34:43.830794 20800 net.cpp:157] Top shape: 10 64 161 161 (16589440)
I0227 04:34:43.830801 20800 net.cpp:165] Memory required for data: 1137984160
I0227 04:34:43.830808 20800 layer_factory.hpp:77] Creating layer conv2_1
I0227 04:34:43.830819 20800 net.cpp:106] Creating Layer conv2_1
I0227 04:34:43.830826 20800 net.cpp:454] conv2_1 <- pool1
I0227 04:34:43.830833 20800 net.cpp:411] conv2_1 -> conv2_1
I0227 04:34:43.831092 20800 net.cpp:150] Setting up conv2_1
I0227 04:34:43.831109 20800 net.cpp:157] Top shape: 10 128 161 161 (33178880)
I0227 04:34:43.831115 20800 net.cpp:165] Memory required for data: 1270699680
I0227 04:34:43.831126 20800 layer_factory.hpp:77] Creating layer relu2_1
I0227 04:34:43.831135 20800 net.cpp:106] Creating Layer relu2_1
I0227 04:34:43.831141 20800 net.cpp:454] relu2_1 <- conv2_1
I0227 04:34:43.831151 20800 net.cpp:397] relu2_1 -> conv2_1 (in-place)
I0227 04:34:43.831159 20800 net.cpp:150] Setting up relu2_1
I0227 04:34:43.831167 20800 net.cpp:157] Top shape: 10 128 161 161 (33178880)
I0227 04:34:43.831172 20800 net.cpp:165] Memory required for data: 1403415200
I0227 04:34:43.831179 20800 layer_factory.hpp:77] Creating layer conv2_2
I0227 04:34:43.831212 20800 net.cpp:106] Creating Layer conv2_2
I0227 04:34:43.831225 20800 net.cpp:454] conv2_2 <- conv2_1
I0227 04:34:43.831240 20800 net.cpp:411] conv2_2 -> conv2_2
I0227 04:34:43.831861 20800 net.cpp:150] Setting up conv2_2
I0227 04:34:43.831887 20800 net.cpp:157] Top shape: 10 128 161 161 (33178880)
I0227 04:34:43.831898 20800 net.cpp:165] Memory required for data: 1536130720
I0227 04:34:43.831917 20800 layer_factory.hpp:77] Creating layer relu2_2
I0227 04:34:43.831933 20800 net.cpp:106] Creating Layer relu2_2
I0227 04:34:43.831945 20800 net.cpp:454] relu2_2 <- conv2_2
I0227 04:34:43.831959 20800 net.cpp:397] relu2_2 -> conv2_2 (in-place)
I0227 04:34:43.831975 20800 net.cpp:150] Setting up relu2_2
I0227 04:34:43.831990 20800 net.cpp:157] Top shape: 10 128 161 161 (33178880)
I0227 04:34:43.832002 20800 net.cpp:165] Memory required for data: 1668846240
I0227 04:34:43.832016 20800 layer_factory.hpp:77] Creating layer pool2
I0227 04:34:43.832034 20800 net.cpp:106] Creating Layer pool2
I0227 04:34:43.832046 20800 net.cpp:454] pool2 <- conv2_2
I0227 04:34:43.832064 20800 net.cpp:411] pool2 -> pool2
I0227 04:34:43.832134 20800 net.cpp:150] Setting up pool2
I0227 04:34:43.832154 20800 net.cpp:157] Top shape: 10 128 81 81 (8398080)
I0227 04:34:43.832166 20800 net.cpp:165] Memory required for data: 1702438560
I0227 04:34:43.832180 20800 layer_factory.hpp:77] Creating layer conv3_1
I0227 04:34:43.832201 20800 net.cpp:106] Creating Layer conv3_1
I0227 04:34:43.832214 20800 net.cpp:454] conv3_1 <- pool2
I0227 04:34:43.832232 20800 net.cpp:411] conv3_1 -> conv3_1
I0227 04:34:43.840297 20800 net.cpp:150] Setting up conv3_1
I0227 04:34:43.840343 20800 net.cpp:157] Top shape: 10 256 81 81 (16796160)
I0227 04:34:43.840358 20800 net.cpp:165] Memory required for data: 1769623200
I0227 04:34:43.840387 20800 layer_factory.hpp:77] Creating layer relu3_1
I0227 04:34:43.840411 20800 net.cpp:106] Creating Layer relu3_1
I0227 04:34:43.840426 20800 net.cpp:454] relu3_1 <- conv3_1
I0227 04:34:43.840445 20800 net.cpp:397] relu3_1 -> conv3_1 (in-place)
I0227 04:34:43.840468 20800 net.cpp:150] Setting up relu3_1
I0227 04:34:43.840485 20800 net.cpp:157] Top shape: 10 256 81 81 (16796160)
I0227 04:34:43.840498 20800 net.cpp:165] Memory required for data: 1836807840
I0227 04:34:43.840512 20800 layer_factory.hpp:77] Creating layer conv3_2
I0227 04:34:43.840539 20800 net.cpp:106] Creating Layer conv3_2
I0227 04:34:43.840553 20800 net.cpp:454] conv3_2 <- conv3_1
I0227 04:34:43.840574 20800 net.cpp:411] conv3_2 -> conv3_2
I0227 04:34:43.843533 20800 net.cpp:150] Setting up conv3_2
I0227 04:34:43.843575 20800 net.cpp:157] Top shape: 10 256 81 81 (16796160)
I0227 04:34:43.843590 20800 net.cpp:165] Memory required for data: 1903992480
I0227 04:34:43.843611 20800 layer_factory.hpp:77] Creating layer relu3_2
I0227 04:34:43.843631 20800 net.cpp:106] Creating Layer relu3_2
I0227 04:34:43.843647 20800 net.cpp:454] relu3_2 <- conv3_2
I0227 04:34:43.843663 20800 net.cpp:397] relu3_2 -> conv3_2 (in-place)
I0227 04:34:43.843683 20800 net.cpp:150] Setting up relu3_2
I0227 04:34:43.843700 20800 net.cpp:157] Top shape: 10 256 81 81 (16796160)
I0227 04:34:43.843713 20800 net.cpp:165] Memory required for data: 1971177120
I0227 04:34:43.843726 20800 layer_factory.hpp:77] Creating layer conv3_3
I0227 04:34:43.843750 20800 net.cpp:106] Creating Layer conv3_3
I0227 04:34:43.843766 20800 net.cpp:454] conv3_3 <- conv3_2
I0227 04:34:43.843783 20800 net.cpp:411] conv3_3 -> conv3_3
I0227 04:34:43.846860 20800 net.cpp:150] Setting up conv3_3
I0227 04:34:43.846925 20800 net.cpp:157] Top shape: 10 256 81 81 (16796160)
I0227 04:34:43.846940 20800 net.cpp:165] Memory required for data: 2038361760
I0227 04:34:43.846964 20800 layer_factory.hpp:77] Creating layer relu3_3
I0227 04:34:43.846987 20800 net.cpp:106] Creating Layer relu3_3
I0227 04:34:43.847002 20800 net.cpp:454] relu3_3 <- conv3_3
I0227 04:34:43.847034 20800 net.cpp:397] relu3_3 -> conv3_3 (in-place)
I0227 04:34:43.847044 20800 net.cpp:150] Setting up relu3_3
I0227 04:34:43.847051 20800 net.cpp:157] Top shape: 10 256 81 81 (16796160)
I0227 04:34:43.847057 20800 net.cpp:165] Memory required for data: 2105546400
I0227 04:34:43.847064 20800 layer_factory.hpp:77] Creating layer pool3
I0227 04:34:43.847075 20800 net.cpp:106] Creating Layer pool3
I0227 04:34:43.847081 20800 net.cpp:454] pool3 <- conv3_3
I0227 04:34:43.847090 20800 net.cpp:411] pool3 -> pool3
I0227 04:34:43.847127 20800 net.cpp:150] Setting up pool3
I0227 04:34:43.847139 20800 net.cpp:157] Top shape: 10 256 41 41 (4303360)
I0227 04:34:43.847153 20800 net.cpp:165] Memory required for data: 2122759840
I0227 04:34:43.847160 20800 layer_factory.hpp:77] Creating layer conv4_1
I0227 04:34:43.847172 20800 net.cpp:106] Creating Layer conv4_1
I0227 04:34:43.847179 20800 net.cpp:454] conv4_1 <- pool3
I0227 04:34:43.847187 20800 net.cpp:411] conv4_1 -> conv4_1
I0227 04:34:43.850803 20800 net.cpp:150] Setting up conv4_1
I0227 04:34:43.850839 20800 net.cpp:157] Top shape: 10 512 41 41 (8606720)
I0227 04:34:43.850847 20800 net.cpp:165] Memory required for data: 2157186720
I0227 04:34:43.850857 20800 layer_factory.hpp:77] Creating layer relu4_1
I0227 04:34:43.850867 20800 net.cpp:106] Creating Layer relu4_1
I0227 04:34:43.850881 20800 net.cpp:454] relu4_1 <- conv4_1
I0227 04:34:43.850893 20800 net.cpp:397] relu4_1 -> conv4_1 (in-place)
I0227 04:34:43.850903 20800 net.cpp:150] Setting up relu4_1
I0227 04:34:43.850919 20800 net.cpp:157] Top shape: 10 512 41 41 (8606720)
I0227 04:34:43.850925 20800 net.cpp:165] Memory required for data: 2191613600
I0227 04:34:43.850932 20800 layer_factory.hpp:77] Creating layer conv4_2
I0227 04:34:43.850945 20800 net.cpp:106] Creating Layer conv4_2
I0227 04:34:43.850951 20800 net.cpp:454] conv4_2 <- conv4_1
I0227 04:34:43.850960 20800 net.cpp:411] conv4_2 -> conv4_2
I0227 04:34:43.855823 20800 net.cpp:150] Setting up conv4_2
I0227 04:34:43.855857 20800 net.cpp:157] Top shape: 10 512 41 41 (8606720)
I0227 04:34:43.855864 20800 net.cpp:165] Memory required for data: 2226040480
I0227 04:34:43.855877 20800 layer_factory.hpp:77] Creating layer relu4_2
I0227 04:34:43.855886 20800 net.cpp:106] Creating Layer relu4_2
I0227 04:34:43.855892 20800 net.cpp:454] relu4_2 <- conv4_2
I0227 04:34:43.855901 20800 net.cpp:397] relu4_2 -> conv4_2 (in-place)
I0227 04:34:43.855908 20800 net.cpp:150] Setting up relu4_2
I0227 04:34:43.855916 20800 net.cpp:157] Top shape: 10 512 41 41 (8606720)
I0227 04:34:43.855921 20800 net.cpp:165] Memory required for data: 2260467360
I0227 04:34:43.855927 20800 layer_factory.hpp:77] Creating layer conv4_3
I0227 04:34:43.855938 20800 net.cpp:106] Creating Layer conv4_3
I0227 04:34:43.855944 20800 net.cpp:454] conv4_3 <- conv4_2
I0227 04:34:43.855954 20800 net.cpp:411] conv4_3 -> conv4_3
I0227 04:34:43.860682 20800 net.cpp:150] Setting up conv4_3
I0227 04:34:43.860715 20800 net.cpp:157] Top shape: 10 512 41 41 (8606720)
I0227 04:34:43.860721 20800 net.cpp:165] Memory required for data: 2294894240
I0227 04:34:43.860730 20800 layer_factory.hpp:77] Creating layer relu4_3
I0227 04:34:43.860740 20800 net.cpp:106] Creating Layer relu4_3
I0227 04:34:43.860747 20800 net.cpp:454] relu4_3 <- conv4_3
I0227 04:34:43.860756 20800 net.cpp:397] relu4_3 -> conv4_3 (in-place)
I0227 04:34:43.860765 20800 net.cpp:150] Setting up relu4_3
I0227 04:34:43.860772 20800 net.cpp:157] Top shape: 10 512 41 41 (8606720)
I0227 04:34:43.860779 20800 net.cpp:165] Memory required for data: 2329321120
I0227 04:34:43.860783 20800 layer_factory.hpp:77] Creating layer pool4
I0227 04:34:43.860791 20800 net.cpp:106] Creating Layer pool4
I0227 04:34:43.860796 20800 net.cpp:454] pool4 <- conv4_3
I0227 04:34:43.860803 20800 net.cpp:411] pool4 -> pool4
I0227 04:34:43.860839 20800 net.cpp:150] Setting up pool4
I0227 04:34:43.860848 20800 net.cpp:157] Top shape: 10 512 41 41 (8606720)
I0227 04:34:43.860853 20800 net.cpp:165] Memory required for data: 2363748000
I0227 04:34:43.860858 20800 layer_factory.hpp:77] Creating layer conv5_1
I0227 04:34:43.860870 20800 net.cpp:106] Creating Layer conv5_1
I0227 04:34:43.860877 20800 net.cpp:454] conv5_1 <- pool4
I0227 04:34:43.860886 20800 net.cpp:411] conv5_1 -> conv5_1
I0227 04:34:43.865996 20800 net.cpp:150] Setting up conv5_1
I0227 04:34:43.866031 20800 net.cpp:157] Top shape: 10 512 41 41 (8606720)
I0227 04:34:43.866037 20800 net.cpp:165] Memory required for data: 2398174880
I0227 04:34:43.866046 20800 layer_factory.hpp:77] Creating layer relu5_1
I0227 04:34:43.866056 20800 net.cpp:106] Creating Layer relu5_1
I0227 04:34:43.866062 20800 net.cpp:454] relu5_1 <- conv5_1
I0227 04:34:43.866072 20800 net.cpp:397] relu5_1 -> conv5_1 (in-place)
I0227 04:34:43.866081 20800 net.cpp:150] Setting up relu5_1
I0227 04:34:43.866088 20800 net.cpp:157] Top shape: 10 512 41 41 (8606720)
I0227 04:34:43.866094 20800 net.cpp:165] Memory required for data: 2432601760
I0227 04:34:43.866099 20800 layer_factory.hpp:77] Creating layer conv5_2
I0227 04:34:43.866111 20800 net.cpp:106] Creating Layer conv5_2
I0227 04:34:43.866118 20800 net.cpp:454] conv5_2 <- conv5_1
I0227 04:34:43.866125 20800 net.cpp:411] conv5_2 -> conv5_2
I0227 04:34:43.871304 20800 net.cpp:150] Setting up conv5_2
I0227 04:34:43.871336 20800 net.cpp:157] Top shape: 10 512 41 41 (8606720)
I0227 04:34:43.871358 20800 net.cpp:165] Memory required for data: 2467028640
I0227 04:34:43.871368 20800 layer_factory.hpp:77] Creating layer relu5_2
I0227 04:34:43.871377 20800 net.cpp:106] Creating Layer relu5_2
I0227 04:34:43.871384 20800 net.cpp:454] relu5_2 <- conv5_2
I0227 04:34:43.871409 20800 net.cpp:397] relu5_2 -> conv5_2 (in-place)
I0227 04:34:43.871421 20800 net.cpp:150] Setting up relu5_2
I0227 04:34:43.871430 20800 net.cpp:157] Top shape: 10 512 41 41 (8606720)
I0227 04:34:43.871438 20800 net.cpp:165] Memory required for data: 2501455520
I0227 04:34:43.871444 20800 layer_factory.hpp:77] Creating layer conv5_3
I0227 04:34:43.871457 20800 net.cpp:106] Creating Layer conv5_3
I0227 04:34:43.871467 20800 net.cpp:454] conv5_3 <- conv5_2
I0227 04:34:43.871476 20800 net.cpp:411] conv5_3 -> conv5_3
I0227 04:34:43.877902 20800 net.cpp:150] Setting up conv5_3
I0227 04:34:43.877929 20800 net.cpp:157] Top shape: 10 512 41 41 (8606720)
I0227 04:34:43.877938 20800 net.cpp:165] Memory required for data: 2535882400
I0227 04:34:43.877949 20800 layer_factory.hpp:77] Creating layer relu5_3
I0227 04:34:43.877964 20800 net.cpp:106] Creating Layer relu5_3
I0227 04:34:43.877974 20800 net.cpp:454] relu5_3 <- conv5_3
I0227 04:34:43.877984 20800 net.cpp:397] relu5_3 -> conv5_3 (in-place)
I0227 04:34:43.877995 20800 net.cpp:150] Setting up relu5_3
I0227 04:34:43.878005 20800 net.cpp:157] Top shape: 10 512 41 41 (8606720)
I0227 04:34:43.878011 20800 net.cpp:165] Memory required for data: 2570309280
I0227 04:34:43.878018 20800 layer_factory.hpp:77] Creating layer pool5
I0227 04:34:43.878031 20800 net.cpp:106] Creating Layer pool5
I0227 04:34:43.878039 20800 net.cpp:454] pool5 <- conv5_3
I0227 04:34:43.878048 20800 net.cpp:411] pool5 -> pool5
I0227 04:34:43.878096 20800 net.cpp:150] Setting up pool5
I0227 04:34:43.878108 20800 net.cpp:157] Top shape: 10 512 41 41 (8606720)
I0227 04:34:43.878114 20800 net.cpp:165] Memory required for data: 2604736160
I0227 04:34:43.878121 20800 layer_factory.hpp:77] Creating layer pool5a
I0227 04:34:43.878137 20800 net.cpp:106] Creating Layer pool5a
I0227 04:34:43.878147 20800 net.cpp:454] pool5a <- pool5
I0227 04:34:43.878156 20800 net.cpp:411] pool5a -> pool5a
I0227 04:34:43.878182 20800 net.cpp:150] Setting up pool5a
I0227 04:34:43.878192 20800 net.cpp:157] Top shape: 10 512 41 41 (8606720)
I0227 04:34:43.878201 20800 net.cpp:165] Memory required for data: 2639163040
I0227 04:34:43.878208 20800 layer_factory.hpp:77] Creating layer pool5a_pool5a_0_split
I0227 04:34:43.878224 20800 net.cpp:106] Creating Layer pool5a_pool5a_0_split
I0227 04:34:43.878232 20800 net.cpp:454] pool5a_pool5a_0_split <- pool5a
I0227 04:34:43.878247 20800 net.cpp:411] pool5a_pool5a_0_split -> pool5a_pool5a_0_split_0
I0227 04:34:43.878258 20800 net.cpp:411] pool5a_pool5a_0_split -> pool5a_pool5a_0_split_1
I0227 04:34:43.878268 20800 net.cpp:411] pool5a_pool5a_0_split -> pool5a_pool5a_0_split_2
I0227 04:34:43.878278 20800 net.cpp:411] pool5a_pool5a_0_split -> pool5a_pool5a_0_split_3
I0227 04:34:43.878346 20800 net.cpp:150] Setting up pool5a_pool5a_0_split
I0227 04:34:43.878360 20800 net.cpp:157] Top shape: 10 512 41 41 (8606720)
I0227 04:34:43.878370 20800 net.cpp:157] Top shape: 10 512 41 41 (8606720)
I0227 04:34:43.878377 20800 net.cpp:157] Top shape: 10 512 41 41 (8606720)
I0227 04:34:43.878386 20800 net.cpp:157] Top shape: 10 512 41 41 (8606720)
I0227 04:34:43.878393 20800 net.cpp:165] Memory required for data: 2776870560
I0227 04:34:43.878401 20800 layer_factory.hpp:77] Creating layer fc6_1
I0227 04:34:43.878415 20800 net.cpp:106] Creating Layer fc6_1
I0227 04:34:43.878423 20800 net.cpp:454] fc6_1 <- pool5a_pool5a_0_split_0
I0227 04:34:43.878433 20800 net.cpp:411] fc6_1 -> fc6_1
I0227 04:34:43.893741 20800 net.cpp:150] Setting up fc6_1
I0227 04:34:43.893774 20800 net.cpp:157] Top shape: 10 1024 41 41 (17213440)
I0227 04:34:43.893782 20800 net.cpp:165] Memory required for data: 2845724320
I0227 04:34:43.893796 20800 layer_factory.hpp:77] Creating layer relu6_1
I0227 04:34:43.893810 20800 net.cpp:106] Creating Layer relu6_1
I0227 04:34:43.893820 20800 net.cpp:454] relu6_1 <- fc6_1
I0227 04:34:43.893829 20800 net.cpp:397] relu6_1 -> fc6_1 (in-place)
I0227 04:34:43.893842 20800 net.cpp:150] Setting up relu6_1
I0227 04:34:43.893851 20800 net.cpp:157] Top shape: 10 1024 41 41 (17213440)
I0227 04:34:43.893858 20800 net.cpp:165] Memory required for data: 2914578080
I0227 04:34:43.893865 20800 layer_factory.hpp:77] Creating layer drop6_1
I0227 04:34:43.893883 20800 net.cpp:106] Creating Layer drop6_1
I0227 04:34:43.893891 20800 net.cpp:454] drop6_1 <- fc6_1
I0227 04:34:43.893900 20800 net.cpp:397] drop6_1 -> fc6_1 (in-place)
I0227 04:34:43.893934 20800 net.cpp:150] Setting up drop6_1
I0227 04:34:43.893945 20800 net.cpp:157] Top shape: 10 1024 41 41 (17213440)
I0227 04:34:43.893952 20800 net.cpp:165] Memory required for data: 2983431840
I0227 04:34:43.893960 20800 layer_factory.hpp:77] Creating layer fc7_1
I0227 04:34:43.893976 20800 net.cpp:106] Creating Layer fc7_1
I0227 04:34:43.893985 20800 net.cpp:454] fc7_1 <- fc6_1
I0227 04:34:43.893995 20800 net.cpp:411] fc7_1 -> fc7_1
I0227 04:34:43.897876 20800 net.cpp:150] Setting up fc7_1
I0227 04:34:43.897912 20800 net.cpp:157] Top shape: 10 1024 41 41 (17213440)
I0227 04:34:43.897924 20800 net.cpp:165] Memory required for data: 3052285600
I0227 04:34:43.897943 20800 layer_factory.hpp:77] Creating layer relu7_1
I0227 04:34:43.897963 20800 net.cpp:106] Creating Layer relu7_1
I0227 04:34:43.897975 20800 net.cpp:454] relu7_1 <- fc7_1
I0227 04:34:43.897989 20800 net.cpp:397] relu7_1 -> fc7_1 (in-place)
I0227 04:34:43.898007 20800 net.cpp:150] Setting up relu7_1
I0227 04:34:43.898022 20800 net.cpp:157] Top shape: 10 1024 41 41 (17213440)
I0227 04:34:43.898034 20800 net.cpp:165] Memory required for data: 3121139360
I0227 04:34:43.898046 20800 layer_factory.hpp:77] Creating layer drop7_1
I0227 04:34:43.898063 20800 net.cpp:106] Creating Layer drop7_1
I0227 04:34:43.898075 20800 net.cpp:454] drop7_1 <- fc7_1
I0227 04:34:43.898089 20800 net.cpp:397] drop7_1 -> fc7_1 (in-place)
I0227 04:34:43.898138 20800 net.cpp:150] Setting up drop7_1
I0227 04:34:43.898156 20800 net.cpp:157] Top shape: 10 1024 41 41 (17213440)
I0227 04:34:43.898169 20800 net.cpp:165] Memory required for data: 3189993120
I0227 04:34:43.898180 20800 layer_factory.hpp:77] Creating layer fc8-SEC_1
I0227 04:34:43.898202 20800 net.cpp:106] Creating Layer fc8-SEC_1
I0227 04:34:43.898216 20800 net.cpp:454] fc8-SEC_1 <- fc7_1
I0227 04:34:43.898234 20800 net.cpp:411] fc8-SEC_1 -> fc8-SEC_1
I0227 04:34:43.899065 20800 net.cpp:150] Setting up fc8-SEC_1
I0227 04:34:43.899089 20800 net.cpp:157] Top shape: 10 21 41 41 (353010)
I0227 04:34:43.899101 20800 net.cpp:165] Memory required for data: 3191405160
I0227 04:34:43.899119 20800 layer_factory.hpp:77] Creating layer fc6_2
I0227 04:34:43.899142 20800 net.cpp:106] Creating Layer fc6_2
I0227 04:34:43.899154 20800 net.cpp:454] fc6_2 <- pool5a_pool5a_0_split_1
I0227 04:34:43.899169 20800 net.cpp:411] fc6_2 -> fc6_2
I0227 04:34:43.911162 20800 net.cpp:150] Setting up fc6_2
I0227 04:34:43.911185 20800 net.cpp:157] Top shape: 10 1024 41 41 (17213440)
I0227 04:34:43.911190 20800 net.cpp:165] Memory required for data: 3260258920
I0227 04:34:43.911208 20800 layer_factory.hpp:77] Creating layer relu6_2
I0227 04:34:43.911218 20800 net.cpp:106] Creating Layer relu6_2
I0227 04:34:43.911226 20800 net.cpp:454] relu6_2 <- fc6_2
I0227 04:34:43.911233 20800 net.cpp:397] relu6_2 -> fc6_2 (in-place)
I0227 04:34:43.911242 20800 net.cpp:150] Setting up relu6_2
I0227 04:34:43.911249 20800 net.cpp:157] Top shape: 10 1024 41 41 (17213440)
I0227 04:34:43.911272 20800 net.cpp:165] Memory required for data: 3329112680
I0227 04:34:43.911291 20800 layer_factory.hpp:77] Creating layer drop6_2
I0227 04:34:43.911299 20800 net.cpp:106] Creating Layer drop6_2
I0227 04:34:43.911304 20800 net.cpp:454] drop6_2 <- fc6_2
I0227 04:34:43.911314 20800 net.cpp:397] drop6_2 -> fc6_2 (in-place)
I0227 04:34:43.911337 20800 net.cpp:150] Setting up drop6_2
I0227 04:34:43.911345 20800 net.cpp:157] Top shape: 10 1024 41 41 (17213440)
I0227 04:34:43.911352 20800 net.cpp:165] Memory required for data: 3397966440
I0227 04:34:43.911358 20800 layer_factory.hpp:77] Creating layer fc7_2
I0227 04:34:43.911367 20800 net.cpp:106] Creating Layer fc7_2
I0227 04:34:43.911373 20800 net.cpp:454] fc7_2 <- fc6_2
I0227 04:34:43.911381 20800 net.cpp:411] fc7_2 -> fc7_2
I0227 04:34:43.913585 20800 net.cpp:150] Setting up fc7_2
I0227 04:34:43.913620 20800 net.cpp:157] Top shape: 10 1024 41 41 (17213440)
I0227 04:34:43.913626 20800 net.cpp:165] Memory required for data: 3466820200
I0227 04:34:43.913635 20800 layer_factory.hpp:77] Creating layer relu7_2
I0227 04:34:43.913646 20800 net.cpp:106] Creating Layer relu7_2
I0227 04:34:43.913653 20800 net.cpp:454] relu7_2 <- fc7_2
I0227 04:34:43.913663 20800 net.cpp:397] relu7_2 -> fc7_2 (in-place)
I0227 04:34:43.913671 20800 net.cpp:150] Setting up relu7_2
I0227 04:34:43.913678 20800 net.cpp:157] Top shape: 10 1024 41 41 (17213440)
I0227 04:34:43.913684 20800 net.cpp:165] Memory required for data: 3535673960
I0227 04:34:43.913689 20800 layer_factory.hpp:77] Creating layer drop7_2
I0227 04:34:43.913698 20800 net.cpp:106] Creating Layer drop7_2
I0227 04:34:43.913704 20800 net.cpp:454] drop7_2 <- fc7_2
I0227 04:34:43.913712 20800 net.cpp:397] drop7_2 -> fc7_2 (in-place)
I0227 04:34:43.913735 20800 net.cpp:150] Setting up drop7_2
I0227 04:34:43.913744 20800 net.cpp:157] Top shape: 10 1024 41 41 (17213440)
I0227 04:34:43.913749 20800 net.cpp:165] Memory required for data: 3604527720
I0227 04:34:43.913755 20800 layer_factory.hpp:77] Creating layer fc8-SEC_2
I0227 04:34:43.913766 20800 net.cpp:106] Creating Layer fc8-SEC_2
I0227 04:34:43.913772 20800 net.cpp:454] fc8-SEC_2 <- fc7_2
I0227 04:34:43.913780 20800 net.cpp:411] fc8-SEC_2 -> fc8-SEC_2
I0227 04:34:43.914163 20800 net.cpp:150] Setting up fc8-SEC_2
I0227 04:34:43.914175 20800 net.cpp:157] Top shape: 10 21 41 41 (353010)
I0227 04:34:43.914196 20800 net.cpp:165] Memory required for data: 3605939760
I0227 04:34:43.914203 20800 layer_factory.hpp:77] Creating layer fc6_3
I0227 04:34:43.914213 20800 net.cpp:106] Creating Layer fc6_3
I0227 04:34:43.914219 20800 net.cpp:454] fc6_3 <- pool5a_pool5a_0_split_2
I0227 04:34:43.914228 20800 net.cpp:411] fc6_3 -> fc6_3
I0227 04:34:43.922900 20800 net.cpp:150] Setting up fc6_3
I0227 04:34:43.922950 20800 net.cpp:157] Top shape: 10 1024 41 41 (17213440)
I0227 04:34:43.922957 20800 net.cpp:165] Memory required for data: 3674793520
I0227 04:34:43.922967 20800 layer_factory.hpp:77] Creating layer relu6_3
I0227 04:34:43.922977 20800 net.cpp:106] Creating Layer relu6_3
I0227 04:34:43.922986 20800 net.cpp:454] relu6_3 <- fc6_3
I0227 04:34:43.922996 20800 net.cpp:397] relu6_3 -> fc6_3 (in-place)
I0227 04:34:43.923007 20800 net.cpp:150] Setting up relu6_3
I0227 04:34:43.923013 20800 net.cpp:157] Top shape: 10 1024 41 41 (17213440)
I0227 04:34:43.923019 20800 net.cpp:165] Memory required for data: 3743647280
I0227 04:34:43.923025 20800 layer_factory.hpp:77] Creating layer drop6_3
I0227 04:34:43.923033 20800 net.cpp:106] Creating Layer drop6_3
I0227 04:34:43.923040 20800 net.cpp:454] drop6_3 <- fc6_3
I0227 04:34:43.923048 20800 net.cpp:397] drop6_3 -> fc6_3 (in-place)
I0227 04:34:43.923074 20800 net.cpp:150] Setting up drop6_3
I0227 04:34:43.923082 20800 net.cpp:157] Top shape: 10 1024 41 41 (17213440)
I0227 04:34:43.923089 20800 net.cpp:165] Memory required for data: 3812501040
I0227 04:34:43.923094 20800 layer_factory.hpp:77] Creating layer fc7_3
I0227 04:34:43.923105 20800 net.cpp:106] Creating Layer fc7_3
I0227 04:34:43.923111 20800 net.cpp:454] fc7_3 <- fc6_3
I0227 04:34:43.923120 20800 net.cpp:411] fc7_3 -> fc7_3
I0227 04:34:43.925629 20800 net.cpp:150] Setting up fc7_3
I0227 04:34:43.925663 20800 net.cpp:157] Top shape: 10 1024 41 41 (17213440)
I0227 04:34:43.925670 20800 net.cpp:165] Memory required for data: 3881354800
I0227 04:34:43.925679 20800 layer_factory.hpp:77] Creating layer relu7_3
I0227 04:34:43.925690 20800 net.cpp:106] Creating Layer relu7_3
I0227 04:34:43.925698 20800 net.cpp:454] relu7_3 <- fc7_3
I0227 04:34:43.925705 20800 net.cpp:397] relu7_3 -> fc7_3 (in-place)
I0227 04:34:43.925714 20800 net.cpp:150] Setting up relu7_3
I0227 04:34:43.925721 20800 net.cpp:157] Top shape: 10 1024 41 41 (17213440)
I0227 04:34:43.925727 20800 net.cpp:165] Memory required for data: 3950208560
I0227 04:34:43.925734 20800 layer_factory.hpp:77] Creating layer drop7_3
I0227 04:34:43.925743 20800 net.cpp:106] Creating Layer drop7_3
I0227 04:34:43.925750 20800 net.cpp:454] drop7_3 <- fc7_3
I0227 04:34:43.925760 20800 net.cpp:397] drop7_3 -> fc7_3 (in-place)
I0227 04:34:43.925783 20800 net.cpp:150] Setting up drop7_3
I0227 04:34:43.925792 20800 net.cpp:157] Top shape: 10 1024 41 41 (17213440)
I0227 04:34:43.925798 20800 net.cpp:165] Memory required for data: 4019062320
I0227 04:34:43.925803 20800 layer_factory.hpp:77] Creating layer fc8-SEC_3
I0227 04:34:43.925815 20800 net.cpp:106] Creating Layer fc8-SEC_3
I0227 04:34:43.925822 20800 net.cpp:454] fc8-SEC_3 <- fc7_3
I0227 04:34:43.925829 20800 net.cpp:411] fc8-SEC_3 -> fc8-SEC_3
I0227 04:34:43.926224 20800 net.cpp:150] Setting up fc8-SEC_3
I0227 04:34:43.926236 20800 net.cpp:157] Top shape: 10 21 41 41 (353010)
I0227 04:34:43.926257 20800 net.cpp:165] Memory required for data: 4020474360
I0227 04:34:43.926266 20800 layer_factory.hpp:77] Creating layer fc6_4
I0227 04:34:43.926276 20800 net.cpp:106] Creating Layer fc6_4
I0227 04:34:43.926282 20800 net.cpp:454] fc6_4 <- pool5a_pool5a_0_split_3
I0227 04:34:43.926293 20800 net.cpp:411] fc6_4 -> fc6_4
I0227 04:34:43.935410 20800 net.cpp:150] Setting up fc6_4
I0227 04:34:43.935444 20800 net.cpp:157] Top shape: 10 1024 41 41 (17213440)
I0227 04:34:43.935451 20800 net.cpp:165] Memory required for data: 4089328120
I0227 04:34:43.935459 20800 layer_factory.hpp:77] Creating layer relu6_4
I0227 04:34:43.935468 20800 net.cpp:106] Creating Layer relu6_4
I0227 04:34:43.935474 20800 net.cpp:454] relu6_4 <- fc6_4
I0227 04:34:43.935483 20800 net.cpp:397] relu6_4 -> fc6_4 (in-place)
I0227 04:34:43.935493 20800 net.cpp:150] Setting up relu6_4
I0227 04:34:43.935500 20800 net.cpp:157] Top shape: 10 1024 41 41 (17213440)
I0227 04:34:43.935505 20800 net.cpp:165] Memory required for data: 4158181880
I0227 04:34:43.935511 20800 layer_factory.hpp:77] Creating layer drop6_4
I0227 04:34:43.935518 20800 net.cpp:106] Creating Layer drop6_4
I0227 04:34:43.935524 20800 net.cpp:454] drop6_4 <- fc6_4
I0227 04:34:43.935531 20800 net.cpp:397] drop6_4 -> fc6_4 (in-place)
I0227 04:34:43.935555 20800 net.cpp:150] Setting up drop6_4
I0227 04:34:43.935564 20800 net.cpp:157] Top shape: 10 1024 41 41 (17213440)
I0227 04:34:43.935570 20800 net.cpp:165] Memory required for data: 4227035640
I0227 04:34:43.935575 20800 layer_factory.hpp:77] Creating layer fc7_4
I0227 04:34:43.935585 20800 net.cpp:106] Creating Layer fc7_4
I0227 04:34:43.935590 20800 net.cpp:454] fc7_4 <- fc6_4
I0227 04:34:43.935597 20800 net.cpp:411] fc7_4 -> fc7_4
I0227 04:34:43.938311 20800 net.cpp:150] Setting up fc7_4
I0227 04:34:43.938344 20800 net.cpp:157] Top shape: 10 1024 41 41 (17213440)
I0227 04:34:43.938351 20800 net.cpp:165] Memory required for data: 4295889400
I0227 04:34:43.938360 20800 layer_factory.hpp:77] Creating layer relu7_4
I0227 04:34:43.938370 20800 net.cpp:106] Creating Layer relu7_4
I0227 04:34:43.938377 20800 net.cpp:454] relu7_4 <- fc7_4
I0227 04:34:43.938388 20800 net.cpp:397] relu7_4 -> fc7_4 (in-place)
I0227 04:34:43.938397 20800 net.cpp:150] Setting up relu7_4
I0227 04:34:43.938405 20800 net.cpp:157] Top shape: 10 1024 41 41 (17213440)
I0227 04:34:43.938410 20800 net.cpp:165] Memory required for data: 4364743160
I0227 04:34:43.938416 20800 layer_factory.hpp:77] Creating layer drop7_4
I0227 04:34:43.938423 20800 net.cpp:106] Creating Layer drop7_4
I0227 04:34:43.938429 20800 net.cpp:454] drop7_4 <- fc7_4
I0227 04:34:43.938437 20800 net.cpp:397] drop7_4 -> fc7_4 (in-place)
I0227 04:34:43.938459 20800 net.cpp:150] Setting up drop7_4
I0227 04:34:43.938467 20800 net.cpp:157] Top shape: 10 1024 41 41 (17213440)
I0227 04:34:43.938473 20800 net.cpp:165] Memory required for data: 4433596920
I0227 04:34:43.938478 20800 layer_factory.hpp:77] Creating layer fc8-SEC_4
I0227 04:34:43.938491 20800 net.cpp:106] Creating Layer fc8-SEC_4
I0227 04:34:43.938498 20800 net.cpp:454] fc8-SEC_4 <- fc7_4
I0227 04:34:43.938505 20800 net.cpp:411] fc8-SEC_4 -> fc8-SEC_4
I0227 04:34:43.938947 20800 net.cpp:150] Setting up fc8-SEC_4
I0227 04:34:43.938958 20800 net.cpp:157] Top shape: 10 21 41 41 (353010)
I0227 04:34:43.938978 20800 net.cpp:165] Memory required for data: 4435008960
I0227 04:34:43.938987 20800 layer_factory.hpp:77] Creating layer fc8-SEC
I0227 04:34:43.938999 20800 net.cpp:106] Creating Layer fc8-SEC
I0227 04:34:43.939007 20800 net.cpp:454] fc8-SEC <- fc8-SEC_1
I0227 04:34:43.939013 20800 net.cpp:454] fc8-SEC <- fc8-SEC_2
I0227 04:34:43.939018 20800 net.cpp:454] fc8-SEC <- fc8-SEC_3
I0227 04:34:43.939023 20800 net.cpp:454] fc8-SEC <- fc8-SEC_4
I0227 04:34:43.939030 20800 net.cpp:411] fc8-SEC -> fc8-SEC
I0227 04:34:43.939057 20800 net.cpp:150] Setting up fc8-SEC
I0227 04:34:43.939065 20800 net.cpp:157] Top shape: 10 21 41 41 (353010)
I0227 04:34:43.939070 20800 net.cpp:165] Memory required for data: 4436421000
I0227 04:34:43.939075 20800 layer_factory.hpp:77] Creating layer fc8-SEC_fc8-SEC_0_split
I0227 04:34:43.939083 20800 net.cpp:106] Creating Layer fc8-SEC_fc8-SEC_0_split
I0227 04:34:43.939088 20800 net.cpp:454] fc8-SEC_fc8-SEC_0_split <- fc8-SEC
I0227 04:34:43.939096 20800 net.cpp:411] fc8-SEC_fc8-SEC_0_split -> fc8-SEC_fc8-SEC_0_split_0
I0227 04:34:43.939103 20800 net.cpp:411] fc8-SEC_fc8-SEC_0_split -> fc8-SEC_fc8-SEC_0_split_1
I0227 04:34:43.939131 20800 net.cpp:150] Setting up fc8-SEC_fc8-SEC_0_split
I0227 04:34:43.939141 20800 net.cpp:157] Top shape: 10 21 41 41 (353010)
I0227 04:34:43.939146 20800 net.cpp:157] Top shape: 10 21 41 41 (353010)
I0227 04:34:43.939152 20800 net.cpp:165] Memory required for data: 4439245080
I0227 04:34:43.939157 20800 layer_factory.hpp:77] Creating layer label_shrink
I0227 04:34:43.940989 20800 net.cpp:106] Creating Layer label_shrink
I0227 04:34:43.941015 20800 net.cpp:454] label_shrink <- label
I0227 04:34:43.941037 20800 net.cpp:411] label_shrink -> label_shrink
I0227 04:34:43.941066 20800 net.cpp:150] Setting up label_shrink
I0227 04:34:43.941076 20800 net.cpp:157] Top shape: 10 1 41 41 (16810)
I0227 04:34:43.941082 20800 net.cpp:165] Memory required for data: 4439312320
I0227 04:34:43.941088 20800 layer_factory.hpp:77] Creating layer label_shrink_label_shrink_0_split
I0227 04:34:43.941097 20800 net.cpp:106] Creating Layer label_shrink_label_shrink_0_split
I0227 04:34:43.941102 20800 net.cpp:454] label_shrink_label_shrink_0_split <- label_shrink
I0227 04:34:43.941110 20800 net.cpp:411] label_shrink_label_shrink_0_split -> label_shrink_label_shrink_0_split_0
I0227 04:34:43.941118 20800 net.cpp:411] label_shrink_label_shrink_0_split -> label_shrink_label_shrink_0_split_1
I0227 04:34:43.941148 20800 net.cpp:150] Setting up label_shrink_label_shrink_0_split
I0227 04:34:43.941156 20800 net.cpp:157] Top shape: 10 1 41 41 (16810)
I0227 04:34:43.941164 20800 net.cpp:157] Top shape: 10 1 41 41 (16810)
I0227 04:34:43.941169 20800 net.cpp:165] Memory required for data: 4439446800
I0227 04:34:43.941174 20800 layer_factory.hpp:77] Creating layer loss
I0227 04:34:43.941545 20800 net.cpp:106] Creating Layer loss
I0227 04:34:43.941579 20800 net.cpp:454] loss <- fc8-SEC_fc8-SEC_0_split_0
I0227 04:34:43.941588 20800 net.cpp:454] loss <- label_shrink_label_shrink_0_split_0
I0227 04:34:43.941602 20800 net.cpp:411] loss -> (automatic)
I0227 04:34:43.941617 20800 layer_factory.hpp:77] Creating layer loss
I0227 04:34:43.943300 20800 net.cpp:150] Setting up loss
I0227 04:34:43.943322 20800 net.cpp:157] Top shape: (1)
I0227 04:34:43.943331 20800 net.cpp:160]     with loss weight 1
I0227 04:34:43.943348 20800 net.cpp:165] Memory required for data: 4439446804
I0227 04:34:43.943357 20800 layer_factory.hpp:77] Creating layer accuracy
I0227 04:34:43.943657 20800 net.cpp:106] Creating Layer accuracy
I0227 04:34:43.943672 20800 net.cpp:454] accuracy <- fc8-SEC_fc8-SEC_0_split_1
I0227 04:34:43.943683 20800 net.cpp:454] accuracy <- label_shrink_label_shrink_0_split_1
I0227 04:34:43.943697 20800 net.cpp:411] accuracy -> accuracy
I0227 04:34:43.943747 20800 net.cpp:150] Setting up accuracy
I0227 04:34:43.943761 20800 net.cpp:157] Top shape: 1 1 1 3 (3)
I0227 04:34:43.943770 20800 net.cpp:165] Memory required for data: 4439446816
I0227 04:34:43.943779 20800 net.cpp:228] accuracy does not need backward computation.
I0227 04:34:43.943787 20800 net.cpp:226] loss needs backward computation.
I0227 04:34:43.943796 20800 net.cpp:228] label_shrink_label_shrink_0_split does not need backward computation.
I0227 04:34:43.943804 20800 net.cpp:228] label_shrink does not need backward computation.
I0227 04:34:43.943814 20800 net.cpp:226] fc8-SEC_fc8-SEC_0_split needs backward computation.
I0227 04:34:43.943821 20800 net.cpp:226] fc8-SEC needs backward computation.
I0227 04:34:43.943830 20800 net.cpp:226] fc8-SEC_4 needs backward computation.
I0227 04:34:43.943837 20800 net.cpp:226] drop7_4 needs backward computation.
I0227 04:34:43.943845 20800 net.cpp:226] relu7_4 needs backward computation.
I0227 04:34:43.943852 20800 net.cpp:226] fc7_4 needs backward computation.
I0227 04:34:43.943861 20800 net.cpp:226] drop6_4 needs backward computation.
I0227 04:34:43.943867 20800 net.cpp:226] relu6_4 needs backward computation.
I0227 04:34:43.943874 20800 net.cpp:226] fc6_4 needs backward computation.
I0227 04:34:43.943882 20800 net.cpp:226] fc8-SEC_3 needs backward computation.
I0227 04:34:43.943889 20800 net.cpp:226] drop7_3 needs backward computation.
I0227 04:34:43.943897 20800 net.cpp:226] relu7_3 needs backward computation.
I0227 04:34:43.943905 20800 net.cpp:226] fc7_3 needs backward computation.
I0227 04:34:43.943913 20800 net.cpp:226] drop6_3 needs backward computation.
I0227 04:34:43.943920 20800 net.cpp:226] relu6_3 needs backward computation.
I0227 04:34:43.943928 20800 net.cpp:226] fc6_3 needs backward computation.
I0227 04:34:43.943935 20800 net.cpp:226] fc8-SEC_2 needs backward computation.
I0227 04:34:43.943943 20800 net.cpp:226] drop7_2 needs backward computation.
I0227 04:34:43.943950 20800 net.cpp:226] relu7_2 needs backward computation.
I0227 04:34:43.943958 20800 net.cpp:226] fc7_2 needs backward computation.
I0227 04:34:43.943966 20800 net.cpp:226] drop6_2 needs backward computation.
I0227 04:34:43.943974 20800 net.cpp:226] relu6_2 needs backward computation.
I0227 04:34:43.943980 20800 net.cpp:226] fc6_2 needs backward computation.
I0227 04:34:43.943989 20800 net.cpp:226] fc8-SEC_1 needs backward computation.
I0227 04:34:43.943995 20800 net.cpp:226] drop7_1 needs backward computation.
I0227 04:34:43.944005 20800 net.cpp:226] relu7_1 needs backward computation.
I0227 04:34:43.944012 20800 net.cpp:226] fc7_1 needs backward computation.
I0227 04:34:43.944020 20800 net.cpp:226] drop6_1 needs backward computation.
I0227 04:34:43.944027 20800 net.cpp:226] relu6_1 needs backward computation.
I0227 04:34:43.944034 20800 net.cpp:226] fc6_1 needs backward computation.
I0227 04:34:43.944042 20800 net.cpp:226] pool5a_pool5a_0_split needs backward computation.
I0227 04:34:43.944051 20800 net.cpp:226] pool5a needs backward computation.
I0227 04:34:43.944059 20800 net.cpp:226] pool5 needs backward computation.
I0227 04:34:43.944067 20800 net.cpp:226] relu5_3 needs backward computation.
I0227 04:34:43.944074 20800 net.cpp:226] conv5_3 needs backward computation.
I0227 04:34:43.944082 20800 net.cpp:226] relu5_2 needs backward computation.
I0227 04:34:43.944089 20800 net.cpp:226] conv5_2 needs backward computation.
I0227 04:34:43.944097 20800 net.cpp:226] relu5_1 needs backward computation.
I0227 04:34:43.944105 20800 net.cpp:226] conv5_1 needs backward computation.
I0227 04:34:43.944113 20800 net.cpp:226] pool4 needs backward computation.
I0227 04:34:43.944121 20800 net.cpp:226] relu4_3 needs backward computation.
I0227 04:34:43.944128 20800 net.cpp:226] conv4_3 needs backward computation.
I0227 04:34:43.944136 20800 net.cpp:226] relu4_2 needs backward computation.
I0227 04:34:43.944144 20800 net.cpp:226] conv4_2 needs backward computation.
I0227 04:34:43.944151 20800 net.cpp:226] relu4_1 needs backward computation.
I0227 04:34:43.944159 20800 net.cpp:226] conv4_1 needs backward computation.
I0227 04:34:43.944167 20800 net.cpp:226] pool3 needs backward computation.
I0227 04:34:43.944175 20800 net.cpp:226] relu3_3 needs backward computation.
I0227 04:34:43.944182 20800 net.cpp:226] conv3_3 needs backward computation.
I0227 04:34:43.944190 20800 net.cpp:226] relu3_2 needs backward computation.
I0227 04:34:43.944197 20800 net.cpp:226] conv3_2 needs backward computation.
I0227 04:34:43.944205 20800 net.cpp:226] relu3_1 needs backward computation.
I0227 04:34:43.944213 20800 net.cpp:226] conv3_1 needs backward computation.
I0227 04:34:43.944221 20800 net.cpp:226] pool2 needs backward computation.
I0227 04:34:43.944231 20800 net.cpp:226] relu2_2 needs backward computation.
I0227 04:34:43.944239 20800 net.cpp:226] conv2_2 needs backward computation.
I0227 04:34:43.944247 20800 net.cpp:226] relu2_1 needs backward computation.
I0227 04:34:43.944254 20800 net.cpp:226] conv2_1 needs backward computation.
I0227 04:34:43.944262 20800 net.cpp:226] pool1 needs backward computation.
I0227 04:34:43.944269 20800 net.cpp:226] relu1_2 needs backward computation.
I0227 04:34:43.944278 20800 net.cpp:226] conv1_2 needs backward computation.
I0227 04:34:43.944285 20800 net.cpp:226] relu1_1 needs backward computation.
I0227 04:34:43.944293 20800 net.cpp:226] conv1_1 needs backward computation.
I0227 04:34:43.944301 20800 net.cpp:228] data does not need backward computation.
I0227 04:34:43.944308 20800 net.cpp:270] This network produces output accuracy
I0227 04:34:43.944355 20800 net.cpp:283] Network initialization done.
I0227 04:34:43.944572 20800 solver.cpp:60] Solver scaffolding done.
Loading pretrained model weights from models/model-s_iter_8000.caffemodel
I0227 04:34:44.017217 20800 net.cpp:816] Ignoring source layer Input
I0227 04:34:44.017246 20800 net.cpp:816] Ignoring source layer Annotation
I0227 04:34:44.017251 20800 net.cpp:816] Ignoring source layer images_Annotation_2_split
I0227 04:34:44.044319 20800 net.cpp:816] Ignoring source layer Softmax
I0227 04:34:44.044358 20800 net.cpp:816] Ignoring source layer fc8-SEC-Softmax_Softmax_0_split
I0227 04:34:44.044364 20800 net.cpp:816] Ignoring source layer CRF
I0227 04:34:44.044370 20800 net.cpp:816] Ignoring source layer update-seed
I0227 04:34:44.044376 20800 net.cpp:816] Ignoring source layer loss-Seed
I0227 04:34:44.044381 20800 net.cpp:816] Ignoring source layer loss-Constrain
Solving...
I0227 04:34:44.047345 20800 solver.cpp:280] Solving DSRG
I0227 04:34:44.047354 20800 solver.cpp:281] Learning Rate Policy: poly
I0227 04:34:44.677335 20800 solver.cpp:229] Iteration 0, loss = 0.449066
I0227 04:34:44.677374 20800 solver.cpp:245]     Train net output #0: accuracy = 0.849503
I0227 04:34:44.677386 20800 solver.cpp:245]     Train net output #1: accuracy = 0.580284
I0227 04:34:44.677394 20800 solver.cpp:245]     Train net output #2: accuracy = 0.674547
I0227 04:34:44.677407 20800 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0227 04:35:01.799964 20800 solver.cpp:229] Iteration 20, loss = 0.359671
I0227 04:35:01.800009 20800 solver.cpp:245]     Train net output #0: accuracy = 0.812314
I0227 04:35:01.800019 20800 solver.cpp:245]     Train net output #1: accuracy = 0.675281
I0227 04:35:01.800026 20800 solver.cpp:245]     Train net output #2: accuracy = 0.56706
I0227 04:35:01.800036 20800 sgd_solver.cpp:106] Iteration 20, lr = 0.0009991
I0227 04:35:18.989398 20800 solver.cpp:229] Iteration 40, loss = 0.351744
I0227 04:35:18.989428 20800 solver.cpp:245]     Train net output #0: accuracy = 0.86282
I0227 04:35:18.989435 20800 solver.cpp:245]     Train net output #1: accuracy = 0.53745
I0227 04:35:18.989442 20800 solver.cpp:245]     Train net output #2: accuracy = 0.663837
I0227 04:35:18.989451 20800 sgd_solver.cpp:106] Iteration 40, lr = 0.0009982
I0227 04:35:36.212411 20800 solver.cpp:229] Iteration 60, loss = 0.338397
I0227 04:35:36.212441 20800 solver.cpp:245]     Train net output #0: accuracy = 0.899988
I0227 04:35:36.212450 20800 solver.cpp:245]     Train net output #1: accuracy = 0.778923
I0227 04:35:36.212457 20800 solver.cpp:245]     Train net output #2: accuracy = 0.778166
I0227 04:35:36.212466 20800 sgd_solver.cpp:106] Iteration 60, lr = 0.0009973
I0227 04:35:53.434265 20800 solver.cpp:229] Iteration 80, loss = 0.360216
I0227 04:35:53.434310 20800 solver.cpp:245]     Train net output #0: accuracy = 0.903748
I0227 04:35:53.434319 20800 solver.cpp:245]     Train net output #1: accuracy = 0.624166
I0227 04:35:53.434326 20800 solver.cpp:245]     Train net output #2: accuracy = 0.528809
I0227 04:35:53.434335 20800 sgd_solver.cpp:106] Iteration 80, lr = 0.000996399
I0227 04:36:10.633389 20800 solver.cpp:229] Iteration 100, loss = 0.417691
I0227 04:36:10.633435 20800 solver.cpp:245]     Train net output #0: accuracy = 0.87697
I0227 04:36:10.633445 20800 solver.cpp:245]     Train net output #1: accuracy = 0.676172
I0227 04:36:10.633451 20800 solver.cpp:245]     Train net output #2: accuracy = 0.403499
I0227 04:36:10.633460 20800 sgd_solver.cpp:106] Iteration 100, lr = 0.000995499
I0227 04:36:27.870427 20800 solver.cpp:229] Iteration 120, loss = 0.384345
I0227 04:36:27.870473 20800 solver.cpp:245]     Train net output #0: accuracy = 0.874599
I0227 04:36:27.870482 20800 solver.cpp:245]     Train net output #1: accuracy = 0.613884
I0227 04:36:27.870488 20800 solver.cpp:245]     Train net output #2: accuracy = 0.823718
I0227 04:36:27.870498 20800 sgd_solver.cpp:106] Iteration 120, lr = 0.000994598
I0227 04:36:45.119765 20800 solver.cpp:229] Iteration 140, loss = 0.351368
I0227 04:36:45.119810 20800 solver.cpp:245]     Train net output #0: accuracy = 0.904938
I0227 04:36:45.119820 20800 solver.cpp:245]     Train net output #1: accuracy = 0.666216
I0227 04:36:45.119827 20800 solver.cpp:245]     Train net output #2: accuracy = 0.665686
I0227 04:36:45.119837 20800 sgd_solver.cpp:106] Iteration 140, lr = 0.000993698
I0227 04:37:02.364385 20800 solver.cpp:229] Iteration 160, loss = 0.327112
I0227 04:37:02.364429 20800 solver.cpp:245]     Train net output #0: accuracy = 0.793456
I0227 04:37:02.364439 20800 solver.cpp:245]     Train net output #1: accuracy = 0.447137
I0227 04:37:02.364445 20800 solver.cpp:245]     Train net output #2: accuracy = 0.577378
I0227 04:37:02.364454 20800 sgd_solver.cpp:106] Iteration 160, lr = 0.000992797
I0227 04:37:19.594913 20800 solver.cpp:229] Iteration 180, loss = 0.358437
I0227 04:37:19.594944 20800 solver.cpp:245]     Train net output #0: accuracy = 0.865764
I0227 04:37:19.594952 20800 solver.cpp:245]     Train net output #1: accuracy = 0.663794
I0227 04:37:19.594960 20800 solver.cpp:245]     Train net output #2: accuracy = 0.536958
I0227 04:37:19.594969 20800 sgd_solver.cpp:106] Iteration 180, lr = 0.000991896
I0227 04:37:36.840457 20800 solver.cpp:229] Iteration 200, loss = 0.329482
I0227 04:37:36.840502 20800 solver.cpp:245]     Train net output #0: accuracy = 0.936347
I0227 04:37:36.840512 20800 solver.cpp:245]     Train net output #1: accuracy = 0.761003
I0227 04:37:36.840518 20800 solver.cpp:245]     Train net output #2: accuracy = 0.837594
I0227 04:37:36.840528 20800 sgd_solver.cpp:106] Iteration 200, lr = 0.000990996
I0227 04:37:54.112511 20800 solver.cpp:229] Iteration 220, loss = 0.302132
I0227 04:37:54.112558 20800 solver.cpp:245]     Train net output #0: accuracy = 0.93373
I0227 04:37:54.112568 20800 solver.cpp:245]     Train net output #1: accuracy = 0.773521
I0227 04:37:54.112576 20800 solver.cpp:245]     Train net output #2: accuracy = 0.850892
I0227 04:37:54.112586 20800 sgd_solver.cpp:106] Iteration 220, lr = 0.000990095
I0227 04:38:11.389232 20800 solver.cpp:229] Iteration 240, loss = 0.351814
I0227 04:38:11.389263 20800 solver.cpp:245]     Train net output #0: accuracy = 0.811035
I0227 04:38:11.389272 20800 solver.cpp:245]     Train net output #1: accuracy = 0.560694
I0227 04:38:11.389279 20800 solver.cpp:245]     Train net output #2: accuracy = 0.575442
I0227 04:38:11.389289 20800 sgd_solver.cpp:106] Iteration 240, lr = 0.000989194
I0227 04:38:28.666836 20800 solver.cpp:229] Iteration 260, loss = 0.470878
I0227 04:38:28.666868 20800 solver.cpp:245]     Train net output #0: accuracy = 0.817522
I0227 04:38:28.666895 20800 solver.cpp:245]     Train net output #1: accuracy = 0.649666
I0227 04:38:28.666903 20800 solver.cpp:245]     Train net output #2: accuracy = 0.584136
I0227 04:38:28.666913 20800 sgd_solver.cpp:106] Iteration 260, lr = 0.000988292
I0227 04:38:45.912565 20800 solver.cpp:229] Iteration 280, loss = 0.403046
I0227 04:38:45.912595 20800 solver.cpp:245]     Train net output #0: accuracy = 0.86702
I0227 04:38:45.912605 20800 solver.cpp:245]     Train net output #1: accuracy = 0.760124
I0227 04:38:45.912611 20800 solver.cpp:245]     Train net output #2: accuracy = 0.563753
I0227 04:38:45.912621 20800 sgd_solver.cpp:106] Iteration 280, lr = 0.000987391
I0227 04:39:03.178709 20800 solver.cpp:229] Iteration 300, loss = 0.441926
I0227 04:39:03.178740 20800 solver.cpp:245]     Train net output #0: accuracy = 0.86227
I0227 04:39:03.178750 20800 solver.cpp:245]     Train net output #1: accuracy = 0.669995
I0227 04:39:03.178755 20800 solver.cpp:245]     Train net output #2: accuracy = 0.561374
I0227 04:39:03.178766 20800 sgd_solver.cpp:106] Iteration 300, lr = 0.00098649
I0227 04:39:20.448321 20800 solver.cpp:229] Iteration 320, loss = 0.385361
I0227 04:39:20.448366 20800 solver.cpp:245]     Train net output #0: accuracy = 0.903688
I0227 04:39:20.448375 20800 solver.cpp:245]     Train net output #1: accuracy = 0.743741
I0227 04:39:20.448382 20800 solver.cpp:245]     Train net output #2: accuracy = 0.637568
I0227 04:39:20.448391 20800 sgd_solver.cpp:106] Iteration 320, lr = 0.000985589
I0227 04:39:37.700408 20800 solver.cpp:229] Iteration 340, loss = 0.364476
I0227 04:39:37.700439 20800 solver.cpp:245]     Train net output #0: accuracy = 0.876264
I0227 04:39:37.700448 20800 solver.cpp:245]     Train net output #1: accuracy = 0.572834
I0227 04:39:37.700455 20800 solver.cpp:245]     Train net output #2: accuracy = 0.48165
I0227 04:39:37.700464 20800 sgd_solver.cpp:106] Iteration 340, lr = 0.000984687
I0227 04:39:54.977234 20800 solver.cpp:229] Iteration 360, loss = 0.361843
I0227 04:39:54.977264 20800 solver.cpp:245]     Train net output #0: accuracy = 0.832897
I0227 04:39:54.977273 20800 solver.cpp:245]     Train net output #1: accuracy = 0.583737
I0227 04:39:54.977280 20800 solver.cpp:245]     Train net output #2: accuracy = 0.585483
I0227 04:39:54.977290 20800 sgd_solver.cpp:106] Iteration 360, lr = 0.000983785
I0227 04:40:12.275246 20800 solver.cpp:229] Iteration 380, loss = 0.329672
I0227 04:40:12.275288 20800 solver.cpp:245]     Train net output #0: accuracy = 0.884771
I0227 04:40:12.275297 20800 solver.cpp:245]     Train net output #1: accuracy = 0.622631
I0227 04:40:12.275305 20800 solver.cpp:245]     Train net output #2: accuracy = 0.582254
I0227 04:40:12.275313 20800 sgd_solver.cpp:106] Iteration 380, lr = 0.000982884
I0227 04:40:29.549412 20800 solver.cpp:229] Iteration 400, loss = 0.380799
I0227 04:40:29.549458 20800 solver.cpp:245]     Train net output #0: accuracy = 0.900255
I0227 04:40:29.549466 20800 solver.cpp:245]     Train net output #1: accuracy = 0.720065
I0227 04:40:29.549474 20800 solver.cpp:245]     Train net output #2: accuracy = 0.568459
I0227 04:40:29.549484 20800 sgd_solver.cpp:106] Iteration 400, lr = 0.000981982
I0227 04:40:46.809506 20800 solver.cpp:229] Iteration 420, loss = 0.310876
I0227 04:40:46.809553 20800 solver.cpp:245]     Train net output #0: accuracy = 0.86956
I0227 04:40:46.809562 20800 solver.cpp:245]     Train net output #1: accuracy = 0.659933
I0227 04:40:46.809569 20800 solver.cpp:245]     Train net output #2: accuracy = 0.540876
I0227 04:40:46.809578 20800 sgd_solver.cpp:106] Iteration 420, lr = 0.00098108
I0227 04:41:04.059873 20800 solver.cpp:229] Iteration 440, loss = 0.388634
I0227 04:41:04.059903 20800 solver.cpp:245]     Train net output #0: accuracy = 0.85812
I0227 04:41:04.059913 20800 solver.cpp:245]     Train net output #1: accuracy = 0.551688
I0227 04:41:04.059921 20800 solver.cpp:245]     Train net output #2: accuracy = 0.584234
I0227 04:41:04.059929 20800 sgd_solver.cpp:106] Iteration 440, lr = 0.000980178
I0227 04:41:21.317874 20800 solver.cpp:229] Iteration 460, loss = 0.400168
I0227 04:41:21.317904 20800 solver.cpp:245]     Train net output #0: accuracy = 0.889785
I0227 04:41:21.317914 20800 solver.cpp:245]     Train net output #1: accuracy = 0.670058
I0227 04:41:21.317920 20800 solver.cpp:245]     Train net output #2: accuracy = 0.470966
I0227 04:41:21.317930 20800 sgd_solver.cpp:106] Iteration 460, lr = 0.000979276
I0227 04:41:38.589056 20800 solver.cpp:229] Iteration 480, loss = 0.356646
I0227 04:41:38.589099 20800 solver.cpp:245]     Train net output #0: accuracy = 0.848245
I0227 04:41:38.589108 20800 solver.cpp:245]     Train net output #1: accuracy = 0.656292
I0227 04:41:38.589115 20800 solver.cpp:245]     Train net output #2: accuracy = 0.679097
I0227 04:41:38.589126 20800 sgd_solver.cpp:106] Iteration 480, lr = 0.000978374
I0227 04:41:55.861354 20800 solver.cpp:229] Iteration 500, loss = 0.359404
I0227 04:41:55.861383 20800 solver.cpp:245]     Train net output #0: accuracy = 0.87886
I0227 04:41:55.861392 20800 solver.cpp:245]     Train net output #1: accuracy = 0.659657
I0227 04:41:55.861399 20800 solver.cpp:245]     Train net output #2: accuracy = 0.596831
I0227 04:41:55.861409 20800 sgd_solver.cpp:106] Iteration 500, lr = 0.000977472
I0227 04:42:13.143510 20800 solver.cpp:229] Iteration 520, loss = 0.381431
I0227 04:42:13.143553 20800 solver.cpp:245]     Train net output #0: accuracy = 0.832778
I0227 04:42:13.143561 20800 solver.cpp:245]     Train net output #1: accuracy = 0.568404
I0227 04:42:13.143568 20800 solver.cpp:245]     Train net output #2: accuracy = 0.546361
I0227 04:42:13.143579 20800 sgd_solver.cpp:106] Iteration 520, lr = 0.000976569
I0227 04:42:30.401281 20800 solver.cpp:229] Iteration 540, loss = 0.345853
I0227 04:42:30.401311 20800 solver.cpp:245]     Train net output #0: accuracy = 0.819892
I0227 04:42:30.401320 20800 solver.cpp:245]     Train net output #1: accuracy = 0.658236
I0227 04:42:30.401327 20800 solver.cpp:245]     Train net output #2: accuracy = 0.500576
I0227 04:42:30.401336 20800 sgd_solver.cpp:106] Iteration 540, lr = 0.000975667
I0227 04:42:47.686591 20800 solver.cpp:229] Iteration 560, loss = 0.368592
I0227 04:42:47.686638 20800 solver.cpp:245]     Train net output #0: accuracy = 0.876443
I0227 04:42:47.686646 20800 solver.cpp:245]     Train net output #1: accuracy = 0.780378
I0227 04:42:47.686653 20800 solver.cpp:245]     Train net output #2: accuracy = 0.707465
I0227 04:42:47.686663 20800 sgd_solver.cpp:106] Iteration 560, lr = 0.000974764
I0227 04:43:04.955283 20800 solver.cpp:229] Iteration 580, loss = 0.371252
I0227 04:43:04.955313 20800 solver.cpp:245]     Train net output #0: accuracy = 0.876859
I0227 04:43:04.955322 20800 solver.cpp:245]     Train net output #1: accuracy = 0.773435
I0227 04:43:04.955329 20800 solver.cpp:245]     Train net output #2: accuracy = 0.674669
I0227 04:43:04.955339 20800 sgd_solver.cpp:106] Iteration 580, lr = 0.000973862
I0227 04:43:22.231025 20800 solver.cpp:229] Iteration 600, loss = 0.284903
I0227 04:43:22.231055 20800 solver.cpp:245]     Train net output #0: accuracy = 0.922665
I0227 04:43:22.231065 20800 solver.cpp:245]     Train net output #1: accuracy = 0.917659
I0227 04:43:22.231071 20800 solver.cpp:245]     Train net output #2: accuracy = 0.642017
I0227 04:43:22.231081 20800 sgd_solver.cpp:106] Iteration 600, lr = 0.000972959
I0227 04:43:39.507812 20800 solver.cpp:229] Iteration 620, loss = 0.366015
I0227 04:43:39.507854 20800 solver.cpp:245]     Train net output #0: accuracy = 0.824557
I0227 04:43:39.507863 20800 solver.cpp:245]     Train net output #1: accuracy = 0.577918
I0227 04:43:39.507870 20800 solver.cpp:245]     Train net output #2: accuracy = 0.60426
I0227 04:43:39.507880 20800 sgd_solver.cpp:106] Iteration 620, lr = 0.000972056
I0227 04:43:56.763772 20800 solver.cpp:229] Iteration 640, loss = 0.319785
I0227 04:43:56.763818 20800 solver.cpp:245]     Train net output #0: accuracy = 0.865913
I0227 04:43:56.763825 20800 solver.cpp:245]     Train net output #1: accuracy = 0.725805
I0227 04:43:56.763833 20800 solver.cpp:245]     Train net output #2: accuracy = 0.493527
I0227 04:43:56.763842 20800 sgd_solver.cpp:106] Iteration 640, lr = 0.000971153
I0227 04:44:14.039695 20800 solver.cpp:229] Iteration 660, loss = 0.324495
I0227 04:44:14.039741 20800 solver.cpp:245]     Train net output #0: accuracy = 0.803807
I0227 04:44:14.039752 20800 solver.cpp:245]     Train net output #1: accuracy = 0.578281
I0227 04:44:14.039757 20800 solver.cpp:245]     Train net output #2: accuracy = 0.392221
I0227 04:44:14.039767 20800 sgd_solver.cpp:106] Iteration 660, lr = 0.00097025
I0227 04:44:31.311374 20800 solver.cpp:229] Iteration 680, loss = 0.346713
I0227 04:44:31.311404 20800 solver.cpp:245]     Train net output #0: accuracy = 0.878542
I0227 04:44:31.311414 20800 solver.cpp:245]     Train net output #1: accuracy = 0.885874
I0227 04:44:31.311420 20800 solver.cpp:245]     Train net output #2: accuracy = 0.631436
I0227 04:44:31.311430 20800 sgd_solver.cpp:106] Iteration 680, lr = 0.000969347
I0227 04:44:48.581380 20800 solver.cpp:229] Iteration 700, loss = 0.342326
I0227 04:44:48.581424 20800 solver.cpp:245]     Train net output #0: accuracy = 0.875788
I0227 04:44:48.581434 20800 solver.cpp:245]     Train net output #1: accuracy = 0.745501
I0227 04:44:48.581440 20800 solver.cpp:245]     Train net output #2: accuracy = 0.691444
I0227 04:44:48.581450 20800 sgd_solver.cpp:106] Iteration 700, lr = 0.000968444
I0227 04:45:05.857084 20800 solver.cpp:229] Iteration 720, loss = 0.299417
I0227 04:45:05.857127 20800 solver.cpp:245]     Train net output #0: accuracy = 0.926294
I0227 04:45:05.857136 20800 solver.cpp:245]     Train net output #1: accuracy = 0.785688
I0227 04:45:05.857143 20800 solver.cpp:245]     Train net output #2: accuracy = 0.727335
I0227 04:45:05.857154 20800 sgd_solver.cpp:106] Iteration 720, lr = 0.000967541
I0227 04:45:23.122449 20800 solver.cpp:229] Iteration 740, loss = 0.32455
I0227 04:45:23.122479 20800 solver.cpp:245]     Train net output #0: accuracy = 0.843783
I0227 04:45:23.122488 20800 solver.cpp:245]     Train net output #1: accuracy = 0.717437
I0227 04:45:23.122494 20800 solver.cpp:245]     Train net output #2: accuracy = 0.79247
I0227 04:45:23.122505 20800 sgd_solver.cpp:106] Iteration 740, lr = 0.000966638
I0227 04:45:40.401588 20800 solver.cpp:229] Iteration 760, loss = 0.382878
I0227 04:45:40.401633 20800 solver.cpp:245]     Train net output #0: accuracy = 0.8558
I0227 04:45:40.401643 20800 solver.cpp:245]     Train net output #1: accuracy = 0.701096
I0227 04:45:40.401649 20800 solver.cpp:245]     Train net output #2: accuracy = 0.632658
I0227 04:45:40.401659 20800 sgd_solver.cpp:106] Iteration 760, lr = 0.000965734
I0227 04:45:57.681677 20800 solver.cpp:229] Iteration 780, loss = 0.370808
I0227 04:45:57.681722 20800 solver.cpp:245]     Train net output #0: accuracy = 0.811779
I0227 04:45:57.681731 20800 solver.cpp:245]     Train net output #1: accuracy = 0.789586
I0227 04:45:57.681738 20800 solver.cpp:245]     Train net output #2: accuracy = 0.799688
I0227 04:45:57.681748 20800 sgd_solver.cpp:106] Iteration 780, lr = 0.000964831
I0227 04:46:14.927727 20800 solver.cpp:229] Iteration 800, loss = 0.364693
I0227 04:46:14.927773 20800 solver.cpp:245]     Train net output #0: accuracy = 0.836466
I0227 04:46:14.927783 20800 solver.cpp:245]     Train net output #1: accuracy = 0.76795
I0227 04:46:14.927790 20800 solver.cpp:245]     Train net output #2: accuracy = 0.676508
I0227 04:46:14.927800 20800 sgd_solver.cpp:106] Iteration 800, lr = 0.000963927
I0227 04:46:32.191754 20800 solver.cpp:229] Iteration 820, loss = 0.357353
I0227 04:46:32.191799 20800 solver.cpp:245]     Train net output #0: accuracy = 0.806459
I0227 04:46:32.191808 20800 solver.cpp:245]     Train net output #1: accuracy = 0.615002
I0227 04:46:32.191815 20800 solver.cpp:245]     Train net output #2: accuracy = 0.495955
I0227 04:46:32.191825 20800 sgd_solver.cpp:106] Iteration 820, lr = 0.000963023
I0227 04:46:49.463671 20800 solver.cpp:229] Iteration 840, loss = 0.278862
I0227 04:46:49.463716 20800 solver.cpp:245]     Train net output #0: accuracy = 0.909563
I0227 04:46:49.463726 20800 solver.cpp:245]     Train net output #1: accuracy = 0.711822
I0227 04:46:49.463732 20800 solver.cpp:245]     Train net output #2: accuracy = 0.790098
I0227 04:46:49.463742 20800 sgd_solver.cpp:106] Iteration 840, lr = 0.000962119
I0227 04:47:06.704386 20800 solver.cpp:229] Iteration 860, loss = 0.318315
I0227 04:47:06.704432 20800 solver.cpp:245]     Train net output #0: accuracy = 0.884674
I0227 04:47:06.704440 20800 solver.cpp:245]     Train net output #1: accuracy = 0.786746
I0227 04:47:06.704447 20800 solver.cpp:245]     Train net output #2: accuracy = 0.662328
I0227 04:47:06.704457 20800 sgd_solver.cpp:106] Iteration 860, lr = 0.000961216
I0227 04:47:23.962260 20800 solver.cpp:229] Iteration 880, loss = 0.319174
I0227 04:47:23.962303 20800 solver.cpp:245]     Train net output #0: accuracy = 0.868971
I0227 04:47:23.962312 20800 solver.cpp:245]     Train net output #1: accuracy = 0.683556
I0227 04:47:23.962319 20800 solver.cpp:245]     Train net output #2: accuracy = 0.594424
I0227 04:47:23.962328 20800 sgd_solver.cpp:106] Iteration 880, lr = 0.000960311
I0227 04:47:41.233683 20800 solver.cpp:229] Iteration 900, loss = 0.401186
I0227 04:47:41.233737 20800 solver.cpp:245]     Train net output #0: accuracy = 0.804638
I0227 04:47:41.233769 20800 solver.cpp:245]     Train net output #1: accuracy = 0.50707
I0227 04:47:41.233783 20800 solver.cpp:245]     Train net output #2: accuracy = 0.564022
I0227 04:47:41.233799 20800 sgd_solver.cpp:106] Iteration 900, lr = 0.000959407
I0227 04:47:58.485780 20800 solver.cpp:229] Iteration 920, loss = 0.378147
I0227 04:47:58.485826 20800 solver.cpp:245]     Train net output #0: accuracy = 0.888043
I0227 04:47:58.485834 20800 solver.cpp:245]     Train net output #1: accuracy = 0.690796
I0227 04:47:58.485841 20800 solver.cpp:245]     Train net output #2: accuracy = 0.628468
I0227 04:47:58.485852 20800 sgd_solver.cpp:106] Iteration 920, lr = 0.000958503
I0227 04:48:15.759510 20800 solver.cpp:229] Iteration 940, loss = 0.33076
I0227 04:48:15.759553 20800 solver.cpp:245]     Train net output #0: accuracy = 0.919988
I0227 04:48:15.759562 20800 solver.cpp:245]     Train net output #1: accuracy = 0.712741
I0227 04:48:15.759569 20800 solver.cpp:245]     Train net output #2: accuracy = 0.748238
I0227 04:48:15.759593 20800 sgd_solver.cpp:106] Iteration 940, lr = 0.000957599
I0227 04:48:33.007858 20800 solver.cpp:229] Iteration 960, loss = 0.353579
I0227 04:48:33.007887 20800 solver.cpp:245]     Train net output #0: accuracy = 0.896966
I0227 04:48:33.007895 20800 solver.cpp:245]     Train net output #1: accuracy = 0.684322
I0227 04:48:33.007901 20800 solver.cpp:245]     Train net output #2: accuracy = 0.714628
I0227 04:48:33.007910 20800 sgd_solver.cpp:106] Iteration 960, lr = 0.000956695
I0227 04:48:50.275655 20800 solver.cpp:229] Iteration 980, loss = 0.360982
I0227 04:48:50.275684 20800 solver.cpp:245]     Train net output #0: accuracy = 0.868174
I0227 04:48:50.275693 20800 solver.cpp:245]     Train net output #1: accuracy = 0.716613
I0227 04:48:50.275701 20800 solver.cpp:245]     Train net output #2: accuracy = 0.568215
I0227 04:48:50.275710 20800 sgd_solver.cpp:106] Iteration 980, lr = 0.00095579
I0227 04:49:07.540453 20800 solver.cpp:229] Iteration 1000, loss = 0.325289
I0227 04:49:07.540484 20800 solver.cpp:245]     Train net output #0: accuracy = 0.896014
I0227 04:49:07.540493 20800 solver.cpp:245]     Train net output #1: accuracy = 0.682975
I0227 04:49:07.540501 20800 solver.cpp:245]     Train net output #2: accuracy = 0.612005
I0227 04:49:07.540510 20800 sgd_solver.cpp:106] Iteration 1000, lr = 0.000954885
I0227 04:49:24.793699 20800 solver.cpp:229] Iteration 1020, loss = 0.332064
I0227 04:49:24.793742 20800 solver.cpp:245]     Train net output #0: accuracy = 0.848505
I0227 04:49:24.793751 20800 solver.cpp:245]     Train net output #1: accuracy = 0.741126
I0227 04:49:24.793757 20800 solver.cpp:245]     Train net output #2: accuracy = 0.599014
I0227 04:49:24.793766 20800 sgd_solver.cpp:106] Iteration 1020, lr = 0.000953981
I0227 04:49:42.069874 20800 solver.cpp:229] Iteration 1040, loss = 0.320399
I0227 04:49:42.069917 20800 solver.cpp:245]     Train net output #0: accuracy = 0.82969
I0227 04:49:42.069926 20800 solver.cpp:245]     Train net output #1: accuracy = 0.565344
I0227 04:49:42.069933 20800 solver.cpp:245]     Train net output #2: accuracy = 0.63225
I0227 04:49:42.069942 20800 sgd_solver.cpp:106] Iteration 1040, lr = 0.000953076
I0227 04:49:59.358299 20800 solver.cpp:229] Iteration 1060, loss = 0.381094
I0227 04:49:59.358345 20800 solver.cpp:245]     Train net output #0: accuracy = 0.919334
I0227 04:49:59.358353 20800 solver.cpp:245]     Train net output #1: accuracy = 0.7366
I0227 04:49:59.358359 20800 solver.cpp:245]     Train net output #2: accuracy = 0.775191
I0227 04:49:59.358369 20800 sgd_solver.cpp:106] Iteration 1060, lr = 0.000952171
I0227 04:50:16.608295 20800 solver.cpp:229] Iteration 1080, loss = 0.305153
I0227 04:50:16.608340 20800 solver.cpp:245]     Train net output #0: accuracy = 0.881865
I0227 04:50:16.608350 20800 solver.cpp:245]     Train net output #1: accuracy = 0.777804
I0227 04:50:16.608356 20800 solver.cpp:245]     Train net output #2: accuracy = 0.646943
I0227 04:50:16.608366 20800 sgd_solver.cpp:106] Iteration 1080, lr = 0.000951266
I0227 04:50:33.878266 20800 solver.cpp:229] Iteration 1100, loss = 0.270406
I0227 04:50:33.878296 20800 solver.cpp:245]     Train net output #0: accuracy = 0.895033
I0227 04:50:33.878305 20800 solver.cpp:245]     Train net output #1: accuracy = 0.554691
I0227 04:50:33.878312 20800 solver.cpp:245]     Train net output #2: accuracy = 0.528887
I0227 04:50:33.878321 20800 sgd_solver.cpp:106] Iteration 1100, lr = 0.000950361
I0227 04:50:51.167405 20800 solver.cpp:229] Iteration 1120, loss = 0.278886
I0227 04:50:51.167450 20800 solver.cpp:245]     Train net output #0: accuracy = 0.873517
I0227 04:50:51.167459 20800 solver.cpp:245]     Train net output #1: accuracy = 0.441245
I0227 04:50:51.167465 20800 solver.cpp:245]     Train net output #2: accuracy = 0.461678
I0227 04:50:51.167475 20800 sgd_solver.cpp:106] Iteration 1120, lr = 0.000949456
I0227 04:51:08.436775 20800 solver.cpp:229] Iteration 1140, loss = 0.271372
I0227 04:51:08.436820 20800 solver.cpp:245]     Train net output #0: accuracy = 0.917549
I0227 04:51:08.436830 20800 solver.cpp:245]     Train net output #1: accuracy = 0.857132
I0227 04:51:08.436836 20800 solver.cpp:245]     Train net output #2: accuracy = 0.806096
I0227 04:51:08.436846 20800 sgd_solver.cpp:106] Iteration 1140, lr = 0.000948551
I0227 04:51:25.701561 20800 solver.cpp:229] Iteration 1160, loss = 0.248123
I0227 04:51:25.701604 20800 solver.cpp:245]     Train net output #0: accuracy = 0.916797
I0227 04:51:25.701613 20800 solver.cpp:245]     Train net output #1: accuracy = 0.758198
I0227 04:51:25.701620 20800 solver.cpp:245]     Train net output #2: accuracy = 0.755404
I0227 04:51:25.701629 20800 sgd_solver.cpp:106] Iteration 1160, lr = 0.000947645
I0227 04:51:42.947615 20800 solver.cpp:229] Iteration 1180, loss = 0.283143
I0227 04:51:42.947660 20800 solver.cpp:245]     Train net output #0: accuracy = 0.908983
I0227 04:51:42.947669 20800 solver.cpp:245]     Train net output #1: accuracy = 0.699647
I0227 04:51:42.947676 20800 solver.cpp:245]     Train net output #2: accuracy = 0.678226
I0227 04:51:42.947685 20800 sgd_solver.cpp:106] Iteration 1180, lr = 0.00094674
I0227 04:52:00.195185 20800 solver.cpp:229] Iteration 1200, loss = 0.255608
I0227 04:52:00.195231 20800 solver.cpp:245]     Train net output #0: accuracy = 0.925625
I0227 04:52:00.195240 20800 solver.cpp:245]     Train net output #1: accuracy = 0.735152
I0227 04:52:00.195247 20800 solver.cpp:245]     Train net output #2: accuracy = 0.791045
I0227 04:52:00.195257 20800 sgd_solver.cpp:106] Iteration 1200, lr = 0.000945834
I0227 04:52:17.461721 20800 solver.cpp:229] Iteration 1220, loss = 0.28501
I0227 04:52:17.461766 20800 solver.cpp:245]     Train net output #0: accuracy = 0.926353
I0227 04:52:17.461776 20800 solver.cpp:245]     Train net output #1: accuracy = 0.692002
I0227 04:52:17.461782 20800 solver.cpp:245]     Train net output #2: accuracy = 0.599337
I0227 04:52:17.461792 20800 sgd_solver.cpp:106] Iteration 1220, lr = 0.000944929
I0227 04:52:34.723389 20800 solver.cpp:229] Iteration 1240, loss = 0.292625
I0227 04:52:34.723433 20800 solver.cpp:245]     Train net output #0: accuracy = 0.900178
I0227 04:52:34.723443 20800 solver.cpp:245]     Train net output #1: accuracy = 0.702681
I0227 04:52:34.723448 20800 solver.cpp:245]     Train net output #2: accuracy = 0.643219
I0227 04:52:34.723459 20800 sgd_solver.cpp:106] Iteration 1240, lr = 0.000944023
I0227 04:52:52.005095 20800 solver.cpp:229] Iteration 1260, loss = 0.272405
I0227 04:52:52.005125 20800 solver.cpp:245]     Train net output #0: accuracy = 0.874685
I0227 04:52:52.005132 20800 solver.cpp:245]     Train net output #1: accuracy = 0.701958
I0227 04:52:52.005138 20800 solver.cpp:245]     Train net output #2: accuracy = 0.717557
I0227 04:52:52.005147 20800 sgd_solver.cpp:106] Iteration 1260, lr = 0.000943117
I0227 04:53:09.281618 20800 solver.cpp:229] Iteration 1280, loss = 0.273754
I0227 04:53:09.281649 20800 solver.cpp:245]     Train net output #0: accuracy = 0.895343
I0227 04:53:09.281658 20800 solver.cpp:245]     Train net output #1: accuracy = 0.607341
I0227 04:53:09.281666 20800 solver.cpp:245]     Train net output #2: accuracy = 0.626133
I0227 04:53:09.281675 20800 sgd_solver.cpp:106] Iteration 1280, lr = 0.000942211
I0227 04:53:26.562991 20800 solver.cpp:229] Iteration 1300, loss = 0.292323
I0227 04:53:26.563036 20800 solver.cpp:245]     Train net output #0: accuracy = 0.918377
I0227 04:53:26.563045 20800 solver.cpp:245]     Train net output #1: accuracy = 0.763294
I0227 04:53:26.563051 20800 solver.cpp:245]     Train net output #2: accuracy = 0.80722
I0227 04:53:26.563061 20800 sgd_solver.cpp:106] Iteration 1300, lr = 0.000941305
I0227 04:53:43.827085 20800 solver.cpp:229] Iteration 1320, loss = 0.260191
I0227 04:53:43.827128 20800 solver.cpp:245]     Train net output #0: accuracy = 0.88608
I0227 04:53:43.827137 20800 solver.cpp:245]     Train net output #1: accuracy = 0.817116
I0227 04:53:43.827143 20800 solver.cpp:245]     Train net output #2: accuracy = 0.718906
I0227 04:53:43.827153 20800 sgd_solver.cpp:106] Iteration 1320, lr = 0.000940399
I0227 04:54:01.084472 20800 solver.cpp:229] Iteration 1340, loss = 0.279402
I0227 04:54:01.084517 20800 solver.cpp:245]     Train net output #0: accuracy = 0.874539
I0227 04:54:01.084527 20800 solver.cpp:245]     Train net output #1: accuracy = 0.556724
I0227 04:54:01.084533 20800 solver.cpp:245]     Train net output #2: accuracy = 0.47305
I0227 04:54:01.084542 20800 sgd_solver.cpp:106] Iteration 1340, lr = 0.000939493
I0227 04:54:18.355890 20800 solver.cpp:229] Iteration 1360, loss = 0.250475
I0227 04:54:18.355921 20800 solver.cpp:245]     Train net output #0: accuracy = 0.864307
I0227 04:54:18.355931 20800 solver.cpp:245]     Train net output #1: accuracy = 0.597898
I0227 04:54:18.355937 20800 solver.cpp:245]     Train net output #2: accuracy = 0.584159
I0227 04:54:18.355947 20800 sgd_solver.cpp:106] Iteration 1360, lr = 0.000938587
I0227 04:54:35.617887 20800 solver.cpp:229] Iteration 1380, loss = 0.26506
I0227 04:54:35.617933 20800 solver.cpp:245]     Train net output #0: accuracy = 0.886377
I0227 04:54:35.617941 20800 solver.cpp:245]     Train net output #1: accuracy = 0.719058
I0227 04:54:35.617949 20800 solver.cpp:245]     Train net output #2: accuracy = 0.58128
I0227 04:54:35.617957 20800 sgd_solver.cpp:106] Iteration 1380, lr = 0.00093768
I0227 04:54:52.882436 20800 solver.cpp:229] Iteration 1400, loss = 0.251443
I0227 04:54:52.882464 20800 solver.cpp:245]     Train net output #0: accuracy = 0.937683
I0227 04:54:52.882472 20800 solver.cpp:245]     Train net output #1: accuracy = 0.941517
I0227 04:54:52.882479 20800 solver.cpp:245]     Train net output #2: accuracy = 0.946226
I0227 04:54:52.882488 20800 sgd_solver.cpp:106] Iteration 1400, lr = 0.000936774
I0227 04:55:10.143698 20800 solver.cpp:229] Iteration 1420, loss = 0.271256
I0227 04:55:10.143728 20800 solver.cpp:245]     Train net output #0: accuracy = 0.925461
I0227 04:55:10.143738 20800 solver.cpp:245]     Train net output #1: accuracy = 0.750068
I0227 04:55:10.143744 20800 solver.cpp:245]     Train net output #2: accuracy = 0.735307
I0227 04:55:10.143754 20800 sgd_solver.cpp:106] Iteration 1420, lr = 0.000935867
I0227 04:55:27.377461 20800 solver.cpp:229] Iteration 1440, loss = 0.289
I0227 04:55:27.377490 20800 solver.cpp:245]     Train net output #0: accuracy = 0.880845
I0227 04:55:27.377499 20800 solver.cpp:245]     Train net output #1: accuracy = 0.656108
I0227 04:55:27.377506 20800 solver.cpp:245]     Train net output #2: accuracy = 0.493862
I0227 04:55:27.377516 20800 sgd_solver.cpp:106] Iteration 1440, lr = 0.00093496
I0227 04:55:44.666357 20800 solver.cpp:229] Iteration 1460, loss = 0.265532
I0227 04:55:44.666401 20800 solver.cpp:245]     Train net output #0: accuracy = 0.904402
I0227 04:55:44.666410 20800 solver.cpp:245]     Train net output #1: accuracy = 0.624341
I0227 04:55:44.666417 20800 solver.cpp:245]     Train net output #2: accuracy = 0.523028
I0227 04:55:44.666427 20800 sgd_solver.cpp:106] Iteration 1460, lr = 0.000934054
I0227 04:56:01.932301 20800 solver.cpp:229] Iteration 1480, loss = 0.264682
I0227 04:56:01.932346 20800 solver.cpp:245]     Train net output #0: accuracy = 0.857058
I0227 04:56:01.932356 20800 solver.cpp:245]     Train net output #1: accuracy = 0.637538
I0227 04:56:01.932363 20800 solver.cpp:245]     Train net output #2: accuracy = 0.631308
I0227 04:56:01.932374 20800 sgd_solver.cpp:106] Iteration 1480, lr = 0.000933147
I0227 04:56:19.211272 20800 solver.cpp:229] Iteration 1500, loss = 0.286317
I0227 04:56:19.211302 20800 solver.cpp:245]     Train net output #0: accuracy = 0.889394
I0227 04:56:19.211309 20800 solver.cpp:245]     Train net output #1: accuracy = 0.687453
I0227 04:56:19.211316 20800 solver.cpp:245]     Train net output #2: accuracy = 0.558765
I0227 04:56:19.211324 20800 sgd_solver.cpp:106] Iteration 1500, lr = 0.00093224
I0227 04:56:36.471357 20800 solver.cpp:229] Iteration 1520, loss = 0.270239
I0227 04:56:36.471403 20800 solver.cpp:245]     Train net output #0: accuracy = 0.876145
I0227 04:56:36.471412 20800 solver.cpp:245]     Train net output #1: accuracy = 0.784894
I0227 04:56:36.471419 20800 solver.cpp:245]     Train net output #2: accuracy = 0.775408
I0227 04:56:36.471436 20800 sgd_solver.cpp:106] Iteration 1520, lr = 0.000931333
I0227 04:56:53.745584 20800 solver.cpp:229] Iteration 1540, loss = 0.277847
I0227 04:56:53.745630 20800 solver.cpp:245]     Train net output #0: accuracy = 0.92523
I0227 04:56:53.745640 20800 solver.cpp:245]     Train net output #1: accuracy = 0.791629
I0227 04:56:53.745646 20800 solver.cpp:245]     Train net output #2: accuracy = 0.748009
I0227 04:56:53.745656 20800 sgd_solver.cpp:106] Iteration 1540, lr = 0.000930425
I0227 04:57:11.021167 20800 solver.cpp:229] Iteration 1560, loss = 0.317061
I0227 04:57:11.021212 20800 solver.cpp:245]     Train net output #0: accuracy = 0.85693
I0227 04:57:11.021220 20800 solver.cpp:245]     Train net output #1: accuracy = 0.640335
I0227 04:57:11.021227 20800 solver.cpp:245]     Train net output #2: accuracy = 0.686309
I0227 04:57:11.021237 20800 sgd_solver.cpp:106] Iteration 1560, lr = 0.000929518
I0227 04:57:28.278175 20800 solver.cpp:229] Iteration 1580, loss = 0.281731
I0227 04:57:28.278220 20800 solver.cpp:245]     Train net output #0: accuracy = 0.903212
I0227 04:57:28.278229 20800 solver.cpp:245]     Train net output #1: accuracy = 0.666707
I0227 04:57:28.278236 20800 solver.cpp:245]     Train net output #2: accuracy = 0.570471
I0227 04:57:28.278246 20800 sgd_solver.cpp:106] Iteration 1580, lr = 0.000928611
I0227 04:57:45.534579 20800 solver.cpp:229] Iteration 1600, loss = 0.277366
I0227 04:57:45.534608 20800 solver.cpp:245]     Train net output #0: accuracy = 0.902618
I0227 04:57:45.534617 20800 solver.cpp:245]     Train net output #1: accuracy = 0.59867
I0227 04:57:45.534624 20800 solver.cpp:245]     Train net output #2: accuracy = 0.549124
I0227 04:57:45.534634 20800 sgd_solver.cpp:106] Iteration 1600, lr = 0.000927703
I0227 04:58:02.792842 20800 solver.cpp:229] Iteration 1620, loss = 0.243924
I0227 04:58:02.792888 20800 solver.cpp:245]     Train net output #0: accuracy = 0.926413
I0227 04:58:02.792897 20800 solver.cpp:245]     Train net output #1: accuracy = 0.561935
I0227 04:58:02.792904 20800 solver.cpp:245]     Train net output #2: accuracy = 0.603682
I0227 04:58:02.792913 20800 sgd_solver.cpp:106] Iteration 1620, lr = 0.000926796
I0227 04:58:20.049451 20800 solver.cpp:229] Iteration 1640, loss = 0.250787
I0227 04:58:20.049481 20800 solver.cpp:245]     Train net output #0: accuracy = 0.926768
I0227 04:58:20.049490 20800 solver.cpp:245]     Train net output #1: accuracy = 0.816816
I0227 04:58:20.049497 20800 solver.cpp:245]     Train net output #2: accuracy = 0.594829
I0227 04:58:20.049506 20800 sgd_solver.cpp:106] Iteration 1640, lr = 0.000925888
I0227 04:58:37.309382 20800 solver.cpp:229] Iteration 1660, loss = 0.263528
I0227 04:58:37.309429 20800 solver.cpp:245]     Train net output #0: accuracy = 0.851398
I0227 04:58:37.309438 20800 solver.cpp:245]     Train net output #1: accuracy = 0.734639
I0227 04:58:37.309460 20800 solver.cpp:245]     Train net output #2: accuracy = 0.673523
I0227 04:58:37.309470 20800 sgd_solver.cpp:106] Iteration 1660, lr = 0.00092498
I0227 04:58:54.569217 20800 solver.cpp:229] Iteration 1680, loss = 0.281351
I0227 04:58:54.569255 20800 solver.cpp:245]     Train net output #0: accuracy = 0.926413
I0227 04:58:54.569272 20800 solver.cpp:245]     Train net output #1: accuracy = 0.699131
I0227 04:58:54.569283 20800 solver.cpp:245]     Train net output #2: accuracy = 0.67709
I0227 04:58:54.569298 20800 sgd_solver.cpp:106] Iteration 1680, lr = 0.000924072
I0227 04:59:11.821192 20800 solver.cpp:229] Iteration 1700, loss = 0.320164
I0227 04:59:11.821223 20800 solver.cpp:245]     Train net output #0: accuracy = 0.905607
I0227 04:59:11.821233 20800 solver.cpp:245]     Train net output #1: accuracy = 0.77253
I0227 04:59:11.821239 20800 solver.cpp:245]     Train net output #2: accuracy = 0.736072
I0227 04:59:11.821249 20800 sgd_solver.cpp:106] Iteration 1700, lr = 0.000923164
I0227 04:59:29.069147 20800 solver.cpp:229] Iteration 1720, loss = 0.282849
I0227 04:59:29.069193 20800 solver.cpp:245]     Train net output #0: accuracy = 0.920286
I0227 04:59:29.069202 20800 solver.cpp:245]     Train net output #1: accuracy = 0.859768
I0227 04:59:29.069209 20800 solver.cpp:245]     Train net output #2: accuracy = 0.754424
I0227 04:59:29.069219 20800 sgd_solver.cpp:106] Iteration 1720, lr = 0.000922256
I0227 04:59:46.331938 20800 solver.cpp:229] Iteration 1740, loss = 0.265893
I0227 04:59:46.331966 20800 solver.cpp:245]     Train net output #0: accuracy = 0.929923
I0227 04:59:46.331974 20800 solver.cpp:245]     Train net output #1: accuracy = 0.826513
I0227 04:59:46.331981 20800 solver.cpp:245]     Train net output #2: accuracy = 0.678749
I0227 04:59:46.331990 20800 sgd_solver.cpp:106] Iteration 1740, lr = 0.000921348
I0227 05:00:03.565536 20800 solver.cpp:229] Iteration 1760, loss = 0.267082
I0227 05:00:03.565579 20800 solver.cpp:245]     Train net output #0: accuracy = 0.91981
I0227 05:00:03.565588 20800 solver.cpp:245]     Train net output #1: accuracy = 0.835406
I0227 05:00:03.565595 20800 solver.cpp:245]     Train net output #2: accuracy = 0.767155
I0227 05:00:03.565605 20800 sgd_solver.cpp:106] Iteration 1760, lr = 0.00092044
I0227 05:00:20.815735 20800 solver.cpp:229] Iteration 1780, loss = 0.283391
I0227 05:00:20.815763 20800 solver.cpp:245]     Train net output #0: accuracy = 0.904938
I0227 05:00:20.815788 20800 solver.cpp:245]     Train net output #1: accuracy = 0.62488
I0227 05:00:20.815795 20800 solver.cpp:245]     Train net output #2: accuracy = 0.552127
I0227 05:00:20.815805 20800 sgd_solver.cpp:106] Iteration 1780, lr = 0.000919531
I0227 05:00:38.077512 20800 solver.cpp:229] Iteration 1800, loss = 0.239375
I0227 05:00:38.077543 20800 solver.cpp:245]     Train net output #0: accuracy = 0.888816
I0227 05:00:38.077551 20800 solver.cpp:245]     Train net output #1: accuracy = 0.746346
I0227 05:00:38.077559 20800 solver.cpp:245]     Train net output #2: accuracy = 0.788538
I0227 05:00:38.077569 20800 sgd_solver.cpp:106] Iteration 1800, lr = 0.000918623
I0227 05:00:55.319562 20800 solver.cpp:229] Iteration 1820, loss = 0.246072
I0227 05:00:55.319602 20800 solver.cpp:245]     Train net output #0: accuracy = 0.921713
I0227 05:00:55.319617 20800 solver.cpp:245]     Train net output #1: accuracy = 0.919267
I0227 05:00:55.319630 20800 solver.cpp:245]     Train net output #2: accuracy = 0.934013
I0227 05:00:55.319646 20800 sgd_solver.cpp:106] Iteration 1820, lr = 0.000917714
I0227 05:01:12.614452 20800 solver.cpp:229] Iteration 1840, loss = 0.297126
I0227 05:01:12.614496 20800 solver.cpp:245]     Train net output #0: accuracy = 0.86746
I0227 05:01:12.614506 20800 solver.cpp:245]     Train net output #1: accuracy = 0.68966
I0227 05:01:12.614512 20800 solver.cpp:245]     Train net output #2: accuracy = 0.686222
I0227 05:01:12.614522 20800 sgd_solver.cpp:106] Iteration 1840, lr = 0.000916806
I0227 05:01:29.890005 20800 solver.cpp:229] Iteration 1860, loss = 0.241998
I0227 05:01:29.890051 20800 solver.cpp:245]     Train net output #0: accuracy = 0.894884
I0227 05:01:29.890060 20800 solver.cpp:245]     Train net output #1: accuracy = 0.760817
I0227 05:01:29.890067 20800 solver.cpp:245]     Train net output #2: accuracy = 0.761965
I0227 05:01:29.890077 20800 sgd_solver.cpp:106] Iteration 1860, lr = 0.000915897
I0227 05:01:47.141911 20800 solver.cpp:229] Iteration 1880, loss = 0.262758
I0227 05:01:47.141954 20800 solver.cpp:245]     Train net output #0: accuracy = 0.891969
I0227 05:01:47.141964 20800 solver.cpp:245]     Train net output #1: accuracy = 0.679383
I0227 05:01:47.141970 20800 solver.cpp:245]     Train net output #2: accuracy = 0.604075
I0227 05:01:47.141980 20800 sgd_solver.cpp:106] Iteration 1880, lr = 0.000914988
I0227 05:02:04.401924 20800 solver.cpp:229] Iteration 1900, loss = 0.245864
I0227 05:02:04.401968 20800 solver.cpp:245]     Train net output #0: accuracy = 0.905488
I0227 05:02:04.401978 20800 solver.cpp:245]     Train net output #1: accuracy = 0.803322
I0227 05:02:04.401983 20800 solver.cpp:245]     Train net output #2: accuracy = 0.777305
I0227 05:02:04.401993 20800 sgd_solver.cpp:106] Iteration 1900, lr = 0.000914079
I0227 05:02:21.649896 20800 solver.cpp:229] Iteration 1920, loss = 0.271812
I0227 05:02:21.649940 20800 solver.cpp:245]     Train net output #0: accuracy = 0.865021
I0227 05:02:21.649950 20800 solver.cpp:245]     Train net output #1: accuracy = 0.643815
I0227 05:02:21.649956 20800 solver.cpp:245]     Train net output #2: accuracy = 0.633304
I0227 05:02:21.649966 20800 sgd_solver.cpp:106] Iteration 1920, lr = 0.00091317
I0227 05:02:38.910306 20800 solver.cpp:229] Iteration 1940, loss = 0.263663
I0227 05:02:38.910337 20800 solver.cpp:245]     Train net output #0: accuracy = 0.894064
I0227 05:02:38.910346 20800 solver.cpp:245]     Train net output #1: accuracy = 0.689947
I0227 05:02:38.910353 20800 solver.cpp:245]     Train net output #2: accuracy = 0.625568
I0227 05:02:38.910363 20800 sgd_solver.cpp:106] Iteration 1940, lr = 0.000912261
I0227 05:02:56.174567 20800 solver.cpp:229] Iteration 1960, loss = 0.280088
I0227 05:02:56.174610 20800 solver.cpp:245]     Train net output #0: accuracy = 0.928877
I0227 05:02:56.174619 20800 solver.cpp:245]     Train net output #1: accuracy = 0.854547
I0227 05:02:56.174625 20800 solver.cpp:245]     Train net output #2: accuracy = 0.912597
I0227 05:02:56.174635 20800 sgd_solver.cpp:106] Iteration 1960, lr = 0.000911351
I0227 05:03:13.423316 20800 solver.cpp:229] Iteration 1980, loss = 0.248294
I0227 05:03:13.423375 20800 solver.cpp:245]     Train net output #0: accuracy = 0.893406
I0227 05:03:13.423383 20800 solver.cpp:245]     Train net output #1: accuracy = 0.761734
I0227 05:03:13.423390 20800 solver.cpp:245]     Train net output #2: accuracy = 0.729434
I0227 05:03:13.423400 20800 sgd_solver.cpp:106] Iteration 1980, lr = 0.000910442
I0227 05:03:30.705608 20800 solver.cpp:229] Iteration 2000, loss = 0.257981
I0227 05:03:30.705669 20800 solver.cpp:245]     Train net output #0: accuracy = 0.921262
I0227 05:03:30.705678 20800 solver.cpp:245]     Train net output #1: accuracy = 0.793029
I0227 05:03:30.705685 20800 solver.cpp:245]     Train net output #2: accuracy = 0.794057
I0227 05:03:30.705695 20800 sgd_solver.cpp:106] Iteration 2000, lr = 0.000909533
I0227 05:03:47.982187 20800 solver.cpp:229] Iteration 2020, loss = 0.259843
I0227 05:03:47.982233 20800 solver.cpp:245]     Train net output #0: accuracy = 0.889213
I0227 05:03:47.982241 20800 solver.cpp:245]     Train net output #1: accuracy = 0.736096
I0227 05:03:47.982249 20800 solver.cpp:245]     Train net output #2: accuracy = 0.719877
I0227 05:03:47.982259 20800 sgd_solver.cpp:106] Iteration 2020, lr = 0.000908623
I0227 05:04:05.225821 20800 solver.cpp:229] Iteration 2040, loss = 0.283956
I0227 05:04:05.225849 20800 solver.cpp:245]     Train net output #0: accuracy = 0.864426
I0227 05:04:05.225858 20800 solver.cpp:245]     Train net output #1: accuracy = 0.634082
I0227 05:04:05.225865 20800 solver.cpp:245]     Train net output #2: accuracy = 0.571971
I0227 05:04:05.225875 20800 sgd_solver.cpp:106] Iteration 2040, lr = 0.000907713
I0227 05:04:22.512316 20800 solver.cpp:229] Iteration 2060, loss = 0.251227
I0227 05:04:22.512359 20800 solver.cpp:245]     Train net output #0: accuracy = 0.940553
I0227 05:04:22.512368 20800 solver.cpp:245]     Train net output #1: accuracy = 0.688689
I0227 05:04:22.512389 20800 solver.cpp:245]     Train net output #2: accuracy = 0.632527
I0227 05:04:22.512398 20800 sgd_solver.cpp:106] Iteration 2060, lr = 0.000906804
I0227 05:04:39.764374 20800 solver.cpp:229] Iteration 2080, loss = 0.287231
I0227 05:04:39.764417 20800 solver.cpp:245]     Train net output #0: accuracy = 0.851015
I0227 05:04:39.764426 20800 solver.cpp:245]     Train net output #1: accuracy = 0.667849
I0227 05:04:39.764433 20800 solver.cpp:245]     Train net output #2: accuracy = 0.706839
I0227 05:04:39.764444 20800 sgd_solver.cpp:106] Iteration 2080, lr = 0.000905894
I0227 05:04:57.019598 20800 solver.cpp:229] Iteration 2100, loss = 0.284253
I0227 05:04:57.019629 20800 solver.cpp:245]     Train net output #0: accuracy = 0.908507
I0227 05:04:57.019639 20800 solver.cpp:245]     Train net output #1: accuracy = 0.706543
I0227 05:04:57.019646 20800 solver.cpp:245]     Train net output #2: accuracy = 0.67662
I0227 05:04:57.019656 20800 sgd_solver.cpp:106] Iteration 2100, lr = 0.000904984
I0227 05:05:14.272243 20800 solver.cpp:229] Iteration 2120, loss = 0.261714
I0227 05:05:14.272289 20800 solver.cpp:245]     Train net output #0: accuracy = 0.898334
I0227 05:05:14.272298 20800 solver.cpp:245]     Train net output #1: accuracy = 0.885711
I0227 05:05:14.272306 20800 solver.cpp:245]     Train net output #2: accuracy = 0.74233
I0227 05:05:14.272316 20800 sgd_solver.cpp:106] Iteration 2120, lr = 0.000904074
I0227 05:05:31.541484 20800 solver.cpp:229] Iteration 2140, loss = 0.23162
I0227 05:05:31.541530 20800 solver.cpp:245]     Train net output #0: accuracy = 0.905889
I0227 05:05:31.541539 20800 solver.cpp:245]     Train net output #1: accuracy = 0.642379
I0227 05:05:31.541546 20800 solver.cpp:245]     Train net output #2: accuracy = 0.59787
I0227 05:05:31.541556 20800 sgd_solver.cpp:106] Iteration 2140, lr = 0.000903163
I0227 05:05:48.805675 20800 solver.cpp:229] Iteration 2160, loss = 0.204444
I0227 05:05:48.805718 20800 solver.cpp:245]     Train net output #0: accuracy = 0.928138
I0227 05:05:48.805727 20800 solver.cpp:245]     Train net output #1: accuracy = 0.762382
I0227 05:05:48.805734 20800 solver.cpp:245]     Train net output #2: accuracy = 0.821878
I0227 05:05:48.805744 20800 sgd_solver.cpp:106] Iteration 2160, lr = 0.000902253
I0227 05:06:06.064934 20800 solver.cpp:229] Iteration 2180, loss = 0.225349
I0227 05:06:06.064980 20800 solver.cpp:245]     Train net output #0: accuracy = 0.902191
I0227 05:06:06.064990 20800 solver.cpp:245]     Train net output #1: accuracy = 0.644578
I0227 05:06:06.064996 20800 solver.cpp:245]     Train net output #2: accuracy = 0.659941
I0227 05:06:06.065006 20800 sgd_solver.cpp:106] Iteration 2180, lr = 0.000901343
I0227 05:06:23.296026 20800 solver.cpp:229] Iteration 2200, loss = 0.215979
I0227 05:06:23.296072 20800 solver.cpp:245]     Train net output #0: accuracy = 0.94828
I0227 05:06:23.296082 20800 solver.cpp:245]     Train net output #1: accuracy = 0.745549
I0227 05:06:23.296088 20800 solver.cpp:245]     Train net output #2: accuracy = 0.701863
I0227 05:06:23.296098 20800 sgd_solver.cpp:106] Iteration 2200, lr = 0.000900432
I0227 05:06:40.546910 20800 solver.cpp:229] Iteration 2220, loss = 0.256604
I0227 05:06:40.546941 20800 solver.cpp:245]     Train net output #0: accuracy = 0.864009
I0227 05:06:40.546950 20800 solver.cpp:245]     Train net output #1: accuracy = 0.777044
I0227 05:06:40.546957 20800 solver.cpp:245]     Train net output #2: accuracy = 0.663112
I0227 05:06:40.546967 20800 sgd_solver.cpp:106] Iteration 2220, lr = 0.000899522
I0227 05:06:57.790103 20800 solver.cpp:229] Iteration 2240, loss = 0.225576
I0227 05:06:57.790148 20800 solver.cpp:245]     Train net output #0: accuracy = 0.923328
I0227 05:06:57.790158 20800 solver.cpp:245]     Train net output #1: accuracy = 0.707656
I0227 05:06:57.790164 20800 solver.cpp:245]     Train net output #2: accuracy = 0.815811
I0227 05:06:57.790174 20800 sgd_solver.cpp:106] Iteration 2240, lr = 0.000898611
I0227 05:07:15.045656 20800 solver.cpp:229] Iteration 2260, loss = 0.222412
I0227 05:07:15.045702 20800 solver.cpp:245]     Train net output #0: accuracy = 0.931945
I0227 05:07:15.045711 20800 solver.cpp:245]     Train net output #1: accuracy = 0.83827
I0227 05:07:15.045717 20800 solver.cpp:245]     Train net output #2: accuracy = 0.780737
I0227 05:07:15.045727 20800 sgd_solver.cpp:106] Iteration 2260, lr = 0.0008977
I0227 05:07:32.311332 20800 solver.cpp:229] Iteration 2280, loss = 0.203359
I0227 05:07:32.311393 20800 solver.cpp:245]     Train net output #0: accuracy = 0.942594
I0227 05:07:32.311403 20800 solver.cpp:245]     Train net output #1: accuracy = 0.699843
I0227 05:07:32.311410 20800 solver.cpp:245]     Train net output #2: accuracy = 0.774906
I0227 05:07:32.311420 20800 sgd_solver.cpp:106] Iteration 2280, lr = 0.000896789
I0227 05:07:49.566087 20800 solver.cpp:229] Iteration 2300, loss = 0.218082
I0227 05:07:49.566131 20800 solver.cpp:245]     Train net output #0: accuracy = 0.917301
I0227 05:07:49.566140 20800 solver.cpp:245]     Train net output #1: accuracy = 0.706231
I0227 05:07:49.566148 20800 solver.cpp:245]     Train net output #2: accuracy = 0.724724
I0227 05:07:49.566157 20800 sgd_solver.cpp:106] Iteration 2300, lr = 0.000895878
I0227 05:08:06.843086 20800 solver.cpp:229] Iteration 2320, loss = 0.218393
I0227 05:08:06.843116 20800 solver.cpp:245]     Train net output #0: accuracy = 0.892921
I0227 05:08:06.843127 20800 solver.cpp:245]     Train net output #1: accuracy = 0.814229
I0227 05:08:06.843133 20800 solver.cpp:245]     Train net output #2: accuracy = 0.708243
I0227 05:08:06.843143 20800 sgd_solver.cpp:106] Iteration 2320, lr = 0.000894967
I0227 05:08:24.118429 20800 solver.cpp:229] Iteration 2340, loss = 0.214849
I0227 05:08:24.118475 20800 solver.cpp:245]     Train net output #0: accuracy = 0.903034
I0227 05:08:24.118484 20800 solver.cpp:245]     Train net output #1: accuracy = 0.819441
I0227 05:08:24.118492 20800 solver.cpp:245]     Train net output #2: accuracy = 0.645194
I0227 05:08:24.118502 20800 sgd_solver.cpp:106] Iteration 2340, lr = 0.000894056
I0227 05:08:41.377328 20800 solver.cpp:229] Iteration 2360, loss = 0.232672
I0227 05:08:41.377358 20800 solver.cpp:245]     Train net output #0: accuracy = 0.877627
I0227 05:08:41.377367 20800 solver.cpp:245]     Train net output #1: accuracy = 0.819368
I0227 05:08:41.377374 20800 solver.cpp:245]     Train net output #2: accuracy = 0.6981
I0227 05:08:41.377384 20800 sgd_solver.cpp:106] Iteration 2360, lr = 0.000893145
I0227 05:08:58.638770 20800 solver.cpp:229] Iteration 2380, loss = 0.209772
I0227 05:08:58.638799 20800 solver.cpp:245]     Train net output #0: accuracy = 0.939143
I0227 05:08:58.638808 20800 solver.cpp:245]     Train net output #1: accuracy = 0.829518
I0227 05:08:58.638814 20800 solver.cpp:245]     Train net output #2: accuracy = 0.763522
I0227 05:08:58.638823 20800 sgd_solver.cpp:106] Iteration 2380, lr = 0.000892233
I0227 05:09:15.898866 20800 solver.cpp:229] Iteration 2400, loss = 0.254448
I0227 05:09:15.898926 20800 solver.cpp:245]     Train net output #0: accuracy = 0.912433
I0227 05:09:15.898936 20800 solver.cpp:245]     Train net output #1: accuracy = 0.698248
I0227 05:09:15.898943 20800 solver.cpp:245]     Train net output #2: accuracy = 0.816597
I0227 05:09:15.898954 20800 sgd_solver.cpp:106] Iteration 2400, lr = 0.000891322
I0227 05:09:33.165649 20800 solver.cpp:229] Iteration 2420, loss = 0.268201
I0227 05:09:33.165693 20800 solver.cpp:245]     Train net output #0: accuracy = 0.918302
I0227 05:09:33.165702 20800 solver.cpp:245]     Train net output #1: accuracy = 0.800854
I0227 05:09:33.165709 20800 solver.cpp:245]     Train net output #2: accuracy = 0.770117
I0227 05:09:33.165720 20800 sgd_solver.cpp:106] Iteration 2420, lr = 0.00089041
I0227 05:09:50.433514 20800 solver.cpp:229] Iteration 2440, loss = 0.239061
I0227 05:09:50.433545 20800 solver.cpp:245]     Train net output #0: accuracy = 0.870214
I0227 05:09:50.433554 20800 solver.cpp:245]     Train net output #1: accuracy = 0.6309
I0227 05:09:50.433562 20800 solver.cpp:245]     Train net output #2: accuracy = 0.779056
I0227 05:09:50.433571 20800 sgd_solver.cpp:106] Iteration 2440, lr = 0.000889498
I0227 05:10:07.711422 20800 solver.cpp:229] Iteration 2460, loss = 0.218611
I0227 05:10:07.711452 20800 solver.cpp:245]     Train net output #0: accuracy = 0.945167
I0227 05:10:07.711460 20800 solver.cpp:245]     Train net output #1: accuracy = 0.720541
I0227 05:10:07.711467 20800 solver.cpp:245]     Train net output #2: accuracy = 0.716273
I0227 05:10:07.711478 20800 sgd_solver.cpp:106] Iteration 2460, lr = 0.000888586
I0227 05:10:24.974856 20800 solver.cpp:229] Iteration 2480, loss = 0.202839
I0227 05:10:24.974908 20800 solver.cpp:245]     Train net output #0: accuracy = 0.935223
I0227 05:10:24.974918 20800 solver.cpp:245]     Train net output #1: accuracy = 0.753528
I0227 05:10:24.974925 20800 solver.cpp:245]     Train net output #2: accuracy = 0.758576
I0227 05:10:24.974936 20800 sgd_solver.cpp:106] Iteration 2480, lr = 0.000887674
I0227 05:10:42.259531 20800 solver.cpp:229] Iteration 2500, loss = 0.201299
I0227 05:10:42.259560 20800 solver.cpp:245]     Train net output #0: accuracy = 0.94289
I0227 05:10:42.259569 20800 solver.cpp:245]     Train net output #1: accuracy = 0.879893
I0227 05:10:42.259577 20800 solver.cpp:245]     Train net output #2: accuracy = 0.88031
I0227 05:10:42.259586 20800 sgd_solver.cpp:106] Iteration 2500, lr = 0.000886762
I0227 05:10:59.523494 20800 solver.cpp:229] Iteration 2520, loss = 0.215373
I0227 05:10:59.523524 20800 solver.cpp:245]     Train net output #0: accuracy = 0.909756
I0227 05:10:59.523548 20800 solver.cpp:245]     Train net output #1: accuracy = 0.731642
I0227 05:10:59.523556 20800 solver.cpp:245]     Train net output #2: accuracy = 0.784011
I0227 05:10:59.523566 20800 sgd_solver.cpp:106] Iteration 2520, lr = 0.00088585
I0227 05:11:16.809571 20800 solver.cpp:229] Iteration 2540, loss = 0.232357
I0227 05:11:16.809605 20800 solver.cpp:245]     Train net output #0: accuracy = 0.899868
I0227 05:11:16.809615 20800 solver.cpp:245]     Train net output #1: accuracy = 0.541078
I0227 05:11:16.809623 20800 solver.cpp:245]     Train net output #2: accuracy = 0.481566
I0227 05:11:16.809633 20800 sgd_solver.cpp:106] Iteration 2540, lr = 0.000884938
I0227 05:11:34.074247 20800 solver.cpp:229] Iteration 2560, loss = 0.212866
I0227 05:11:34.074277 20800 solver.cpp:245]     Train net output #0: accuracy = 0.875312
I0227 05:11:34.074286 20800 solver.cpp:245]     Train net output #1: accuracy = 0.696049
I0227 05:11:34.074293 20800 solver.cpp:245]     Train net output #2: accuracy = 0.689772
I0227 05:11:34.074303 20800 sgd_solver.cpp:106] Iteration 2560, lr = 0.000884026
I0227 05:11:51.309375 20800 solver.cpp:229] Iteration 2580, loss = 0.211048
I0227 05:11:51.309404 20800 solver.cpp:245]     Train net output #0: accuracy = 0.920821
I0227 05:11:51.309414 20800 solver.cpp:245]     Train net output #1: accuracy = 0.906671
I0227 05:11:51.309422 20800 solver.cpp:245]     Train net output #2: accuracy = 0.786684
I0227 05:11:51.309432 20800 sgd_solver.cpp:106] Iteration 2580, lr = 0.000883113
I0227 05:12:08.577008 20800 solver.cpp:229] Iteration 2600, loss = 0.231542
I0227 05:12:08.577052 20800 solver.cpp:245]     Train net output #0: accuracy = 0.902023
I0227 05:12:08.577061 20800 solver.cpp:245]     Train net output #1: accuracy = 0.57102
I0227 05:12:08.577069 20800 solver.cpp:245]     Train net output #2: accuracy = 0.606308
I0227 05:12:08.577078 20800 sgd_solver.cpp:106] Iteration 2600, lr = 0.000882201
I0227 05:12:25.872169 20800 solver.cpp:229] Iteration 2620, loss = 0.218091
I0227 05:12:25.872200 20800 solver.cpp:245]     Train net output #0: accuracy = 0.865973
I0227 05:12:25.872208 20800 solver.cpp:245]     Train net output #1: accuracy = 0.443311
I0227 05:12:25.872215 20800 solver.cpp:245]     Train net output #2: accuracy = 0.54047
I0227 05:12:25.872225 20800 sgd_solver.cpp:106] Iteration 2620, lr = 0.000881288
I0227 05:12:43.138391 20800 solver.cpp:229] Iteration 2640, loss = 0.211397
I0227 05:12:43.138437 20800 solver.cpp:245]     Train net output #0: accuracy = 0.907079
I0227 05:12:43.138445 20800 solver.cpp:245]     Train net output #1: accuracy = 0.718408
I0227 05:12:43.138453 20800 solver.cpp:245]     Train net output #2: accuracy = 0.607914
I0227 05:12:43.138463 20800 sgd_solver.cpp:106] Iteration 2640, lr = 0.000880375
I0227 05:13:00.402276 20800 solver.cpp:229] Iteration 2660, loss = 0.208117
I0227 05:13:00.402320 20800 solver.cpp:245]     Train net output #0: accuracy = 0.906888
I0227 05:13:00.402329 20800 solver.cpp:245]     Train net output #1: accuracy = 0.788904
I0227 05:13:00.402336 20800 solver.cpp:245]     Train net output #2: accuracy = 0.685752
I0227 05:13:00.402345 20800 sgd_solver.cpp:106] Iteration 2660, lr = 0.000879462
I0227 05:13:17.647572 20800 solver.cpp:229] Iteration 2680, loss = 0.221558
I0227 05:13:17.647603 20800 solver.cpp:245]     Train net output #0: accuracy = 0.931886
I0227 05:13:17.647611 20800 solver.cpp:245]     Train net output #1: accuracy = 0.80808
I0227 05:13:17.647619 20800 solver.cpp:245]     Train net output #2: accuracy = 0.785401
I0227 05:13:17.647629 20800 sgd_solver.cpp:106] Iteration 2680, lr = 0.000878549
I0227 05:13:34.934644 20800 solver.cpp:229] Iteration 2700, loss = 0.228233
I0227 05:13:34.934689 20800 solver.cpp:245]     Train net output #0: accuracy = 0.953777
I0227 05:13:34.934697 20800 solver.cpp:245]     Train net output #1: accuracy = 0.808292
I0227 05:13:34.934705 20800 solver.cpp:245]     Train net output #2: accuracy = 0.746424
I0227 05:13:34.934715 20800 sgd_solver.cpp:106] Iteration 2700, lr = 0.000877636
I0227 05:13:52.177382 20800 solver.cpp:229] Iteration 2720, loss = 0.195395
I0227 05:13:52.177413 20800 solver.cpp:245]     Train net output #0: accuracy = 0.920226
I0227 05:13:52.177423 20800 solver.cpp:245]     Train net output #1: accuracy = 0.802902
I0227 05:13:52.177429 20800 solver.cpp:245]     Train net output #2: accuracy = 0.845762
I0227 05:13:52.177439 20800 sgd_solver.cpp:106] Iteration 2720, lr = 0.000876723
I0227 05:14:09.435917 20800 solver.cpp:229] Iteration 2740, loss = 0.223527
I0227 05:14:09.435961 20800 solver.cpp:245]     Train net output #0: accuracy = 0.921569
I0227 05:14:09.435969 20800 solver.cpp:245]     Train net output #1: accuracy = 0.916419
I0227 05:14:09.435976 20800 solver.cpp:245]     Train net output #2: accuracy = 0.946694
I0227 05:14:09.435986 20800 sgd_solver.cpp:106] Iteration 2740, lr = 0.00087581
I0227 05:14:26.702107 20800 solver.cpp:229] Iteration 2760, loss = 0.219583
I0227 05:14:26.702138 20800 solver.cpp:245]     Train net output #0: accuracy = 0.94771
I0227 05:14:26.702148 20800 solver.cpp:245]     Train net output #1: accuracy = 0.936487
I0227 05:14:26.702155 20800 solver.cpp:245]     Train net output #2: accuracy = 0.901116
I0227 05:14:26.702165 20800 sgd_solver.cpp:106] Iteration 2760, lr = 0.000874896
I0227 05:14:43.959208 20800 solver.cpp:229] Iteration 2780, loss = 0.249878
I0227 05:14:43.959239 20800 solver.cpp:245]     Train net output #0: accuracy = 0.945375
I0227 05:14:43.959247 20800 solver.cpp:245]     Train net output #1: accuracy = 0.801837
I0227 05:14:43.959254 20800 solver.cpp:245]     Train net output #2: accuracy = 0.869396
I0227 05:14:43.959264 20800 sgd_solver.cpp:106] Iteration 2780, lr = 0.000873983
I0227 05:15:01.203542 20800 solver.cpp:229] Iteration 2800, loss = 0.232975
I0227 05:15:01.203572 20800 solver.cpp:245]     Train net output #0: accuracy = 0.914337
I0227 05:15:01.203582 20800 solver.cpp:245]     Train net output #1: accuracy = 0.638668
I0227 05:15:01.203588 20800 solver.cpp:245]     Train net output #2: accuracy = 0.770451
I0227 05:15:01.203598 20800 sgd_solver.cpp:106] Iteration 2800, lr = 0.000873069
I0227 05:15:18.469172 20800 solver.cpp:229] Iteration 2820, loss = 0.215099
I0227 05:15:18.469218 20800 solver.cpp:245]     Train net output #0: accuracy = 0.899643
I0227 05:15:18.469226 20800 solver.cpp:245]     Train net output #1: accuracy = 0.74836
I0227 05:15:18.469233 20800 solver.cpp:245]     Train net output #2: accuracy = 0.63632
I0227 05:15:18.469242 20800 sgd_solver.cpp:106] Iteration 2820, lr = 0.000872155
I0227 05:15:35.733572 20800 solver.cpp:229] Iteration 2840, loss = 0.209408
I0227 05:15:35.733603 20800 solver.cpp:245]     Train net output #0: accuracy = 0.922134
I0227 05:15:35.733613 20800 solver.cpp:245]     Train net output #1: accuracy = 0.8275
I0227 05:15:35.733619 20800 solver.cpp:245]     Train net output #2: accuracy = 0.859275
I0227 05:15:35.733629 20800 sgd_solver.cpp:106] Iteration 2840, lr = 0.000871242
I0227 05:15:53.032531 20800 solver.cpp:229] Iteration 2860, loss = 0.24353
I0227 05:15:53.032562 20800 solver.cpp:245]     Train net output #0: accuracy = 0.875907
I0227 05:15:53.032572 20800 solver.cpp:245]     Train net output #1: accuracy = 0.794381
I0227 05:15:53.032578 20800 solver.cpp:245]     Train net output #2: accuracy = 0.782082
I0227 05:15:53.032588 20800 sgd_solver.cpp:106] Iteration 2860, lr = 0.000870328
I0227 05:16:10.279109 20800 solver.cpp:229] Iteration 2880, loss = 0.233839
I0227 05:16:10.279139 20800 solver.cpp:245]     Train net output #0: accuracy = 0.92416
I0227 05:16:10.279148 20800 solver.cpp:245]     Train net output #1: accuracy = 0.885019
I0227 05:16:10.279155 20800 solver.cpp:245]     Train net output #2: accuracy = 0.795173
I0227 05:16:10.279165 20800 sgd_solver.cpp:106] Iteration 2880, lr = 0.000869414
I0227 05:16:27.535563 20800 solver.cpp:229] Iteration 2900, loss = 0.242403
I0227 05:16:27.535593 20800 solver.cpp:245]     Train net output #0: accuracy = 0.950446
I0227 05:16:27.535603 20800 solver.cpp:245]     Train net output #1: accuracy = 0.868883
I0227 05:16:27.535609 20800 solver.cpp:245]     Train net output #2: accuracy = 0.811174
I0227 05:16:27.535619 20800 sgd_solver.cpp:106] Iteration 2900, lr = 0.000868499
I0227 05:16:44.795601 20800 solver.cpp:229] Iteration 2920, loss = 0.246258
I0227 05:16:44.795631 20800 solver.cpp:245]     Train net output #0: accuracy = 0.888876
I0227 05:16:44.795640 20800 solver.cpp:245]     Train net output #1: accuracy = 0.832831
I0227 05:16:44.795647 20800 solver.cpp:245]     Train net output #2: accuracy = 0.789427
I0227 05:16:44.795657 20800 sgd_solver.cpp:106] Iteration 2920, lr = 0.000867585
I0227 05:17:02.078333 20800 solver.cpp:229] Iteration 2940, loss = 0.243216
I0227 05:17:02.078379 20800 solver.cpp:245]     Train net output #0: accuracy = 0.942356
I0227 05:17:02.078389 20800 solver.cpp:245]     Train net output #1: accuracy = 0.834223
I0227 05:17:02.078397 20800 solver.cpp:245]     Train net output #2: accuracy = 0.909607
I0227 05:17:02.078406 20800 sgd_solver.cpp:106] Iteration 2940, lr = 0.000866671
I0227 05:17:19.359320 20800 solver.cpp:229] Iteration 2960, loss = 0.231945
I0227 05:17:19.359366 20800 solver.cpp:245]     Train net output #0: accuracy = 0.906127
I0227 05:17:19.359375 20800 solver.cpp:245]     Train net output #1: accuracy = 0.739441
I0227 05:17:19.359382 20800 solver.cpp:245]     Train net output #2: accuracy = 0.684928
I0227 05:17:19.359393 20800 sgd_solver.cpp:106] Iteration 2960, lr = 0.000865756
I0227 05:17:36.601745 20800 solver.cpp:229] Iteration 2980, loss = 0.234852
I0227 05:17:36.601790 20800 solver.cpp:245]     Train net output #0: accuracy = 0.92044
I0227 05:17:36.601800 20800 solver.cpp:245]     Train net output #1: accuracy = 0.812155
I0227 05:17:36.601807 20800 solver.cpp:245]     Train net output #2: accuracy = 0.713002
I0227 05:17:36.601817 20800 sgd_solver.cpp:106] Iteration 2980, lr = 0.000864842
I0227 05:17:53.871158 20800 solver.cpp:229] Iteration 3000, loss = 0.230603
I0227 05:17:53.871191 20800 solver.cpp:245]     Train net output #0: accuracy = 0.93279
I0227 05:17:53.871201 20800 solver.cpp:245]     Train net output #1: accuracy = 0.687367
I0227 05:17:53.871207 20800 solver.cpp:245]     Train net output #2: accuracy = 0.726808
I0227 05:17:53.871217 20800 sgd_solver.cpp:106] Iteration 3000, lr = 0.000863927
I0227 05:18:11.108330 20800 solver.cpp:229] Iteration 3020, loss = 0.234658
I0227 05:18:11.108373 20800 solver.cpp:245]     Train net output #0: accuracy = 0.864485
I0227 05:18:11.108382 20800 solver.cpp:245]     Train net output #1: accuracy = 0.636191
I0227 05:18:11.108389 20800 solver.cpp:245]     Train net output #2: accuracy = 0.528907
I0227 05:18:11.108398 20800 sgd_solver.cpp:106] Iteration 3020, lr = 0.000863012
I0227 05:18:28.368428 20800 solver.cpp:229] Iteration 3040, loss = 0.234545
I0227 05:18:28.368486 20800 solver.cpp:245]     Train net output #0: accuracy = 0.905354
I0227 05:18:28.368512 20800 solver.cpp:245]     Train net output #1: accuracy = 0.798154
I0227 05:18:28.368520 20800 solver.cpp:245]     Train net output #2: accuracy = 0.803226
I0227 05:18:28.368530 20800 sgd_solver.cpp:106] Iteration 3040, lr = 0.000862097
I0227 05:18:45.625787 20800 solver.cpp:229] Iteration 3060, loss = 0.245769
I0227 05:18:45.625833 20800 solver.cpp:245]     Train net output #0: accuracy = 0.897116
I0227 05:18:45.625844 20800 solver.cpp:245]     Train net output #1: accuracy = 0.825087
I0227 05:18:45.625850 20800 solver.cpp:245]     Train net output #2: accuracy = 0.821339
I0227 05:18:45.625860 20800 sgd_solver.cpp:106] Iteration 3060, lr = 0.000861182
I0227 05:19:02.881541 20800 solver.cpp:229] Iteration 3080, loss = 0.227052
I0227 05:19:02.881587 20800 solver.cpp:245]     Train net output #0: accuracy = 0.895538
I0227 05:19:02.881597 20800 solver.cpp:245]     Train net output #1: accuracy = 0.682434
I0227 05:19:02.881603 20800 solver.cpp:245]     Train net output #2: accuracy = 0.731807
I0227 05:19:02.881613 20800 sgd_solver.cpp:106] Iteration 3080, lr = 0.000860267
I0227 05:19:20.154567 20800 solver.cpp:229] Iteration 3100, loss = 0.217566
I0227 05:19:20.154610 20800 solver.cpp:245]     Train net output #0: accuracy = 0.936109
I0227 05:19:20.154618 20800 solver.cpp:245]     Train net output #1: accuracy = 0.707547
I0227 05:19:20.154625 20800 solver.cpp:245]     Train net output #2: accuracy = 0.629499
I0227 05:19:20.154635 20800 sgd_solver.cpp:106] Iteration 3100, lr = 0.000859352
I0227 05:19:37.410748 20800 solver.cpp:229] Iteration 3120, loss = 0.227583
I0227 05:19:37.410794 20800 solver.cpp:245]     Train net output #0: accuracy = 0.921416
I0227 05:19:37.410802 20800 solver.cpp:245]     Train net output #1: accuracy = 0.758887
I0227 05:19:37.410809 20800 solver.cpp:245]     Train net output #2: accuracy = 0.847428
I0227 05:19:37.410820 20800 sgd_solver.cpp:106] Iteration 3120, lr = 0.000858437
I0227 05:19:54.677438 20800 solver.cpp:229] Iteration 3140, loss = 0.25927
I0227 05:19:54.677469 20800 solver.cpp:245]     Train net output #0: accuracy = 0.868352
I0227 05:19:54.677479 20800 solver.cpp:245]     Train net output #1: accuracy = 0.557669
I0227 05:19:54.677485 20800 solver.cpp:245]     Train net output #2: accuracy = 0.671588
I0227 05:19:54.677495 20800 sgd_solver.cpp:106] Iteration 3140, lr = 0.000857521
I0227 05:20:11.958681 20800 solver.cpp:229] Iteration 3160, loss = 0.220161
I0227 05:20:11.958711 20800 solver.cpp:245]     Train net output #0: accuracy = 0.924986
I0227 05:20:11.958720 20800 solver.cpp:245]     Train net output #1: accuracy = 0.695936
I0227 05:20:11.958726 20800 solver.cpp:245]     Train net output #2: accuracy = 0.821203
I0227 05:20:11.958736 20800 sgd_solver.cpp:106] Iteration 3160, lr = 0.000856606
I0227 05:20:29.234743 20800 solver.cpp:229] Iteration 3180, loss = 0.232788
I0227 05:20:29.234788 20800 solver.cpp:245]     Train net output #0: accuracy = 0.894309
I0227 05:20:29.234797 20800 solver.cpp:245]     Train net output #1: accuracy = 0.78757
I0227 05:20:29.234805 20800 solver.cpp:245]     Train net output #2: accuracy = 0.588833
I0227 05:20:29.234815 20800 sgd_solver.cpp:106] Iteration 3180, lr = 0.00085569
I0227 05:20:46.507726 20800 solver.cpp:229] Iteration 3200, loss = 0.214395
I0227 05:20:46.507771 20800 solver.cpp:245]     Train net output #0: accuracy = 0.920401
I0227 05:20:46.507781 20800 solver.cpp:245]     Train net output #1: accuracy = 0.740624
I0227 05:20:46.507788 20800 solver.cpp:245]     Train net output #2: accuracy = 0.766429
I0227 05:20:46.507798 20800 sgd_solver.cpp:106] Iteration 3200, lr = 0.000854774
I0227 05:21:03.770936 20800 solver.cpp:229] Iteration 3220, loss = 0.215571
I0227 05:21:03.770968 20800 solver.cpp:245]     Train net output #0: accuracy = 0.919518
I0227 05:21:03.770977 20800 solver.cpp:245]     Train net output #1: accuracy = 0.797707
I0227 05:21:03.770984 20800 solver.cpp:245]     Train net output #2: accuracy = 0.672339
I0227 05:21:03.770994 20800 sgd_solver.cpp:106] Iteration 3220, lr = 0.000853858
I0227 05:21:21.014806 20800 solver.cpp:229] Iteration 3240, loss = 0.221725
I0227 05:21:21.014835 20800 solver.cpp:245]     Train net output #0: accuracy = 0.898909
I0227 05:21:21.014844 20800 solver.cpp:245]     Train net output #1: accuracy = 0.791872
I0227 05:21:21.014852 20800 solver.cpp:245]     Train net output #2: accuracy = 0.712722
I0227 05:21:21.014861 20800 sgd_solver.cpp:106] Iteration 3240, lr = 0.000852942
I0227 05:21:38.272711 20800 solver.cpp:229] Iteration 3260, loss = 0.248253
I0227 05:21:38.272754 20800 solver.cpp:245]     Train net output #0: accuracy = 0.910708
I0227 05:21:38.272763 20800 solver.cpp:245]     Train net output #1: accuracy = 0.90902
I0227 05:21:38.272770 20800 solver.cpp:245]     Train net output #2: accuracy = 0.889129
I0227 05:21:38.272779 20800 sgd_solver.cpp:106] Iteration 3260, lr = 0.000852026
I0227 05:21:55.515846 20800 solver.cpp:229] Iteration 3280, loss = 0.227544
I0227 05:21:55.515890 20800 solver.cpp:245]     Train net output #0: accuracy = 0.90232
I0227 05:21:55.515899 20800 solver.cpp:245]     Train net output #1: accuracy = 0.722539
I0227 05:21:55.515905 20800 solver.cpp:245]     Train net output #2: accuracy = 0.760245
I0227 05:21:55.515915 20800 sgd_solver.cpp:106] Iteration 3280, lr = 0.00085111
I0227 05:22:12.777118 20800 solver.cpp:229] Iteration 3300, loss = 0.213933
I0227 05:22:12.777164 20800 solver.cpp:245]     Train net output #0: accuracy = 0.920972
I0227 05:22:12.777173 20800 solver.cpp:245]     Train net output #1: accuracy = 0.935763
I0227 05:22:12.777180 20800 solver.cpp:245]     Train net output #2: accuracy = 0.838508
I0227 05:22:12.777190 20800 sgd_solver.cpp:106] Iteration 3300, lr = 0.000850194
I0227 05:22:30.059393 20800 solver.cpp:229] Iteration 3320, loss = 0.199782
I0227 05:22:30.059439 20800 solver.cpp:245]     Train net output #0: accuracy = 0.901487
I0227 05:22:30.059448 20800 solver.cpp:245]     Train net output #1: accuracy = 0.703602
I0227 05:22:30.059455 20800 solver.cpp:245]     Train net output #2: accuracy = 0.665678
I0227 05:22:30.059465 20800 sgd_solver.cpp:106] Iteration 3320, lr = 0.000849277
I0227 05:22:47.298154 20800 solver.cpp:229] Iteration 3340, loss = 0.198268
I0227 05:22:47.298199 20800 solver.cpp:245]     Train net output #0: accuracy = 0.929387
I0227 05:22:47.298208 20800 solver.cpp:245]     Train net output #1: accuracy = 0.802383
I0227 05:22:47.298215 20800 solver.cpp:245]     Train net output #2: accuracy = 0.705587
I0227 05:22:47.298225 20800 sgd_solver.cpp:106] Iteration 3340, lr = 0.000848361
I0227 05:23:04.559001 20800 solver.cpp:229] Iteration 3360, loss = 0.195595
I0227 05:23:04.559047 20800 solver.cpp:245]     Train net output #0: accuracy = 0.902439
I0227 05:23:04.559057 20800 solver.cpp:245]     Train net output #1: accuracy = 0.815176
I0227 05:23:04.559064 20800 solver.cpp:245]     Train net output #2: accuracy = 0.736406
I0227 05:23:04.559074 20800 sgd_solver.cpp:106] Iteration 3360, lr = 0.000847444
I0227 05:23:21.804556 20800 solver.cpp:229] Iteration 3380, loss = 0.190649
I0227 05:23:21.804602 20800 solver.cpp:245]     Train net output #0: accuracy = 0.915086
I0227 05:23:21.804611 20800 solver.cpp:245]     Train net output #1: accuracy = 0.903444
I0227 05:23:21.804632 20800 solver.cpp:245]     Train net output #2: accuracy = 0.929836
I0227 05:23:21.804642 20800 sgd_solver.cpp:106] Iteration 3380, lr = 0.000846527
I0227 05:23:39.089404 20800 solver.cpp:229] Iteration 3400, loss = 0.203549
I0227 05:23:39.089434 20800 solver.cpp:245]     Train net output #0: accuracy = 0.952409
I0227 05:23:39.089443 20800 solver.cpp:245]     Train net output #1: accuracy = 0.90176
I0227 05:23:39.089452 20800 solver.cpp:245]     Train net output #2: accuracy = 0.835683
I0227 05:23:39.089462 20800 sgd_solver.cpp:106] Iteration 3400, lr = 0.00084561
I0227 05:23:56.347379 20800 solver.cpp:229] Iteration 3420, loss = 0.199645
I0227 05:23:56.347409 20800 solver.cpp:245]     Train net output #0: accuracy = 0.922252
I0227 05:23:56.347419 20800 solver.cpp:245]     Train net output #1: accuracy = 0.62234
I0227 05:23:56.347425 20800 solver.cpp:245]     Train net output #2: accuracy = 0.772011
I0227 05:23:56.347436 20800 sgd_solver.cpp:106] Iteration 3420, lr = 0.000844693
I0227 05:24:13.621124 20800 solver.cpp:229] Iteration 3440, loss = 0.223552
I0227 05:24:13.621168 20800 solver.cpp:245]     Train net output #0: accuracy = 0.870672
I0227 05:24:13.621178 20800 solver.cpp:245]     Train net output #1: accuracy = 0.766193
I0227 05:24:13.621199 20800 solver.cpp:245]     Train net output #2: accuracy = 0.608761
I0227 05:24:13.621209 20800 sgd_solver.cpp:106] Iteration 3440, lr = 0.000843776
I0227 05:24:30.900944 20800 solver.cpp:229] Iteration 3460, loss = 0.198737
I0227 05:24:30.900990 20800 solver.cpp:245]     Train net output #0: accuracy = 0.935277
I0227 05:24:30.901000 20800 solver.cpp:245]     Train net output #1: accuracy = 0.834459
I0227 05:24:30.901006 20800 solver.cpp:245]     Train net output #2: accuracy = 0.821581
I0227 05:24:30.901016 20800 sgd_solver.cpp:106] Iteration 3460, lr = 0.000842859
I0227 05:24:48.185051 20800 solver.cpp:229] Iteration 3480, loss = 0.184967
I0227 05:24:48.185096 20800 solver.cpp:245]     Train net output #0: accuracy = 0.924319
I0227 05:24:48.185104 20800 solver.cpp:245]     Train net output #1: accuracy = 0.800415
I0227 05:24:48.185111 20800 solver.cpp:245]     Train net output #2: accuracy = 0.891865
I0227 05:24:48.185120 20800 sgd_solver.cpp:106] Iteration 3480, lr = 0.000841942
I0227 05:25:05.425797 20800 solver.cpp:229] Iteration 3500, loss = 0.215034
I0227 05:25:05.425840 20800 solver.cpp:245]     Train net output #0: accuracy = 0.935101
I0227 05:25:05.425849 20800 solver.cpp:245]     Train net output #1: accuracy = 0.771056
I0227 05:25:05.425856 20800 solver.cpp:245]     Train net output #2: accuracy = 0.81691
I0227 05:25:05.425865 20800 sgd_solver.cpp:106] Iteration 3500, lr = 0.000841024
I0227 05:25:22.685679 20800 solver.cpp:229] Iteration 3520, loss = 0.221811
I0227 05:25:22.685708 20800 solver.cpp:245]     Train net output #0: accuracy = 0.919334
I0227 05:25:22.685717 20800 solver.cpp:245]     Train net output #1: accuracy = 0.870372
I0227 05:25:22.685724 20800 solver.cpp:245]     Train net output #2: accuracy = 0.673793
I0227 05:25:22.685734 20800 sgd_solver.cpp:106] Iteration 3520, lr = 0.000840107
I0227 05:25:39.945654 20800 solver.cpp:229] Iteration 3540, loss = 0.208504
I0227 05:25:39.945683 20800 solver.cpp:245]     Train net output #0: accuracy = 0.940498
I0227 05:25:39.945691 20800 solver.cpp:245]     Train net output #1: accuracy = 0.831273
I0227 05:25:39.945698 20800 solver.cpp:245]     Train net output #2: accuracy = 0.873292
I0227 05:25:39.945706 20800 sgd_solver.cpp:106] Iteration 3540, lr = 0.000839189
I0227 05:25:57.198804 20800 solver.cpp:229] Iteration 3560, loss = 0.191832
I0227 05:25:57.198848 20800 solver.cpp:245]     Train net output #0: accuracy = 0.923082
I0227 05:25:57.198858 20800 solver.cpp:245]     Train net output #1: accuracy = 0.887014
I0227 05:25:57.198864 20800 solver.cpp:245]     Train net output #2: accuracy = 0.642701
I0227 05:25:57.198887 20800 sgd_solver.cpp:106] Iteration 3560, lr = 0.000838271
I0227 05:26:14.460327 20800 solver.cpp:229] Iteration 3580, loss = 0.206856
I0227 05:26:14.460371 20800 solver.cpp:245]     Train net output #0: accuracy = 0.907839
I0227 05:26:14.460395 20800 solver.cpp:245]     Train net output #1: accuracy = 0.689784
I0227 05:26:14.460403 20800 solver.cpp:245]     Train net output #2: accuracy = 0.598868
I0227 05:26:14.460413 20800 sgd_solver.cpp:106] Iteration 3580, lr = 0.000837354
I0227 05:26:31.721766 20800 solver.cpp:229] Iteration 3600, loss = 0.208483
I0227 05:26:31.721812 20800 solver.cpp:245]     Train net output #0: accuracy = 0.926532
I0227 05:26:31.721820 20800 solver.cpp:245]     Train net output #1: accuracy = 0.790051
I0227 05:26:31.721827 20800 solver.cpp:245]     Train net output #2: accuracy = 0.853191
I0227 05:26:31.721837 20800 sgd_solver.cpp:106] Iteration 3600, lr = 0.000836436
I0227 05:26:49.001485 20800 solver.cpp:229] Iteration 3620, loss = 0.231228
I0227 05:26:49.001528 20800 solver.cpp:245]     Train net output #0: accuracy = 0.872547
I0227 05:26:49.001538 20800 solver.cpp:245]     Train net output #1: accuracy = 0.892582
I0227 05:26:49.001544 20800 solver.cpp:245]     Train net output #2: accuracy = 0.722707
I0227 05:26:49.001554 20800 sgd_solver.cpp:106] Iteration 3620, lr = 0.000835517
I0227 05:27:06.260823 20800 solver.cpp:229] Iteration 3640, loss = 0.192167
I0227 05:27:06.260866 20800 solver.cpp:245]     Train net output #0: accuracy = 0.936864
I0227 05:27:06.260875 20800 solver.cpp:245]     Train net output #1: accuracy = 0.783849
I0227 05:27:06.260882 20800 solver.cpp:245]     Train net output #2: accuracy = 0.827601
I0227 05:27:06.260892 20800 sgd_solver.cpp:106] Iteration 3640, lr = 0.000834599
I0227 05:27:23.522048 20800 solver.cpp:229] Iteration 3660, loss = 0.208747
I0227 05:27:23.522092 20800 solver.cpp:245]     Train net output #0: accuracy = 0.934092
I0227 05:27:23.522101 20800 solver.cpp:245]     Train net output #1: accuracy = 0.69565
I0227 05:27:23.522109 20800 solver.cpp:245]     Train net output #2: accuracy = 0.685399
I0227 05:27:23.522117 20800 sgd_solver.cpp:106] Iteration 3660, lr = 0.000833681
I0227 05:27:40.785485 20800 solver.cpp:229] Iteration 3680, loss = 0.208734
I0227 05:27:40.785529 20800 solver.cpp:245]     Train net output #0: accuracy = 0.924013
I0227 05:27:40.785537 20800 solver.cpp:245]     Train net output #1: accuracy = 0.850902
I0227 05:27:40.785544 20800 solver.cpp:245]     Train net output #2: accuracy = 0.922293
I0227 05:27:40.785553 20800 sgd_solver.cpp:106] Iteration 3680, lr = 0.000832763
I0227 05:27:58.041189 20800 solver.cpp:229] Iteration 3700, loss = 0.21321
I0227 05:27:58.041237 20800 solver.cpp:245]     Train net output #0: accuracy = 0.920067
I0227 05:27:58.041246 20800 solver.cpp:245]     Train net output #1: accuracy = 0.711562
I0227 05:27:58.041254 20800 solver.cpp:245]     Train net output #2: accuracy = 0.646789
I0227 05:27:58.041263 20800 sgd_solver.cpp:106] Iteration 3700, lr = 0.000831844
I0227 05:28:15.283995 20800 solver.cpp:229] Iteration 3720, loss = 0.209917
I0227 05:28:15.284026 20800 solver.cpp:245]     Train net output #0: accuracy = 0.929149
I0227 05:28:15.284035 20800 solver.cpp:245]     Train net output #1: accuracy = 0.812508
I0227 05:28:15.284042 20800 solver.cpp:245]     Train net output #2: accuracy = 0.829212
I0227 05:28:15.284051 20800 sgd_solver.cpp:106] Iteration 3720, lr = 0.000830925
I0227 05:28:32.549266 20800 solver.cpp:229] Iteration 3740, loss = 0.204374
I0227 05:28:32.549298 20800 solver.cpp:245]     Train net output #0: accuracy = 0.891969
I0227 05:28:32.549306 20800 solver.cpp:245]     Train net output #1: accuracy = 0.762015
I0227 05:28:32.549314 20800 solver.cpp:245]     Train net output #2: accuracy = 0.685673
I0227 05:28:32.549324 20800 sgd_solver.cpp:106] Iteration 3740, lr = 0.000830006
I0227 05:28:49.810891 20800 solver.cpp:229] Iteration 3760, loss = 0.198319
I0227 05:28:49.810936 20800 solver.cpp:245]     Train net output #0: accuracy = 0.919185
I0227 05:28:49.810945 20800 solver.cpp:245]     Train net output #1: accuracy = 0.828145
I0227 05:28:49.810952 20800 solver.cpp:245]     Train net output #2: accuracy = 0.773194
I0227 05:28:49.810977 20800 sgd_solver.cpp:106] Iteration 3760, lr = 0.000829088
I0227 05:29:07.099050 20800 solver.cpp:229] Iteration 3780, loss = 0.198026
I0227 05:29:07.099081 20800 solver.cpp:245]     Train net output #0: accuracy = 0.94181
I0227 05:29:07.099090 20800 solver.cpp:245]     Train net output #1: accuracy = 0.784406
I0227 05:29:07.099097 20800 solver.cpp:245]     Train net output #2: accuracy = 0.670117
I0227 05:29:07.099107 20800 sgd_solver.cpp:106] Iteration 3780, lr = 0.000828169
I0227 05:29:24.354251 20800 solver.cpp:229] Iteration 3800, loss = 0.227217
I0227 05:29:24.354295 20800 solver.cpp:245]     Train net output #0: accuracy = 0.914454
I0227 05:29:24.354305 20800 solver.cpp:245]     Train net output #1: accuracy = 0.580171
I0227 05:29:24.354311 20800 solver.cpp:245]     Train net output #2: accuracy = 0.569054
I0227 05:29:24.354321 20800 sgd_solver.cpp:106] Iteration 3800, lr = 0.00082725
I0227 05:29:41.595168 20800 solver.cpp:229] Iteration 3820, loss = 0.219383
I0227 05:29:41.595227 20800 solver.cpp:245]     Train net output #0: accuracy = 0.904981
I0227 05:29:41.595237 20800 solver.cpp:245]     Train net output #1: accuracy = 0.747088
I0227 05:29:41.595244 20800 solver.cpp:245]     Train net output #2: accuracy = 0.748885
I0227 05:29:41.595254 20800 sgd_solver.cpp:106] Iteration 3820, lr = 0.00082633
I0227 05:29:58.861419 20800 solver.cpp:229] Iteration 3840, loss = 0.186388
I0227 05:29:58.861464 20800 solver.cpp:245]     Train net output #0: accuracy = 0.920404
I0227 05:29:58.861472 20800 solver.cpp:245]     Train net output #1: accuracy = 0.79385
I0227 05:29:58.861479 20800 solver.cpp:245]     Train net output #2: accuracy = 0.803971
I0227 05:29:58.861488 20800 sgd_solver.cpp:106] Iteration 3840, lr = 0.000825411
I0227 05:30:16.098193 20800 solver.cpp:229] Iteration 3860, loss = 0.17359
I0227 05:30:16.098238 20800 solver.cpp:245]     Train net output #0: accuracy = 0.953677
I0227 05:30:16.098248 20800 solver.cpp:245]     Train net output #1: accuracy = 0.91143
I0227 05:30:16.098254 20800 solver.cpp:245]     Train net output #2: accuracy = 0.889727
I0227 05:30:16.098263 20800 sgd_solver.cpp:106] Iteration 3860, lr = 0.000824492
I0227 05:30:33.366235 20800 solver.cpp:229] Iteration 3880, loss = 0.19776
I0227 05:30:33.366263 20800 solver.cpp:245]     Train net output #0: accuracy = 0.913028
I0227 05:30:33.366272 20800 solver.cpp:245]     Train net output #1: accuracy = 0.70195
I0227 05:30:33.366279 20800 solver.cpp:245]     Train net output #2: accuracy = 0.623105
I0227 05:30:33.366289 20800 sgd_solver.cpp:106] Iteration 3880, lr = 0.000823572
I0227 05:30:50.646203 20800 solver.cpp:229] Iteration 3900, loss = 0.198926
I0227 05:30:50.646265 20800 solver.cpp:245]     Train net output #0: accuracy = 0.929149
I0227 05:30:50.646275 20800 solver.cpp:245]     Train net output #1: accuracy = 0.683466
I0227 05:30:50.646281 20800 solver.cpp:245]     Train net output #2: accuracy = 0.713133
I0227 05:30:50.646292 20800 sgd_solver.cpp:106] Iteration 3900, lr = 0.000822652
I0227 05:31:07.891273 20800 solver.cpp:229] Iteration 3920, loss = 0.182746
I0227 05:31:07.891320 20800 solver.cpp:245]     Train net output #0: accuracy = 0.921535
I0227 05:31:07.891330 20800 solver.cpp:245]     Train net output #1: accuracy = 0.884949
I0227 05:31:07.891336 20800 solver.cpp:245]     Train net output #2: accuracy = 0.91104
I0227 05:31:07.891346 20800 sgd_solver.cpp:106] Iteration 3920, lr = 0.000821733
I0227 05:31:25.169378 20800 solver.cpp:229] Iteration 3940, loss = 0.199764
I0227 05:31:25.169409 20800 solver.cpp:245]     Train net output #0: accuracy = 0.898668
I0227 05:31:25.169418 20800 solver.cpp:245]     Train net output #1: accuracy = 0.891469
I0227 05:31:25.169425 20800 solver.cpp:245]     Train net output #2: accuracy = 0.83609
I0227 05:31:25.169435 20800 sgd_solver.cpp:106] Iteration 3940, lr = 0.000820813
I0227 05:31:42.436942 20800 solver.cpp:229] Iteration 3960, loss = 0.182646
I0227 05:31:42.436987 20800 solver.cpp:245]     Train net output #0: accuracy = 0.913279
I0227 05:31:42.436996 20800 solver.cpp:245]     Train net output #1: accuracy = 0.752373
I0227 05:31:42.437005 20800 solver.cpp:245]     Train net output #2: accuracy = 0.755203
I0227 05:31:42.437013 20800 sgd_solver.cpp:106] Iteration 3960, lr = 0.000819893
I0227 05:31:59.732436 20800 solver.cpp:229] Iteration 3980, loss = 0.190045
I0227 05:31:59.732466 20800 solver.cpp:245]     Train net output #0: accuracy = 0.936704
I0227 05:31:59.732475 20800 solver.cpp:245]     Train net output #1: accuracy = 0.853311
I0227 05:31:59.732482 20800 solver.cpp:245]     Train net output #2: accuracy = 0.858098
I0227 05:31:59.732492 20800 sgd_solver.cpp:106] Iteration 3980, lr = 0.000818972
I0227 05:32:17.012064 20800 solver.cpp:229] Iteration 4000, loss = 0.20218
I0227 05:32:17.012095 20800 solver.cpp:245]     Train net output #0: accuracy = 0.91648
I0227 05:32:17.012105 20800 solver.cpp:245]     Train net output #1: accuracy = 0.676437
I0227 05:32:17.012112 20800 solver.cpp:245]     Train net output #2: accuracy = 0.769216
I0227 05:32:17.012122 20800 sgd_solver.cpp:106] Iteration 4000, lr = 0.000818052
I0227 05:32:34.271131 20800 solver.cpp:229] Iteration 4020, loss = 0.188684
I0227 05:32:34.271160 20800 solver.cpp:245]     Train net output #0: accuracy = 0.915844
I0227 05:32:34.271170 20800 solver.cpp:245]     Train net output #1: accuracy = 0.782789
I0227 05:32:34.271178 20800 solver.cpp:245]     Train net output #2: accuracy = 0.736719
I0227 05:32:34.271186 20800 sgd_solver.cpp:106] Iteration 4020, lr = 0.000817132
I0227 05:32:51.542686 20800 solver.cpp:229] Iteration 4040, loss = 0.2153
I0227 05:32:51.542733 20800 solver.cpp:245]     Train net output #0: accuracy = 0.887853
I0227 05:32:51.542743 20800 solver.cpp:245]     Train net output #1: accuracy = 0.704492
I0227 05:32:51.542750 20800 solver.cpp:245]     Train net output #2: accuracy = 0.782546
I0227 05:32:51.542760 20800 sgd_solver.cpp:106] Iteration 4040, lr = 0.000816211
I0227 05:33:08.821584 20800 solver.cpp:229] Iteration 4060, loss = 0.206486
I0227 05:33:08.821629 20800 solver.cpp:245]     Train net output #0: accuracy = 0.92526
I0227 05:33:08.821653 20800 solver.cpp:245]     Train net output #1: accuracy = 0.851252
I0227 05:33:08.821660 20800 solver.cpp:245]     Train net output #2: accuracy = 0.705105
I0227 05:33:08.821671 20800 sgd_solver.cpp:106] Iteration 4060, lr = 0.000815291
I0227 05:33:26.086292 20800 solver.cpp:229] Iteration 4080, loss = 0.205632
I0227 05:33:26.086336 20800 solver.cpp:245]     Train net output #0: accuracy = 0.916835
I0227 05:33:26.086345 20800 solver.cpp:245]     Train net output #1: accuracy = 0.757485
I0227 05:33:26.086352 20800 solver.cpp:245]     Train net output #2: accuracy = 0.751
I0227 05:33:26.086361 20800 sgd_solver.cpp:106] Iteration 4080, lr = 0.00081437
I0227 05:33:43.344630 20800 solver.cpp:229] Iteration 4100, loss = 0.204671
I0227 05:33:43.344657 20800 solver.cpp:245]     Train net output #0: accuracy = 0.908566
I0227 05:33:43.344681 20800 solver.cpp:245]     Train net output #1: accuracy = 0.843222
I0227 05:33:43.344688 20800 solver.cpp:245]     Train net output #2: accuracy = 0.755058
I0227 05:33:43.344699 20800 sgd_solver.cpp:106] Iteration 4100, lr = 0.000813449
I0227 05:34:00.626055 20800 solver.cpp:229] Iteration 4120, loss = 0.217712
I0227 05:34:00.626085 20800 solver.cpp:245]     Train net output #0: accuracy = 0.962908
I0227 05:34:00.626093 20800 solver.cpp:245]     Train net output #1: accuracy = 0.752229
I0227 05:34:00.626101 20800 solver.cpp:245]     Train net output #2: accuracy = 0.717876
I0227 05:34:00.626111 20800 sgd_solver.cpp:106] Iteration 4120, lr = 0.000812528
I0227 05:34:17.876883 20800 solver.cpp:229] Iteration 4140, loss = 0.209907
I0227 05:34:17.876911 20800 solver.cpp:245]     Train net output #0: accuracy = 0.909161
I0227 05:34:17.876920 20800 solver.cpp:245]     Train net output #1: accuracy = 0.691071
I0227 05:34:17.876927 20800 solver.cpp:245]     Train net output #2: accuracy = 0.799738
I0227 05:34:17.876937 20800 sgd_solver.cpp:106] Iteration 4140, lr = 0.000811607
I0227 05:34:35.134068 20800 solver.cpp:229] Iteration 4160, loss = 0.205331
I0227 05:34:35.134114 20800 solver.cpp:245]     Train net output #0: accuracy = 0.92424
I0227 05:34:35.134122 20800 solver.cpp:245]     Train net output #1: accuracy = 0.640178
I0227 05:34:35.134130 20800 solver.cpp:245]     Train net output #2: accuracy = 0.609734
I0227 05:34:35.134140 20800 sgd_solver.cpp:106] Iteration 4160, lr = 0.000810686
I0227 05:34:52.401818 20800 solver.cpp:229] Iteration 4180, loss = 0.222777
I0227 05:34:52.401860 20800 solver.cpp:245]     Train net output #0: accuracy = 0.919715
I0227 05:34:52.401870 20800 solver.cpp:245]     Train net output #1: accuracy = 0.908093
I0227 05:34:52.401876 20800 solver.cpp:245]     Train net output #2: accuracy = 0.94507
I0227 05:34:52.401886 20800 sgd_solver.cpp:106] Iteration 4180, lr = 0.000809765
I0227 05:35:09.670049 20800 solver.cpp:229] Iteration 4200, loss = 0.211798
I0227 05:35:09.670078 20800 solver.cpp:245]     Train net output #0: accuracy = 0.940869
I0227 05:35:09.670086 20800 solver.cpp:245]     Train net output #1: accuracy = 0.837617
I0227 05:35:09.670094 20800 solver.cpp:245]     Train net output #2: accuracy = 0.835445
I0227 05:35:09.670104 20800 sgd_solver.cpp:106] Iteration 4200, lr = 0.000808843
I0227 05:35:26.939970 20800 solver.cpp:229] Iteration 4220, loss = 0.221839
I0227 05:35:26.940013 20800 solver.cpp:245]     Train net output #0: accuracy = 0.903297
I0227 05:35:26.940022 20800 solver.cpp:245]     Train net output #1: accuracy = 0.717675
I0227 05:35:26.940029 20800 solver.cpp:245]     Train net output #2: accuracy = 0.691452
I0227 05:35:26.940039 20800 sgd_solver.cpp:106] Iteration 4220, lr = 0.000807922
I0227 05:35:44.203996 20800 solver.cpp:229] Iteration 4240, loss = 0.207881
I0227 05:35:44.204039 20800 solver.cpp:245]     Train net output #0: accuracy = 0.886556
I0227 05:35:44.204047 20800 solver.cpp:245]     Train net output #1: accuracy = 0.693889
I0227 05:35:44.204054 20800 solver.cpp:245]     Train net output #2: accuracy = 0.744779
I0227 05:35:44.204064 20800 sgd_solver.cpp:106] Iteration 4240, lr = 0.000807
I0227 05:36:01.493659 20800 solver.cpp:229] Iteration 4260, loss = 0.182937
I0227 05:36:01.493703 20800 solver.cpp:245]     Train net output #0: accuracy = 0.933077
I0227 05:36:01.493712 20800 solver.cpp:245]     Train net output #1: accuracy = 0.725127
I0227 05:36:01.493719 20800 solver.cpp:245]     Train net output #2: accuracy = 0.71849
I0227 05:36:01.493729 20800 sgd_solver.cpp:106] Iteration 4260, lr = 0.000806078
I0227 05:36:18.753023 20800 solver.cpp:229] Iteration 4280, loss = 0.181362
I0227 05:36:18.753053 20800 solver.cpp:245]     Train net output #0: accuracy = 0.939953
I0227 05:36:18.753062 20800 solver.cpp:245]     Train net output #1: accuracy = 0.804719
I0227 05:36:18.753069 20800 solver.cpp:245]     Train net output #2: accuracy = 0.871847
I0227 05:36:18.753078 20800 sgd_solver.cpp:106] Iteration 4280, lr = 0.000805157
I0227 05:36:36.021025 20800 solver.cpp:229] Iteration 4300, loss = 0.187612
I0227 05:36:36.021055 20800 solver.cpp:245]     Train net output #0: accuracy = 0.883522
I0227 05:36:36.021064 20800 solver.cpp:245]     Train net output #1: accuracy = 0.70047
I0227 05:36:36.021071 20800 solver.cpp:245]     Train net output #2: accuracy = 0.785414
I0227 05:36:36.021081 20800 sgd_solver.cpp:106] Iteration 4300, lr = 0.000804234
I0227 05:36:53.285697 20800 solver.cpp:229] Iteration 4320, loss = 0.191236
I0227 05:36:53.285740 20800 solver.cpp:245]     Train net output #0: accuracy = 0.917692
I0227 05:36:53.285749 20800 solver.cpp:245]     Train net output #1: accuracy = 0.550391
I0227 05:36:53.285756 20800 solver.cpp:245]     Train net output #2: accuracy = 0.705261
I0227 05:36:53.285766 20800 sgd_solver.cpp:106] Iteration 4320, lr = 0.000803312
I0227 05:37:10.546342 20800 solver.cpp:229] Iteration 4340, loss = 0.181376
I0227 05:37:10.546386 20800 solver.cpp:245]     Train net output #0: accuracy = 0.928399
I0227 05:37:10.546394 20800 solver.cpp:245]     Train net output #1: accuracy = 0.86154
I0227 05:37:10.546401 20800 solver.cpp:245]     Train net output #2: accuracy = 0.908199
I0227 05:37:10.546411 20800 sgd_solver.cpp:106] Iteration 4340, lr = 0.00080239
I0227 05:37:27.802623 20800 solver.cpp:229] Iteration 4360, loss = 0.189972
I0227 05:37:27.802652 20800 solver.cpp:245]     Train net output #0: accuracy = 0.941761
I0227 05:37:27.802662 20800 solver.cpp:245]     Train net output #1: accuracy = 0.8051
I0227 05:37:27.802670 20800 solver.cpp:245]     Train net output #2: accuracy = 0.823364
I0227 05:37:27.802680 20800 sgd_solver.cpp:106] Iteration 4360, lr = 0.000801468
I0227 05:37:45.067297 20800 solver.cpp:229] Iteration 4380, loss = 0.200018
I0227 05:37:45.067358 20800 solver.cpp:245]     Train net output #0: accuracy = 0.903629
I0227 05:37:45.067366 20800 solver.cpp:245]     Train net output #1: accuracy = 0.830886
I0227 05:37:45.067373 20800 solver.cpp:245]     Train net output #2: accuracy = 0.848432
I0227 05:37:45.067384 20800 sgd_solver.cpp:106] Iteration 4380, lr = 0.000800545
I0227 05:38:02.323257 20800 solver.cpp:229] Iteration 4400, loss = 0.194852
I0227 05:38:02.323302 20800 solver.cpp:245]     Train net output #0: accuracy = 0.924916
I0227 05:38:02.323312 20800 solver.cpp:245]     Train net output #1: accuracy = 0.851352
I0227 05:38:02.323318 20800 solver.cpp:245]     Train net output #2: accuracy = 0.692284
I0227 05:38:02.323328 20800 sgd_solver.cpp:106] Iteration 4400, lr = 0.000799623
I0227 05:38:19.552794 20800 solver.cpp:229] Iteration 4420, loss = 0.186097
I0227 05:38:19.552822 20800 solver.cpp:245]     Train net output #0: accuracy = 0.893932
I0227 05:38:19.552846 20800 solver.cpp:245]     Train net output #1: accuracy = 0.605568
I0227 05:38:19.552853 20800 solver.cpp:245]     Train net output #2: accuracy = 0.518781
I0227 05:38:19.552863 20800 sgd_solver.cpp:106] Iteration 4420, lr = 0.0007987
I0227 05:38:36.848139 20800 solver.cpp:229] Iteration 4440, loss = 0.1771
I0227 05:38:36.848167 20800 solver.cpp:245]     Train net output #0: accuracy = 0.927556
I0227 05:38:36.848177 20800 solver.cpp:245]     Train net output #1: accuracy = 0.934473
I0227 05:38:36.848184 20800 solver.cpp:245]     Train net output #2: accuracy = 0.826398
I0227 05:38:36.848193 20800 sgd_solver.cpp:106] Iteration 4440, lr = 0.000797777
I0227 05:38:54.107934 20800 solver.cpp:229] Iteration 4460, loss = 0.193969
I0227 05:38:54.107980 20800 solver.cpp:245]     Train net output #0: accuracy = 0.902082
I0227 05:38:54.107990 20800 solver.cpp:245]     Train net output #1: accuracy = 0.595635
I0227 05:38:54.107996 20800 solver.cpp:245]     Train net output #2: accuracy = 0.673346
I0227 05:38:54.108006 20800 sgd_solver.cpp:106] Iteration 4460, lr = 0.000796854
I0227 05:39:11.357388 20800 solver.cpp:229] Iteration 4480, loss = 0.179569
I0227 05:39:11.357421 20800 solver.cpp:245]     Train net output #0: accuracy = 0.924236
I0227 05:39:11.357430 20800 solver.cpp:245]     Train net output #1: accuracy = 0.774733
I0227 05:39:11.357437 20800 solver.cpp:245]     Train net output #2: accuracy = 0.815689
I0227 05:39:11.357447 20800 sgd_solver.cpp:106] Iteration 4480, lr = 0.000795931
I0227 05:39:28.617914 20800 solver.cpp:229] Iteration 4500, loss = 0.206117
I0227 05:39:28.617959 20800 solver.cpp:245]     Train net output #0: accuracy = 0.932897
I0227 05:39:28.617969 20800 solver.cpp:245]     Train net output #1: accuracy = 0.837366
I0227 05:39:28.617976 20800 solver.cpp:245]     Train net output #2: accuracy = 0.837454
I0227 05:39:28.617986 20800 sgd_solver.cpp:106] Iteration 4500, lr = 0.000795008
I0227 05:39:45.893573 20800 solver.cpp:229] Iteration 4520, loss = 0.186745
I0227 05:39:45.893617 20800 solver.cpp:245]     Train net output #0: accuracy = 0.945438
I0227 05:39:45.893626 20800 solver.cpp:245]     Train net output #1: accuracy = 0.842906
I0227 05:39:45.893633 20800 solver.cpp:245]     Train net output #2: accuracy = 0.75524
I0227 05:39:45.893643 20800 sgd_solver.cpp:106] Iteration 4520, lr = 0.000794085
I0227 05:40:03.156395 20800 solver.cpp:229] Iteration 4540, loss = 0.175591
I0227 05:40:03.156425 20800 solver.cpp:245]     Train net output #0: accuracy = 0.915943
I0227 05:40:03.156435 20800 solver.cpp:245]     Train net output #1: accuracy = 0.760747
I0227 05:40:03.156441 20800 solver.cpp:245]     Train net output #2: accuracy = 0.838117
I0227 05:40:03.156451 20800 sgd_solver.cpp:106] Iteration 4540, lr = 0.000793161
I0227 05:40:20.407738 20800 solver.cpp:229] Iteration 4560, loss = 0.18363
I0227 05:40:20.407783 20800 solver.cpp:245]     Train net output #0: accuracy = 0.927793
I0227 05:40:20.407793 20800 solver.cpp:245]     Train net output #1: accuracy = 0.817565
I0227 05:40:20.407799 20800 solver.cpp:245]     Train net output #2: accuracy = 0.814236
I0227 05:40:20.407809 20800 sgd_solver.cpp:106] Iteration 4560, lr = 0.000792238
I0227 05:40:37.695108 20800 solver.cpp:229] Iteration 4580, loss = 0.183594
I0227 05:40:37.695139 20800 solver.cpp:245]     Train net output #0: accuracy = 0.921355
I0227 05:40:37.695148 20800 solver.cpp:245]     Train net output #1: accuracy = 0.851923
I0227 05:40:37.695155 20800 solver.cpp:245]     Train net output #2: accuracy = 0.870993
I0227 05:40:37.695165 20800 sgd_solver.cpp:106] Iteration 4580, lr = 0.000791314
I0227 05:40:54.947976 20800 solver.cpp:229] Iteration 4600, loss = 0.181522
I0227 05:40:54.948004 20800 solver.cpp:245]     Train net output #0: accuracy = 0.956122
I0227 05:40:54.948029 20800 solver.cpp:245]     Train net output #1: accuracy = 0.860309
I0227 05:40:54.948036 20800 solver.cpp:245]     Train net output #2: accuracy = 0.927665
I0227 05:40:54.948045 20800 sgd_solver.cpp:106] Iteration 4600, lr = 0.00079039
I0227 05:41:12.227771 20800 solver.cpp:229] Iteration 4620, loss = 0.195054
I0227 05:41:12.227798 20800 solver.cpp:245]     Train net output #0: accuracy = 0.93367
I0227 05:41:12.227808 20800 solver.cpp:245]     Train net output #1: accuracy = 0.814839
I0227 05:41:12.227815 20800 solver.cpp:245]     Train net output #2: accuracy = 0.751957
I0227 05:41:12.227824 20800 sgd_solver.cpp:106] Iteration 4620, lr = 0.000789467
I0227 05:41:29.485409 20800 solver.cpp:229] Iteration 4640, loss = 0.206425
I0227 05:41:29.485453 20800 solver.cpp:245]     Train net output #0: accuracy = 0.91642
I0227 05:41:29.485461 20800 solver.cpp:245]     Train net output #1: accuracy = 0.693818
I0227 05:41:29.485468 20800 solver.cpp:245]     Train net output #2: accuracy = 0.746605
I0227 05:41:29.485478 20800 sgd_solver.cpp:106] Iteration 4640, lr = 0.000788543
I0227 05:41:46.728958 20800 solver.cpp:229] Iteration 4660, loss = 0.19589
I0227 05:41:46.728989 20800 solver.cpp:245]     Train net output #0: accuracy = 0.918263
I0227 05:41:46.728998 20800 solver.cpp:245]     Train net output #1: accuracy = 0.587186
I0227 05:41:46.729005 20800 solver.cpp:245]     Train net output #2: accuracy = 0.6694
I0227 05:41:46.729015 20800 sgd_solver.cpp:106] Iteration 4660, lr = 0.000787618
I0227 05:42:04.000452 20800 solver.cpp:229] Iteration 4680, loss = 0.184106
I0227 05:42:04.000516 20800 solver.cpp:245]     Train net output #0: accuracy = 0.917576
I0227 05:42:04.000526 20800 solver.cpp:245]     Train net output #1: accuracy = 0.787373
I0227 05:42:04.000533 20800 solver.cpp:245]     Train net output #2: accuracy = 0.855672
I0227 05:42:04.000543 20800 sgd_solver.cpp:106] Iteration 4680, lr = 0.000786694
I0227 05:42:21.257442 20800 solver.cpp:229] Iteration 4700, loss = 0.206286
I0227 05:42:21.257488 20800 solver.cpp:245]     Train net output #0: accuracy = 0.911541
I0227 05:42:21.257498 20800 solver.cpp:245]     Train net output #1: accuracy = 0.557642
I0227 05:42:21.257504 20800 solver.cpp:245]     Train net output #2: accuracy = 0.572545
I0227 05:42:21.257513 20800 sgd_solver.cpp:106] Iteration 4700, lr = 0.00078577
I0227 05:42:38.544659 20800 solver.cpp:229] Iteration 4720, loss = 0.187471
I0227 05:42:38.544690 20800 solver.cpp:245]     Train net output #0: accuracy = 0.923577
I0227 05:42:38.544699 20800 solver.cpp:245]     Train net output #1: accuracy = 0.831577
I0227 05:42:38.544706 20800 solver.cpp:245]     Train net output #2: accuracy = 0.672337
I0227 05:42:38.544715 20800 sgd_solver.cpp:106] Iteration 4720, lr = 0.000784845
I0227 05:42:55.822233 20800 solver.cpp:229] Iteration 4740, loss = 0.200677
I0227 05:42:55.822263 20800 solver.cpp:245]     Train net output #0: accuracy = 0.958418
I0227 05:42:55.822271 20800 solver.cpp:245]     Train net output #1: accuracy = 0.941689
I0227 05:42:55.822278 20800 solver.cpp:245]     Train net output #2: accuracy = 0.852041
I0227 05:42:55.822288 20800 sgd_solver.cpp:106] Iteration 4740, lr = 0.000783921
I0227 05:43:13.072535 20800 solver.cpp:229] Iteration 4760, loss = 0.199736
I0227 05:43:13.072579 20800 solver.cpp:245]     Train net output #0: accuracy = 0.917073
I0227 05:43:13.072588 20800 solver.cpp:245]     Train net output #1: accuracy = 0.780967
I0227 05:43:13.072595 20800 solver.cpp:245]     Train net output #2: accuracy = 0.758744
I0227 05:43:13.072604 20800 sgd_solver.cpp:106] Iteration 4760, lr = 0.000782996
I0227 05:43:30.352619 20800 solver.cpp:229] Iteration 4780, loss = 0.201458
I0227 05:43:30.352663 20800 solver.cpp:245]     Train net output #0: accuracy = 0.893966
I0227 05:43:30.352671 20800 solver.cpp:245]     Train net output #1: accuracy = 0.784462
I0227 05:43:30.352679 20800 solver.cpp:245]     Train net output #2: accuracy = 0.813733
I0227 05:43:30.352687 20800 sgd_solver.cpp:106] Iteration 4780, lr = 0.000782071
I0227 05:43:47.612555 20800 solver.cpp:229] Iteration 4800, loss = 0.190397
I0227 05:43:47.612584 20800 solver.cpp:245]     Train net output #0: accuracy = 0.934741
I0227 05:43:47.612593 20800 solver.cpp:245]     Train net output #1: accuracy = 0.761806
I0227 05:43:47.612601 20800 solver.cpp:245]     Train net output #2: accuracy = 0.734232
I0227 05:43:47.612610 20800 sgd_solver.cpp:106] Iteration 4800, lr = 0.000781146
I0227 05:44:04.874967 20800 solver.cpp:229] Iteration 4820, loss = 0.181718
I0227 05:44:04.875000 20800 solver.cpp:245]     Train net output #0: accuracy = 0.905354
I0227 05:44:04.875010 20800 solver.cpp:245]     Train net output #1: accuracy = 0.675865
I0227 05:44:04.875016 20800 solver.cpp:245]     Train net output #2: accuracy = 0.67321
I0227 05:44:04.875026 20800 sgd_solver.cpp:106] Iteration 4820, lr = 0.000780221
I0227 05:44:22.129364 20800 solver.cpp:229] Iteration 4840, loss = 0.181427
I0227 05:44:22.129407 20800 solver.cpp:245]     Train net output #0: accuracy = 0.934503
I0227 05:44:22.129416 20800 solver.cpp:245]     Train net output #1: accuracy = 0.826237
I0227 05:44:22.129422 20800 solver.cpp:245]     Train net output #2: accuracy = 0.622572
I0227 05:44:22.129432 20800 sgd_solver.cpp:106] Iteration 4840, lr = 0.000779296
I0227 05:44:39.386453 20800 solver.cpp:229] Iteration 4860, loss = 0.193509
I0227 05:44:39.386498 20800 solver.cpp:245]     Train net output #0: accuracy = 0.944914
I0227 05:44:39.386507 20800 solver.cpp:245]     Train net output #1: accuracy = 0.765739
I0227 05:44:39.386513 20800 solver.cpp:245]     Train net output #2: accuracy = 0.797157
I0227 05:44:39.386524 20800 sgd_solver.cpp:106] Iteration 4860, lr = 0.00077837
I0227 05:44:56.636966 20800 solver.cpp:229] Iteration 4880, loss = 0.195637
I0227 05:44:56.637012 20800 solver.cpp:245]     Train net output #0: accuracy = 0.929863
I0227 05:44:56.637022 20800 solver.cpp:245]     Train net output #1: accuracy = 0.812157
I0227 05:44:56.637028 20800 solver.cpp:245]     Train net output #2: accuracy = 0.80701
I0227 05:44:56.637038 20800 sgd_solver.cpp:106] Iteration 4880, lr = 0.000777445
I0227 05:45:13.924197 20800 solver.cpp:229] Iteration 4900, loss = 0.182683
I0227 05:45:13.924227 20800 solver.cpp:245]     Train net output #0: accuracy = 0.904521
I0227 05:45:13.924237 20800 solver.cpp:245]     Train net output #1: accuracy = 0.887656
I0227 05:45:13.924243 20800 solver.cpp:245]     Train net output #2: accuracy = 0.742657
I0227 05:45:13.924254 20800 sgd_solver.cpp:106] Iteration 4900, lr = 0.000776519
I0227 05:45:31.184756 20800 solver.cpp:229] Iteration 4920, loss = 0.199026
I0227 05:45:31.184787 20800 solver.cpp:245]     Train net output #0: accuracy = 0.908804
I0227 05:45:31.184795 20800 solver.cpp:245]     Train net output #1: accuracy = 0.764476
I0227 05:45:31.184803 20800 solver.cpp:245]     Train net output #2: accuracy = 0.754333
I0227 05:45:31.184813 20800 sgd_solver.cpp:106] Iteration 4920, lr = 0.000775594
I0227 05:45:48.457178 20800 solver.cpp:229] Iteration 4940, loss = 0.211385
I0227 05:45:48.457223 20800 solver.cpp:245]     Train net output #0: accuracy = 0.893813
I0227 05:45:48.457233 20800 solver.cpp:245]     Train net output #1: accuracy = 0.809223
I0227 05:45:48.457240 20800 solver.cpp:245]     Train net output #2: accuracy = 0.602354
I0227 05:45:48.457250 20800 sgd_solver.cpp:106] Iteration 4940, lr = 0.000774668
I0227 05:46:05.729737 20800 solver.cpp:229] Iteration 4960, loss = 0.191676
I0227 05:46:05.729768 20800 solver.cpp:245]     Train net output #0: accuracy = 0.913206
I0227 05:46:05.729777 20800 solver.cpp:245]     Train net output #1: accuracy = 0.81846
I0227 05:46:05.729784 20800 solver.cpp:245]     Train net output #2: accuracy = 0.687037
I0227 05:46:05.729794 20800 sgd_solver.cpp:106] Iteration 4960, lr = 0.000773742
I0227 05:46:22.990911 20800 solver.cpp:229] Iteration 4980, loss = 0.202555
I0227 05:46:22.990942 20800 solver.cpp:245]     Train net output #0: accuracy = 0.918979
I0227 05:46:22.990950 20800 solver.cpp:245]     Train net output #1: accuracy = 0.836197
I0227 05:46:22.990957 20800 solver.cpp:245]     Train net output #2: accuracy = 0.855047
I0227 05:46:22.990967 20800 sgd_solver.cpp:106] Iteration 4980, lr = 0.000772816
I0227 05:46:40.259251 20800 solver.cpp:229] Iteration 5000, loss = 0.1647
I0227 05:46:40.259281 20800 solver.cpp:245]     Train net output #0: accuracy = 0.952528
I0227 05:46:40.259290 20800 solver.cpp:245]     Train net output #1: accuracy = 0.758753
I0227 05:46:40.259297 20800 solver.cpp:245]     Train net output #2: accuracy = 0.823364
I0227 05:46:40.259307 20800 sgd_solver.cpp:106] Iteration 5000, lr = 0.00077189
I0227 05:46:57.530443 20800 solver.cpp:229] Iteration 5020, loss = 0.202119
I0227 05:46:57.530490 20800 solver.cpp:245]     Train net output #0: accuracy = 0.930399
I0227 05:46:57.530514 20800 solver.cpp:245]     Train net output #1: accuracy = 0.830424
I0227 05:46:57.530521 20800 solver.cpp:245]     Train net output #2: accuracy = 0.830858
I0227 05:46:57.530531 20800 sgd_solver.cpp:106] Iteration 5020, lr = 0.000770963
I0227 05:47:14.788024 20800 solver.cpp:229] Iteration 5040, loss = 0.176807
I0227 05:47:14.788054 20800 solver.cpp:245]     Train net output #0: accuracy = 0.942237
I0227 05:47:14.788064 20800 solver.cpp:245]     Train net output #1: accuracy = 0.594866
I0227 05:47:14.788070 20800 solver.cpp:245]     Train net output #2: accuracy = 0.613223
I0227 05:47:14.788081 20800 sgd_solver.cpp:106] Iteration 5040, lr = 0.000770037
I0227 05:47:32.056903 20800 solver.cpp:229] Iteration 5060, loss = 0.195913
I0227 05:47:32.056946 20800 solver.cpp:245]     Train net output #0: accuracy = 0.943388
I0227 05:47:32.056955 20800 solver.cpp:245]     Train net output #1: accuracy = 0.746542
I0227 05:47:32.056962 20800 solver.cpp:245]     Train net output #2: accuracy = 0.865887
I0227 05:47:32.056973 20800 sgd_solver.cpp:106] Iteration 5060, lr = 0.00076911
I0227 05:47:49.326459 20800 solver.cpp:229] Iteration 5080, loss = 0.178571
I0227 05:47:49.326490 20800 solver.cpp:245]     Train net output #0: accuracy = 0.928022
I0227 05:47:49.326499 20800 solver.cpp:245]     Train net output #1: accuracy = 0.872646
I0227 05:47:49.326506 20800 solver.cpp:245]     Train net output #2: accuracy = 0.87269
I0227 05:47:49.326516 20800 sgd_solver.cpp:106] Iteration 5080, lr = 0.000768183
I0227 05:48:06.609272 20800 solver.cpp:229] Iteration 5100, loss = 0.212281
I0227 05:48:06.609318 20800 solver.cpp:245]     Train net output #0: accuracy = 0.926056
I0227 05:48:06.609326 20800 solver.cpp:245]     Train net output #1: accuracy = 0.758483
I0227 05:48:06.609333 20800 solver.cpp:245]     Train net output #2: accuracy = 0.808008
I0227 05:48:06.609344 20800 sgd_solver.cpp:106] Iteration 5100, lr = 0.000767257
I0227 05:48:23.896462 20800 solver.cpp:229] Iteration 5120, loss = 0.201074
I0227 05:48:23.896508 20800 solver.cpp:245]     Train net output #0: accuracy = 0.922427
I0227 05:48:23.896518 20800 solver.cpp:245]     Train net output #1: accuracy = 0.734746
I0227 05:48:23.896539 20800 solver.cpp:245]     Train net output #2: accuracy = 0.696667
I0227 05:48:23.896549 20800 sgd_solver.cpp:106] Iteration 5120, lr = 0.00076633
I0227 05:48:41.172266 20800 solver.cpp:229] Iteration 5140, loss = 0.185254
I0227 05:48:41.172309 20800 solver.cpp:245]     Train net output #0: accuracy = 0.913147
I0227 05:48:41.172318 20800 solver.cpp:245]     Train net output #1: accuracy = 0.882071
I0227 05:48:41.172325 20800 solver.cpp:245]     Train net output #2: accuracy = 0.868522
I0227 05:48:41.172334 20800 sgd_solver.cpp:106] Iteration 5140, lr = 0.000765403
I0227 05:48:58.429047 20800 solver.cpp:229] Iteration 5160, loss = 0.167732
I0227 05:48:58.429092 20800 solver.cpp:245]     Train net output #0: accuracy = 0.914059
I0227 05:48:58.429102 20800 solver.cpp:245]     Train net output #1: accuracy = 0.78869
I0227 05:48:58.429109 20800 solver.cpp:245]     Train net output #2: accuracy = 0.628335
I0227 05:48:58.429119 20800 sgd_solver.cpp:106] Iteration 5160, lr = 0.000764475
I0227 05:49:15.732483 20800 solver.cpp:229] Iteration 5180, loss = 0.177219
I0227 05:49:15.732527 20800 solver.cpp:245]     Train net output #0: accuracy = 0.937775
I0227 05:49:15.732535 20800 solver.cpp:245]     Train net output #1: accuracy = 0.763925
I0227 05:49:15.732542 20800 solver.cpp:245]     Train net output #2: accuracy = 0.69358
I0227 05:49:15.732551 20800 sgd_solver.cpp:106] Iteration 5180, lr = 0.000763548
I0227 05:49:33.014178 20800 solver.cpp:229] Iteration 5200, loss = 0.181537
I0227 05:49:33.014223 20800 solver.cpp:245]     Train net output #0: accuracy = 0.907258
I0227 05:49:33.014233 20800 solver.cpp:245]     Train net output #1: accuracy = 0.687483
I0227 05:49:33.014240 20800 solver.cpp:245]     Train net output #2: accuracy = 0.691774
I0227 05:49:33.014251 20800 sgd_solver.cpp:106] Iteration 5200, lr = 0.000762621
I0227 05:49:50.299432 20800 solver.cpp:229] Iteration 5220, loss = 0.194473
I0227 05:49:50.299460 20800 solver.cpp:245]     Train net output #0: accuracy = 0.944281
I0227 05:49:50.299469 20800 solver.cpp:245]     Train net output #1: accuracy = 0.712139
I0227 05:49:50.299476 20800 solver.cpp:245]     Train net output #2: accuracy = 0.790875
I0227 05:49:50.299487 20800 sgd_solver.cpp:106] Iteration 5220, lr = 0.000761693
I0227 05:50:07.565107 20800 solver.cpp:229] Iteration 5240, loss = 0.19209
I0227 05:50:07.565151 20800 solver.cpp:245]     Train net output #0: accuracy = 0.918739
I0227 05:50:07.565160 20800 solver.cpp:245]     Train net output #1: accuracy = 0.82423
I0227 05:50:07.565167 20800 solver.cpp:245]     Train net output #2: accuracy = 0.79653
I0227 05:50:07.565177 20800 sgd_solver.cpp:106] Iteration 5240, lr = 0.000760765
I0227 05:50:24.817548 20800 solver.cpp:229] Iteration 5260, loss = 0.192644
I0227 05:50:24.817590 20800 solver.cpp:245]     Train net output #0: accuracy = 0.92439
I0227 05:50:24.817600 20800 solver.cpp:245]     Train net output #1: accuracy = 0.83822
I0227 05:50:24.817606 20800 solver.cpp:245]     Train net output #2: accuracy = 0.849427
I0227 05:50:24.817616 20800 sgd_solver.cpp:106] Iteration 5260, lr = 0.000759838
I0227 05:50:42.107385 20800 solver.cpp:229] Iteration 5280, loss = 0.199417
I0227 05:50:42.107427 20800 solver.cpp:245]     Train net output #0: accuracy = 0.935634
I0227 05:50:42.107436 20800 solver.cpp:245]     Train net output #1: accuracy = 0.785205
I0227 05:50:42.107444 20800 solver.cpp:245]     Train net output #2: accuracy = 0.832138
I0227 05:50:42.107453 20800 sgd_solver.cpp:106] Iteration 5280, lr = 0.00075891
I0227 05:50:59.380436 20800 solver.cpp:229] Iteration 5300, loss = 0.184995
I0227 05:50:59.380466 20800 solver.cpp:245]     Train net output #0: accuracy = 0.952645
I0227 05:50:59.380475 20800 solver.cpp:245]     Train net output #1: accuracy = 0.797543
I0227 05:50:59.380481 20800 solver.cpp:245]     Train net output #2: accuracy = 0.789926
I0227 05:50:59.380491 20800 sgd_solver.cpp:106] Iteration 5300, lr = 0.000757982
I0227 05:51:16.656237 20800 solver.cpp:229] Iteration 5320, loss = 0.186121
I0227 05:51:16.656282 20800 solver.cpp:245]     Train net output #0: accuracy = 0.933608
I0227 05:51:16.656292 20800 solver.cpp:245]     Train net output #1: accuracy = 0.79724
I0227 05:51:16.656299 20800 solver.cpp:245]     Train net output #2: accuracy = 0.758463
I0227 05:51:16.656309 20800 sgd_solver.cpp:106] Iteration 5320, lr = 0.000757053
I0227 05:51:33.933375 20800 solver.cpp:229] Iteration 5340, loss = 0.151633
I0227 05:51:33.933406 20800 solver.cpp:245]     Train net output #0: accuracy = 0.948424
I0227 05:51:33.933416 20800 solver.cpp:245]     Train net output #1: accuracy = 0.736192
I0227 05:51:33.933423 20800 solver.cpp:245]     Train net output #2: accuracy = 0.795373
I0227 05:51:33.933432 20800 sgd_solver.cpp:106] Iteration 5340, lr = 0.000756125
I0227 05:51:51.213529 20800 solver.cpp:229] Iteration 5360, loss = 0.165929
I0227 05:51:51.213574 20800 solver.cpp:245]     Train net output #0: accuracy = 0.915084
I0227 05:51:51.213584 20800 solver.cpp:245]     Train net output #1: accuracy = 0.865573
I0227 05:51:51.213590 20800 solver.cpp:245]     Train net output #2: accuracy = 0.779943
I0227 05:51:51.213601 20800 sgd_solver.cpp:106] Iteration 5360, lr = 0.000755197
I0227 05:52:08.461800 20800 solver.cpp:229] Iteration 5380, loss = 0.159771
I0227 05:52:08.461827 20800 solver.cpp:245]     Train net output #0: accuracy = 0.942713
I0227 05:52:08.461835 20800 solver.cpp:245]     Train net output #1: accuracy = 0.800428
I0227 05:52:08.461841 20800 solver.cpp:245]     Train net output #2: accuracy = 0.831257
I0227 05:52:08.461850 20800 sgd_solver.cpp:106] Iteration 5380, lr = 0.000754268
I0227 05:52:25.716990 20800 solver.cpp:229] Iteration 5400, loss = 0.179071
I0227 05:52:25.717036 20800 solver.cpp:245]     Train net output #0: accuracy = 0.928138
I0227 05:52:25.717046 20800 solver.cpp:245]     Train net output #1: accuracy = 0.883223
I0227 05:52:25.717052 20800 solver.cpp:245]     Train net output #2: accuracy = 0.856192
I0227 05:52:25.717062 20800 sgd_solver.cpp:106] Iteration 5400, lr = 0.000753339
I0227 05:52:42.995208 20800 solver.cpp:229] Iteration 5420, loss = 0.175062
I0227 05:52:42.995240 20800 solver.cpp:245]     Train net output #0: accuracy = 0.950803
I0227 05:52:42.995249 20800 solver.cpp:245]     Train net output #1: accuracy = 0.770089
I0227 05:52:42.995256 20800 solver.cpp:245]     Train net output #2: accuracy = 0.899864
I0227 05:52:42.995266 20800 sgd_solver.cpp:106] Iteration 5420, lr = 0.00075241
I0227 05:53:00.273846 20800 solver.cpp:229] Iteration 5440, loss = 0.189998
I0227 05:53:00.273890 20800 solver.cpp:245]     Train net output #0: accuracy = 0.941582
I0227 05:53:00.273914 20800 solver.cpp:245]     Train net output #1: accuracy = 0.847482
I0227 05:53:00.273921 20800 solver.cpp:245]     Train net output #2: accuracy = 0.673345
I0227 05:53:00.273931 20800 sgd_solver.cpp:106] Iteration 5440, lr = 0.000751481
I0227 05:53:17.530531 20800 solver.cpp:229] Iteration 5460, loss = 0.183701
I0227 05:53:17.530561 20800 solver.cpp:245]     Train net output #0: accuracy = 0.885833
I0227 05:53:17.530570 20800 solver.cpp:245]     Train net output #1: accuracy = 0.752963
I0227 05:53:17.530577 20800 solver.cpp:245]     Train net output #2: accuracy = 0.725538
I0227 05:53:17.530601 20800 sgd_solver.cpp:106] Iteration 5460, lr = 0.000750552
I0227 05:53:34.777034 20800 solver.cpp:229] Iteration 5480, loss = 0.178144
I0227 05:53:34.777076 20800 solver.cpp:245]     Train net output #0: accuracy = 0.921813
I0227 05:53:34.777086 20800 solver.cpp:245]     Train net output #1: accuracy = 0.724966
I0227 05:53:34.777091 20800 solver.cpp:245]     Train net output #2: accuracy = 0.784086
I0227 05:53:34.777101 20800 sgd_solver.cpp:106] Iteration 5480, lr = 0.000749623
I0227 05:53:52.024390 20800 solver.cpp:229] Iteration 5500, loss = 0.174845
I0227 05:53:52.024418 20800 solver.cpp:245]     Train net output #0: accuracy = 0.946936
I0227 05:53:52.024426 20800 solver.cpp:245]     Train net output #1: accuracy = 0.739465
I0227 05:53:52.024433 20800 solver.cpp:245]     Train net output #2: accuracy = 0.727195
I0227 05:53:52.024442 20800 sgd_solver.cpp:106] Iteration 5500, lr = 0.000748694
I0227 05:54:09.282172 20800 solver.cpp:229] Iteration 5520, loss = 0.175572
I0227 05:54:09.282227 20800 solver.cpp:245]     Train net output #0: accuracy = 0.923389
I0227 05:54:09.282251 20800 solver.cpp:245]     Train net output #1: accuracy = 0.650557
I0227 05:54:09.282258 20800 solver.cpp:245]     Train net output #2: accuracy = 0.635977
I0227 05:54:09.282269 20800 sgd_solver.cpp:106] Iteration 5520, lr = 0.000747764
I0227 05:54:26.551956 20800 solver.cpp:229] Iteration 5540, loss = 0.164447
I0227 05:54:26.552000 20800 solver.cpp:245]     Train net output #0: accuracy = 0.930458
I0227 05:54:26.552009 20800 solver.cpp:245]     Train net output #1: accuracy = 0.881305
I0227 05:54:26.552016 20800 solver.cpp:245]     Train net output #2: accuracy = 0.747756
I0227 05:54:26.552026 20800 sgd_solver.cpp:106] Iteration 5540, lr = 0.000746835
I0227 05:54:43.823659 20800 solver.cpp:229] Iteration 5560, loss = 0.174125
I0227 05:54:43.823689 20800 solver.cpp:245]     Train net output #0: accuracy = 0.943601
I0227 05:54:43.823698 20800 solver.cpp:245]     Train net output #1: accuracy = 0.759987
I0227 05:54:43.823705 20800 solver.cpp:245]     Train net output #2: accuracy = 0.866663
I0227 05:54:43.823715 20800 sgd_solver.cpp:106] Iteration 5560, lr = 0.000745905
I0227 05:55:01.102737 20800 solver.cpp:229] Iteration 5580, loss = 0.181968
I0227 05:55:01.102783 20800 solver.cpp:245]     Train net output #0: accuracy = 0.944319
I0227 05:55:01.102792 20800 solver.cpp:245]     Train net output #1: accuracy = 0.860508
I0227 05:55:01.102799 20800 solver.cpp:245]     Train net output #2: accuracy = 0.863326
I0227 05:55:01.102808 20800 sgd_solver.cpp:106] Iteration 5580, lr = 0.000744975
I0227 05:55:18.360627 20800 solver.cpp:229] Iteration 5600, loss = 0.180462
I0227 05:55:18.360671 20800 solver.cpp:245]     Train net output #0: accuracy = 0.918965
I0227 05:55:18.360682 20800 solver.cpp:245]     Train net output #1: accuracy = 0.725817
I0227 05:55:18.360688 20800 solver.cpp:245]     Train net output #2: accuracy = 0.713851
I0227 05:55:18.360698 20800 sgd_solver.cpp:106] Iteration 5600, lr = 0.000744045
I0227 05:55:35.618890 20800 solver.cpp:229] Iteration 5620, loss = 0.186326
I0227 05:55:35.618950 20800 solver.cpp:245]     Train net output #0: accuracy = 0.899346
I0227 05:55:35.618975 20800 solver.cpp:245]     Train net output #1: accuracy = 0.693029
I0227 05:55:35.618983 20800 solver.cpp:245]     Train net output #2: accuracy = 0.588902
I0227 05:55:35.618994 20800 sgd_solver.cpp:106] Iteration 5620, lr = 0.000743115
I0227 05:55:52.907191 20800 solver.cpp:229] Iteration 5640, loss = 0.174741
I0227 05:55:52.907222 20800 solver.cpp:245]     Train net output #0: accuracy = 0.902023
I0227 05:55:52.907230 20800 solver.cpp:245]     Train net output #1: accuracy = 0.826022
I0227 05:55:52.907238 20800 solver.cpp:245]     Train net output #2: accuracy = 0.760759
I0227 05:55:52.907248 20800 sgd_solver.cpp:106] Iteration 5640, lr = 0.000742185
I0227 05:56:10.166505 20800 solver.cpp:229] Iteration 5660, loss = 0.172488
I0227 05:56:10.166549 20800 solver.cpp:245]     Train net output #0: accuracy = 0.945676
I0227 05:56:10.166558 20800 solver.cpp:245]     Train net output #1: accuracy = 0.76228
I0227 05:56:10.166564 20800 solver.cpp:245]     Train net output #2: accuracy = 0.803035
I0227 05:56:10.166574 20800 sgd_solver.cpp:106] Iteration 5660, lr = 0.000741254
I0227 05:56:27.428303 20800 solver.cpp:229] Iteration 5680, loss = 0.18165
I0227 05:56:27.428349 20800 solver.cpp:245]     Train net output #0: accuracy = 0.936526
I0227 05:56:27.428359 20800 solver.cpp:245]     Train net output #1: accuracy = 0.809552
I0227 05:56:27.428365 20800 solver.cpp:245]     Train net output #2: accuracy = 0.817767
I0227 05:56:27.428375 20800 sgd_solver.cpp:106] Iteration 5680, lr = 0.000740324
I0227 05:56:44.701514 20800 solver.cpp:229] Iteration 5700, loss = 0.186745
I0227 05:56:44.701558 20800 solver.cpp:245]     Train net output #0: accuracy = 0.922754
I0227 05:56:44.701567 20800 solver.cpp:245]     Train net output #1: accuracy = 0.774618
I0227 05:56:44.701575 20800 solver.cpp:245]     Train net output #2: accuracy = 0.702204
I0227 05:56:44.701584 20800 sgd_solver.cpp:106] Iteration 5700, lr = 0.000739393
I0227 05:57:01.949884 20800 solver.cpp:229] Iteration 5720, loss = 0.180938
I0227 05:57:01.949929 20800 solver.cpp:245]     Train net output #0: accuracy = 0.940095
I0227 05:57:01.949939 20800 solver.cpp:245]     Train net output #1: accuracy = 0.571797
I0227 05:57:01.949945 20800 solver.cpp:245]     Train net output #2: accuracy = 0.741205
I0227 05:57:01.949956 20800 sgd_solver.cpp:106] Iteration 5720, lr = 0.000738462
I0227 05:57:19.217406 20800 solver.cpp:229] Iteration 5740, loss = 0.178128
I0227 05:57:19.217451 20800 solver.cpp:245]     Train net output #0: accuracy = 0.963205
I0227 05:57:19.217460 20800 solver.cpp:245]     Train net output #1: accuracy = 0.892302
I0227 05:57:19.217468 20800 solver.cpp:245]     Train net output #2: accuracy = 0.914364
I0227 05:57:19.217478 20800 sgd_solver.cpp:106] Iteration 5740, lr = 0.000737532
I0227 05:57:36.501111 20800 solver.cpp:229] Iteration 5760, loss = 0.172791
I0227 05:57:36.501138 20800 solver.cpp:245]     Train net output #0: accuracy = 0.940896
I0227 05:57:36.501147 20800 solver.cpp:245]     Train net output #1: accuracy = 0.896188
I0227 05:57:36.501154 20800 solver.cpp:245]     Train net output #2: accuracy = 0.750625
I0227 05:57:36.501164 20800 sgd_solver.cpp:106] Iteration 5760, lr = 0.000736601
I0227 05:57:53.761045 20800 solver.cpp:229] Iteration 5780, loss = 0.189037
I0227 05:57:53.761090 20800 solver.cpp:245]     Train net output #0: accuracy = 0.929863
I0227 05:57:53.761099 20800 solver.cpp:245]     Train net output #1: accuracy = 0.912569
I0227 05:57:53.761106 20800 solver.cpp:245]     Train net output #2: accuracy = 0.783478
I0227 05:57:53.761116 20800 sgd_solver.cpp:106] Iteration 5780, lr = 0.000735669
I0227 05:58:11.028017 20800 solver.cpp:229] Iteration 5800, loss = 0.167789
I0227 05:58:11.028061 20800 solver.cpp:245]     Train net output #0: accuracy = 0.928257
I0227 05:58:11.028070 20800 solver.cpp:245]     Train net output #1: accuracy = 0.713681
I0227 05:58:11.028077 20800 solver.cpp:245]     Train net output #2: accuracy = 0.606438
I0227 05:58:11.028087 20800 sgd_solver.cpp:106] Iteration 5800, lr = 0.000734738
I0227 05:58:28.287328 20800 solver.cpp:229] Iteration 5820, loss = 0.156179
I0227 05:58:28.287359 20800 solver.cpp:245]     Train net output #0: accuracy = 0.96112
I0227 05:58:28.287369 20800 solver.cpp:245]     Train net output #1: accuracy = 0.815683
I0227 05:58:28.287375 20800 solver.cpp:245]     Train net output #2: accuracy = 0.878737
I0227 05:58:28.287385 20800 sgd_solver.cpp:106] Iteration 5820, lr = 0.000733807
I0227 05:58:45.555261 20800 solver.cpp:229] Iteration 5840, loss = 0.169016
I0227 05:58:45.555321 20800 solver.cpp:245]     Train net output #0: accuracy = 0.946378
I0227 05:58:45.555330 20800 solver.cpp:245]     Train net output #1: accuracy = 0.902145
I0227 05:58:45.555337 20800 solver.cpp:245]     Train net output #2: accuracy = 0.908464
I0227 05:58:45.555346 20800 sgd_solver.cpp:106] Iteration 5840, lr = 0.000732875
I0227 05:59:02.836349 20800 solver.cpp:229] Iteration 5860, loss = 0.177203
I0227 05:59:02.836392 20800 solver.cpp:245]     Train net output #0: accuracy = 0.915969
I0227 05:59:02.836401 20800 solver.cpp:245]     Train net output #1: accuracy = 0.847596
I0227 05:59:02.836410 20800 solver.cpp:245]     Train net output #2: accuracy = 0.753937
I0227 05:59:02.836418 20800 sgd_solver.cpp:106] Iteration 5860, lr = 0.000731943
I0227 05:59:20.072875 20800 solver.cpp:229] Iteration 5880, loss = 0.183948
I0227 05:59:20.072919 20800 solver.cpp:245]     Train net output #0: accuracy = 0.929447
I0227 05:59:20.072928 20800 solver.cpp:245]     Train net output #1: accuracy = 0.883977
I0227 05:59:20.072935 20800 solver.cpp:245]     Train net output #2: accuracy = 0.807678
I0227 05:59:20.072945 20800 sgd_solver.cpp:106] Iteration 5880, lr = 0.000731012
I0227 05:59:37.354858 20800 solver.cpp:229] Iteration 5900, loss = 0.176244
I0227 05:59:37.354941 20800 solver.cpp:245]     Train net output #0: accuracy = 0.93209
I0227 05:59:37.354959 20800 solver.cpp:245]     Train net output #1: accuracy = 0.797911
I0227 05:59:37.354974 20800 solver.cpp:245]     Train net output #2: accuracy = 0.763572
I0227 05:59:37.354990 20800 sgd_solver.cpp:106] Iteration 5900, lr = 0.00073008
I0227 05:59:54.615263 20800 solver.cpp:229] Iteration 5920, loss = 0.183538
I0227 05:59:54.615320 20800 solver.cpp:245]     Train net output #0: accuracy = 0.951814
I0227 05:59:54.615345 20800 solver.cpp:245]     Train net output #1: accuracy = 0.818775
I0227 05:59:54.615351 20800 solver.cpp:245]     Train net output #2: accuracy = 0.78817
I0227 05:59:54.615361 20800 sgd_solver.cpp:106] Iteration 5920, lr = 0.000729148
I0227 06:00:11.874989 20800 solver.cpp:229] Iteration 5940, loss = 0.202098
I0227 06:00:11.875017 20800 solver.cpp:245]     Train net output #0: accuracy = 0.920583
I0227 06:00:11.875026 20800 solver.cpp:245]     Train net output #1: accuracy = 0.789244
I0227 06:00:11.875033 20800 solver.cpp:245]     Train net output #2: accuracy = 0.748087
I0227 06:00:11.875043 20800 sgd_solver.cpp:106] Iteration 5940, lr = 0.000728215
I0227 06:00:29.138540 20800 solver.cpp:229] Iteration 5960, loss = 0.170922
I0227 06:00:29.138584 20800 solver.cpp:245]     Train net output #0: accuracy = 0.94307
I0227 06:00:29.138593 20800 solver.cpp:245]     Train net output #1: accuracy = 0.838332
I0227 06:00:29.138600 20800 solver.cpp:245]     Train net output #2: accuracy = 0.905227
I0227 06:00:29.138610 20800 sgd_solver.cpp:106] Iteration 5960, lr = 0.000727283
I0227 06:00:46.407605 20800 solver.cpp:229] Iteration 5980, loss = 0.16989
I0227 06:00:46.407651 20800 solver.cpp:245]     Train net output #0: accuracy = 0.919274
I0227 06:00:46.407661 20800 solver.cpp:245]     Train net output #1: accuracy = 0.822947
I0227 06:00:46.407682 20800 solver.cpp:245]     Train net output #2: accuracy = 0.712489
I0227 06:00:46.407691 20800 sgd_solver.cpp:106] Iteration 5980, lr = 0.00072635
I0227 06:01:03.657080 20800 solver.cpp:229] Iteration 6000, loss = 0.174609
I0227 06:01:03.657125 20800 solver.cpp:245]     Train net output #0: accuracy = 0.906544
I0227 06:01:03.657135 20800 solver.cpp:245]     Train net output #1: accuracy = 0.792011
I0227 06:01:03.657141 20800 solver.cpp:245]     Train net output #2: accuracy = 0.854894
I0227 06:01:03.657150 20800 sgd_solver.cpp:106] Iteration 6000, lr = 0.000725418
I0227 06:01:20.927947 20800 solver.cpp:229] Iteration 6020, loss = 0.175445
I0227 06:01:20.927991 20800 solver.cpp:245]     Train net output #0: accuracy = 0.95176
I0227 06:01:20.928015 20800 solver.cpp:245]     Train net output #1: accuracy = 0.787211
I0227 06:01:20.928022 20800 solver.cpp:245]     Train net output #2: accuracy = 0.866655
I0227 06:01:20.928031 20800 sgd_solver.cpp:106] Iteration 6020, lr = 0.000724485
I0227 06:01:38.215400 20800 solver.cpp:229] Iteration 6040, loss = 0.201769
I0227 06:01:38.215446 20800 solver.cpp:245]     Train net output #0: accuracy = 0.875172
I0227 06:01:38.215456 20800 solver.cpp:245]     Train net output #1: accuracy = 0.737825
I0227 06:01:38.215462 20800 solver.cpp:245]     Train net output #2: accuracy = 0.757191
I0227 06:01:38.215472 20800 sgd_solver.cpp:106] Iteration 6040, lr = 0.000723552
I0227 06:01:55.479275 20800 solver.cpp:229] Iteration 6060, loss = 0.188307
I0227 06:01:55.479306 20800 solver.cpp:245]     Train net output #0: accuracy = 0.929804
I0227 06:01:55.479315 20800 solver.cpp:245]     Train net output #1: accuracy = 0.759545
I0227 06:01:55.479322 20800 solver.cpp:245]     Train net output #2: accuracy = 0.756833
I0227 06:01:55.479332 20800 sgd_solver.cpp:106] Iteration 6060, lr = 0.000722619
I0227 06:02:12.741307 20800 solver.cpp:229] Iteration 6080, loss = 0.176884
I0227 06:02:12.741350 20800 solver.cpp:245]     Train net output #0: accuracy = 0.940928
I0227 06:02:12.741359 20800 solver.cpp:245]     Train net output #1: accuracy = 0.706612
I0227 06:02:12.741366 20800 solver.cpp:245]     Train net output #2: accuracy = 0.821263
I0227 06:02:12.741375 20800 sgd_solver.cpp:106] Iteration 6080, lr = 0.000721686
I0227 06:02:30.024242 20800 solver.cpp:229] Iteration 6100, loss = 0.204459
I0227 06:02:30.024286 20800 solver.cpp:245]     Train net output #0: accuracy = 0.905711
I0227 06:02:30.024294 20800 solver.cpp:245]     Train net output #1: accuracy = 0.722501
I0227 06:02:30.024302 20800 solver.cpp:245]     Train net output #2: accuracy = 0.820574
I0227 06:02:30.024310 20800 sgd_solver.cpp:106] Iteration 6100, lr = 0.000720753
I0227 06:02:47.299760 20800 solver.cpp:229] Iteration 6120, loss = 0.194802
I0227 06:02:47.299805 20800 solver.cpp:245]     Train net output #0: accuracy = 0.922844
I0227 06:02:47.299814 20800 solver.cpp:245]     Train net output #1: accuracy = 0.891409
I0227 06:02:47.299821 20800 solver.cpp:245]     Train net output #2: accuracy = 0.874183
I0227 06:02:47.299831 20800 sgd_solver.cpp:106] Iteration 6120, lr = 0.000719819
I0227 06:03:04.579855 20800 solver.cpp:229] Iteration 6140, loss = 0.180547
I0227 06:03:04.579885 20800 solver.cpp:245]     Train net output #0: accuracy = 0.925996
I0227 06:03:04.579895 20800 solver.cpp:245]     Train net output #1: accuracy = 0.601142
I0227 06:03:04.579901 20800 solver.cpp:245]     Train net output #2: accuracy = 0.548786
I0227 06:03:04.579911 20800 sgd_solver.cpp:106] Iteration 6140, lr = 0.000718886
I0227 06:03:21.855288 20800 solver.cpp:229] Iteration 6160, loss = 0.18527
I0227 06:03:21.855317 20800 solver.cpp:245]     Train net output #0: accuracy = 0.916895
I0227 06:03:21.855326 20800 solver.cpp:245]     Train net output #1: accuracy = 0.777216
I0227 06:03:21.855334 20800 solver.cpp:245]     Train net output #2: accuracy = 0.680494
I0227 06:03:21.855342 20800 sgd_solver.cpp:106] Iteration 6160, lr = 0.000717952
I0227 06:03:39.112855 20800 solver.cpp:229] Iteration 6180, loss = 0.182699
I0227 06:03:39.112884 20800 solver.cpp:245]     Train net output #0: accuracy = 0.930305
I0227 06:03:39.112892 20800 solver.cpp:245]     Train net output #1: accuracy = 0.780616
I0227 06:03:39.112898 20800 solver.cpp:245]     Train net output #2: accuracy = 0.654125
I0227 06:03:39.112907 20800 sgd_solver.cpp:106] Iteration 6180, lr = 0.000717018
I0227 06:03:56.382586 20800 solver.cpp:229] Iteration 6200, loss = 0.192088
I0227 06:03:56.382616 20800 solver.cpp:245]     Train net output #0: accuracy = 0.934682
I0227 06:03:56.382624 20800 solver.cpp:245]     Train net output #1: accuracy = 0.712725
I0227 06:03:56.382632 20800 solver.cpp:245]     Train net output #2: accuracy = 0.690478
I0227 06:03:56.382640 20800 sgd_solver.cpp:106] Iteration 6200, lr = 0.000716084
I0227 06:04:13.664836 20800 solver.cpp:229] Iteration 6220, loss = 0.18504
I0227 06:04:13.664881 20800 solver.cpp:245]     Train net output #0: accuracy = 0.944046
I0227 06:04:13.664891 20800 solver.cpp:245]     Train net output #1: accuracy = 0.686923
I0227 06:04:13.664897 20800 solver.cpp:245]     Train net output #2: accuracy = 0.760959
I0227 06:04:13.664906 20800 sgd_solver.cpp:106] Iteration 6220, lr = 0.00071515
I0227 06:04:30.926095 20800 solver.cpp:229] Iteration 6240, loss = 0.181363
I0227 06:04:30.926123 20800 solver.cpp:245]     Train net output #0: accuracy = 0.951482
I0227 06:04:30.926131 20800 solver.cpp:245]     Train net output #1: accuracy = 0.819384
I0227 06:04:30.926138 20800 solver.cpp:245]     Train net output #2: accuracy = 0.747398
I0227 06:04:30.926147 20800 sgd_solver.cpp:106] Iteration 6240, lr = 0.000714216
I0227 06:04:48.212967 20800 solver.cpp:229] Iteration 6260, loss = 0.1774
I0227 06:04:48.212998 20800 solver.cpp:245]     Train net output #0: accuracy = 0.912195
I0227 06:04:48.213008 20800 solver.cpp:245]     Train net output #1: accuracy = 0.544065
I0227 06:04:48.213016 20800 solver.cpp:245]     Train net output #2: accuracy = 0.64463
I0227 06:04:48.213026 20800 sgd_solver.cpp:106] Iteration 6260, lr = 0.000713282
I0227 06:05:05.493077 20800 solver.cpp:229] Iteration 6280, loss = 0.182196
I0227 06:05:05.493119 20800 solver.cpp:245]     Train net output #0: accuracy = 0.904267
I0227 06:05:05.493136 20800 solver.cpp:245]     Train net output #1: accuracy = 0.757382
I0227 06:05:05.493149 20800 solver.cpp:245]     Train net output #2: accuracy = 0.625609
I0227 06:05:05.493165 20800 sgd_solver.cpp:106] Iteration 6280, lr = 0.000712347
I0227 06:05:22.773257 20800 solver.cpp:229] Iteration 6300, loss = 0.1784
I0227 06:05:22.773301 20800 solver.cpp:245]     Train net output #0: accuracy = 0.925104
I0227 06:05:22.773310 20800 solver.cpp:245]     Train net output #1: accuracy = 0.737126
I0227 06:05:22.773317 20800 solver.cpp:245]     Train net output #2: accuracy = 0.661223
I0227 06:05:22.773326 20800 sgd_solver.cpp:106] Iteration 6300, lr = 0.000711413
I0227 06:05:40.055447 20800 solver.cpp:229] Iteration 6320, loss = 0.182765
I0227 06:05:40.055477 20800 solver.cpp:245]     Train net output #0: accuracy = 0.911938
I0227 06:05:40.055486 20800 solver.cpp:245]     Train net output #1: accuracy = 0.683298
I0227 06:05:40.055493 20800 solver.cpp:245]     Train net output #2: accuracy = 0.653094
I0227 06:05:40.055503 20800 sgd_solver.cpp:106] Iteration 6320, lr = 0.000710478
I0227 06:05:57.331706 20800 solver.cpp:229] Iteration 6340, loss = 0.183572
I0227 06:05:57.331737 20800 solver.cpp:245]     Train net output #0: accuracy = 0.929447
I0227 06:05:57.331745 20800 solver.cpp:245]     Train net output #1: accuracy = 0.76865
I0227 06:05:57.331753 20800 solver.cpp:245]     Train net output #2: accuracy = 0.821645
I0227 06:05:57.331761 20800 sgd_solver.cpp:106] Iteration 6340, lr = 0.000709543
I0227 06:06:14.608496 20800 solver.cpp:229] Iteration 6360, loss = 0.166543
I0227 06:06:14.608526 20800 solver.cpp:245]     Train net output #0: accuracy = 0.944676
I0227 06:06:14.608536 20800 solver.cpp:245]     Train net output #1: accuracy = 0.768523
I0227 06:06:14.608543 20800 solver.cpp:245]     Train net output #2: accuracy = 0.785063
I0227 06:06:14.608552 20800 sgd_solver.cpp:106] Iteration 6360, lr = 0.000708608
I0227 06:06:31.875474 20800 solver.cpp:229] Iteration 6380, loss = 0.170178
I0227 06:06:31.875504 20800 solver.cpp:245]     Train net output #0: accuracy = 0.949182
I0227 06:06:31.875514 20800 solver.cpp:245]     Train net output #1: accuracy = 0.823327
I0227 06:06:31.875521 20800 solver.cpp:245]     Train net output #2: accuracy = 0.788311
I0227 06:06:31.875530 20800 sgd_solver.cpp:106] Iteration 6380, lr = 0.000707673
I0227 06:06:49.152873 20800 solver.cpp:229] Iteration 6400, loss = 0.151153
I0227 06:06:49.152902 20800 solver.cpp:245]     Train net output #0: accuracy = 0.921773
I0227 06:06:49.152911 20800 solver.cpp:245]     Train net output #1: accuracy = 0.89099
I0227 06:06:49.152920 20800 solver.cpp:245]     Train net output #2: accuracy = 0.833474
I0227 06:06:49.152928 20800 sgd_solver.cpp:106] Iteration 6400, lr = 0.000706737
I0227 06:07:06.452742 20800 solver.cpp:229] Iteration 6420, loss = 0.175957
I0227 06:07:06.452786 20800 solver.cpp:245]     Train net output #0: accuracy = 0.904288
I0227 06:07:06.452795 20800 solver.cpp:245]     Train net output #1: accuracy = 0.890573
I0227 06:07:06.452802 20800 solver.cpp:245]     Train net output #2: accuracy = 0.753136
I0227 06:07:06.452812 20800 sgd_solver.cpp:106] Iteration 6420, lr = 0.000705802
I0227 06:07:23.703153 20800 solver.cpp:229] Iteration 6440, loss = 0.170446
I0227 06:07:23.703198 20800 solver.cpp:245]     Train net output #0: accuracy = 0.942749
I0227 06:07:23.703207 20800 solver.cpp:245]     Train net output #1: accuracy = 0.6919
I0227 06:07:23.703214 20800 solver.cpp:245]     Train net output #2: accuracy = 0.777175
I0227 06:07:23.703224 20800 sgd_solver.cpp:106] Iteration 6440, lr = 0.000704866
I0227 06:07:40.967172 20800 solver.cpp:229] Iteration 6460, loss = 0.158885
I0227 06:07:40.967203 20800 solver.cpp:245]     Train net output #0: accuracy = 0.942356
I0227 06:07:40.967212 20800 solver.cpp:245]     Train net output #1: accuracy = 0.875562
I0227 06:07:40.967219 20800 solver.cpp:245]     Train net output #2: accuracy = 0.84613
I0227 06:07:40.967229 20800 sgd_solver.cpp:106] Iteration 6460, lr = 0.000703931
I0227 06:07:58.242709 20800 solver.cpp:229] Iteration 6480, loss = 0.173522
I0227 06:07:58.242755 20800 solver.cpp:245]     Train net output #0: accuracy = 0.932698
I0227 06:07:58.242764 20800 solver.cpp:245]     Train net output #1: accuracy = 0.764572
I0227 06:07:58.242771 20800 solver.cpp:245]     Train net output #2: accuracy = 0.813889
I0227 06:07:58.242780 20800 sgd_solver.cpp:106] Iteration 6480, lr = 0.000702995
I0227 06:08:15.510723 20800 solver.cpp:229] Iteration 6500, loss = 0.179155
I0227 06:08:15.510751 20800 solver.cpp:245]     Train net output #0: accuracy = 0.957644
I0227 06:08:15.510759 20800 solver.cpp:245]     Train net output #1: accuracy = 0.916105
I0227 06:08:15.510766 20800 solver.cpp:245]     Train net output #2: accuracy = 0.96864
I0227 06:08:15.510774 20800 sgd_solver.cpp:106] Iteration 6500, lr = 0.000702059
I0227 06:08:32.793452 20800 solver.cpp:229] Iteration 6520, loss = 0.17927
I0227 06:08:32.793494 20800 solver.cpp:245]     Train net output #0: accuracy = 0.895272
I0227 06:08:32.793503 20800 solver.cpp:245]     Train net output #1: accuracy = 0.651533
I0227 06:08:32.793510 20800 solver.cpp:245]     Train net output #2: accuracy = 0.476491
I0227 06:08:32.793520 20800 sgd_solver.cpp:106] Iteration 6520, lr = 0.000701123
I0227 06:08:50.056964 20800 solver.cpp:229] Iteration 6540, loss = 0.187816
I0227 06:08:50.057008 20800 solver.cpp:245]     Train net output #0: accuracy = 0.950446
I0227 06:08:50.057016 20800 solver.cpp:245]     Train net output #1: accuracy = 0.854137
I0227 06:08:50.057024 20800 solver.cpp:245]     Train net output #2: accuracy = 0.860561
I0227 06:08:50.057034 20800 sgd_solver.cpp:106] Iteration 6540, lr = 0.000700186
I0227 06:09:07.321199 20800 solver.cpp:229] Iteration 6560, loss = 0.185681
I0227 06:09:07.321228 20800 solver.cpp:245]     Train net output #0: accuracy = 0.936942
I0227 06:09:07.321254 20800 solver.cpp:245]     Train net output #1: accuracy = 0.803447
I0227 06:09:07.321260 20800 solver.cpp:245]     Train net output #2: accuracy = 0.697413
I0227 06:09:07.321270 20800 sgd_solver.cpp:106] Iteration 6560, lr = 0.00069925
I0227 06:09:24.626310 20800 solver.cpp:229] Iteration 6580, loss = 0.169291
I0227 06:09:24.626353 20800 solver.cpp:245]     Train net output #0: accuracy = 0.961946
I0227 06:09:24.626361 20800 solver.cpp:245]     Train net output #1: accuracy = 0.782495
I0227 06:09:24.626368 20800 solver.cpp:245]     Train net output #2: accuracy = 0.78813
I0227 06:09:24.626377 20800 sgd_solver.cpp:106] Iteration 6580, lr = 0.000698313
I0227 06:09:41.875412 20800 solver.cpp:229] Iteration 6600, loss = 0.162575
I0227 06:09:41.875460 20800 solver.cpp:245]     Train net output #0: accuracy = 0.934959
I0227 06:09:41.875469 20800 solver.cpp:245]     Train net output #1: accuracy = 0.651296
I0227 06:09:41.875476 20800 solver.cpp:245]     Train net output #2: accuracy = 0.690578
I0227 06:09:41.875485 20800 sgd_solver.cpp:106] Iteration 6600, lr = 0.000697376
I0227 06:09:59.155854 20800 solver.cpp:229] Iteration 6620, loss = 0.162102
I0227 06:09:59.155897 20800 solver.cpp:245]     Train net output #0: accuracy = 0.911362
I0227 06:09:59.155907 20800 solver.cpp:245]     Train net output #1: accuracy = 0.822984
I0227 06:09:59.155913 20800 solver.cpp:245]     Train net output #2: accuracy = 0.849631
I0227 06:09:59.155923 20800 sgd_solver.cpp:106] Iteration 6620, lr = 0.00069644
I0227 06:10:16.429123 20800 solver.cpp:229] Iteration 6640, loss = 0.166665
I0227 06:10:16.429153 20800 solver.cpp:245]     Train net output #0: accuracy = 0.950446
I0227 06:10:16.429162 20800 solver.cpp:245]     Train net output #1: accuracy = 0.770607
I0227 06:10:16.429169 20800 solver.cpp:245]     Train net output #2: accuracy = 0.821088
I0227 06:10:16.429179 20800 sgd_solver.cpp:106] Iteration 6640, lr = 0.000695503
I0227 06:10:33.710211 20800 solver.cpp:229] Iteration 6660, loss = 0.171144
I0227 06:10:33.710255 20800 solver.cpp:245]     Train net output #0: accuracy = 0.933515
I0227 06:10:33.710264 20800 solver.cpp:245]     Train net output #1: accuracy = 0.474424
I0227 06:10:33.710271 20800 solver.cpp:245]     Train net output #2: accuracy = 0.594347
I0227 06:10:33.710280 20800 sgd_solver.cpp:106] Iteration 6660, lr = 0.000694566
I0227 06:10:50.972497 20800 solver.cpp:229] Iteration 6680, loss = 0.158129
I0227 06:10:50.972543 20800 solver.cpp:245]     Train net output #0: accuracy = 0.934513
I0227 06:10:50.972550 20800 solver.cpp:245]     Train net output #1: accuracy = 0.698831
I0227 06:10:50.972558 20800 solver.cpp:245]     Train net output #2: accuracy = 0.704827
I0227 06:10:50.972568 20800 sgd_solver.cpp:106] Iteration 6680, lr = 0.000693628
I0227 06:11:08.226784 20800 solver.cpp:229] Iteration 6700, loss = 0.159086
I0227 06:11:08.226814 20800 solver.cpp:245]     Train net output #0: accuracy = 0.940214
I0227 06:11:08.226822 20800 solver.cpp:245]     Train net output #1: accuracy = 0.901264
I0227 06:11:08.226830 20800 solver.cpp:245]     Train net output #2: accuracy = 0.867197
I0227 06:11:08.226838 20800 sgd_solver.cpp:106] Iteration 6700, lr = 0.000692691
I0227 06:11:25.493007 20800 solver.cpp:229] Iteration 6720, loss = 0.159957
I0227 06:11:25.493036 20800 solver.cpp:245]     Train net output #0: accuracy = 0.933076
I0227 06:11:25.493046 20800 solver.cpp:245]     Train net output #1: accuracy = 0.920988
I0227 06:11:25.493052 20800 solver.cpp:245]     Train net output #2: accuracy = 0.840699
I0227 06:11:25.493062 20800 sgd_solver.cpp:106] Iteration 6720, lr = 0.000691753
I0227 06:11:42.753908 20800 solver.cpp:229] Iteration 6740, loss = 0.168476
I0227 06:11:42.753952 20800 solver.cpp:245]     Train net output #0: accuracy = 0.950206
I0227 06:11:42.753960 20800 solver.cpp:245]     Train net output #1: accuracy = 0.784131
I0227 06:11:42.753968 20800 solver.cpp:245]     Train net output #2: accuracy = 0.767968
I0227 06:11:42.753976 20800 sgd_solver.cpp:106] Iteration 6740, lr = 0.000690816
I0227 06:12:00.018146 20800 solver.cpp:229] Iteration 6760, loss = 0.19094
I0227 06:12:00.018190 20800 solver.cpp:245]     Train net output #0: accuracy = 0.925164
I0227 06:12:00.018200 20800 solver.cpp:245]     Train net output #1: accuracy = 0.893683
I0227 06:12:00.018223 20800 solver.cpp:245]     Train net output #2: accuracy = 0.883547
I0227 06:12:00.018232 20800 sgd_solver.cpp:106] Iteration 6760, lr = 0.000689878
I0227 06:12:17.258450 20800 solver.cpp:229] Iteration 6780, loss = 0.173635
I0227 06:12:17.258499 20800 solver.cpp:245]     Train net output #0: accuracy = 0.944735
I0227 06:12:17.258508 20800 solver.cpp:245]     Train net output #1: accuracy = 0.824334
I0227 06:12:17.258515 20800 solver.cpp:245]     Train net output #2: accuracy = 0.839233
I0227 06:12:17.258527 20800 sgd_solver.cpp:106] Iteration 6780, lr = 0.00068894
I0227 06:12:34.527431 20800 solver.cpp:229] Iteration 6800, loss = 0.16751
I0227 06:12:34.527477 20800 solver.cpp:245]     Train net output #0: accuracy = 0.936443
I0227 06:12:34.527485 20800 solver.cpp:245]     Train net output #1: accuracy = 0.638646
I0227 06:12:34.527493 20800 solver.cpp:245]     Train net output #2: accuracy = 0.678205
I0227 06:12:34.527501 20800 sgd_solver.cpp:106] Iteration 6800, lr = 0.000688002
I0227 06:12:51.822026 20800 solver.cpp:229] Iteration 6820, loss = 0.173373
I0227 06:12:51.822070 20800 solver.cpp:245]     Train net output #0: accuracy = 0.936513
I0227 06:12:51.822079 20800 solver.cpp:245]     Train net output #1: accuracy = 0.876894
I0227 06:12:51.822085 20800 solver.cpp:245]     Train net output #2: accuracy = 0.783009
I0227 06:12:51.822095 20800 sgd_solver.cpp:106] Iteration 6820, lr = 0.000687064
I0227 06:13:09.073227 20800 solver.cpp:229] Iteration 6840, loss = 0.153617
I0227 06:13:09.073256 20800 solver.cpp:245]     Train net output #0: accuracy = 0.943171
I0227 06:13:09.073278 20800 solver.cpp:245]     Train net output #1: accuracy = 0.714264
I0227 06:13:09.073285 20800 solver.cpp:245]     Train net output #2: accuracy = 0.73523
I0227 06:13:09.073294 20800 sgd_solver.cpp:106] Iteration 6840, lr = 0.000686125
I0227 06:13:26.337760 20800 solver.cpp:229] Iteration 6860, loss = 0.174232
I0227 06:13:26.337791 20800 solver.cpp:245]     Train net output #0: accuracy = 0.900255
I0227 06:13:26.337800 20800 solver.cpp:245]     Train net output #1: accuracy = 0.791532
I0227 06:13:26.337807 20800 solver.cpp:245]     Train net output #2: accuracy = 0.714194
I0227 06:13:26.337816 20800 sgd_solver.cpp:106] Iteration 6860, lr = 0.000685187
I0227 06:13:43.604868 20800 solver.cpp:229] Iteration 6880, loss = 0.177502
I0227 06:13:43.604898 20800 solver.cpp:245]     Train net output #0: accuracy = 0.932791
I0227 06:13:43.604907 20800 solver.cpp:245]     Train net output #1: accuracy = 0.606898
I0227 06:13:43.604914 20800 solver.cpp:245]     Train net output #2: accuracy = 0.650419
I0227 06:13:43.604924 20800 sgd_solver.cpp:106] Iteration 6880, lr = 0.000684248
I0227 06:14:00.874639 20800 solver.cpp:229] Iteration 6900, loss = 0.171163
I0227 06:14:00.874684 20800 solver.cpp:245]     Train net output #0: accuracy = 0.944021
I0227 06:14:00.874693 20800 solver.cpp:245]     Train net output #1: accuracy = 0.897575
I0227 06:14:00.874701 20800 solver.cpp:245]     Train net output #2: accuracy = 0.820049
I0227 06:14:00.874711 20800 sgd_solver.cpp:106] Iteration 6900, lr = 0.000683309
I0227 06:14:18.138787 20800 solver.cpp:229] Iteration 6920, loss = 0.176795
I0227 06:14:18.138849 20800 solver.cpp:245]     Train net output #0: accuracy = 0.942698
I0227 06:14:18.138859 20800 solver.cpp:245]     Train net output #1: accuracy = 0.694187
I0227 06:14:18.138865 20800 solver.cpp:245]     Train net output #2: accuracy = 0.697602
I0227 06:14:18.138887 20800 sgd_solver.cpp:106] Iteration 6920, lr = 0.00068237
I0227 06:14:35.415586 20800 solver.cpp:229] Iteration 6940, loss = 0.164965
I0227 06:14:35.415632 20800 solver.cpp:245]     Train net output #0: accuracy = 0.940036
I0227 06:14:35.415642 20800 solver.cpp:245]     Train net output #1: accuracy = 0.878665
I0227 06:14:35.415648 20800 solver.cpp:245]     Train net output #2: accuracy = 0.791337
I0227 06:14:35.415657 20800 sgd_solver.cpp:106] Iteration 6940, lr = 0.000681431
I0227 06:14:52.678920 20800 solver.cpp:229] Iteration 6960, loss = 0.173259
I0227 06:14:52.678948 20800 solver.cpp:245]     Train net output #0: accuracy = 0.938786
I0227 06:14:52.678957 20800 solver.cpp:245]     Train net output #1: accuracy = 0.861616
I0227 06:14:52.678964 20800 solver.cpp:245]     Train net output #2: accuracy = 0.876413
I0227 06:14:52.678974 20800 sgd_solver.cpp:106] Iteration 6960, lr = 0.000680492
I0227 06:15:09.941926 20800 solver.cpp:229] Iteration 6980, loss = 0.164811
I0227 06:15:09.941972 20800 solver.cpp:245]     Train net output #0: accuracy = 0.935812
I0227 06:15:09.941980 20800 solver.cpp:245]     Train net output #1: accuracy = 0.852465
I0227 06:15:09.941987 20800 solver.cpp:245]     Train net output #2: accuracy = 0.892553
I0227 06:15:09.941998 20800 sgd_solver.cpp:106] Iteration 6980, lr = 0.000679552
I0227 06:15:27.213843 20800 solver.cpp:229] Iteration 7000, loss = 0.166873
I0227 06:15:27.213889 20800 solver.cpp:245]     Train net output #0: accuracy = 0.930049
I0227 06:15:27.213898 20800 solver.cpp:245]     Train net output #1: accuracy = 0.789029
I0227 06:15:27.213905 20800 solver.cpp:245]     Train net output #2: accuracy = 0.793349
I0227 06:15:27.213915 20800 sgd_solver.cpp:106] Iteration 7000, lr = 0.000678613
I0227 06:15:44.471804 20800 solver.cpp:229] Iteration 7020, loss = 0.162951
I0227 06:15:44.471849 20800 solver.cpp:245]     Train net output #0: accuracy = 0.957855
I0227 06:15:44.471858 20800 solver.cpp:245]     Train net output #1: accuracy = 0.927511
I0227 06:15:44.471865 20800 solver.cpp:245]     Train net output #2: accuracy = 0.807332
I0227 06:15:44.471884 20800 sgd_solver.cpp:106] Iteration 7020, lr = 0.000677673
I0227 06:16:01.726322 20800 solver.cpp:229] Iteration 7040, loss = 0.175634
I0227 06:16:01.726367 20800 solver.cpp:245]     Train net output #0: accuracy = 0.929052
I0227 06:16:01.726377 20800 solver.cpp:245]     Train net output #1: accuracy = 0.833555
I0227 06:16:01.726384 20800 solver.cpp:245]     Train net output #2: accuracy = 0.742633
I0227 06:16:01.726393 20800 sgd_solver.cpp:106] Iteration 7040, lr = 0.000676733
I0227 06:16:18.992727 20800 solver.cpp:229] Iteration 7060, loss = 0.169019
I0227 06:16:18.992772 20800 solver.cpp:245]     Train net output #0: accuracy = 0.923016
I0227 06:16:18.992782 20800 solver.cpp:245]     Train net output #1: accuracy = 0.680994
I0227 06:16:18.992789 20800 solver.cpp:245]     Train net output #2: accuracy = 0.711062
I0227 06:16:18.992799 20800 sgd_solver.cpp:106] Iteration 7060, lr = 0.000675793
I0227 06:16:36.263710 20800 solver.cpp:229] Iteration 7080, loss = 0.167543
I0227 06:16:36.263753 20800 solver.cpp:245]     Train net output #0: accuracy = 0.947531
I0227 06:16:36.263761 20800 solver.cpp:245]     Train net output #1: accuracy = 0.713253
I0227 06:16:36.263768 20800 solver.cpp:245]     Train net output #2: accuracy = 0.824077
I0227 06:16:36.263777 20800 sgd_solver.cpp:106] Iteration 7080, lr = 0.000674853
I0227 06:16:53.532016 20800 solver.cpp:229] Iteration 7100, loss = 0.15886
I0227 06:16:53.532044 20800 solver.cpp:245]     Train net output #0: accuracy = 0.916538
I0227 06:16:53.532052 20800 solver.cpp:245]     Train net output #1: accuracy = 0.689809
I0227 06:16:53.532059 20800 solver.cpp:245]     Train net output #2: accuracy = 0.786985
I0227 06:16:53.532068 20800 sgd_solver.cpp:106] Iteration 7100, lr = 0.000673913
I0227 06:17:10.807785 20800 solver.cpp:229] Iteration 7120, loss = 0.171899
I0227 06:17:10.807814 20800 solver.cpp:245]     Train net output #0: accuracy = 0.919155
I0227 06:17:10.807823 20800 solver.cpp:245]     Train net output #1: accuracy = 0.807982
I0227 06:17:10.807831 20800 solver.cpp:245]     Train net output #2: accuracy = 0.825816
I0227 06:17:10.807839 20800 sgd_solver.cpp:106] Iteration 7120, lr = 0.000672972
I0227 06:17:28.080839 20800 solver.cpp:229] Iteration 7140, loss = 0.181468
I0227 06:17:28.080883 20800 solver.cpp:245]     Train net output #0: accuracy = 0.919453
I0227 06:17:28.080893 20800 solver.cpp:245]     Train net output #1: accuracy = 0.77099
I0227 06:17:28.080899 20800 solver.cpp:245]     Train net output #2: accuracy = 0.793582
I0227 06:17:28.080909 20800 sgd_solver.cpp:106] Iteration 7140, lr = 0.000672032
I0227 06:17:45.368578 20800 solver.cpp:229] Iteration 7160, loss = 0.165553
I0227 06:17:45.368608 20800 solver.cpp:245]     Train net output #0: accuracy = 0.913838
I0227 06:17:45.368616 20800 solver.cpp:245]     Train net output #1: accuracy = 0.809755
I0227 06:17:45.368623 20800 solver.cpp:245]     Train net output #2: accuracy = 0.877341
I0227 06:17:45.368633 20800 sgd_solver.cpp:106] Iteration 7160, lr = 0.000671091
I0227 06:18:02.660262 20800 solver.cpp:229] Iteration 7180, loss = 0.176486
I0227 06:18:02.660293 20800 solver.cpp:245]     Train net output #0: accuracy = 0.930815
I0227 06:18:02.660302 20800 solver.cpp:245]     Train net output #1: accuracy = 0.934475
I0227 06:18:02.660310 20800 solver.cpp:245]     Train net output #2: accuracy = 0.721484
I0227 06:18:02.660318 20800 sgd_solver.cpp:106] Iteration 7180, lr = 0.00067015
I0227 06:18:19.954466 20800 solver.cpp:229] Iteration 7200, loss = 0.176775
I0227 06:18:19.954511 20800 solver.cpp:245]     Train net output #0: accuracy = 0.95693
I0227 06:18:19.954521 20800 solver.cpp:245]     Train net output #1: accuracy = 0.790304
I0227 06:18:19.954529 20800 solver.cpp:245]     Train net output #2: accuracy = 0.767322
I0227 06:18:19.954540 20800 sgd_solver.cpp:106] Iteration 7200, lr = 0.000669209
I0227 06:18:37.225798 20800 solver.cpp:229] Iteration 7220, loss = 0.168362
I0227 06:18:37.225844 20800 solver.cpp:245]     Train net output #0: accuracy = 0.960761
I0227 06:18:37.225853 20800 solver.cpp:245]     Train net output #1: accuracy = 0.950573
I0227 06:18:37.225859 20800 solver.cpp:245]     Train net output #2: accuracy = 0.794301
I0227 06:18:37.225869 20800 sgd_solver.cpp:106] Iteration 7220, lr = 0.000668268
I0227 06:18:54.484041 20800 solver.cpp:229] Iteration 7240, loss = 0.168941
I0227 06:18:54.484088 20800 solver.cpp:245]     Train net output #0: accuracy = 0.953359
I0227 06:18:54.484098 20800 solver.cpp:245]     Train net output #1: accuracy = 0.81041
I0227 06:18:54.484105 20800 solver.cpp:245]     Train net output #2: accuracy = 0.86375
I0227 06:18:54.484115 20800 sgd_solver.cpp:106] Iteration 7240, lr = 0.000667327
I0227 06:19:11.753687 20800 solver.cpp:229] Iteration 7260, loss = 0.182333
I0227 06:19:11.753733 20800 solver.cpp:245]     Train net output #0: accuracy = 0.91204
I0227 06:19:11.753742 20800 solver.cpp:245]     Train net output #1: accuracy = 0.690021
I0227 06:19:11.753749 20800 solver.cpp:245]     Train net output #2: accuracy = 0.630276
I0227 06:19:11.753759 20800 sgd_solver.cpp:106] Iteration 7260, lr = 0.000666385
I0227 06:19:29.026660 20800 solver.cpp:229] Iteration 7280, loss = 0.178312
I0227 06:19:29.026706 20800 solver.cpp:245]     Train net output #0: accuracy = 0.922416
I0227 06:19:29.026715 20800 solver.cpp:245]     Train net output #1: accuracy = 0.812987
I0227 06:19:29.026722 20800 solver.cpp:245]     Train net output #2: accuracy = 0.842628
I0227 06:19:29.026732 20800 sgd_solver.cpp:106] Iteration 7280, lr = 0.000665444
I0227 06:19:46.287093 20800 solver.cpp:229] Iteration 7300, loss = 0.159603
I0227 06:19:46.287125 20800 solver.cpp:245]     Train net output #0: accuracy = 0.95116
I0227 06:19:46.287134 20800 solver.cpp:245]     Train net output #1: accuracy = 0.680085
I0227 06:19:46.287142 20800 solver.cpp:245]     Train net output #2: accuracy = 0.65521
I0227 06:19:46.287151 20800 sgd_solver.cpp:106] Iteration 7300, lr = 0.000664502
I0227 06:20:03.547361 20800 solver.cpp:229] Iteration 7320, loss = 0.164373
I0227 06:20:03.547390 20800 solver.cpp:245]     Train net output #0: accuracy = 0.963146
I0227 06:20:03.547399 20800 solver.cpp:245]     Train net output #1: accuracy = 0.748627
I0227 06:20:03.547405 20800 solver.cpp:245]     Train net output #2: accuracy = 0.880809
I0227 06:20:03.547413 20800 sgd_solver.cpp:106] Iteration 7320, lr = 0.00066356
I0227 06:20:20.819671 20800 solver.cpp:229] Iteration 7340, loss = 0.16448
I0227 06:20:20.819717 20800 solver.cpp:245]     Train net output #0: accuracy = 0.938608
I0227 06:20:20.819726 20800 solver.cpp:245]     Train net output #1: accuracy = 0.77805
I0227 06:20:20.819733 20800 solver.cpp:245]     Train net output #2: accuracy = 0.866667
I0227 06:20:20.819742 20800 sgd_solver.cpp:106] Iteration 7340, lr = 0.000662618
I0227 06:20:38.104462 20800 solver.cpp:229] Iteration 7360, loss = 0.168681
I0227 06:20:38.104496 20800 solver.cpp:245]     Train net output #0: accuracy = 0.94321
I0227 06:20:38.104504 20800 solver.cpp:245]     Train net output #1: accuracy = 0.75649
I0227 06:20:38.104511 20800 solver.cpp:245]     Train net output #2: accuracy = 0.835126
I0227 06:20:38.104521 20800 sgd_solver.cpp:106] Iteration 7360, lr = 0.000661676
I0227 06:20:55.382364 20800 solver.cpp:229] Iteration 7380, loss = 0.162622
I0227 06:20:55.382391 20800 solver.cpp:245]     Train net output #0: accuracy = 0.961238
I0227 06:20:55.382400 20800 solver.cpp:245]     Train net output #1: accuracy = 0.834023
I0227 06:20:55.382406 20800 solver.cpp:245]     Train net output #2: accuracy = 0.908293
I0227 06:20:55.382416 20800 sgd_solver.cpp:106] Iteration 7380, lr = 0.000660734
I0227 06:21:12.652810 20800 solver.cpp:229] Iteration 7400, loss = 0.173718
I0227 06:21:12.652853 20800 solver.cpp:245]     Train net output #0: accuracy = 0.940259
I0227 06:21:12.652863 20800 solver.cpp:245]     Train net output #1: accuracy = 0.905801
I0227 06:21:12.652868 20800 solver.cpp:245]     Train net output #2: accuracy = 0.788983
I0227 06:21:12.652878 20800 sgd_solver.cpp:106] Iteration 7400, lr = 0.000659791
I0227 06:21:29.905122 20800 solver.cpp:229] Iteration 7420, loss = 0.169049
I0227 06:21:29.905153 20800 solver.cpp:245]     Train net output #0: accuracy = 0.910295
I0227 06:21:29.905164 20800 solver.cpp:245]     Train net output #1: accuracy = 0.898224
I0227 06:21:29.905170 20800 solver.cpp:245]     Train net output #2: accuracy = 0.726663
I0227 06:21:29.905179 20800 sgd_solver.cpp:106] Iteration 7420, lr = 0.000658849
I0227 06:21:47.167896 20800 solver.cpp:229] Iteration 7440, loss = 0.149601
I0227 06:21:47.167927 20800 solver.cpp:245]     Train net output #0: accuracy = 0.915572
I0227 06:21:47.167937 20800 solver.cpp:245]     Train net output #1: accuracy = 0.82601
I0227 06:21:47.167943 20800 solver.cpp:245]     Train net output #2: accuracy = 0.82956
I0227 06:21:47.167953 20800 sgd_solver.cpp:106] Iteration 7440, lr = 0.000657906
I0227 06:22:04.424139 20800 solver.cpp:229] Iteration 7460, loss = 0.155259
I0227 06:22:04.424183 20800 solver.cpp:245]     Train net output #0: accuracy = 0.954432
I0227 06:22:04.424191 20800 solver.cpp:245]     Train net output #1: accuracy = 0.824032
I0227 06:22:04.424198 20800 solver.cpp:245]     Train net output #2: accuracy = 0.894454
I0227 06:22:04.424207 20800 sgd_solver.cpp:106] Iteration 7460, lr = 0.000656963
I0227 06:22:21.680665 20800 solver.cpp:229] Iteration 7480, loss = 0.152895
I0227 06:22:21.680708 20800 solver.cpp:245]     Train net output #0: accuracy = 0.957529
I0227 06:22:21.680717 20800 solver.cpp:245]     Train net output #1: accuracy = 0.693984
I0227 06:22:21.680724 20800 solver.cpp:245]     Train net output #2: accuracy = 0.767819
I0227 06:22:21.680734 20800 sgd_solver.cpp:106] Iteration 7480, lr = 0.00065602
I0227 06:22:38.943066 20800 solver.cpp:229] Iteration 7500, loss = 0.154687
I0227 06:22:38.943097 20800 solver.cpp:245]     Train net output #0: accuracy = 0.950261
I0227 06:22:38.943106 20800 solver.cpp:245]     Train net output #1: accuracy = 0.774552
I0227 06:22:38.943114 20800 solver.cpp:245]     Train net output #2: accuracy = 0.742108
I0227 06:22:38.943123 20800 sgd_solver.cpp:106] Iteration 7500, lr = 0.000655077
I0227 06:22:56.199594 20800 solver.cpp:229] Iteration 7520, loss = 0.14905
I0227 06:22:56.199640 20800 solver.cpp:245]     Train net output #0: accuracy = 0.930458
I0227 06:22:56.199651 20800 solver.cpp:245]     Train net output #1: accuracy = 0.685975
I0227 06:22:56.199657 20800 solver.cpp:245]     Train net output #2: accuracy = 0.692557
I0227 06:22:56.199666 20800 sgd_solver.cpp:106] Iteration 7520, lr = 0.000654133
I0227 06:23:13.474537 20800 solver.cpp:229] Iteration 7540, loss = 0.155382
I0227 06:23:13.474567 20800 solver.cpp:245]     Train net output #0: accuracy = 0.930696
I0227 06:23:13.474576 20800 solver.cpp:245]     Train net output #1: accuracy = 0.80004
I0227 06:23:13.474583 20800 solver.cpp:245]     Train net output #2: accuracy = 0.797801
I0227 06:23:13.474592 20800 sgd_solver.cpp:106] Iteration 7540, lr = 0.00065319
I0227 06:23:30.755983 20800 solver.cpp:229] Iteration 7560, loss = 0.163234
I0227 06:23:30.756031 20800 solver.cpp:245]     Train net output #0: accuracy = 0.947769
I0227 06:23:30.756039 20800 solver.cpp:245]     Train net output #1: accuracy = 0.697032
I0227 06:23:30.756047 20800 solver.cpp:245]     Train net output #2: accuracy = 0.880791
I0227 06:23:30.756057 20800 sgd_solver.cpp:106] Iteration 7560, lr = 0.000652246
I0227 06:23:48.022115 20800 solver.cpp:229] Iteration 7580, loss = 0.170293
I0227 06:23:48.022146 20800 solver.cpp:245]     Train net output #0: accuracy = 0.931112
I0227 06:23:48.022156 20800 solver.cpp:245]     Train net output #1: accuracy = 0.87823
I0227 06:23:48.022162 20800 solver.cpp:245]     Train net output #2: accuracy = 0.916037
I0227 06:23:48.022172 20800 sgd_solver.cpp:106] Iteration 7580, lr = 0.000651302
I0227 06:24:05.268242 20800 solver.cpp:229] Iteration 7600, loss = 0.167889
I0227 06:24:05.268287 20800 solver.cpp:245]     Train net output #0: accuracy = 0.929566
I0227 06:24:05.268296 20800 solver.cpp:245]     Train net output #1: accuracy = 0.720524
I0227 06:24:05.268303 20800 solver.cpp:245]     Train net output #2: accuracy = 0.726821
I0227 06:24:05.268313 20800 sgd_solver.cpp:106] Iteration 7600, lr = 0.000650358
I0227 06:24:22.541561 20800 solver.cpp:229] Iteration 7620, loss = 0.139791
I0227 06:24:22.541592 20800 solver.cpp:245]     Train net output #0: accuracy = 0.947123
I0227 06:24:22.541601 20800 solver.cpp:245]     Train net output #1: accuracy = 0.880513
I0227 06:24:22.541609 20800 solver.cpp:245]     Train net output #2: accuracy = 0.871733
I0227 06:24:22.541620 20800 sgd_solver.cpp:106] Iteration 7620, lr = 0.000649414
I0227 06:24:39.792580 20800 solver.cpp:229] Iteration 7640, loss = 0.151201
I0227 06:24:39.792610 20800 solver.cpp:245]     Train net output #0: accuracy = 0.947701
I0227 06:24:39.792619 20800 solver.cpp:245]     Train net output #1: accuracy = 0.905857
I0227 06:24:39.792626 20800 solver.cpp:245]     Train net output #2: accuracy = 0.8791
I0227 06:24:39.792635 20800 sgd_solver.cpp:106] Iteration 7640, lr = 0.00064847
I0227 06:24:57.040073 20800 solver.cpp:229] Iteration 7660, loss = 0.154973
I0227 06:24:57.040102 20800 solver.cpp:245]     Train net output #0: accuracy = 0.952826
I0227 06:24:57.040110 20800 solver.cpp:245]     Train net output #1: accuracy = 0.809695
I0227 06:24:57.040117 20800 solver.cpp:245]     Train net output #2: accuracy = 0.749509
I0227 06:24:57.040125 20800 sgd_solver.cpp:106] Iteration 7660, lr = 0.000647525
I0227 06:25:14.310628 20800 solver.cpp:229] Iteration 7680, loss = 0.173098
I0227 06:25:14.310681 20800 solver.cpp:245]     Train net output #0: accuracy = 0.938845
I0227 06:25:14.310690 20800 solver.cpp:245]     Train net output #1: accuracy = 0.938889
I0227 06:25:14.310696 20800 solver.cpp:245]     Train net output #2: accuracy = 0.934655
I0227 06:25:14.310706 20800 sgd_solver.cpp:106] Iteration 7680, lr = 0.000646581
I0227 06:25:31.574380 20800 solver.cpp:229] Iteration 7700, loss = 0.168589
I0227 06:25:31.574426 20800 solver.cpp:245]     Train net output #0: accuracy = 0.930399
I0227 06:25:31.574435 20800 solver.cpp:245]     Train net output #1: accuracy = 0.819402
I0227 06:25:31.574443 20800 solver.cpp:245]     Train net output #2: accuracy = 0.823512
I0227 06:25:31.574453 20800 sgd_solver.cpp:106] Iteration 7700, lr = 0.000645636
I0227 06:25:48.842062 20800 solver.cpp:229] Iteration 7720, loss = 0.164444
I0227 06:25:48.842108 20800 solver.cpp:245]     Train net output #0: accuracy = 0.94182
I0227 06:25:48.842116 20800 solver.cpp:245]     Train net output #1: accuracy = 0.819156
I0227 06:25:48.842123 20800 solver.cpp:245]     Train net output #2: accuracy = 0.798672
I0227 06:25:48.842133 20800 sgd_solver.cpp:106] Iteration 7720, lr = 0.000644691
I0227 06:26:06.095283 20800 solver.cpp:229] Iteration 7740, loss = 0.174612
I0227 06:26:06.095314 20800 solver.cpp:245]     Train net output #0: accuracy = 0.948696
I0227 06:26:06.095324 20800 solver.cpp:245]     Train net output #1: accuracy = 0.832571
I0227 06:26:06.095330 20800 solver.cpp:245]     Train net output #2: accuracy = 0.857709
I0227 06:26:06.095341 20800 sgd_solver.cpp:106] Iteration 7740, lr = 0.000643746
I0227 06:26:23.366806 20800 solver.cpp:229] Iteration 7760, loss = 0.176968
I0227 06:26:23.366853 20800 solver.cpp:245]     Train net output #0: accuracy = 0.938507
I0227 06:26:23.366863 20800 solver.cpp:245]     Train net output #1: accuracy = 0.924701
I0227 06:26:23.366870 20800 solver.cpp:245]     Train net output #2: accuracy = 0.900818
I0227 06:26:23.366889 20800 sgd_solver.cpp:106] Iteration 7760, lr = 0.000642801
I0227 06:26:40.612655 20800 solver.cpp:229] Iteration 7780, loss = 0.154529
I0227 06:26:40.612701 20800 solver.cpp:245]     Train net output #0: accuracy = 0.956276
I0227 06:26:40.612710 20800 solver.cpp:245]     Train net output #1: accuracy = 0.783604
I0227 06:26:40.612718 20800 solver.cpp:245]     Train net output #2: accuracy = 0.693074
I0227 06:26:40.612728 20800 sgd_solver.cpp:106] Iteration 7780, lr = 0.000641855
I0227 06:26:57.875541 20800 solver.cpp:229] Iteration 7800, loss = 0.160647
I0227 06:26:57.875586 20800 solver.cpp:245]     Train net output #0: accuracy = 0.927232
I0227 06:26:57.875594 20800 solver.cpp:245]     Train net output #1: accuracy = 0.75166
I0227 06:26:57.875602 20800 solver.cpp:245]     Train net output #2: accuracy = 0.856477
I0227 06:26:57.875612 20800 sgd_solver.cpp:106] Iteration 7800, lr = 0.00064091
I0227 06:27:15.116041 20800 solver.cpp:229] Iteration 7820, loss = 0.140134
I0227 06:27:15.116087 20800 solver.cpp:245]     Train net output #0: accuracy = 0.933676
I0227 06:27:15.116096 20800 solver.cpp:245]     Train net output #1: accuracy = 0.760258
I0227 06:27:15.116103 20800 solver.cpp:245]     Train net output #2: accuracy = 0.765051
I0227 06:27:15.116113 20800 sgd_solver.cpp:106] Iteration 7820, lr = 0.000639964
I0227 06:27:32.359460 20800 solver.cpp:229] Iteration 7840, loss = 0.161545
I0227 06:27:32.359505 20800 solver.cpp:245]     Train net output #0: accuracy = 0.941939
I0227 06:27:32.359514 20800 solver.cpp:245]     Train net output #1: accuracy = 0.751714
I0227 06:27:32.359522 20800 solver.cpp:245]     Train net output #2: accuracy = 0.748044
I0227 06:27:32.359532 20800 sgd_solver.cpp:106] Iteration 7840, lr = 0.000639018
I0227 06:27:49.644989 20800 solver.cpp:229] Iteration 7860, loss = 0.161283
I0227 06:27:49.645031 20800 solver.cpp:245]     Train net output #0: accuracy = 0.942451
I0227 06:27:49.645040 20800 solver.cpp:245]     Train net output #1: accuracy = 0.852641
I0227 06:27:49.645047 20800 solver.cpp:245]     Train net output #2: accuracy = 0.840088
I0227 06:27:49.645057 20800 sgd_solver.cpp:106] Iteration 7860, lr = 0.000638072
I0227 06:28:06.913017 20800 solver.cpp:229] Iteration 7880, loss = 0.167293
I0227 06:28:06.913062 20800 solver.cpp:245]     Train net output #0: accuracy = 0.940452
I0227 06:28:06.913071 20800 solver.cpp:245]     Train net output #1: accuracy = 0.805611
I0227 06:28:06.913079 20800 solver.cpp:245]     Train net output #2: accuracy = 0.823189
I0227 06:28:06.913089 20800 sgd_solver.cpp:106] Iteration 7880, lr = 0.000637126
I0227 06:28:24.201472 20800 solver.cpp:229] Iteration 7900, loss = 0.16862
I0227 06:28:24.201503 20800 solver.cpp:245]     Train net output #0: accuracy = 0.955808
I0227 06:28:24.201511 20800 solver.cpp:245]     Train net output #1: accuracy = 0.875395
I0227 06:28:24.201519 20800 solver.cpp:245]     Train net output #2: accuracy = 0.830828
I0227 06:28:24.201527 20800 sgd_solver.cpp:106] Iteration 7900, lr = 0.00063618
I0227 06:28:41.459347 20800 solver.cpp:229] Iteration 7920, loss = 0.167624
I0227 06:28:41.459374 20800 solver.cpp:245]     Train net output #0: accuracy = 0.944319
I0227 06:28:41.459383 20800 solver.cpp:245]     Train net output #1: accuracy = 0.814721
I0227 06:28:41.459388 20800 solver.cpp:245]     Train net output #2: accuracy = 0.739479
I0227 06:28:41.459398 20800 sgd_solver.cpp:106] Iteration 7920, lr = 0.000635233
I0227 06:28:58.711330 20800 solver.cpp:229] Iteration 7940, loss = 0.164767
I0227 06:28:58.711378 20800 solver.cpp:245]     Train net output #0: accuracy = 0.943308
I0227 06:28:58.711387 20800 solver.cpp:245]     Train net output #1: accuracy = 0.752612
I0227 06:28:58.711395 20800 solver.cpp:245]     Train net output #2: accuracy = 0.805051
I0227 06:28:58.711405 20800 sgd_solver.cpp:106] Iteration 7940, lr = 0.000634287
I0227 06:29:15.983253 20800 solver.cpp:229] Iteration 7960, loss = 0.148927
I0227 06:29:15.983283 20800 solver.cpp:245]     Train net output #0: accuracy = 0.959548
I0227 06:29:15.983292 20800 solver.cpp:245]     Train net output #1: accuracy = 0.780662
I0227 06:29:15.983299 20800 solver.cpp:245]     Train net output #2: accuracy = 0.817696
I0227 06:29:15.983309 20800 sgd_solver.cpp:106] Iteration 7960, lr = 0.00063334
I0227 06:29:33.249109 20800 solver.cpp:229] Iteration 7980, loss = 0.144548
I0227 06:29:33.249151 20800 solver.cpp:245]     Train net output #0: accuracy = 0.944557
I0227 06:29:33.249161 20800 solver.cpp:245]     Train net output #1: accuracy = 0.788961
I0227 06:29:33.249167 20800 solver.cpp:245]     Train net output #2: accuracy = 0.757585
I0227 06:29:33.249178 20800 sgd_solver.cpp:106] Iteration 7980, lr = 0.000632393
I0227 06:29:50.529247 20800 solver.cpp:229] Iteration 8000, loss = 0.157635
I0227 06:29:50.529291 20800 solver.cpp:245]     Train net output #0: accuracy = 0.935622
I0227 06:29:50.529300 20800 solver.cpp:245]     Train net output #1: accuracy = 0.886418
I0227 06:29:50.529307 20800 solver.cpp:245]     Train net output #2: accuracy = 0.874609
I0227 06:29:50.529317 20800 sgd_solver.cpp:106] Iteration 8000, lr = 0.000631446
I0227 06:30:07.815596 20800 solver.cpp:229] Iteration 8020, loss = 0.167645
I0227 06:30:07.815644 20800 solver.cpp:245]     Train net output #0: accuracy = 0.943129
I0227 06:30:07.815652 20800 solver.cpp:245]     Train net output #1: accuracy = 0.755006
I0227 06:30:07.815659 20800 solver.cpp:245]     Train net output #2: accuracy = 0.729675
I0227 06:30:07.815668 20800 sgd_solver.cpp:106] Iteration 8020, lr = 0.000630499
I0227 06:30:25.084226 20800 solver.cpp:229] Iteration 8040, loss = 0.152365
I0227 06:30:25.084270 20800 solver.cpp:245]     Train net output #0: accuracy = 0.93367
I0227 06:30:25.084280 20800 solver.cpp:245]     Train net output #1: accuracy = 0.774843
I0227 06:30:25.084285 20800 solver.cpp:245]     Train net output #2: accuracy = 0.785202
I0227 06:30:25.084295 20800 sgd_solver.cpp:106] Iteration 8040, lr = 0.000629551
I0227 06:30:42.377727 20800 solver.cpp:229] Iteration 8060, loss = 0.156233
I0227 06:30:42.377769 20800 solver.cpp:245]     Train net output #0: accuracy = 0.929447
I0227 06:30:42.377779 20800 solver.cpp:245]     Train net output #1: accuracy = 0.785389
I0227 06:30:42.377785 20800 solver.cpp:245]     Train net output #2: accuracy = 0.751516
I0227 06:30:42.377794 20800 sgd_solver.cpp:106] Iteration 8060, lr = 0.000628604
I0227 06:30:59.619876 20800 solver.cpp:229] Iteration 8080, loss = 0.153038
I0227 06:30:59.619918 20800 solver.cpp:245]     Train net output #0: accuracy = 0.92879
I0227 06:30:59.619927 20800 solver.cpp:245]     Train net output #1: accuracy = 0.759634
I0227 06:30:59.619935 20800 solver.cpp:245]     Train net output #2: accuracy = 0.758939
I0227 06:30:59.619943 20800 sgd_solver.cpp:106] Iteration 8080, lr = 0.000627656
I0227 06:31:16.869642 20800 solver.cpp:229] Iteration 8100, loss = 0.168453
I0227 06:31:16.869688 20800 solver.cpp:245]     Train net output #0: accuracy = 0.956894
I0227 06:31:16.869698 20800 solver.cpp:245]     Train net output #1: accuracy = 0.913158
I0227 06:31:16.869704 20800 solver.cpp:245]     Train net output #2: accuracy = 0.852157
I0227 06:31:16.869714 20800 sgd_solver.cpp:106] Iteration 8100, lr = 0.000626708
I0227 06:31:34.161279 20800 solver.cpp:229] Iteration 8120, loss = 0.17223
I0227 06:31:34.161309 20800 solver.cpp:245]     Train net output #0: accuracy = 0.928455
I0227 06:31:34.161319 20800 solver.cpp:245]     Train net output #1: accuracy = 0.916421
I0227 06:31:34.161325 20800 solver.cpp:245]     Train net output #2: accuracy = 0.846883
I0227 06:31:34.161335 20800 sgd_solver.cpp:106] Iteration 8120, lr = 0.00062576
I0227 06:31:51.399200 20800 solver.cpp:229] Iteration 8140, loss = 0.149052
I0227 06:31:51.399245 20800 solver.cpp:245]     Train net output #0: accuracy = 0.945806
I0227 06:31:51.399255 20800 solver.cpp:245]     Train net output #1: accuracy = 0.816295
I0227 06:31:51.399261 20800 solver.cpp:245]     Train net output #2: accuracy = 0.768604
I0227 06:31:51.399271 20800 sgd_solver.cpp:106] Iteration 8140, lr = 0.000624812
I0227 06:32:08.672024 20800 solver.cpp:229] Iteration 8160, loss = 0.165237
I0227 06:32:08.672052 20800 solver.cpp:245]     Train net output #0: accuracy = 0.939505
I0227 06:32:08.672060 20800 solver.cpp:245]     Train net output #1: accuracy = 0.9021
I0227 06:32:08.672066 20800 solver.cpp:245]     Train net output #2: accuracy = 0.928196
I0227 06:32:08.672075 20800 sgd_solver.cpp:106] Iteration 8160, lr = 0.000623863
I0227 06:32:25.948360 20800 solver.cpp:229] Iteration 8180, loss = 0.16894
I0227 06:32:25.948407 20800 solver.cpp:245]     Train net output #0: accuracy = 0.918532
I0227 06:32:25.948416 20800 solver.cpp:245]     Train net output #1: accuracy = 0.823978
I0227 06:32:25.948423 20800 solver.cpp:245]     Train net output #2: accuracy = 0.84314
I0227 06:32:25.948433 20800 sgd_solver.cpp:106] Iteration 8180, lr = 0.000622915
I0227 06:32:43.233466 20800 solver.cpp:229] Iteration 8200, loss = 0.159666
I0227 06:32:43.233512 20800 solver.cpp:245]     Train net output #0: accuracy = 0.934027
I0227 06:32:43.233521 20800 solver.cpp:245]     Train net output #1: accuracy = 0.824385
I0227 06:32:43.233528 20800 solver.cpp:245]     Train net output #2: accuracy = 0.840339
I0227 06:32:43.233537 20800 sgd_solver.cpp:106] Iteration 8200, lr = 0.000621966
I0227 06:33:00.524461 20800 solver.cpp:229] Iteration 8220, loss = 0.158991
I0227 06:33:00.524505 20800 solver.cpp:245]     Train net output #0: accuracy = 0.947606
I0227 06:33:00.524514 20800 solver.cpp:245]     Train net output #1: accuracy = 0.721862
I0227 06:33:00.524521 20800 solver.cpp:245]     Train net output #2: accuracy = 0.769032
I0227 06:33:00.524533 20800 sgd_solver.cpp:106] Iteration 8220, lr = 0.000621017
I0227 06:33:17.793017 20800 solver.cpp:229] Iteration 8240, loss = 0.152885
I0227 06:33:17.793061 20800 solver.cpp:245]     Train net output #0: accuracy = 0.9279
I0227 06:33:17.793071 20800 solver.cpp:245]     Train net output #1: accuracy = 0.844266
I0227 06:33:17.793078 20800 solver.cpp:245]     Train net output #2: accuracy = 0.858936
I0227 06:33:17.793088 20800 sgd_solver.cpp:106] Iteration 8240, lr = 0.000620068
I0227 06:33:35.039249 20800 solver.cpp:229] Iteration 8260, loss = 0.159328
I0227 06:33:35.039307 20800 solver.cpp:245]     Train net output #0: accuracy = 0.939679
I0227 06:33:35.039316 20800 solver.cpp:245]     Train net output #1: accuracy = 0.781659
I0227 06:33:35.039324 20800 solver.cpp:245]     Train net output #2: accuracy = 0.726143
I0227 06:33:35.039333 20800 sgd_solver.cpp:106] Iteration 8260, lr = 0.000619119
I0227 06:33:52.300258 20800 solver.cpp:229] Iteration 8280, loss = 0.157114
I0227 06:33:52.300302 20800 solver.cpp:245]     Train net output #0: accuracy = 0.939024
I0227 06:33:52.300310 20800 solver.cpp:245]     Train net output #1: accuracy = 0.950497
I0227 06:33:52.300318 20800 solver.cpp:245]     Train net output #2: accuracy = 0.754344
I0227 06:33:52.300328 20800 sgd_solver.cpp:106] Iteration 8280, lr = 0.00061817
I0227 06:34:09.577016 20800 solver.cpp:229] Iteration 8300, loss = 0.154658
I0227 06:34:09.577060 20800 solver.cpp:245]     Train net output #0: accuracy = 0.933875
I0227 06:34:09.577070 20800 solver.cpp:245]     Train net output #1: accuracy = 0.678958
I0227 06:34:09.577077 20800 solver.cpp:245]     Train net output #2: accuracy = 0.718916
I0227 06:34:09.577087 20800 sgd_solver.cpp:106] Iteration 8300, lr = 0.00061722
I0227 06:34:26.829414 20800 solver.cpp:229] Iteration 8320, loss = 0.151767
I0227 06:34:26.829444 20800 solver.cpp:245]     Train net output #0: accuracy = 0.947033
I0227 06:34:26.829453 20800 solver.cpp:245]     Train net output #1: accuracy = 0.800995
I0227 06:34:26.829460 20800 solver.cpp:245]     Train net output #2: accuracy = 0.739504
I0227 06:34:26.829470 20800 sgd_solver.cpp:106] Iteration 8320, lr = 0.000616271
I0227 06:34:44.089453 20800 solver.cpp:229] Iteration 8340, loss = 0.160669
I0227 06:34:44.089498 20800 solver.cpp:245]     Train net output #0: accuracy = 0.933394
I0227 06:34:44.089507 20800 solver.cpp:245]     Train net output #1: accuracy = 0.833982
I0227 06:34:44.089514 20800 solver.cpp:245]     Train net output #2: accuracy = 0.702112
I0227 06:34:44.089524 20800 sgd_solver.cpp:106] Iteration 8340, lr = 0.000615321
I0227 06:35:01.376272 20800 solver.cpp:229] Iteration 8360, loss = 0.167041
I0227 06:35:01.376307 20800 solver.cpp:245]     Train net output #0: accuracy = 0.936755
I0227 06:35:01.376317 20800 solver.cpp:245]     Train net output #1: accuracy = 0.837176
I0227 06:35:01.376324 20800 solver.cpp:245]     Train net output #2: accuracy = 0.85008
I0227 06:35:01.376334 20800 sgd_solver.cpp:106] Iteration 8360, lr = 0.000614371
I0227 06:35:18.645124 20800 solver.cpp:229] Iteration 8380, loss = 0.164682
I0227 06:35:18.645185 20800 solver.cpp:245]     Train net output #0: accuracy = 0.954995
I0227 06:35:18.645195 20800 solver.cpp:245]     Train net output #1: accuracy = 0.861256
I0227 06:35:18.645201 20800 solver.cpp:245]     Train net output #2: accuracy = 0.811038
I0227 06:35:18.645210 20800 sgd_solver.cpp:106] Iteration 8380, lr = 0.000613421
I0227 06:35:35.906976 20800 solver.cpp:229] Iteration 8400, loss = 0.151527
I0227 06:35:35.907006 20800 solver.cpp:245]     Train net output #0: accuracy = 0.927214
I0227 06:35:35.907016 20800 solver.cpp:245]     Train net output #1: accuracy = 0.775479
I0227 06:35:35.907022 20800 solver.cpp:245]     Train net output #2: accuracy = 0.756915
I0227 06:35:35.907032 20800 sgd_solver.cpp:106] Iteration 8400, lr = 0.000612471
I0227 06:35:53.160457 20800 solver.cpp:229] Iteration 8420, loss = 0.173697
I0227 06:35:53.160485 20800 solver.cpp:245]     Train net output #0: accuracy = 0.946389
I0227 06:35:53.160511 20800 solver.cpp:245]     Train net output #1: accuracy = 0.776458
I0227 06:35:53.160517 20800 solver.cpp:245]     Train net output #2: accuracy = 0.755459
I0227 06:35:53.160527 20800 sgd_solver.cpp:106] Iteration 8420, lr = 0.00061152
I0227 06:36:10.416777 20800 solver.cpp:229] Iteration 8440, loss = 0.168553
I0227 06:36:10.416821 20800 solver.cpp:245]     Train net output #0: accuracy = 0.915948
I0227 06:36:10.416829 20800 solver.cpp:245]     Train net output #1: accuracy = 0.765846
I0227 06:36:10.416836 20800 solver.cpp:245]     Train net output #2: accuracy = 0.745792
I0227 06:36:10.416846 20800 sgd_solver.cpp:106] Iteration 8440, lr = 0.000610569
I0227 06:36:27.702714 20800 solver.cpp:229] Iteration 8460, loss = 0.156403
I0227 06:36:27.702760 20800 solver.cpp:245]     Train net output #0: accuracy = 0.950863
I0227 06:36:27.702770 20800 solver.cpp:245]     Train net output #1: accuracy = 0.600916
I0227 06:36:27.702777 20800 solver.cpp:245]     Train net output #2: accuracy = 0.741861
I0227 06:36:27.702787 20800 sgd_solver.cpp:106] Iteration 8460, lr = 0.000609619
I0227 06:36:44.980834 20800 solver.cpp:229] Iteration 8480, loss = 0.15716
I0227 06:36:44.980865 20800 solver.cpp:245]     Train net output #0: accuracy = 0.935221
I0227 06:36:44.980873 20800 solver.cpp:245]     Train net output #1: accuracy = 0.792679
I0227 06:36:44.980880 20800 solver.cpp:245]     Train net output #2: accuracy = 0.876694
I0227 06:36:44.980890 20800 sgd_solver.cpp:106] Iteration 8480, lr = 0.000608668
I0227 06:37:02.242511 20800 solver.cpp:229] Iteration 8500, loss = 0.158899
I0227 06:37:02.242539 20800 solver.cpp:245]     Train net output #0: accuracy = 0.930974
I0227 06:37:02.242548 20800 solver.cpp:245]     Train net output #1: accuracy = 0.860554
I0227 06:37:02.242555 20800 solver.cpp:245]     Train net output #2: accuracy = 0.784439
I0227 06:37:02.242564 20800 sgd_solver.cpp:106] Iteration 8500, lr = 0.000607717
I0227 06:37:19.525482 20800 solver.cpp:229] Iteration 8520, loss = 0.141373
I0227 06:37:19.525527 20800 solver.cpp:245]     Train net output #0: accuracy = 0.94051
I0227 06:37:19.525537 20800 solver.cpp:245]     Train net output #1: accuracy = 0.734764
I0227 06:37:19.525543 20800 solver.cpp:245]     Train net output #2: accuracy = 0.650324
I0227 06:37:19.525552 20800 sgd_solver.cpp:106] Iteration 8520, lr = 0.000606765
I0227 06:37:36.784054 20800 solver.cpp:229] Iteration 8540, loss = 0.153209
I0227 06:37:36.784095 20800 solver.cpp:245]     Train net output #0: accuracy = 0.950369
I0227 06:37:36.784109 20800 solver.cpp:245]     Train net output #1: accuracy = 0.86238
I0227 06:37:36.784122 20800 solver.cpp:245]     Train net output #2: accuracy = 0.818091
I0227 06:37:36.784137 20800 sgd_solver.cpp:106] Iteration 8540, lr = 0.000605814
I0227 06:37:54.060766 20800 solver.cpp:229] Iteration 8560, loss = 0.149595
I0227 06:37:54.060825 20800 solver.cpp:245]     Train net output #0: accuracy = 0.942832
I0227 06:37:54.060834 20800 solver.cpp:245]     Train net output #1: accuracy = 0.847163
I0227 06:37:54.060842 20800 solver.cpp:245]     Train net output #2: accuracy = 0.861687
I0227 06:37:54.060850 20800 sgd_solver.cpp:106] Iteration 8560, lr = 0.000604862
I0227 06:38:11.324218 20800 solver.cpp:229] Iteration 8580, loss = 0.158658
I0227 06:38:11.324249 20800 solver.cpp:245]     Train net output #0: accuracy = 0.928384
I0227 06:38:11.324257 20800 solver.cpp:245]     Train net output #1: accuracy = 0.905367
I0227 06:38:11.324265 20800 solver.cpp:245]     Train net output #2: accuracy = 0.880519
I0227 06:38:11.324275 20800 sgd_solver.cpp:106] Iteration 8580, lr = 0.00060391
I0227 06:38:28.599364 20800 solver.cpp:229] Iteration 8600, loss = 0.15257
I0227 06:38:28.599411 20800 solver.cpp:245]     Train net output #0: accuracy = 0.932958
I0227 06:38:28.599419 20800 solver.cpp:245]     Train net output #1: accuracy = 0.678881
I0227 06:38:28.599426 20800 solver.cpp:245]     Train net output #2: accuracy = 0.790975
I0227 06:38:28.599436 20800 sgd_solver.cpp:106] Iteration 8600, lr = 0.000602958
I0227 06:38:45.879232 20800 solver.cpp:229] Iteration 8620, loss = 0.144889
I0227 06:38:45.879263 20800 solver.cpp:245]     Train net output #0: accuracy = 0.938549
I0227 06:38:45.879272 20800 solver.cpp:245]     Train net output #1: accuracy = 0.738908
I0227 06:38:45.879279 20800 solver.cpp:245]     Train net output #2: accuracy = 0.731176
I0227 06:38:45.879289 20800 sgd_solver.cpp:106] Iteration 8620, lr = 0.000602006
I0227 06:39:03.129263 20800 solver.cpp:229] Iteration 8640, loss = 0.149821
I0227 06:39:03.129308 20800 solver.cpp:245]     Train net output #0: accuracy = 0.942415
I0227 06:39:03.129317 20800 solver.cpp:245]     Train net output #1: accuracy = 0.877587
I0227 06:39:03.129324 20800 solver.cpp:245]     Train net output #2: accuracy = 0.909984
I0227 06:39:03.129334 20800 sgd_solver.cpp:106] Iteration 8640, lr = 0.000601054
I0227 06:39:20.426108 20800 solver.cpp:229] Iteration 8660, loss = 0.141853
I0227 06:39:20.426152 20800 solver.cpp:245]     Train net output #0: accuracy = 0.948456
I0227 06:39:20.426162 20800 solver.cpp:245]     Train net output #1: accuracy = 0.846897
I0227 06:39:20.426177 20800 solver.cpp:245]     Train net output #2: accuracy = 0.917094
I0227 06:39:20.426199 20800 sgd_solver.cpp:106] Iteration 8660, lr = 0.000600102
I0227 06:39:37.715945 20800 solver.cpp:229] Iteration 8680, loss = 0.150232
I0227 06:39:37.715991 20800 solver.cpp:245]     Train net output #0: accuracy = 0.942826
I0227 06:39:37.715999 20800 solver.cpp:245]     Train net output #1: accuracy = 0.848881
I0227 06:39:37.716007 20800 solver.cpp:245]     Train net output #2: accuracy = 0.864889
I0227 06:39:37.716017 20800 sgd_solver.cpp:106] Iteration 8680, lr = 0.000599149
I0227 06:39:55.005843 20800 solver.cpp:229] Iteration 8700, loss = 0.134624
I0227 06:39:55.005888 20800 solver.cpp:245]     Train net output #0: accuracy = 0.950742
I0227 06:39:55.005897 20800 solver.cpp:245]     Train net output #1: accuracy = 0.71064
I0227 06:39:55.005904 20800 solver.cpp:245]     Train net output #2: accuracy = 0.828459
I0227 06:39:55.005914 20800 sgd_solver.cpp:106] Iteration 8700, lr = 0.000598196
I0227 06:40:12.270714 20800 solver.cpp:229] Iteration 8720, loss = 0.143995
I0227 06:40:12.270759 20800 solver.cpp:245]     Train net output #0: accuracy = 0.919554
I0227 06:40:12.270768 20800 solver.cpp:245]     Train net output #1: accuracy = 0.702306
I0227 06:40:12.270776 20800 solver.cpp:245]     Train net output #2: accuracy = 0.66801
I0227 06:40:12.270787 20800 sgd_solver.cpp:106] Iteration 8720, lr = 0.000597243
I0227 06:40:29.546386 20800 solver.cpp:229] Iteration 8740, loss = 0.140234
I0227 06:40:29.546430 20800 solver.cpp:245]     Train net output #0: accuracy = 0.952494
I0227 06:40:29.546439 20800 solver.cpp:245]     Train net output #1: accuracy = 0.942169
I0227 06:40:29.546445 20800 solver.cpp:245]     Train net output #2: accuracy = 0.905985
I0227 06:40:29.546455 20800 sgd_solver.cpp:106] Iteration 8740, lr = 0.00059629
I0227 06:40:46.820881 20800 solver.cpp:229] Iteration 8760, loss = 0.152403
I0227 06:40:46.820914 20800 solver.cpp:245]     Train net output #0: accuracy = 0.943498
I0227 06:40:46.820922 20800 solver.cpp:245]     Train net output #1: accuracy = 0.850222
I0227 06:40:46.820930 20800 solver.cpp:245]     Train net output #2: accuracy = 0.88029
I0227 06:40:46.820940 20800 sgd_solver.cpp:106] Iteration 8760, lr = 0.000595337
I0227 06:41:04.075937 20800 solver.cpp:229] Iteration 8780, loss = 0.161759
I0227 06:41:04.075981 20800 solver.cpp:245]     Train net output #0: accuracy = 0.936271
I0227 06:41:04.075990 20800 solver.cpp:245]     Train net output #1: accuracy = 0.651769
I0227 06:41:04.075997 20800 solver.cpp:245]     Train net output #2: accuracy = 0.640927
I0227 06:41:04.076006 20800 sgd_solver.cpp:106] Iteration 8780, lr = 0.000594383
I0227 06:41:21.341063 20800 solver.cpp:229] Iteration 8800, loss = 0.151113
I0227 06:41:21.341091 20800 solver.cpp:245]     Train net output #0: accuracy = 0.939024
I0227 06:41:21.341100 20800 solver.cpp:245]     Train net output #1: accuracy = 0.84298
I0227 06:41:21.341107 20800 solver.cpp:245]     Train net output #2: accuracy = 0.857923
I0227 06:41:21.341117 20800 sgd_solver.cpp:106] Iteration 8800, lr = 0.00059343
I0227 06:41:38.609722 20800 solver.cpp:229] Iteration 8820, loss = 0.158924
I0227 06:41:38.609752 20800 solver.cpp:245]     Train net output #0: accuracy = 0.942128
I0227 06:41:38.609761 20800 solver.cpp:245]     Train net output #1: accuracy = 0.795196
I0227 06:41:38.609768 20800 solver.cpp:245]     Train net output #2: accuracy = 0.793688
I0227 06:41:38.609777 20800 sgd_solver.cpp:106] Iteration 8820, lr = 0.000592476
I0227 06:41:55.875355 20800 solver.cpp:229] Iteration 8840, loss = 0.155736
I0227 06:41:55.875401 20800 solver.cpp:245]     Train net output #0: accuracy = 0.937402
I0227 06:41:55.875411 20800 solver.cpp:245]     Train net output #1: accuracy = 0.812345
I0227 06:41:55.875417 20800 solver.cpp:245]     Train net output #2: accuracy = 0.758325
I0227 06:41:55.875427 20800 sgd_solver.cpp:106] Iteration 8840, lr = 0.000591522
I0227 06:42:13.158388 20800 solver.cpp:229] Iteration 8860, loss = 0.160842
I0227 06:42:13.158429 20800 solver.cpp:245]     Train net output #0: accuracy = 0.920792
I0227 06:42:13.158438 20800 solver.cpp:245]     Train net output #1: accuracy = 0.800635
I0227 06:42:13.158445 20800 solver.cpp:245]     Train net output #2: accuracy = 0.795509
I0227 06:42:13.158455 20800 sgd_solver.cpp:106] Iteration 8860, lr = 0.000590568
I0227 06:42:30.445466 20800 solver.cpp:229] Iteration 8880, loss = 0.166569
I0227 06:42:30.445493 20800 solver.cpp:245]     Train net output #0: accuracy = 0.925748
I0227 06:42:30.445518 20800 solver.cpp:245]     Train net output #1: accuracy = 0.836949
I0227 06:42:30.445525 20800 solver.cpp:245]     Train net output #2: accuracy = 0.854537
I0227 06:42:30.445534 20800 sgd_solver.cpp:106] Iteration 8880, lr = 0.000589613
I0227 06:42:47.710620 20800 solver.cpp:229] Iteration 8900, loss = 0.166383
I0227 06:42:47.710670 20800 solver.cpp:245]     Train net output #0: accuracy = 0.916657
I0227 06:42:47.710680 20800 solver.cpp:245]     Train net output #1: accuracy = 0.786393
I0227 06:42:47.710687 20800 solver.cpp:245]     Train net output #2: accuracy = 0.67302
I0227 06:42:47.710697 20800 sgd_solver.cpp:106] Iteration 8900, lr = 0.000588659
I0227 06:43:04.969225 20800 solver.cpp:229] Iteration 8920, loss = 0.160464
I0227 06:43:04.969271 20800 solver.cpp:245]     Train net output #0: accuracy = 0.935059
I0227 06:43:04.969280 20800 solver.cpp:245]     Train net output #1: accuracy = 0.653078
I0227 06:43:04.969286 20800 solver.cpp:245]     Train net output #2: accuracy = 0.822131
I0227 06:43:04.969295 20800 sgd_solver.cpp:106] Iteration 8920, lr = 0.000587704
I0227 06:43:22.267659 20800 solver.cpp:229] Iteration 8940, loss = 0.14898
I0227 06:43:22.267689 20800 solver.cpp:245]     Train net output #0: accuracy = 0.945137
I0227 06:43:22.267699 20800 solver.cpp:245]     Train net output #1: accuracy = 0.789566
I0227 06:43:22.267705 20800 solver.cpp:245]     Train net output #2: accuracy = 0.856927
I0227 06:43:22.267715 20800 sgd_solver.cpp:106] Iteration 8940, lr = 0.000586749
I0227 06:43:39.532183 20800 solver.cpp:229] Iteration 8960, loss = 0.164664
I0227 06:43:39.532214 20800 solver.cpp:245]     Train net output #0: accuracy = 0.946944
I0227 06:43:39.532223 20800 solver.cpp:245]     Train net output #1: accuracy = 0.889971
I0227 06:43:39.532230 20800 solver.cpp:245]     Train net output #2: accuracy = 0.91562
I0227 06:43:39.532240 20800 sgd_solver.cpp:106] Iteration 8960, lr = 0.000585794
I0227 06:43:56.805538 20800 solver.cpp:229] Iteration 8980, loss = 0.157754
I0227 06:43:56.805585 20800 solver.cpp:245]     Train net output #0: accuracy = 0.953022
I0227 06:43:56.805594 20800 solver.cpp:245]     Train net output #1: accuracy = 0.850292
I0227 06:43:56.805601 20800 solver.cpp:245]     Train net output #2: accuracy = 0.797904
I0227 06:43:56.805611 20800 sgd_solver.cpp:106] Iteration 8980, lr = 0.000584839
I0227 06:44:14.074101 20800 solver.cpp:229] Iteration 9000, loss = 0.136866
I0227 06:44:14.074132 20800 solver.cpp:245]     Train net output #0: accuracy = 0.968156
I0227 06:44:14.074142 20800 solver.cpp:245]     Train net output #1: accuracy = 0.838909
I0227 06:44:14.074163 20800 solver.cpp:245]     Train net output #2: accuracy = 0.925518
I0227 06:44:14.074189 20800 sgd_solver.cpp:106] Iteration 9000, lr = 0.000583884
I0227 06:44:31.337393 20800 solver.cpp:229] Iteration 9020, loss = 0.152945
I0227 06:44:31.337424 20800 solver.cpp:245]     Train net output #0: accuracy = 0.933313
I0227 06:44:31.337433 20800 solver.cpp:245]     Train net output #1: accuracy = 0.614651
I0227 06:44:31.337440 20800 solver.cpp:245]     Train net output #2: accuracy = 0.63639
I0227 06:44:31.337451 20800 sgd_solver.cpp:106] Iteration 9020, lr = 0.000582928
I0227 06:44:48.628448 20800 solver.cpp:229] Iteration 9040, loss = 0.149274
I0227 06:44:48.628477 20800 solver.cpp:245]     Train net output #0: accuracy = 0.92526
I0227 06:44:48.628486 20800 solver.cpp:245]     Train net output #1: accuracy = 0.657594
I0227 06:44:48.628494 20800 solver.cpp:245]     Train net output #2: accuracy = 0.687349
I0227 06:44:48.628502 20800 sgd_solver.cpp:106] Iteration 9040, lr = 0.000581973
I0227 06:45:05.888885 20800 solver.cpp:229] Iteration 9060, loss = 0.13977
I0227 06:45:05.888928 20800 solver.cpp:245]     Train net output #0: accuracy = 0.915172
I0227 06:45:05.888937 20800 solver.cpp:245]     Train net output #1: accuracy = 0.768876
I0227 06:45:05.888944 20800 solver.cpp:245]     Train net output #2: accuracy = 0.726519
I0227 06:45:05.888969 20800 sgd_solver.cpp:106] Iteration 9060, lr = 0.000581017
I0227 06:45:23.167816 20800 solver.cpp:229] Iteration 9080, loss = 0.136629
I0227 06:45:23.167846 20800 solver.cpp:245]     Train net output #0: accuracy = 0.940078
I0227 06:45:23.167856 20800 solver.cpp:245]     Train net output #1: accuracy = 0.779098
I0227 06:45:23.167863 20800 solver.cpp:245]     Train net output #2: accuracy = 0.747728
I0227 06:45:23.167873 20800 sgd_solver.cpp:106] Iteration 9080, lr = 0.000580061
I0227 06:45:40.443989 20800 solver.cpp:229] Iteration 9100, loss = 0.171011
I0227 06:45:40.444020 20800 solver.cpp:245]     Train net output #0: accuracy = 0.923234
I0227 06:45:40.444030 20800 solver.cpp:245]     Train net output #1: accuracy = 0.903583
I0227 06:45:40.444036 20800 solver.cpp:245]     Train net output #2: accuracy = 0.842149
I0227 06:45:40.444046 20800 sgd_solver.cpp:106] Iteration 9100, lr = 0.000579104
I0227 06:45:57.730795 20800 solver.cpp:229] Iteration 9120, loss = 0.15666
I0227 06:45:57.730840 20800 solver.cpp:245]     Train net output #0: accuracy = 0.923013
I0227 06:45:57.730849 20800 solver.cpp:245]     Train net output #1: accuracy = 0.90622
I0227 06:45:57.730856 20800 solver.cpp:245]     Train net output #2: accuracy = 0.810658
I0227 06:45:57.730866 20800 sgd_solver.cpp:106] Iteration 9120, lr = 0.000578148
I0227 06:46:14.981822 20800 solver.cpp:229] Iteration 9140, loss = 0.162225
I0227 06:46:14.981868 20800 solver.cpp:245]     Train net output #0: accuracy = 0.928435
I0227 06:46:14.981876 20800 solver.cpp:245]     Train net output #1: accuracy = 0.676421
I0227 06:46:14.981884 20800 solver.cpp:245]     Train net output #2: accuracy = 0.726282
I0227 06:46:14.981894 20800 sgd_solver.cpp:106] Iteration 9140, lr = 0.000577191
I0227 06:46:32.252566 20800 solver.cpp:229] Iteration 9160, loss = 0.153538
I0227 06:46:32.252596 20800 solver.cpp:245]     Train net output #0: accuracy = 0.95461
I0227 06:46:32.252605 20800 solver.cpp:245]     Train net output #1: accuracy = 0.741637
I0227 06:46:32.252611 20800 solver.cpp:245]     Train net output #2: accuracy = 0.822733
I0227 06:46:32.252620 20800 sgd_solver.cpp:106] Iteration 9160, lr = 0.000576235
I0227 06:46:49.499176 20800 solver.cpp:229] Iteration 9180, loss = 0.15178
I0227 06:46:49.499207 20800 solver.cpp:245]     Train net output #0: accuracy = 0.928088
I0227 06:46:49.499217 20800 solver.cpp:245]     Train net output #1: accuracy = 0.804106
I0227 06:46:49.499223 20800 solver.cpp:245]     Train net output #2: accuracy = 0.770664
I0227 06:46:49.499233 20800 sgd_solver.cpp:106] Iteration 9180, lr = 0.000575278
I0227 06:47:06.757344 20800 solver.cpp:229] Iteration 9200, loss = 0.160086
I0227 06:47:06.757390 20800 solver.cpp:245]     Train net output #0: accuracy = 0.946845
I0227 06:47:06.757398 20800 solver.cpp:245]     Train net output #1: accuracy = 0.85712
I0227 06:47:06.757421 20800 solver.cpp:245]     Train net output #2: accuracy = 0.932984
I0227 06:47:06.757429 20800 sgd_solver.cpp:106] Iteration 9200, lr = 0.000574321
I0227 06:47:24.045769 20800 solver.cpp:229] Iteration 9220, loss = 0.169076
I0227 06:47:24.045815 20800 solver.cpp:245]     Train net output #0: accuracy = 0.950268
I0227 06:47:24.045825 20800 solver.cpp:245]     Train net output #1: accuracy = 0.696842
I0227 06:47:24.045831 20800 solver.cpp:245]     Train net output #2: accuracy = 0.718431
I0227 06:47:24.045840 20800 sgd_solver.cpp:106] Iteration 9220, lr = 0.000573363
I0227 06:47:41.315309 20800 solver.cpp:229] Iteration 9240, loss = 0.156166
I0227 06:47:41.315338 20800 solver.cpp:245]     Train net output #0: accuracy = 0.939322
I0227 06:47:41.315347 20800 solver.cpp:245]     Train net output #1: accuracy = 0.842163
I0227 06:47:41.315354 20800 solver.cpp:245]     Train net output #2: accuracy = 0.907502
I0227 06:47:41.315363 20800 sgd_solver.cpp:106] Iteration 9240, lr = 0.000572406
I0227 06:47:58.583719 20800 solver.cpp:229] Iteration 9260, loss = 0.148652
I0227 06:47:58.583762 20800 solver.cpp:245]     Train net output #0: accuracy = 0.911129
I0227 06:47:58.583771 20800 solver.cpp:245]     Train net output #1: accuracy = 0.782078
I0227 06:47:58.583778 20800 solver.cpp:245]     Train net output #2: accuracy = 0.802458
I0227 06:47:58.583787 20800 sgd_solver.cpp:106] Iteration 9260, lr = 0.000571448
I0227 06:48:15.855794 20800 solver.cpp:229] Iteration 9280, loss = 0.165959
I0227 06:48:15.855834 20800 solver.cpp:245]     Train net output #0: accuracy = 0.936109
I0227 06:48:15.855847 20800 solver.cpp:245]     Train net output #1: accuracy = 0.816657
I0227 06:48:15.855859 20800 solver.cpp:245]     Train net output #2: accuracy = 0.751516
I0227 06:48:15.855873 20800 sgd_solver.cpp:106] Iteration 9280, lr = 0.00057049
I0227 06:48:33.113911 20800 solver.cpp:229] Iteration 9300, loss = 0.155186
I0227 06:48:33.113957 20800 solver.cpp:245]     Train net output #0: accuracy = 0.935871
I0227 06:48:33.113967 20800 solver.cpp:245]     Train net output #1: accuracy = 0.924457
I0227 06:48:33.113975 20800 solver.cpp:245]     Train net output #2: accuracy = 0.887745
I0227 06:48:33.113984 20800 sgd_solver.cpp:106] Iteration 9300, lr = 0.000569532
I0227 06:48:50.400269 20800 solver.cpp:229] Iteration 9320, loss = 0.16516
I0227 06:48:50.400300 20800 solver.cpp:245]     Train net output #0: accuracy = 0.919869
I0227 06:48:50.400310 20800 solver.cpp:245]     Train net output #1: accuracy = 0.667038
I0227 06:48:50.400316 20800 solver.cpp:245]     Train net output #2: accuracy = 0.740033
I0227 06:48:50.400327 20800 sgd_solver.cpp:106] Iteration 9320, lr = 0.000568574
I0227 06:49:07.650389 20800 solver.cpp:229] Iteration 9340, loss = 0.162369
I0227 06:49:07.650421 20800 solver.cpp:245]     Train net output #0: accuracy = 0.954866
I0227 06:49:07.650431 20800 solver.cpp:245]     Train net output #1: accuracy = 0.899546
I0227 06:49:07.650439 20800 solver.cpp:245]     Train net output #2: accuracy = 0.941706
I0227 06:49:07.650449 20800 sgd_solver.cpp:106] Iteration 9340, lr = 0.000567616
I0227 06:49:24.915601 20800 solver.cpp:229] Iteration 9360, loss = 0.159019
I0227 06:49:24.915644 20800 solver.cpp:245]     Train net output #0: accuracy = 0.945271
I0227 06:49:24.915668 20800 solver.cpp:245]     Train net output #1: accuracy = 0.670004
I0227 06:49:24.915675 20800 solver.cpp:245]     Train net output #2: accuracy = 0.761943
I0227 06:49:24.915684 20800 sgd_solver.cpp:106] Iteration 9360, lr = 0.000566657
I0227 06:49:42.190909 20800 solver.cpp:229] Iteration 9380, loss = 0.160614
I0227 06:49:42.190940 20800 solver.cpp:245]     Train net output #0: accuracy = 0.920627
I0227 06:49:42.190950 20800 solver.cpp:245]     Train net output #1: accuracy = 0.869619
I0227 06:49:42.190958 20800 solver.cpp:245]     Train net output #2: accuracy = 0.712315
I0227 06:49:42.190968 20800 sgd_solver.cpp:106] Iteration 9380, lr = 0.000565699
I0227 06:49:59.461691 20800 solver.cpp:229] Iteration 9400, loss = 0.14989
I0227 06:49:59.461735 20800 solver.cpp:245]     Train net output #0: accuracy = 0.92882
I0227 06:49:59.461760 20800 solver.cpp:245]     Train net output #1: accuracy = 0.856914
I0227 06:49:59.461766 20800 solver.cpp:245]     Train net output #2: accuracy = 0.738809
I0227 06:49:59.461792 20800 sgd_solver.cpp:106] Iteration 9400, lr = 0.00056474
I0227 06:50:16.701448 20800 solver.cpp:229] Iteration 9420, loss = 0.16598
I0227 06:50:16.701480 20800 solver.cpp:245]     Train net output #0: accuracy = 0.922368
I0227 06:50:16.701489 20800 solver.cpp:245]     Train net output #1: accuracy = 0.837513
I0227 06:50:16.701496 20800 solver.cpp:245]     Train net output #2: accuracy = 0.830114
I0227 06:50:16.701506 20800 sgd_solver.cpp:106] Iteration 9420, lr = 0.000563781
I0227 06:50:33.967974 20800 solver.cpp:229] Iteration 9440, loss = 0.16293
I0227 06:50:33.968019 20800 solver.cpp:245]     Train net output #0: accuracy = 0.942951
I0227 06:50:33.968027 20800 solver.cpp:245]     Train net output #1: accuracy = 0.785305
I0227 06:50:33.968034 20800 solver.cpp:245]     Train net output #2: accuracy = 0.658081
I0227 06:50:33.968044 20800 sgd_solver.cpp:106] Iteration 9440, lr = 0.000562821
I0227 06:50:51.234508 20800 solver.cpp:229] Iteration 9460, loss = 0.153716
I0227 06:50:51.234555 20800 solver.cpp:245]     Train net output #0: accuracy = 0.942253
I0227 06:50:51.234563 20800 solver.cpp:245]     Train net output #1: accuracy = 0.809313
I0227 06:50:51.234571 20800 solver.cpp:245]     Train net output #2: accuracy = 0.753234
I0227 06:50:51.234580 20800 sgd_solver.cpp:106] Iteration 9460, lr = 0.000561862
I0227 06:51:08.537967 20800 solver.cpp:229] Iteration 9480, loss = 0.155385
I0227 06:51:08.538000 20800 solver.cpp:245]     Train net output #0: accuracy = 0.935217
I0227 06:51:08.538009 20800 solver.cpp:245]     Train net output #1: accuracy = 0.88164
I0227 06:51:08.538017 20800 solver.cpp:245]     Train net output #2: accuracy = 0.869888
I0227 06:51:08.538028 20800 sgd_solver.cpp:106] Iteration 9480, lr = 0.000560902
I0227 06:51:25.793481 20800 solver.cpp:229] Iteration 9500, loss = 0.157388
I0227 06:51:25.793509 20800 solver.cpp:245]     Train net output #0: accuracy = 0.924207
I0227 06:51:25.793517 20800 solver.cpp:245]     Train net output #1: accuracy = 0.806496
I0227 06:51:25.793524 20800 solver.cpp:245]     Train net output #2: accuracy = 0.728223
I0227 06:51:25.793534 20800 sgd_solver.cpp:106] Iteration 9500, lr = 0.000559942
I0227 06:51:43.035006 20800 solver.cpp:229] Iteration 9520, loss = 0.154881
I0227 06:51:43.035037 20800 solver.cpp:245]     Train net output #0: accuracy = 0.938786
I0227 06:51:43.035045 20800 solver.cpp:245]     Train net output #1: accuracy = 0.717374
I0227 06:51:43.035053 20800 solver.cpp:245]     Train net output #2: accuracy = 0.7031
I0227 06:51:43.035063 20800 sgd_solver.cpp:106] Iteration 9520, lr = 0.000558982
I0227 06:52:00.329726 20800 solver.cpp:229] Iteration 9540, loss = 0.144022
I0227 06:52:00.329756 20800 solver.cpp:245]     Train net output #0: accuracy = 0.95648
I0227 06:52:00.329766 20800 solver.cpp:245]     Train net output #1: accuracy = 0.885905
I0227 06:52:00.329772 20800 solver.cpp:245]     Train net output #2: accuracy = 0.938744
I0227 06:52:00.329782 20800 sgd_solver.cpp:106] Iteration 9540, lr = 0.000558022
I0227 06:52:17.597968 20800 solver.cpp:229] Iteration 9560, loss = 0.151521
I0227 06:52:17.598012 20800 solver.cpp:245]     Train net output #0: accuracy = 0.95774
I0227 06:52:17.598021 20800 solver.cpp:245]     Train net output #1: accuracy = 0.697976
I0227 06:52:17.598027 20800 solver.cpp:245]     Train net output #2: accuracy = 0.790084
I0227 06:52:17.598037 20800 sgd_solver.cpp:106] Iteration 9560, lr = 0.000557062
I0227 06:52:34.866137 20800 solver.cpp:229] Iteration 9580, loss = 0.162098
I0227 06:52:34.866179 20800 solver.cpp:245]     Train net output #0: accuracy = 0.928532
I0227 06:52:34.866189 20800 solver.cpp:245]     Train net output #1: accuracy = 0.788639
I0227 06:52:34.866195 20800 solver.cpp:245]     Train net output #2: accuracy = 0.747328
I0227 06:52:34.866205 20800 sgd_solver.cpp:106] Iteration 9580, lr = 0.000556101
I0227 06:52:52.133790 20800 solver.cpp:229] Iteration 9600, loss = 0.132776
I0227 06:52:52.133836 20800 solver.cpp:245]     Train net output #0: accuracy = 0.953502
I0227 06:52:52.133843 20800 solver.cpp:245]     Train net output #1: accuracy = 0.675571
I0227 06:52:52.133850 20800 solver.cpp:245]     Train net output #2: accuracy = 0.752004
I0227 06:52:52.133860 20800 sgd_solver.cpp:106] Iteration 9600, lr = 0.000555141
I0227 06:53:09.410742 20800 solver.cpp:229] Iteration 9620, loss = 0.132675
I0227 06:53:09.410787 20800 solver.cpp:245]     Train net output #0: accuracy = 0.948245
I0227 06:53:09.410796 20800 solver.cpp:245]     Train net output #1: accuracy = 0.920713
I0227 06:53:09.410804 20800 solver.cpp:245]     Train net output #2: accuracy = 0.866803
I0227 06:53:09.410814 20800 sgd_solver.cpp:106] Iteration 9620, lr = 0.00055418
I0227 06:53:26.677083 20800 solver.cpp:229] Iteration 9640, loss = 0.135269
I0227 06:53:26.677127 20800 solver.cpp:245]     Train net output #0: accuracy = 0.949613
I0227 06:53:26.677136 20800 solver.cpp:245]     Train net output #1: accuracy = 0.707345
I0227 06:53:26.677143 20800 solver.cpp:245]     Train net output #2: accuracy = 0.719399
I0227 06:53:26.677152 20800 sgd_solver.cpp:106] Iteration 9640, lr = 0.000553219
I0227 06:53:43.943115 20800 solver.cpp:229] Iteration 9660, loss = 0.143864
I0227 06:53:43.943161 20800 solver.cpp:245]     Train net output #0: accuracy = 0.958446
I0227 06:53:43.943169 20800 solver.cpp:245]     Train net output #1: accuracy = 0.78706
I0227 06:53:43.943176 20800 solver.cpp:245]     Train net output #2: accuracy = 0.796627
I0227 06:53:43.943186 20800 sgd_solver.cpp:106] Iteration 9660, lr = 0.000552257
I0227 06:54:01.203526 20800 solver.cpp:229] Iteration 9680, loss = 0.125797
I0227 06:54:01.203555 20800 solver.cpp:245]     Train net output #0: accuracy = 0.955334
I0227 06:54:01.203564 20800 solver.cpp:245]     Train net output #1: accuracy = 0.825315
I0227 06:54:01.203572 20800 solver.cpp:245]     Train net output #2: accuracy = 0.889945
I0227 06:54:01.203582 20800 sgd_solver.cpp:106] Iteration 9680, lr = 0.000551296
I0227 06:54:18.455687 20800 solver.cpp:229] Iteration 9700, loss = 0.146436
I0227 06:54:18.455716 20800 solver.cpp:245]     Train net output #0: accuracy = 0.948036
I0227 06:54:18.455740 20800 solver.cpp:245]     Train net output #1: accuracy = 0.725422
I0227 06:54:18.455749 20800 solver.cpp:245]     Train net output #2: accuracy = 0.755895
I0227 06:54:18.455759 20800 sgd_solver.cpp:106] Iteration 9700, lr = 0.000550334
I0227 06:54:35.732719 20800 solver.cpp:229] Iteration 9720, loss = 0.152031
I0227 06:54:35.732748 20800 solver.cpp:245]     Train net output #0: accuracy = 0.937121
I0227 06:54:35.732758 20800 solver.cpp:245]     Train net output #1: accuracy = 0.770986
I0227 06:54:35.732764 20800 solver.cpp:245]     Train net output #2: accuracy = 0.775577
I0227 06:54:35.732774 20800 sgd_solver.cpp:106] Iteration 9720, lr = 0.000549372
I0227 06:54:53.043524 20800 solver.cpp:229] Iteration 9740, loss = 0.160813
I0227 06:54:53.043570 20800 solver.cpp:245]     Train net output #0: accuracy = 0.931053
I0227 06:54:53.043578 20800 solver.cpp:245]     Train net output #1: accuracy = 0.759109
I0227 06:54:53.043586 20800 solver.cpp:245]     Train net output #2: accuracy = 0.800832
I0227 06:54:53.043594 20800 sgd_solver.cpp:106] Iteration 9740, lr = 0.00054841
I0227 06:55:10.320724 20800 solver.cpp:229] Iteration 9760, loss = 0.158014
I0227 06:55:10.320767 20800 solver.cpp:245]     Train net output #0: accuracy = 0.919869
I0227 06:55:10.320776 20800 solver.cpp:245]     Train net output #1: accuracy = 0.900898
I0227 06:55:10.320783 20800 solver.cpp:245]     Train net output #2: accuracy = 0.812069
I0227 06:55:10.320793 20800 sgd_solver.cpp:106] Iteration 9760, lr = 0.000547448
I0227 06:55:27.603518 20800 solver.cpp:229] Iteration 9780, loss = 0.143745
I0227 06:55:27.603564 20800 solver.cpp:245]     Train net output #0: accuracy = 0.954156
I0227 06:55:27.603574 20800 solver.cpp:245]     Train net output #1: accuracy = 0.761408
I0227 06:55:27.603581 20800 solver.cpp:245]     Train net output #2: accuracy = 0.827575
I0227 06:55:27.603591 20800 sgd_solver.cpp:106] Iteration 9780, lr = 0.000546486
I0227 06:55:44.869238 20800 solver.cpp:229] Iteration 9800, loss = 0.146069
I0227 06:55:44.869268 20800 solver.cpp:245]     Train net output #0: accuracy = 0.955086
I0227 06:55:44.869278 20800 solver.cpp:245]     Train net output #1: accuracy = 0.809131
I0227 06:55:44.869285 20800 solver.cpp:245]     Train net output #2: accuracy = 0.784433
I0227 06:55:44.869295 20800 sgd_solver.cpp:106] Iteration 9800, lr = 0.000545523
I0227 06:56:02.136080 20800 solver.cpp:229] Iteration 9820, loss = 0.143877
I0227 06:56:02.136126 20800 solver.cpp:245]     Train net output #0: accuracy = 0.939476
I0227 06:56:02.136134 20800 solver.cpp:245]     Train net output #1: accuracy = 0.929744
I0227 06:56:02.136142 20800 solver.cpp:245]     Train net output #2: accuracy = 0.841254
I0227 06:56:02.136150 20800 sgd_solver.cpp:106] Iteration 9820, lr = 0.00054456
I0227 06:56:19.417604 20800 solver.cpp:229] Iteration 9840, loss = 0.15306
I0227 06:56:19.417634 20800 solver.cpp:245]     Train net output #0: accuracy = 0.929566
I0227 06:56:19.417642 20800 solver.cpp:245]     Train net output #1: accuracy = 0.867828
I0227 06:56:19.417649 20800 solver.cpp:245]     Train net output #2: accuracy = 0.830418
I0227 06:56:19.417659 20800 sgd_solver.cpp:106] Iteration 9840, lr = 0.000543597
I0227 06:56:36.688892 20800 solver.cpp:229] Iteration 9860, loss = 0.150736
I0227 06:56:36.688940 20800 solver.cpp:245]     Train net output #0: accuracy = 0.918382
I0227 06:56:36.688948 20800 solver.cpp:245]     Train net output #1: accuracy = 0.68899
I0227 06:56:36.688956 20800 solver.cpp:245]     Train net output #2: accuracy = 0.745786
I0227 06:56:36.688964 20800 sgd_solver.cpp:106] Iteration 9860, lr = 0.000542634
I0227 06:56:53.954365 20800 solver.cpp:229] Iteration 9880, loss = 0.142179
I0227 06:56:53.954411 20800 solver.cpp:245]     Train net output #0: accuracy = 0.928205
I0227 06:56:53.954419 20800 solver.cpp:245]     Train net output #1: accuracy = 0.673183
I0227 06:56:53.954427 20800 solver.cpp:245]     Train net output #2: accuracy = 0.798112
I0227 06:56:53.954435 20800 sgd_solver.cpp:106] Iteration 9880, lr = 0.000541671
I0227 06:57:11.245496 20800 solver.cpp:229] Iteration 9900, loss = 0.156052
I0227 06:57:11.245528 20800 solver.cpp:245]     Train net output #0: accuracy = 0.941027
I0227 06:57:11.245538 20800 solver.cpp:245]     Train net output #1: accuracy = 0.671745
I0227 06:57:11.245545 20800 solver.cpp:245]     Train net output #2: accuracy = 0.720024
I0227 06:57:11.245555 20800 sgd_solver.cpp:106] Iteration 9900, lr = 0.000540707
I0227 06:57:28.524448 20800 solver.cpp:229] Iteration 9920, loss = 0.173376
I0227 06:57:28.524494 20800 solver.cpp:245]     Train net output #0: accuracy = 0.937883
I0227 06:57:28.524503 20800 solver.cpp:245]     Train net output #1: accuracy = 0.76882
I0227 06:57:28.524510 20800 solver.cpp:245]     Train net output #2: accuracy = 0.715275
I0227 06:57:28.524519 20800 sgd_solver.cpp:106] Iteration 9920, lr = 0.000539744
I0227 06:57:45.812501 20800 solver.cpp:229] Iteration 9940, loss = 0.141824
I0227 06:57:45.812532 20800 solver.cpp:245]     Train net output #0: accuracy = 0.948483
I0227 06:57:45.812541 20800 solver.cpp:245]     Train net output #1: accuracy = 0.769361
I0227 06:57:45.812548 20800 solver.cpp:245]     Train net output #2: accuracy = 0.814707
I0227 06:57:45.812558 20800 sgd_solver.cpp:106] Iteration 9940, lr = 0.00053878
I0227 06:58:03.094208 20800 solver.cpp:229] Iteration 9960, loss = 0.145124
I0227 06:58:03.094254 20800 solver.cpp:245]     Train net output #0: accuracy = 0.9605
I0227 06:58:03.094262 20800 solver.cpp:245]     Train net output #1: accuracy = 0.894353
I0227 06:58:03.094269 20800 solver.cpp:245]     Train net output #2: accuracy = 0.825818
I0227 06:58:03.094280 20800 sgd_solver.cpp:106] Iteration 9960, lr = 0.000537816
I0227 06:58:20.390839 20800 solver.cpp:229] Iteration 9980, loss = 0.154167
I0227 06:58:20.390892 20800 solver.cpp:245]     Train net output #0: accuracy = 0.954343
I0227 06:58:20.390902 20800 solver.cpp:245]     Train net output #1: accuracy = 0.676707
I0227 06:58:20.390910 20800 solver.cpp:245]     Train net output #2: accuracy = 0.737476
I0227 06:58:20.390920 20800 sgd_solver.cpp:106] Iteration 9980, lr = 0.000536851
I0227 06:58:36.877271 20800 solver.cpp:456] Snapshotting to binary proto file models/model-f_iter_10000.caffemodel
I0227 06:58:37.898274 20800 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/model-f_iter_10000.solverstate
I0227 06:58:38.548219 20800 solver.cpp:229] Iteration 10000, loss = 0.158241
I0227 06:58:38.548264 20800 solver.cpp:245]     Train net output #0: accuracy = 0.925203
I0227 06:58:38.548271 20800 solver.cpp:245]     Train net output #1: accuracy = 0.753418
I0227 06:58:38.548279 20800 solver.cpp:245]     Train net output #2: accuracy = 0.841851
I0227 06:58:38.548287 20800 sgd_solver.cpp:106] Iteration 10000, lr = 0.000535887
I0227 06:58:55.811576 20800 solver.cpp:229] Iteration 10020, loss = 0.159446
I0227 06:58:55.811621 20800 solver.cpp:245]     Train net output #0: accuracy = 0.935738
I0227 06:58:55.811630 20800 solver.cpp:245]     Train net output #1: accuracy = 0.861486
I0227 06:58:55.811651 20800 solver.cpp:245]     Train net output #2: accuracy = 0.817828
I0227 06:58:55.811661 20800 sgd_solver.cpp:106] Iteration 10020, lr = 0.000534922
I0227 06:59:13.072932 20800 solver.cpp:229] Iteration 10040, loss = 0.143054
I0227 06:59:13.072978 20800 solver.cpp:245]     Train net output #0: accuracy = 0.948959
I0227 06:59:13.072985 20800 solver.cpp:245]     Train net output #1: accuracy = 0.665781
I0227 06:59:13.072993 20800 solver.cpp:245]     Train net output #2: accuracy = 0.742971
I0227 06:59:13.073001 20800 sgd_solver.cpp:106] Iteration 10040, lr = 0.000533957
I0227 06:59:30.321228 20800 solver.cpp:229] Iteration 10060, loss = 0.137833
I0227 06:59:30.321272 20800 solver.cpp:245]     Train net output #0: accuracy = 0.924033
I0227 06:59:30.321281 20800 solver.cpp:245]     Train net output #1: accuracy = 0.821178
I0227 06:59:30.321288 20800 solver.cpp:245]     Train net output #2: accuracy = 0.783332
I0227 06:59:30.321297 20800 sgd_solver.cpp:106] Iteration 10060, lr = 0.000532992
I0227 06:59:47.576469 20800 solver.cpp:229] Iteration 10080, loss = 0.144883
I0227 06:59:47.576499 20800 solver.cpp:245]     Train net output #0: accuracy = 0.936294
I0227 06:59:47.576508 20800 solver.cpp:245]     Train net output #1: accuracy = 0.864676
I0227 06:59:47.576515 20800 solver.cpp:245]     Train net output #2: accuracy = 0.770813
I0227 06:59:47.576525 20800 sgd_solver.cpp:106] Iteration 10080, lr = 0.000532027
I0227 07:00:04.834298 20800 solver.cpp:229] Iteration 10100, loss = 0.141125
I0227 07:00:04.834326 20800 solver.cpp:245]     Train net output #0: accuracy = 0.949554
I0227 07:00:04.834352 20800 solver.cpp:245]     Train net output #1: accuracy = 0.783709
I0227 07:00:04.834360 20800 solver.cpp:245]     Train net output #2: accuracy = 0.799285
I0227 07:00:04.834370 20800 sgd_solver.cpp:106] Iteration 10100, lr = 0.000531061
I0227 07:00:22.094240 20800 solver.cpp:229] Iteration 10120, loss = 0.151847
I0227 07:00:22.094269 20800 solver.cpp:245]     Train net output #0: accuracy = 0.936526
I0227 07:00:22.094277 20800 solver.cpp:245]     Train net output #1: accuracy = 0.834344
I0227 07:00:22.094285 20800 solver.cpp:245]     Train net output #2: accuracy = 0.795627
I0227 07:00:22.094295 20800 sgd_solver.cpp:106] Iteration 10120, lr = 0.000530096
I0227 07:00:39.380396 20800 solver.cpp:229] Iteration 10140, loss = 0.147585
I0227 07:00:39.380441 20800 solver.cpp:245]     Train net output #0: accuracy = 0.953377
I0227 07:00:39.380450 20800 solver.cpp:245]     Train net output #1: accuracy = 0.682426
I0227 07:00:39.380456 20800 solver.cpp:245]     Train net output #2: accuracy = 0.694159
I0227 07:00:39.380465 20800 sgd_solver.cpp:106] Iteration 10140, lr = 0.00052913
I0227 07:00:56.664743 20800 solver.cpp:229] Iteration 10160, loss = 0.158095
I0227 07:00:56.664801 20800 solver.cpp:245]     Train net output #0: accuracy = 0.954075
I0227 07:00:56.664810 20800 solver.cpp:245]     Train net output #1: accuracy = 0.67479
I0227 07:00:56.664818 20800 solver.cpp:245]     Train net output #2: accuracy = 0.763358
I0227 07:00:56.664826 20800 sgd_solver.cpp:106] Iteration 10160, lr = 0.000528164
I0227 07:01:13.922123 20800 solver.cpp:229] Iteration 10180, loss = 0.140296
I0227 07:01:13.922168 20800 solver.cpp:245]     Train net output #0: accuracy = 0.941285
I0227 07:01:13.922176 20800 solver.cpp:245]     Train net output #1: accuracy = 0.831856
I0227 07:01:13.922183 20800 solver.cpp:245]     Train net output #2: accuracy = 0.841414
I0227 07:01:13.922192 20800 sgd_solver.cpp:106] Iteration 10180, lr = 0.000527198
I0227 07:01:31.186883 20800 solver.cpp:229] Iteration 10200, loss = 0.144481
I0227 07:01:31.186926 20800 solver.cpp:245]     Train net output #0: accuracy = 0.93558
I0227 07:01:31.186935 20800 solver.cpp:245]     Train net output #1: accuracy = 0.739074
I0227 07:01:31.186941 20800 solver.cpp:245]     Train net output #2: accuracy = 0.855711
I0227 07:01:31.186951 20800 sgd_solver.cpp:106] Iteration 10200, lr = 0.000526231
I0227 07:01:48.441339 20800 solver.cpp:229] Iteration 10220, loss = 0.144167
I0227 07:01:48.441370 20800 solver.cpp:245]     Train net output #0: accuracy = 0.929209
I0227 07:01:48.441380 20800 solver.cpp:245]     Train net output #1: accuracy = 0.715902
I0227 07:01:48.441385 20800 solver.cpp:245]     Train net output #2: accuracy = 0.710747
I0227 07:01:48.441395 20800 sgd_solver.cpp:106] Iteration 10220, lr = 0.000525264
I0227 07:02:05.714417 20800 solver.cpp:229] Iteration 10240, loss = 0.138898
I0227 07:02:05.714445 20800 solver.cpp:245]     Train net output #0: accuracy = 0.923371
I0227 07:02:05.714453 20800 solver.cpp:245]     Train net output #1: accuracy = 0.759818
I0227 07:02:05.714460 20800 solver.cpp:245]     Train net output #2: accuracy = 0.801406
I0227 07:02:05.714469 20800 sgd_solver.cpp:106] Iteration 10240, lr = 0.000524298
I0227 07:02:22.990113 20800 solver.cpp:229] Iteration 10260, loss = 0.157116
I0227 07:02:22.990157 20800 solver.cpp:245]     Train net output #0: accuracy = 0.956038
I0227 07:02:22.990165 20800 solver.cpp:245]     Train net output #1: accuracy = 0.87463
I0227 07:02:22.990172 20800 solver.cpp:245]     Train net output #2: accuracy = 0.893913
I0227 07:02:22.990181 20800 sgd_solver.cpp:106] Iteration 10260, lr = 0.000523331
I0227 07:02:40.263315 20800 solver.cpp:229] Iteration 10280, loss = 0.146974
I0227 07:02:40.263361 20800 solver.cpp:245]     Train net output #0: accuracy = 0.922301
I0227 07:02:40.263370 20800 solver.cpp:245]     Train net output #1: accuracy = 0.739349
I0227 07:02:40.263377 20800 solver.cpp:245]     Train net output #2: accuracy = 0.720284
I0227 07:02:40.263387 20800 sgd_solver.cpp:106] Iteration 10280, lr = 0.000522363
I0227 07:02:57.566000 20800 solver.cpp:229] Iteration 10300, loss = 0.150729
I0227 07:02:57.566031 20800 solver.cpp:245]     Train net output #0: accuracy = 0.924623
I0227 07:02:57.566040 20800 solver.cpp:245]     Train net output #1: accuracy = 0.830267
I0227 07:02:57.566047 20800 solver.cpp:245]     Train net output #2: accuracy = 0.785067
I0227 07:02:57.566056 20800 sgd_solver.cpp:106] Iteration 10300, lr = 0.000521396
I0227 07:03:14.851845 20800 solver.cpp:229] Iteration 10320, loss = 0.160495
I0227 07:03:14.851874 20800 solver.cpp:245]     Train net output #0: accuracy = 0.929506
I0227 07:03:14.851882 20800 solver.cpp:245]     Train net output #1: accuracy = 0.88629
I0227 07:03:14.851889 20800 solver.cpp:245]     Train net output #2: accuracy = 0.880374
I0227 07:03:14.851900 20800 sgd_solver.cpp:106] Iteration 10320, lr = 0.000520428
I0227 07:03:32.123797 20800 solver.cpp:229] Iteration 10340, loss = 0.138655
I0227 07:03:32.123842 20800 solver.cpp:245]     Train net output #0: accuracy = 0.944388
I0227 07:03:32.123850 20800 solver.cpp:245]     Train net output #1: accuracy = 0.881178
I0227 07:03:32.123857 20800 solver.cpp:245]     Train net output #2: accuracy = 0.868275
I0227 07:03:32.123867 20800 sgd_solver.cpp:106] Iteration 10340, lr = 0.00051946
I0227 07:03:49.394704 20800 solver.cpp:229] Iteration 10360, loss = 0.158187
I0227 07:03:49.394748 20800 solver.cpp:245]     Train net output #0: accuracy = 0.921215
I0227 07:03:49.394757 20800 solver.cpp:245]     Train net output #1: accuracy = 0.689532
I0227 07:03:49.394764 20800 solver.cpp:245]     Train net output #2: accuracy = 0.701155
I0227 07:03:49.394774 20800 sgd_solver.cpp:106] Iteration 10360, lr = 0.000518492
I0227 07:04:06.679888 20800 solver.cpp:229] Iteration 10380, loss = 0.142559
I0227 07:04:06.679949 20800 solver.cpp:245]     Train net output #0: accuracy = 0.946639
I0227 07:04:06.679956 20800 solver.cpp:245]     Train net output #1: accuracy = 0.910675
I0227 07:04:06.679963 20800 solver.cpp:245]     Train net output #2: accuracy = 0.841986
I0227 07:04:06.679972 20800 sgd_solver.cpp:106] Iteration 10380, lr = 0.000517524
I0227 07:04:23.930394 20800 solver.cpp:229] Iteration 10400, loss = 0.153413
I0227 07:04:23.930426 20800 solver.cpp:245]     Train net output #0: accuracy = 0.933124
I0227 07:04:23.930435 20800 solver.cpp:245]     Train net output #1: accuracy = 0.882325
I0227 07:04:23.930443 20800 solver.cpp:245]     Train net output #2: accuracy = 0.812667
I0227 07:04:23.930452 20800 sgd_solver.cpp:106] Iteration 10400, lr = 0.000516556
I0227 07:04:41.205438 20800 solver.cpp:229] Iteration 10420, loss = 0.156199
I0227 07:04:41.205483 20800 solver.cpp:245]     Train net output #0: accuracy = 0.948214
I0227 07:04:41.205508 20800 solver.cpp:245]     Train net output #1: accuracy = 0.938167
I0227 07:04:41.205515 20800 solver.cpp:245]     Train net output #2: accuracy = 0.575422
I0227 07:04:41.205525 20800 sgd_solver.cpp:106] Iteration 10420, lr = 0.000515587
I0227 07:04:58.512691 20800 solver.cpp:229] Iteration 10440, loss = 0.144864
I0227 07:04:58.512738 20800 solver.cpp:245]     Train net output #0: accuracy = 0.947472
I0227 07:04:58.512748 20800 solver.cpp:245]     Train net output #1: accuracy = 0.926703
I0227 07:04:58.512755 20800 solver.cpp:245]     Train net output #2: accuracy = 0.93161
I0227 07:04:58.512765 20800 sgd_solver.cpp:106] Iteration 10440, lr = 0.000514618
I0227 07:05:15.774507 20800 solver.cpp:229] Iteration 10460, loss = 0.15241
I0227 07:05:15.774550 20800 solver.cpp:245]     Train net output #0: accuracy = 0.934503
I0227 07:05:15.774559 20800 solver.cpp:245]     Train net output #1: accuracy = 0.72271
I0227 07:05:15.774566 20800 solver.cpp:245]     Train net output #2: accuracy = 0.694401
I0227 07:05:15.774575 20800 sgd_solver.cpp:106] Iteration 10460, lr = 0.000513649
I0227 07:05:33.040760 20800 solver.cpp:229] Iteration 10480, loss = 0.148113
I0227 07:05:33.040789 20800 solver.cpp:245]     Train net output #0: accuracy = 0.944438
I0227 07:05:33.040798 20800 solver.cpp:245]     Train net output #1: accuracy = 0.739619
I0227 07:05:33.040805 20800 solver.cpp:245]     Train net output #2: accuracy = 0.777707
I0227 07:05:33.040814 20800 sgd_solver.cpp:106] Iteration 10480, lr = 0.00051268
I0227 07:05:50.295161 20800 solver.cpp:229] Iteration 10500, loss = 0.165134
I0227 07:05:50.295192 20800 solver.cpp:245]     Train net output #0: accuracy = 0.912374
I0227 07:05:50.295200 20800 solver.cpp:245]     Train net output #1: accuracy = 0.883221
I0227 07:05:50.295207 20800 solver.cpp:245]     Train net output #2: accuracy = 0.872011
I0227 07:05:50.295231 20800 sgd_solver.cpp:106] Iteration 10500, lr = 0.00051171
I0227 07:06:07.580559 20800 solver.cpp:229] Iteration 10520, loss = 0.157691
I0227 07:06:07.580603 20800 solver.cpp:245]     Train net output #0: accuracy = 0.900447
I0227 07:06:07.580613 20800 solver.cpp:245]     Train net output #1: accuracy = 0.856973
I0227 07:06:07.580619 20800 solver.cpp:245]     Train net output #2: accuracy = 0.726568
I0227 07:06:07.580629 20800 sgd_solver.cpp:106] Iteration 10520, lr = 0.000510741
I0227 07:06:24.840981 20800 solver.cpp:229] Iteration 10540, loss = 0.15571
I0227 07:06:24.841027 20800 solver.cpp:245]     Train net output #0: accuracy = 0.918619
I0227 07:06:24.841035 20800 solver.cpp:245]     Train net output #1: accuracy = 0.768475
I0227 07:06:24.841042 20800 solver.cpp:245]     Train net output #2: accuracy = 0.624853
I0227 07:06:24.841053 20800 sgd_solver.cpp:106] Iteration 10540, lr = 0.000509771
I0227 07:06:42.093856 20800 solver.cpp:229] Iteration 10560, loss = 0.152327
I0227 07:06:42.093888 20800 solver.cpp:245]     Train net output #0: accuracy = 0.941194
I0227 07:06:42.093899 20800 solver.cpp:245]     Train net output #1: accuracy = 0.808152
I0227 07:06:42.093905 20800 solver.cpp:245]     Train net output #2: accuracy = 0.695058
I0227 07:06:42.093914 20800 sgd_solver.cpp:106] Iteration 10560, lr = 0.000508801
I0227 07:06:59.358073 20800 solver.cpp:229] Iteration 10580, loss = 0.153615
I0227 07:06:59.358120 20800 solver.cpp:245]     Train net output #0: accuracy = 0.922665
I0227 07:06:59.358129 20800 solver.cpp:245]     Train net output #1: accuracy = 0.754647
I0227 07:06:59.358136 20800 solver.cpp:245]     Train net output #2: accuracy = 0.731049
I0227 07:06:59.358147 20800 sgd_solver.cpp:106] Iteration 10580, lr = 0.000507831
I0227 07:07:16.630683 20800 solver.cpp:229] Iteration 10600, loss = 0.142573
I0227 07:07:16.630728 20800 solver.cpp:245]     Train net output #0: accuracy = 0.932155
I0227 07:07:16.630736 20800 solver.cpp:245]     Train net output #1: accuracy = 0.886733
I0227 07:07:16.630743 20800 solver.cpp:245]     Train net output #2: accuracy = 0.819927
I0227 07:07:16.630753 20800 sgd_solver.cpp:106] Iteration 10600, lr = 0.00050686
I0227 07:07:33.907279 20800 solver.cpp:229] Iteration 10620, loss = 0.143028
I0227 07:07:33.907306 20800 solver.cpp:245]     Train net output #0: accuracy = 0.957871
I0227 07:07:33.907315 20800 solver.cpp:245]     Train net output #1: accuracy = 0.810813
I0227 07:07:33.907322 20800 solver.cpp:245]     Train net output #2: accuracy = 0.77258
I0227 07:07:33.907332 20800 sgd_solver.cpp:106] Iteration 10620, lr = 0.000505889
I0227 07:07:51.188848 20800 solver.cpp:229] Iteration 10640, loss = 0.144544
I0227 07:07:51.188892 20800 solver.cpp:245]     Train net output #0: accuracy = 0.961511
I0227 07:07:51.188901 20800 solver.cpp:245]     Train net output #1: accuracy = 0.826195
I0227 07:07:51.188910 20800 solver.cpp:245]     Train net output #2: accuracy = 0.872087
I0227 07:07:51.188918 20800 sgd_solver.cpp:106] Iteration 10640, lr = 0.000504919
I0227 07:08:08.469485 20800 solver.cpp:229] Iteration 10660, loss = 0.148491
I0227 07:08:08.469514 20800 solver.cpp:245]     Train net output #0: accuracy = 0.957212
I0227 07:08:08.469523 20800 solver.cpp:245]     Train net output #1: accuracy = 0.817205
I0227 07:08:08.469530 20800 solver.cpp:245]     Train net output #2: accuracy = 0.68796
I0227 07:08:08.469539 20800 sgd_solver.cpp:106] Iteration 10660, lr = 0.000503947
I0227 07:08:25.741844 20800 solver.cpp:229] Iteration 10680, loss = 0.136995
I0227 07:08:25.741888 20800 solver.cpp:245]     Train net output #0: accuracy = 0.932008
I0227 07:08:25.741897 20800 solver.cpp:245]     Train net output #1: accuracy = 0.808199
I0227 07:08:25.741904 20800 solver.cpp:245]     Train net output #2: accuracy = 0.768869
I0227 07:08:25.741914 20800 sgd_solver.cpp:106] Iteration 10680, lr = 0.000502976
I0227 07:08:43.007860 20800 solver.cpp:229] Iteration 10700, loss = 0.136711
I0227 07:08:43.007890 20800 solver.cpp:245]     Train net output #0: accuracy = 0.969899
I0227 07:08:43.007899 20800 solver.cpp:245]     Train net output #1: accuracy = 0.926796
I0227 07:08:43.007906 20800 solver.cpp:245]     Train net output #2: accuracy = 0.806614
I0227 07:08:43.007916 20800 sgd_solver.cpp:106] Iteration 10700, lr = 0.000502005
I0227 07:09:00.298480 20800 solver.cpp:229] Iteration 10720, loss = 0.134903
I0227 07:09:00.298542 20800 solver.cpp:245]     Train net output #0: accuracy = 0.952317
I0227 07:09:00.298550 20800 solver.cpp:245]     Train net output #1: accuracy = 0.90989
I0227 07:09:00.298558 20800 solver.cpp:245]     Train net output #2: accuracy = 0.901637
I0227 07:09:00.298568 20800 sgd_solver.cpp:106] Iteration 10720, lr = 0.000501033
I0227 07:09:17.582557 20800 solver.cpp:229] Iteration 10740, loss = 0.151954
I0227 07:09:17.582587 20800 solver.cpp:245]     Train net output #0: accuracy = 0.930101
I0227 07:09:17.582597 20800 solver.cpp:245]     Train net output #1: accuracy = 0.845261
I0227 07:09:17.582604 20800 solver.cpp:245]     Train net output #2: accuracy = 0.775027
I0227 07:09:17.582628 20800 sgd_solver.cpp:106] Iteration 10740, lr = 0.000500061
I0227 07:09:34.860116 20800 solver.cpp:229] Iteration 10760, loss = 0.153744
I0227 07:09:34.860162 20800 solver.cpp:245]     Train net output #0: accuracy = 0.935378
I0227 07:09:34.860170 20800 solver.cpp:245]     Train net output #1: accuracy = 0.811382
I0227 07:09:34.860177 20800 solver.cpp:245]     Train net output #2: accuracy = 0.771368
I0227 07:09:34.860188 20800 sgd_solver.cpp:106] Iteration 10760, lr = 0.000499089
I0227 07:09:52.138931 20800 solver.cpp:229] Iteration 10780, loss = 0.140495
I0227 07:09:52.138976 20800 solver.cpp:245]     Train net output #0: accuracy = 0.915586
I0227 07:09:52.138985 20800 solver.cpp:245]     Train net output #1: accuracy = 0.846362
I0227 07:09:52.138993 20800 solver.cpp:245]     Train net output #2: accuracy = 0.725643
I0227 07:09:52.139003 20800 sgd_solver.cpp:106] Iteration 10780, lr = 0.000498116
I0227 07:10:09.419554 20800 solver.cpp:229] Iteration 10800, loss = 0.154605
I0227 07:10:09.419600 20800 solver.cpp:245]     Train net output #0: accuracy = 0.943605
I0227 07:10:09.419610 20800 solver.cpp:245]     Train net output #1: accuracy = 0.861649
I0227 07:10:09.419617 20800 solver.cpp:245]     Train net output #2: accuracy = 0.840265
I0227 07:10:09.419626 20800 sgd_solver.cpp:106] Iteration 10800, lr = 0.000497144
I0227 07:10:26.714068 20800 solver.cpp:229] Iteration 10820, loss = 0.149482
I0227 07:10:26.714112 20800 solver.cpp:245]     Train net output #0: accuracy = 0.951966
I0227 07:10:26.714121 20800 solver.cpp:245]     Train net output #1: accuracy = 0.790803
I0227 07:10:26.714128 20800 solver.cpp:245]     Train net output #2: accuracy = 0.62924
I0227 07:10:26.714138 20800 sgd_solver.cpp:106] Iteration 10820, lr = 0.000496171
I0227 07:10:43.980415 20800 solver.cpp:229] Iteration 10840, loss = 0.128665
I0227 07:10:43.980461 20800 solver.cpp:245]     Train net output #0: accuracy = 0.948523
I0227 07:10:43.980471 20800 solver.cpp:245]     Train net output #1: accuracy = 0.828152
I0227 07:10:43.980479 20800 solver.cpp:245]     Train net output #2: accuracy = 0.798279
I0227 07:10:43.980489 20800 sgd_solver.cpp:106] Iteration 10840, lr = 0.000495198
I0227 07:11:01.252890 20800 solver.cpp:229] Iteration 10860, loss = 0.154605
I0227 07:11:01.252934 20800 solver.cpp:245]     Train net output #0: accuracy = 0.952588
I0227 07:11:01.252943 20800 solver.cpp:245]     Train net output #1: accuracy = 0.915067
I0227 07:11:01.252950 20800 solver.cpp:245]     Train net output #2: accuracy = 0.806651
I0227 07:11:01.252959 20800 sgd_solver.cpp:106] Iteration 10860, lr = 0.000494225
I0227 07:11:18.503511 20800 solver.cpp:229] Iteration 10880, loss = 0.148945
I0227 07:11:18.503542 20800 solver.cpp:245]     Train net output #0: accuracy = 0.954007
I0227 07:11:18.503551 20800 solver.cpp:245]     Train net output #1: accuracy = 0.762914
I0227 07:11:18.503558 20800 solver.cpp:245]     Train net output #2: accuracy = 0.862247
I0227 07:11:18.503567 20800 sgd_solver.cpp:106] Iteration 10880, lr = 0.000493251
I0227 07:11:35.765497 20800 solver.cpp:229] Iteration 10900, loss = 0.142054
I0227 07:11:35.765528 20800 solver.cpp:245]     Train net output #0: accuracy = 0.941761
I0227 07:11:35.765537 20800 solver.cpp:245]     Train net output #1: accuracy = 0.897714
I0227 07:11:35.765545 20800 solver.cpp:245]     Train net output #2: accuracy = 0.874044
I0227 07:11:35.765555 20800 sgd_solver.cpp:106] Iteration 10900, lr = 0.000492278
I0227 07:11:53.037189 20800 solver.cpp:229] Iteration 10920, loss = 0.135823
I0227 07:11:53.037235 20800 solver.cpp:245]     Train net output #0: accuracy = 0.958001
I0227 07:11:53.037243 20800 solver.cpp:245]     Train net output #1: accuracy = 0.951231
I0227 07:11:53.037250 20800 solver.cpp:245]     Train net output #2: accuracy = 0.857008
I0227 07:11:53.037259 20800 sgd_solver.cpp:106] Iteration 10920, lr = 0.000491304
I0227 07:12:10.334722 20800 solver.cpp:229] Iteration 10940, loss = 0.143283
I0227 07:12:10.334766 20800 solver.cpp:245]     Train net output #0: accuracy = 0.950982
I0227 07:12:10.334775 20800 solver.cpp:245]     Train net output #1: accuracy = 0.855428
I0227 07:12:10.334782 20800 solver.cpp:245]     Train net output #2: accuracy = 0.918027
I0227 07:12:10.334791 20800 sgd_solver.cpp:106] Iteration 10940, lr = 0.00049033
I0227 07:12:27.610464 20800 solver.cpp:229] Iteration 10960, loss = 0.143754
I0227 07:12:27.610507 20800 solver.cpp:245]     Train net output #0: accuracy = 0.929622
I0227 07:12:27.610524 20800 solver.cpp:245]     Train net output #1: accuracy = 0.863891
I0227 07:12:27.610548 20800 solver.cpp:245]     Train net output #2: accuracy = 0.789444
I0227 07:12:27.610564 20800 sgd_solver.cpp:106] Iteration 10960, lr = 0.000489356
I0227 07:12:44.880899 20800 solver.cpp:229] Iteration 10980, loss = 0.138471
I0227 07:12:44.880945 20800 solver.cpp:245]     Train net output #0: accuracy = 0.905354
I0227 07:12:44.880954 20800 solver.cpp:245]     Train net output #1: accuracy = 0.663046
I0227 07:12:44.880961 20800 solver.cpp:245]     Train net output #2: accuracy = 0.70193
I0227 07:12:44.880970 20800 sgd_solver.cpp:106] Iteration 10980, lr = 0.000488381
I0227 07:13:02.160671 20800 solver.cpp:229] Iteration 11000, loss = 0.145735
I0227 07:13:02.160717 20800 solver.cpp:245]     Train net output #0: accuracy = 0.95354
I0227 07:13:02.160727 20800 solver.cpp:245]     Train net output #1: accuracy = 0.8801
I0227 07:13:02.160733 20800 solver.cpp:245]     Train net output #2: accuracy = 0.709033
I0227 07:13:02.160743 20800 sgd_solver.cpp:106] Iteration 11000, lr = 0.000487406
I0227 07:13:19.446821 20800 solver.cpp:229] Iteration 11020, loss = 0.143739
I0227 07:13:19.446852 20800 solver.cpp:245]     Train net output #0: accuracy = 0.931529
I0227 07:13:19.446861 20800 solver.cpp:245]     Train net output #1: accuracy = 0.785376
I0227 07:13:19.446868 20800 solver.cpp:245]     Train net output #2: accuracy = 0.829519
I0227 07:13:19.446905 20800 sgd_solver.cpp:106] Iteration 11020, lr = 0.000486432
I0227 07:13:36.705319 20800 solver.cpp:229] Iteration 11040, loss = 0.136719
I0227 07:13:36.705349 20800 solver.cpp:245]     Train net output #0: accuracy = 0.918639
I0227 07:13:36.705358 20800 solver.cpp:245]     Train net output #1: accuracy = 0.834297
I0227 07:13:36.705365 20800 solver.cpp:245]     Train net output #2: accuracy = 0.815443
I0227 07:13:36.705375 20800 sgd_solver.cpp:106] Iteration 11040, lr = 0.000485456
I0227 07:13:53.968379 20800 solver.cpp:229] Iteration 11060, loss = 0.155877
I0227 07:13:53.968410 20800 solver.cpp:245]     Train net output #0: accuracy = 0.922016
I0227 07:13:53.968420 20800 solver.cpp:245]     Train net output #1: accuracy = 0.809181
I0227 07:13:53.968426 20800 solver.cpp:245]     Train net output #2: accuracy = 0.856222
I0227 07:13:53.968436 20800 sgd_solver.cpp:106] Iteration 11060, lr = 0.000484481
I0227 07:14:11.235874 20800 solver.cpp:229] Iteration 11080, loss = 0.139074
I0227 07:14:11.235920 20800 solver.cpp:245]     Train net output #0: accuracy = 0.926353
I0227 07:14:11.235929 20800 solver.cpp:245]     Train net output #1: accuracy = 0.826356
I0227 07:14:11.235936 20800 solver.cpp:245]     Train net output #2: accuracy = 0.750539
I0227 07:14:11.235945 20800 sgd_solver.cpp:106] Iteration 11080, lr = 0.000483505
I0227 07:14:28.506820 20800 solver.cpp:229] Iteration 11100, loss = 0.13898
I0227 07:14:28.506866 20800 solver.cpp:245]     Train net output #0: accuracy = 0.956013
I0227 07:14:28.506884 20800 solver.cpp:245]     Train net output #1: accuracy = 0.84185
I0227 07:14:28.506892 20800 solver.cpp:245]     Train net output #2: accuracy = 0.812969
I0227 07:14:28.506903 20800 sgd_solver.cpp:106] Iteration 11100, lr = 0.00048253
I0227 07:14:45.783085 20800 solver.cpp:229] Iteration 11120, loss = 0.14958
I0227 07:14:45.783129 20800 solver.cpp:245]     Train net output #0: accuracy = 0.95586
I0227 07:14:45.783138 20800 solver.cpp:245]     Train net output #1: accuracy = 0.668433
I0227 07:14:45.783145 20800 solver.cpp:245]     Train net output #2: accuracy = 0.768324
I0227 07:14:45.783155 20800 sgd_solver.cpp:106] Iteration 11120, lr = 0.000481554
I0227 07:15:03.063469 20800 solver.cpp:229] Iteration 11140, loss = 0.144941
I0227 07:15:03.063500 20800 solver.cpp:245]     Train net output #0: accuracy = 0.919543
I0227 07:15:03.063509 20800 solver.cpp:245]     Train net output #1: accuracy = 0.637746
I0227 07:15:03.063516 20800 solver.cpp:245]     Train net output #2: accuracy = 0.688729
I0227 07:15:03.063525 20800 sgd_solver.cpp:106] Iteration 11140, lr = 0.000480577
I0227 07:15:20.353474 20800 solver.cpp:229] Iteration 11160, loss = 0.147114
I0227 07:15:20.353505 20800 solver.cpp:245]     Train net output #0: accuracy = 0.924504
I0227 07:15:20.353514 20800 solver.cpp:245]     Train net output #1: accuracy = 0.785691
I0227 07:15:20.353523 20800 solver.cpp:245]     Train net output #2: accuracy = 0.838433
I0227 07:15:20.353533 20800 sgd_solver.cpp:106] Iteration 11160, lr = 0.000479601
I0227 07:15:37.626961 20800 solver.cpp:229] Iteration 11180, loss = 0.141718
I0227 07:15:37.626991 20800 solver.cpp:245]     Train net output #0: accuracy = 0.95805
I0227 07:15:37.627001 20800 solver.cpp:245]     Train net output #1: accuracy = 0.825265
I0227 07:15:37.627007 20800 solver.cpp:245]     Train net output #2: accuracy = 0.767152
I0227 07:15:37.627017 20800 sgd_solver.cpp:106] Iteration 11180, lr = 0.000478624
I0227 07:15:54.892874 20800 solver.cpp:229] Iteration 11200, loss = 0.135961
I0227 07:15:54.892920 20800 solver.cpp:245]     Train net output #0: accuracy = 0.921878
I0227 07:15:54.892928 20800 solver.cpp:245]     Train net output #1: accuracy = 0.816725
I0227 07:15:54.892935 20800 solver.cpp:245]     Train net output #2: accuracy = 0.716148
I0227 07:15:54.892946 20800 sgd_solver.cpp:106] Iteration 11200, lr = 0.000477647
I0227 07:16:12.154140 20800 solver.cpp:229] Iteration 11220, loss = 0.135476
I0227 07:16:12.154186 20800 solver.cpp:245]     Train net output #0: accuracy = 0.951457
I0227 07:16:12.154194 20800 solver.cpp:245]     Train net output #1: accuracy = 0.756929
I0227 07:16:12.154201 20800 solver.cpp:245]     Train net output #2: accuracy = 0.763484
I0227 07:16:12.154211 20800 sgd_solver.cpp:106] Iteration 11220, lr = 0.00047667
I0227 07:16:29.457924 20800 solver.cpp:229] Iteration 11240, loss = 0.150473
I0227 07:16:29.457968 20800 solver.cpp:245]     Train net output #0: accuracy = 0.932362
I0227 07:16:29.457978 20800 solver.cpp:245]     Train net output #1: accuracy = 0.917739
I0227 07:16:29.457984 20800 solver.cpp:245]     Train net output #2: accuracy = 0.850066
I0227 07:16:29.457994 20800 sgd_solver.cpp:106] Iteration 11240, lr = 0.000475693
I0227 07:16:46.741410 20800 solver.cpp:229] Iteration 11260, loss = 0.151126
I0227 07:16:46.741470 20800 solver.cpp:245]     Train net output #0: accuracy = 0.937061
I0227 07:16:46.741479 20800 solver.cpp:245]     Train net output #1: accuracy = 0.699208
I0227 07:16:46.741487 20800 solver.cpp:245]     Train net output #2: accuracy = 0.710464
I0227 07:16:46.741497 20800 sgd_solver.cpp:106] Iteration 11260, lr = 0.000474715
I0227 07:17:04.007176 20800 solver.cpp:229] Iteration 11280, loss = 0.157077
I0227 07:17:04.007210 20800 solver.cpp:245]     Train net output #0: accuracy = 0.908566
I0227 07:17:04.007218 20800 solver.cpp:245]     Train net output #1: accuracy = 0.8087
I0227 07:17:04.007225 20800 solver.cpp:245]     Train net output #2: accuracy = 0.783081
I0227 07:17:04.007234 20800 sgd_solver.cpp:106] Iteration 11280, lr = 0.000473738
I0227 07:17:21.269248 20800 solver.cpp:229] Iteration 11300, loss = 0.157978
I0227 07:17:21.269281 20800 solver.cpp:245]     Train net output #0: accuracy = 0.92909
I0227 07:17:21.269290 20800 solver.cpp:245]     Train net output #1: accuracy = 0.682023
I0227 07:17:21.269297 20800 solver.cpp:245]     Train net output #2: accuracy = 0.813169
I0227 07:17:21.269307 20800 sgd_solver.cpp:106] Iteration 11300, lr = 0.00047276
I0227 07:17:38.534155 20800 solver.cpp:229] Iteration 11320, loss = 0.142711
I0227 07:17:38.534183 20800 solver.cpp:245]     Train net output #0: accuracy = 0.942891
I0227 07:17:38.534190 20800 solver.cpp:245]     Train net output #1: accuracy = 0.767254
I0227 07:17:38.534198 20800 solver.cpp:245]     Train net output #2: accuracy = 0.851227
I0227 07:17:38.534205 20800 sgd_solver.cpp:106] Iteration 11320, lr = 0.000471781
I0227 07:17:55.824208 20800 solver.cpp:229] Iteration 11340, loss = 0.139519
I0227 07:17:55.824240 20800 solver.cpp:245]     Train net output #0: accuracy = 0.932124
I0227 07:17:55.824250 20800 solver.cpp:245]     Train net output #1: accuracy = 0.819812
I0227 07:17:55.824256 20800 solver.cpp:245]     Train net output #2: accuracy = 0.883156
I0227 07:17:55.824266 20800 sgd_solver.cpp:106] Iteration 11340, lr = 0.000470803
I0227 07:18:13.095077 20800 solver.cpp:229] Iteration 11360, loss = 0.130177
I0227 07:18:13.095108 20800 solver.cpp:245]     Train net output #0: accuracy = 0.955717
I0227 07:18:13.095115 20800 solver.cpp:245]     Train net output #1: accuracy = 0.80739
I0227 07:18:13.095122 20800 solver.cpp:245]     Train net output #2: accuracy = 0.827022
I0227 07:18:13.095132 20800 sgd_solver.cpp:106] Iteration 11360, lr = 0.000469824
I0227 07:18:30.365891 20800 solver.cpp:229] Iteration 11380, loss = 0.154794
I0227 07:18:30.365937 20800 solver.cpp:245]     Train net output #0: accuracy = 0.953421
I0227 07:18:30.365947 20800 solver.cpp:245]     Train net output #1: accuracy = 0.758685
I0227 07:18:30.365953 20800 solver.cpp:245]     Train net output #2: accuracy = 0.815551
I0227 07:18:30.365963 20800 sgd_solver.cpp:106] Iteration 11380, lr = 0.000468845
I0227 07:18:47.638231 20800 solver.cpp:229] Iteration 11400, loss = 0.15721
I0227 07:18:47.638275 20800 solver.cpp:245]     Train net output #0: accuracy = 0.952171
I0227 07:18:47.638284 20800 solver.cpp:245]     Train net output #1: accuracy = 0.808698
I0227 07:18:47.638291 20800 solver.cpp:245]     Train net output #2: accuracy = 0.751384
I0227 07:18:47.638300 20800 sgd_solver.cpp:106] Iteration 11400, lr = 0.000467866
I0227 07:19:04.895557 20800 solver.cpp:229] Iteration 11420, loss = 0.149675
I0227 07:19:04.895586 20800 solver.cpp:245]     Train net output #0: accuracy = 0.939798
I0227 07:19:04.895596 20800 solver.cpp:245]     Train net output #1: accuracy = 0.711602
I0227 07:19:04.895601 20800 solver.cpp:245]     Train net output #2: accuracy = 0.756841
I0227 07:19:04.895611 20800 sgd_solver.cpp:106] Iteration 11420, lr = 0.000466887
I0227 07:19:22.178225 20800 solver.cpp:229] Iteration 11440, loss = 0.142437
I0227 07:19:22.178252 20800 solver.cpp:245]     Train net output #0: accuracy = 0.95391
I0227 07:19:22.178261 20800 solver.cpp:245]     Train net output #1: accuracy = 0.767003
I0227 07:19:22.178267 20800 solver.cpp:245]     Train net output #2: accuracy = 0.872916
I0227 07:19:22.178277 20800 sgd_solver.cpp:106] Iteration 11440, lr = 0.000465907
I0227 07:19:39.465265 20800 solver.cpp:229] Iteration 11460, loss = 0.146019
I0227 07:19:39.465296 20800 solver.cpp:245]     Train net output #0: accuracy = 0.950089
I0227 07:19:39.465304 20800 solver.cpp:245]     Train net output #1: accuracy = 0.805538
I0227 07:19:39.465312 20800 solver.cpp:245]     Train net output #2: accuracy = 0.841101
I0227 07:19:39.465320 20800 sgd_solver.cpp:106] Iteration 11460, lr = 0.000464927
I0227 07:19:56.739452 20800 solver.cpp:229] Iteration 11480, loss = 0.150087
I0227 07:19:56.739483 20800 solver.cpp:245]     Train net output #0: accuracy = 0.944021
I0227 07:19:56.739492 20800 solver.cpp:245]     Train net output #1: accuracy = 0.676905
I0227 07:19:56.739500 20800 solver.cpp:245]     Train net output #2: accuracy = 0.8067
I0227 07:19:56.739508 20800 sgd_solver.cpp:106] Iteration 11480, lr = 0.000463947
I0227 07:20:14.010958 20800 solver.cpp:229] Iteration 11500, loss = 0.133215
I0227 07:20:14.010988 20800 solver.cpp:245]     Train net output #0: accuracy = 0.955265
I0227 07:20:14.010998 20800 solver.cpp:245]     Train net output #1: accuracy = 0.756813
I0227 07:20:14.011004 20800 solver.cpp:245]     Train net output #2: accuracy = 0.817837
I0227 07:20:14.011014 20800 sgd_solver.cpp:106] Iteration 11500, lr = 0.000462967
I0227 07:20:31.265897 20800 solver.cpp:229] Iteration 11520, loss = 0.14722
I0227 07:20:31.265940 20800 solver.cpp:245]     Train net output #0: accuracy = 0.956692
I0227 07:20:31.265949 20800 solver.cpp:245]     Train net output #1: accuracy = 0.871555
I0227 07:20:31.265955 20800 solver.cpp:245]     Train net output #2: accuracy = 0.932057
I0227 07:20:31.265966 20800 sgd_solver.cpp:106] Iteration 11520, lr = 0.000461987
I0227 07:20:48.549870 20800 solver.cpp:229] Iteration 11540, loss = 0.14566
I0227 07:20:48.549917 20800 solver.cpp:245]     Train net output #0: accuracy = 0.950625
I0227 07:20:48.549943 20800 solver.cpp:245]     Train net output #1: accuracy = 0.843418
I0227 07:20:48.549950 20800 solver.cpp:245]     Train net output #2: accuracy = 0.876229
I0227 07:20:48.549960 20800 sgd_solver.cpp:106] Iteration 11540, lr = 0.000461006
I0227 07:21:05.834312 20800 solver.cpp:229] Iteration 11560, loss = 0.144057
I0227 07:21:05.834343 20800 solver.cpp:245]     Train net output #0: accuracy = 0.962939
I0227 07:21:05.834352 20800 solver.cpp:245]     Train net output #1: accuracy = 0.837786
I0227 07:21:05.834359 20800 solver.cpp:245]     Train net output #2: accuracy = 0.924252
I0227 07:21:05.834369 20800 sgd_solver.cpp:106] Iteration 11560, lr = 0.000460025
I0227 07:21:23.107192 20800 solver.cpp:229] Iteration 11580, loss = 0.142907
I0227 07:21:23.107223 20800 solver.cpp:245]     Train net output #0: accuracy = 0.919598
I0227 07:21:23.107264 20800 solver.cpp:245]     Train net output #1: accuracy = 0.624871
I0227 07:21:23.107272 20800 solver.cpp:245]     Train net output #2: accuracy = 0.764967
I0227 07:21:23.107281 20800 sgd_solver.cpp:106] Iteration 11580, lr = 0.000459044
I0227 07:21:40.368645 20800 solver.cpp:229] Iteration 11600, loss = 0.15498
I0227 07:21:40.368676 20800 solver.cpp:245]     Train net output #0: accuracy = 0.925096
I0227 07:21:40.368685 20800 solver.cpp:245]     Train net output #1: accuracy = 0.80252
I0227 07:21:40.368692 20800 solver.cpp:245]     Train net output #2: accuracy = 0.812678
I0227 07:21:40.368702 20800 sgd_solver.cpp:106] Iteration 11600, lr = 0.000458062
I0227 07:21:57.643052 20800 solver.cpp:229] Iteration 11620, loss = 0.154901
I0227 07:21:57.643081 20800 solver.cpp:245]     Train net output #0: accuracy = 0.922361
I0227 07:21:57.643090 20800 solver.cpp:245]     Train net output #1: accuracy = 0.916429
I0227 07:21:57.643096 20800 solver.cpp:245]     Train net output #2: accuracy = 0.867857
I0227 07:21:57.643106 20800 sgd_solver.cpp:106] Iteration 11620, lr = 0.00045708
I0227 07:22:14.915897 20800 solver.cpp:229] Iteration 11640, loss = 0.130552
I0227 07:22:14.915926 20800 solver.cpp:245]     Train net output #0: accuracy = 0.940386
I0227 07:22:14.915935 20800 solver.cpp:245]     Train net output #1: accuracy = 0.838926
I0227 07:22:14.915942 20800 solver.cpp:245]     Train net output #2: accuracy = 0.863004
I0227 07:22:14.915951 20800 sgd_solver.cpp:106] Iteration 11640, lr = 0.000456099
I0227 07:22:32.203748 20800 solver.cpp:229] Iteration 11660, loss = 0.14196
I0227 07:22:32.203793 20800 solver.cpp:245]     Train net output #0: accuracy = 0.957018
I0227 07:22:32.203801 20800 solver.cpp:245]     Train net output #1: accuracy = 0.938951
I0227 07:22:32.203809 20800 solver.cpp:245]     Train net output #2: accuracy = 0.911646
I0227 07:22:32.203817 20800 sgd_solver.cpp:106] Iteration 11660, lr = 0.000455116
I0227 07:22:49.499161 20800 solver.cpp:229] Iteration 11680, loss = 0.1507
I0227 07:22:49.499192 20800 solver.cpp:245]     Train net output #0: accuracy = 0.945766
I0227 07:22:49.499202 20800 solver.cpp:245]     Train net output #1: accuracy = 0.800725
I0227 07:22:49.499208 20800 solver.cpp:245]     Train net output #2: accuracy = 0.805321
I0227 07:22:49.499218 20800 sgd_solver.cpp:106] Iteration 11680, lr = 0.000454134
I0227 07:23:06.746302 20800 solver.cpp:229] Iteration 11700, loss = 0.143668
I0227 07:23:06.746332 20800 solver.cpp:245]     Train net output #0: accuracy = 0.929744
I0227 07:23:06.746341 20800 solver.cpp:245]     Train net output #1: accuracy = 0.889253
I0227 07:23:06.746348 20800 solver.cpp:245]     Train net output #2: accuracy = 0.881044
I0227 07:23:06.746358 20800 sgd_solver.cpp:106] Iteration 11700, lr = 0.000453151
I0227 07:23:24.022538 20800 solver.cpp:229] Iteration 11720, loss = 0.131117
I0227 07:23:24.022585 20800 solver.cpp:245]     Train net output #0: accuracy = 0.937359
I0227 07:23:24.022594 20800 solver.cpp:245]     Train net output #1: accuracy = 0.724176
I0227 07:23:24.022601 20800 solver.cpp:245]     Train net output #2: accuracy = 0.698333
I0227 07:23:24.022611 20800 sgd_solver.cpp:106] Iteration 11720, lr = 0.000452169
I0227 07:23:41.302011 20800 solver.cpp:229] Iteration 11740, loss = 0.141804
I0227 07:23:41.302057 20800 solver.cpp:245]     Train net output #0: accuracy = 0.955336
I0227 07:23:41.302067 20800 solver.cpp:245]     Train net output #1: accuracy = 0.744203
I0227 07:23:41.302073 20800 solver.cpp:245]     Train net output #2: accuracy = 0.791395
I0227 07:23:41.302083 20800 sgd_solver.cpp:106] Iteration 11740, lr = 0.000451185
I0227 07:23:58.580747 20800 solver.cpp:229] Iteration 11760, loss = 0.144569
I0227 07:23:58.580792 20800 solver.cpp:245]     Train net output #0: accuracy = 0.947353
I0227 07:23:58.580801 20800 solver.cpp:245]     Train net output #1: accuracy = 0.924725
I0227 07:23:58.580808 20800 solver.cpp:245]     Train net output #2: accuracy = 0.766865
I0227 07:23:58.580817 20800 sgd_solver.cpp:106] Iteration 11760, lr = 0.000450202
I0227 07:24:15.854903 20800 solver.cpp:229] Iteration 11780, loss = 0.14563
I0227 07:24:15.854948 20800 solver.cpp:245]     Train net output #0: accuracy = 0.958477
I0227 07:24:15.854959 20800 solver.cpp:245]     Train net output #1: accuracy = 0.957474
I0227 07:24:15.854965 20800 solver.cpp:245]     Train net output #2: accuracy = 0.872379
I0227 07:24:15.854974 20800 sgd_solver.cpp:106] Iteration 11780, lr = 0.000449219
I0227 07:24:33.134914 20800 solver.cpp:229] Iteration 11800, loss = 0.13794
I0227 07:24:33.134944 20800 solver.cpp:245]     Train net output #0: accuracy = 0.944732
I0227 07:24:33.134953 20800 solver.cpp:245]     Train net output #1: accuracy = 0.756299
I0227 07:24:33.134960 20800 solver.cpp:245]     Train net output #2: accuracy = 0.780967
I0227 07:24:33.134970 20800 sgd_solver.cpp:106] Iteration 11800, lr = 0.000448235
I0227 07:24:50.418310 20800 solver.cpp:229] Iteration 11820, loss = 0.146445
I0227 07:24:50.418341 20800 solver.cpp:245]     Train net output #0: accuracy = 0.94304
I0227 07:24:50.418350 20800 solver.cpp:245]     Train net output #1: accuracy = 0.742988
I0227 07:24:50.418357 20800 solver.cpp:245]     Train net output #2: accuracy = 0.782658
I0227 07:24:50.418366 20800 sgd_solver.cpp:106] Iteration 11820, lr = 0.000447251
I0227 07:25:07.688347 20800 solver.cpp:229] Iteration 11840, loss = 0.143619
I0227 07:25:07.688378 20800 solver.cpp:245]     Train net output #0: accuracy = 0.94426
I0227 07:25:07.688387 20800 solver.cpp:245]     Train net output #1: accuracy = 0.814541
I0227 07:25:07.688393 20800 solver.cpp:245]     Train net output #2: accuracy = 0.846841
I0227 07:25:07.688403 20800 sgd_solver.cpp:106] Iteration 11840, lr = 0.000446266
I0227 07:25:24.942844 20800 solver.cpp:229] Iteration 11860, loss = 0.141624
I0227 07:25:24.942903 20800 solver.cpp:245]     Train net output #0: accuracy = 0.973007
I0227 07:25:24.942929 20800 solver.cpp:245]     Train net output #1: accuracy = 0.896695
I0227 07:25:24.942935 20800 solver.cpp:245]     Train net output #2: accuracy = 0.9575
I0227 07:25:24.942945 20800 sgd_solver.cpp:106] Iteration 11860, lr = 0.000445282
I0227 07:25:42.220472 20800 solver.cpp:229] Iteration 11880, loss = 0.145725
I0227 07:25:42.220502 20800 solver.cpp:245]     Train net output #0: accuracy = 0.950684
I0227 07:25:42.220510 20800 solver.cpp:245]     Train net output #1: accuracy = 0.74545
I0227 07:25:42.220517 20800 solver.cpp:245]     Train net output #2: accuracy = 0.792208
I0227 07:25:42.220526 20800 sgd_solver.cpp:106] Iteration 11880, lr = 0.000444297
I0227 07:25:59.522105 20800 solver.cpp:229] Iteration 11900, loss = 0.141093
I0227 07:25:59.522152 20800 solver.cpp:245]     Train net output #0: accuracy = 0.963296
I0227 07:25:59.522161 20800 solver.cpp:245]     Train net output #1: accuracy = 0.926956
I0227 07:25:59.522167 20800 solver.cpp:245]     Train net output #2: accuracy = 0.923609
I0227 07:25:59.522177 20800 sgd_solver.cpp:106] Iteration 11900, lr = 0.000443312
I0227 07:26:16.791251 20800 solver.cpp:229] Iteration 11920, loss = 0.148501
I0227 07:26:16.791311 20800 solver.cpp:245]     Train net output #0: accuracy = 0.916407
I0227 07:26:16.791319 20800 solver.cpp:245]     Train net output #1: accuracy = 0.819804
I0227 07:26:16.791326 20800 solver.cpp:245]     Train net output #2: accuracy = 0.712974
I0227 07:26:16.791352 20800 sgd_solver.cpp:106] Iteration 11920, lr = 0.000442327
I0227 07:26:34.076678 20800 solver.cpp:229] Iteration 11940, loss = 0.145295
I0227 07:26:34.076709 20800 solver.cpp:245]     Train net output #0: accuracy = 0.953956
I0227 07:26:34.076717 20800 solver.cpp:245]     Train net output #1: accuracy = 0.707807
I0227 07:26:34.076725 20800 solver.cpp:245]     Train net output #2: accuracy = 0.778065
I0227 07:26:34.076735 20800 sgd_solver.cpp:106] Iteration 11940, lr = 0.000441341
I0227 07:26:51.363544 20800 solver.cpp:229] Iteration 11960, loss = 0.14151
I0227 07:26:51.363574 20800 solver.cpp:245]     Train net output #0: accuracy = 0.948662
I0227 07:26:51.363582 20800 solver.cpp:245]     Train net output #1: accuracy = 0.926591
I0227 07:26:51.363590 20800 solver.cpp:245]     Train net output #2: accuracy = 0.907621
I0227 07:26:51.363598 20800 sgd_solver.cpp:106] Iteration 11960, lr = 0.000440356
I0227 07:27:08.649128 20800 solver.cpp:229] Iteration 11980, loss = 0.140429
I0227 07:27:08.649173 20800 solver.cpp:245]     Train net output #0: accuracy = 0.955254
I0227 07:27:08.649183 20800 solver.cpp:245]     Train net output #1: accuracy = 0.858856
I0227 07:27:08.649190 20800 solver.cpp:245]     Train net output #2: accuracy = 0.909111
I0227 07:27:08.649200 20800 sgd_solver.cpp:106] Iteration 11980, lr = 0.00043937
I0227 07:27:25.915093 20800 solver.cpp:229] Iteration 12000, loss = 0.14902
I0227 07:27:25.915136 20800 solver.cpp:245]     Train net output #0: accuracy = 0.954967
I0227 07:27:25.915145 20800 solver.cpp:245]     Train net output #1: accuracy = 0.706668
I0227 07:27:25.915151 20800 solver.cpp:245]     Train net output #2: accuracy = 0.840586
I0227 07:27:25.915161 20800 sgd_solver.cpp:106] Iteration 12000, lr = 0.000438383
I0227 07:27:43.179533 20800 solver.cpp:229] Iteration 12020, loss = 0.129062
I0227 07:27:43.179563 20800 solver.cpp:245]     Train net output #0: accuracy = 0.949137
I0227 07:27:43.179571 20800 solver.cpp:245]     Train net output #1: accuracy = 0.616081
I0227 07:27:43.179579 20800 solver.cpp:245]     Train net output #2: accuracy = 0.650667
I0227 07:27:43.179589 20800 sgd_solver.cpp:106] Iteration 12020, lr = 0.000437397
I0227 07:28:00.457741 20800 solver.cpp:229] Iteration 12040, loss = 0.142409
I0227 07:28:00.457787 20800 solver.cpp:245]     Train net output #0: accuracy = 0.906565
I0227 07:28:00.457795 20800 solver.cpp:245]     Train net output #1: accuracy = 0.747757
I0227 07:28:00.457803 20800 solver.cpp:245]     Train net output #2: accuracy = 0.669221
I0227 07:28:00.457813 20800 sgd_solver.cpp:106] Iteration 12040, lr = 0.00043641
I0227 07:28:17.707902 20800 solver.cpp:229] Iteration 12060, loss = 0.14986
I0227 07:28:17.707932 20800 solver.cpp:245]     Train net output #0: accuracy = 0.953302
I0227 07:28:17.707942 20800 solver.cpp:245]     Train net output #1: accuracy = 0.881475
I0227 07:28:17.707948 20800 solver.cpp:245]     Train net output #2: accuracy = 0.821491
I0227 07:28:17.707959 20800 sgd_solver.cpp:106] Iteration 12060, lr = 0.000435423
I0227 07:28:34.976477 20800 solver.cpp:229] Iteration 12080, loss = 0.138577
I0227 07:28:34.976521 20800 solver.cpp:245]     Train net output #0: accuracy = 0.946266
I0227 07:28:34.976529 20800 solver.cpp:245]     Train net output #1: accuracy = 0.864988
I0227 07:28:34.976536 20800 solver.cpp:245]     Train net output #2: accuracy = 0.746689
I0227 07:28:34.976545 20800 sgd_solver.cpp:106] Iteration 12080, lr = 0.000434436
I0227 07:28:52.234627 20800 solver.cpp:229] Iteration 12100, loss = 0.148808
I0227 07:28:52.234673 20800 solver.cpp:245]     Train net output #0: accuracy = 0.935665
I0227 07:28:52.234683 20800 solver.cpp:245]     Train net output #1: accuracy = 0.85246
I0227 07:28:52.234689 20800 solver.cpp:245]     Train net output #2: accuracy = 0.863429
I0227 07:28:52.234699 20800 sgd_solver.cpp:106] Iteration 12100, lr = 0.000433448
I0227 07:29:09.515336 20800 solver.cpp:229] Iteration 12120, loss = 0.141565
I0227 07:29:09.515381 20800 solver.cpp:245]     Train net output #0: accuracy = 0.928971
I0227 07:29:09.515390 20800 solver.cpp:245]     Train net output #1: accuracy = 0.805241
I0227 07:29:09.515398 20800 solver.cpp:245]     Train net output #2: accuracy = 0.791705
I0227 07:29:09.515408 20800 sgd_solver.cpp:106] Iteration 12120, lr = 0.000432461
I0227 07:29:26.809614 20800 solver.cpp:229] Iteration 12140, loss = 0.155776
I0227 07:29:26.809664 20800 solver.cpp:245]     Train net output #0: accuracy = 0.947252
I0227 07:29:26.809674 20800 solver.cpp:245]     Train net output #1: accuracy = 0.81381
I0227 07:29:26.809681 20800 solver.cpp:245]     Train net output #2: accuracy = 0.825387
I0227 07:29:26.809691 20800 sgd_solver.cpp:106] Iteration 12140, lr = 0.000431473
I0227 07:29:44.066365 20800 solver.cpp:229] Iteration 12160, loss = 0.13467
I0227 07:29:44.066409 20800 solver.cpp:245]     Train net output #0: accuracy = 0.950325
I0227 07:29:44.066418 20800 solver.cpp:245]     Train net output #1: accuracy = 0.810528
I0227 07:29:44.066424 20800 solver.cpp:245]     Train net output #2: accuracy = 0.799192
I0227 07:29:44.066433 20800 sgd_solver.cpp:106] Iteration 12160, lr = 0.000430484
I0227 07:30:01.343597 20800 solver.cpp:229] Iteration 12180, loss = 0.138439
I0227 07:30:01.343642 20800 solver.cpp:245]     Train net output #0: accuracy = 0.943902
I0227 07:30:01.343652 20800 solver.cpp:245]     Train net output #1: accuracy = 0.698866
I0227 07:30:01.343658 20800 solver.cpp:245]     Train net output #2: accuracy = 0.730141
I0227 07:30:01.343668 20800 sgd_solver.cpp:106] Iteration 12180, lr = 0.000429496
I0227 07:30:18.625828 20800 solver.cpp:229] Iteration 12200, loss = 0.146903
I0227 07:30:18.625874 20800 solver.cpp:245]     Train net output #0: accuracy = 0.936258
I0227 07:30:18.625883 20800 solver.cpp:245]     Train net output #1: accuracy = 0.743767
I0227 07:30:18.625890 20800 solver.cpp:245]     Train net output #2: accuracy = 0.75414
I0227 07:30:18.625900 20800 sgd_solver.cpp:106] Iteration 12200, lr = 0.000428507
I0227 07:30:35.925076 20800 solver.cpp:229] Iteration 12220, loss = 0.142849
I0227 07:30:35.925106 20800 solver.cpp:245]     Train net output #0: accuracy = 0.934224
I0227 07:30:35.925114 20800 solver.cpp:245]     Train net output #1: accuracy = 0.755049
I0227 07:30:35.925120 20800 solver.cpp:245]     Train net output #2: accuracy = 0.795699
I0227 07:30:35.925129 20800 sgd_solver.cpp:106] Iteration 12220, lr = 0.000427518
I0227 07:30:53.192513 20800 solver.cpp:229] Iteration 12240, loss = 0.141047
I0227 07:30:53.192544 20800 solver.cpp:245]     Train net output #0: accuracy = 0.925866
I0227 07:30:53.192553 20800 solver.cpp:245]     Train net output #1: accuracy = 0.635479
I0227 07:30:53.192561 20800 solver.cpp:245]     Train net output #2: accuracy = 0.724289
I0227 07:30:53.192570 20800 sgd_solver.cpp:106] Iteration 12240, lr = 0.000426529
I0227 07:31:10.485133 20800 solver.cpp:229] Iteration 12260, loss = 0.146349
I0227 07:31:10.485193 20800 solver.cpp:245]     Train net output #0: accuracy = 0.944088
I0227 07:31:10.485203 20800 solver.cpp:245]     Train net output #1: accuracy = 0.927217
I0227 07:31:10.485209 20800 solver.cpp:245]     Train net output #2: accuracy = 0.939331
I0227 07:31:10.485219 20800 sgd_solver.cpp:106] Iteration 12260, lr = 0.00042554
I0227 07:31:27.747149 20800 solver.cpp:229] Iteration 12280, loss = 0.132932
I0227 07:31:27.747179 20800 solver.cpp:245]     Train net output #0: accuracy = 0.962522
I0227 07:31:27.747189 20800 solver.cpp:245]     Train net output #1: accuracy = 0.801621
I0227 07:31:27.747195 20800 solver.cpp:245]     Train net output #2: accuracy = 0.848969
I0227 07:31:27.747205 20800 sgd_solver.cpp:106] Iteration 12280, lr = 0.00042455
I0227 07:31:45.043175 20800 solver.cpp:229] Iteration 12300, loss = 0.144917
I0227 07:31:45.043205 20800 solver.cpp:245]     Train net output #0: accuracy = 0.948769
I0227 07:31:45.043215 20800 solver.cpp:245]     Train net output #1: accuracy = 0.823048
I0227 07:31:45.043222 20800 solver.cpp:245]     Train net output #2: accuracy = 0.872763
I0227 07:31:45.043231 20800 sgd_solver.cpp:106] Iteration 12300, lr = 0.00042356
I0227 07:32:02.299685 20800 solver.cpp:229] Iteration 12320, loss = 0.145558
I0227 07:32:02.299713 20800 solver.cpp:245]     Train net output #0: accuracy = 0.923953
I0227 07:32:02.299721 20800 solver.cpp:245]     Train net output #1: accuracy = 0.936815
I0227 07:32:02.299728 20800 solver.cpp:245]     Train net output #2: accuracy = 0.951306
I0227 07:32:02.299737 20800 sgd_solver.cpp:106] Iteration 12320, lr = 0.000422569
I0227 07:32:19.578945 20800 solver.cpp:229] Iteration 12340, loss = 0.13553
I0227 07:32:19.578975 20800 solver.cpp:245]     Train net output #0: accuracy = 0.949078
I0227 07:32:19.578984 20800 solver.cpp:245]     Train net output #1: accuracy = 0.714421
I0227 07:32:19.578991 20800 solver.cpp:245]     Train net output #2: accuracy = 0.669988
I0227 07:32:19.579001 20800 sgd_solver.cpp:106] Iteration 12340, lr = 0.000421579
I0227 07:32:36.845225 20800 solver.cpp:229] Iteration 12360, loss = 0.140501
I0227 07:32:36.845257 20800 solver.cpp:245]     Train net output #0: accuracy = 0.942456
I0227 07:32:36.845265 20800 solver.cpp:245]     Train net output #1: accuracy = 0.721301
I0227 07:32:36.845271 20800 solver.cpp:245]     Train net output #2: accuracy = 0.771082
I0227 07:32:36.845281 20800 sgd_solver.cpp:106] Iteration 12360, lr = 0.000420588
I0227 07:32:54.114995 20800 solver.cpp:229] Iteration 12380, loss = 0.141268
I0227 07:32:54.115025 20800 solver.cpp:245]     Train net output #0: accuracy = 0.95812
I0227 07:32:54.115033 20800 solver.cpp:245]     Train net output #1: accuracy = 0.910001
I0227 07:32:54.115041 20800 solver.cpp:245]     Train net output #2: accuracy = 0.912889
I0227 07:32:54.115051 20800 sgd_solver.cpp:106] Iteration 12380, lr = 0.000419597
I0227 07:33:11.388351 20800 solver.cpp:229] Iteration 12400, loss = 0.140563
I0227 07:33:11.388396 20800 solver.cpp:245]     Train net output #0: accuracy = 0.942415
I0227 07:33:11.388406 20800 solver.cpp:245]     Train net output #1: accuracy = 0.728431
I0227 07:33:11.388412 20800 solver.cpp:245]     Train net output #2: accuracy = 0.742965
I0227 07:33:11.388422 20800 sgd_solver.cpp:106] Iteration 12400, lr = 0.000418606
I0227 07:33:28.656116 20800 solver.cpp:229] Iteration 12420, loss = 0.156965
I0227 07:33:28.656147 20800 solver.cpp:245]     Train net output #0: accuracy = 0.937877
I0227 07:33:28.656155 20800 solver.cpp:245]     Train net output #1: accuracy = 0.826045
I0227 07:33:28.656162 20800 solver.cpp:245]     Train net output #2: accuracy = 0.812489
I0227 07:33:28.656172 20800 sgd_solver.cpp:106] Iteration 12420, lr = 0.000417614
I0227 07:33:45.928905 20800 solver.cpp:229] Iteration 12440, loss = 0.144866
I0227 07:33:45.928951 20800 solver.cpp:245]     Train net output #0: accuracy = 0.930021
I0227 07:33:45.928959 20800 solver.cpp:245]     Train net output #1: accuracy = 0.785828
I0227 07:33:45.928966 20800 solver.cpp:245]     Train net output #2: accuracy = 0.845627
I0227 07:33:45.928977 20800 sgd_solver.cpp:106] Iteration 12440, lr = 0.000416622
I0227 07:34:03.197728 20800 solver.cpp:229] Iteration 12460, loss = 0.140141
I0227 07:34:03.197774 20800 solver.cpp:245]     Train net output #0: accuracy = 0.962393
I0227 07:34:03.197783 20800 solver.cpp:245]     Train net output #1: accuracy = 0.948663
I0227 07:34:03.197790 20800 solver.cpp:245]     Train net output #2: accuracy = 0.912627
I0227 07:34:03.197800 20800 sgd_solver.cpp:106] Iteration 12460, lr = 0.00041563
I0227 07:34:20.481422 20800 solver.cpp:229] Iteration 12480, loss = 0.136193
I0227 07:34:20.481465 20800 solver.cpp:245]     Train net output #0: accuracy = 0.929625
I0227 07:34:20.481474 20800 solver.cpp:245]     Train net output #1: accuracy = 0.800916
I0227 07:34:20.481480 20800 solver.cpp:245]     Train net output #2: accuracy = 0.810985
I0227 07:34:20.481489 20800 sgd_solver.cpp:106] Iteration 12480, lr = 0.000414638
I0227 07:34:37.775018 20800 solver.cpp:229] Iteration 12500, loss = 0.141471
I0227 07:34:37.775050 20800 solver.cpp:245]     Train net output #0: accuracy = 0.943427
I0227 07:34:37.775059 20800 solver.cpp:245]     Train net output #1: accuracy = 0.614252
I0227 07:34:37.775066 20800 solver.cpp:245]     Train net output #2: accuracy = 0.602187
I0227 07:34:37.775076 20800 sgd_solver.cpp:106] Iteration 12500, lr = 0.000413645
I0227 07:34:55.051939 20800 solver.cpp:229] Iteration 12520, loss = 0.134078
I0227 07:34:55.051970 20800 solver.cpp:245]     Train net output #0: accuracy = 0.943962
I0227 07:34:55.051978 20800 solver.cpp:245]     Train net output #1: accuracy = 0.852861
I0227 07:34:55.051985 20800 solver.cpp:245]     Train net output #2: accuracy = 0.91197
I0227 07:34:55.051995 20800 sgd_solver.cpp:106] Iteration 12520, lr = 0.000412653
I0227 07:35:12.334183 20800 solver.cpp:229] Iteration 12540, loss = 0.14495
I0227 07:35:12.334214 20800 solver.cpp:245]     Train net output #0: accuracy = 0.937656
I0227 07:35:12.334223 20800 solver.cpp:245]     Train net output #1: accuracy = 0.710244
I0227 07:35:12.334230 20800 solver.cpp:245]     Train net output #2: accuracy = 0.723313
I0227 07:35:12.334240 20800 sgd_solver.cpp:106] Iteration 12540, lr = 0.000411659
I0227 07:35:29.610433 20800 solver.cpp:229] Iteration 12560, loss = 0.135898
I0227 07:35:29.610477 20800 solver.cpp:245]     Train net output #0: accuracy = 0.954962
I0227 07:35:29.610486 20800 solver.cpp:245]     Train net output #1: accuracy = 0.764547
I0227 07:35:29.610493 20800 solver.cpp:245]     Train net output #2: accuracy = 0.86431
I0227 07:35:29.610502 20800 sgd_solver.cpp:106] Iteration 12560, lr = 0.000410666
I0227 07:35:46.883612 20800 solver.cpp:229] Iteration 12580, loss = 0.141721
I0227 07:35:46.883657 20800 solver.cpp:245]     Train net output #0: accuracy = 0.937418
I0227 07:35:46.883666 20800 solver.cpp:245]     Train net output #1: accuracy = 0.825789
I0227 07:35:46.883672 20800 solver.cpp:245]     Train net output #2: accuracy = 0.856363
I0227 07:35:46.883682 20800 sgd_solver.cpp:106] Iteration 12580, lr = 0.000409672
I0227 07:36:04.159680 20800 solver.cpp:229] Iteration 12600, loss = 0.135765
I0227 07:36:04.159727 20800 solver.cpp:245]     Train net output #0: accuracy = 0.956217
I0227 07:36:04.159736 20800 solver.cpp:245]     Train net output #1: accuracy = 0.925957
I0227 07:36:04.159757 20800 solver.cpp:245]     Train net output #2: accuracy = 0.904892
I0227 07:36:04.159767 20800 sgd_solver.cpp:106] Iteration 12600, lr = 0.000408678
I0227 07:36:21.407102 20800 solver.cpp:229] Iteration 12620, loss = 0.144442
I0227 07:36:21.407145 20800 solver.cpp:245]     Train net output #0: accuracy = 0.939322
I0227 07:36:21.407153 20800 solver.cpp:245]     Train net output #1: accuracy = 0.800488
I0227 07:36:21.407172 20800 solver.cpp:245]     Train net output #2: accuracy = 0.831401
I0227 07:36:21.407181 20800 sgd_solver.cpp:106] Iteration 12620, lr = 0.000407684
I0227 07:36:38.680124 20800 solver.cpp:229] Iteration 12640, loss = 0.145274
I0227 07:36:38.680166 20800 solver.cpp:245]     Train net output #0: accuracy = 0.933076
I0227 07:36:38.680176 20800 solver.cpp:245]     Train net output #1: accuracy = 0.834047
I0227 07:36:38.680182 20800 solver.cpp:245]     Train net output #2: accuracy = 0.753353
I0227 07:36:38.680192 20800 sgd_solver.cpp:106] Iteration 12640, lr = 0.00040669
I0227 07:36:55.948163 20800 solver.cpp:229] Iteration 12660, loss = 0.140863
I0227 07:36:55.948206 20800 solver.cpp:245]     Train net output #0: accuracy = 0.95538
I0227 07:36:55.948215 20800 solver.cpp:245]     Train net output #1: accuracy = 0.778004
I0227 07:36:55.948221 20800 solver.cpp:245]     Train net output #2: accuracy = 0.797203
I0227 07:36:55.948230 20800 sgd_solver.cpp:106] Iteration 12660, lr = 0.000405695
I0227 07:37:13.213296 20800 solver.cpp:229] Iteration 12680, loss = 0.137987
I0227 07:37:13.213342 20800 solver.cpp:245]     Train net output #0: accuracy = 0.956351
I0227 07:37:13.213351 20800 solver.cpp:245]     Train net output #1: accuracy = 0.743629
I0227 07:37:13.213359 20800 solver.cpp:245]     Train net output #2: accuracy = 0.841304
I0227 07:37:13.213369 20800 sgd_solver.cpp:106] Iteration 12680, lr = 0.0004047
I0227 07:37:30.482066 20800 solver.cpp:229] Iteration 12700, loss = 0.140557
I0227 07:37:30.482111 20800 solver.cpp:245]     Train net output #0: accuracy = 0.951339
I0227 07:37:30.482120 20800 solver.cpp:245]     Train net output #1: accuracy = 0.9354
I0227 07:37:30.482127 20800 solver.cpp:245]     Train net output #2: accuracy = 0.90336
I0227 07:37:30.482137 20800 sgd_solver.cpp:106] Iteration 12700, lr = 0.000403705
I0227 07:37:47.755604 20800 solver.cpp:229] Iteration 12720, loss = 0.129599
I0227 07:37:47.755648 20800 solver.cpp:245]     Train net output #0: accuracy = 0.965709
I0227 07:37:47.755658 20800 solver.cpp:245]     Train net output #1: accuracy = 0.939514
I0227 07:37:47.755664 20800 solver.cpp:245]     Train net output #2: accuracy = 0.866224
I0227 07:37:47.755674 20800 sgd_solver.cpp:106] Iteration 12720, lr = 0.000402709
I0227 07:38:05.042584 20800 solver.cpp:229] Iteration 12740, loss = 0.135189
I0227 07:38:05.042614 20800 solver.cpp:245]     Train net output #0: accuracy = 0.94069
I0227 07:38:05.042639 20800 solver.cpp:245]     Train net output #1: accuracy = 0.888619
I0227 07:38:05.042647 20800 solver.cpp:245]     Train net output #2: accuracy = 0.827044
I0227 07:38:05.042656 20800 sgd_solver.cpp:106] Iteration 12740, lr = 0.000401713
I0227 07:38:22.317380 20800 solver.cpp:229] Iteration 12760, loss = 0.142528
I0227 07:38:22.317409 20800 solver.cpp:245]     Train net output #0: accuracy = 0.926704
I0227 07:38:22.317433 20800 solver.cpp:245]     Train net output #1: accuracy = 0.783288
I0227 07:38:22.317440 20800 solver.cpp:245]     Train net output #2: accuracy = 0.760281
I0227 07:38:22.317451 20800 sgd_solver.cpp:106] Iteration 12760, lr = 0.000400717
I0227 07:38:39.612469 20800 solver.cpp:229] Iteration 12780, loss = 0.13302
I0227 07:38:39.612515 20800 solver.cpp:245]     Train net output #0: accuracy = 0.924903
I0227 07:38:39.612524 20800 solver.cpp:245]     Train net output #1: accuracy = 0.898087
I0227 07:38:39.612531 20800 solver.cpp:245]     Train net output #2: accuracy = 0.809562
I0227 07:38:39.612541 20800 sgd_solver.cpp:106] Iteration 12780, lr = 0.000399721
I0227 07:38:56.893735 20800 solver.cpp:229] Iteration 12800, loss = 0.133752
I0227 07:38:56.893781 20800 solver.cpp:245]     Train net output #0: accuracy = 0.930443
I0227 07:38:56.893791 20800 solver.cpp:245]     Train net output #1: accuracy = 0.834594
I0227 07:38:56.893798 20800 solver.cpp:245]     Train net output #2: accuracy = 0.815946
I0227 07:38:56.893808 20800 sgd_solver.cpp:106] Iteration 12800, lr = 0.000398724
I0227 07:39:14.184895 20800 solver.cpp:229] Iteration 12820, loss = 0.142483
I0227 07:39:14.184940 20800 solver.cpp:245]     Train net output #0: accuracy = 0.955448
I0227 07:39:14.184949 20800 solver.cpp:245]     Train net output #1: accuracy = 0.765368
I0227 07:39:14.184957 20800 solver.cpp:245]     Train net output #2: accuracy = 0.824484
I0227 07:39:14.184965 20800 sgd_solver.cpp:106] Iteration 12820, lr = 0.000397727
I0227 07:39:31.433912 20800 solver.cpp:229] Iteration 12840, loss = 0.157567
I0227 07:39:31.433944 20800 solver.cpp:245]     Train net output #0: accuracy = 0.92207
I0227 07:39:31.433954 20800 solver.cpp:245]     Train net output #1: accuracy = 0.813431
I0227 07:39:31.433960 20800 solver.cpp:245]     Train net output #2: accuracy = 0.846121
I0227 07:39:31.433970 20800 sgd_solver.cpp:106] Iteration 12840, lr = 0.00039673
I0227 07:39:48.718055 20800 solver.cpp:229] Iteration 12860, loss = 0.138782
I0227 07:39:48.718101 20800 solver.cpp:245]     Train net output #0: accuracy = 0.936585
I0227 07:39:48.718111 20800 solver.cpp:245]     Train net output #1: accuracy = 0.884452
I0227 07:39:48.718117 20800 solver.cpp:245]     Train net output #2: accuracy = 0.863175
I0227 07:39:48.718127 20800 sgd_solver.cpp:106] Iteration 12860, lr = 0.000395732
I0227 07:40:05.975984 20800 solver.cpp:229] Iteration 12880, loss = 0.132147
I0227 07:40:05.976016 20800 solver.cpp:245]     Train net output #0: accuracy = 0.959738
I0227 07:40:05.976025 20800 solver.cpp:245]     Train net output #1: accuracy = 0.788391
I0227 07:40:05.976033 20800 solver.cpp:245]     Train net output #2: accuracy = 0.862985
I0227 07:40:05.976042 20800 sgd_solver.cpp:106] Iteration 12880, lr = 0.000394734
I0227 07:40:23.256620 20800 solver.cpp:229] Iteration 12900, loss = 0.142967
I0227 07:40:23.256649 20800 solver.cpp:245]     Train net output #0: accuracy = 0.926094
I0227 07:40:23.256659 20800 solver.cpp:245]     Train net output #1: accuracy = 0.766678
I0227 07:40:23.256665 20800 solver.cpp:245]     Train net output #2: accuracy = 0.74049
I0227 07:40:23.256675 20800 sgd_solver.cpp:106] Iteration 12900, lr = 0.000393736
I0227 07:40:40.533291 20800 solver.cpp:229] Iteration 12920, loss = 0.143775
I0227 07:40:40.533336 20800 solver.cpp:245]     Train net output #0: accuracy = 0.944914
I0227 07:40:40.533345 20800 solver.cpp:245]     Train net output #1: accuracy = 0.888838
I0227 07:40:40.533351 20800 solver.cpp:245]     Train net output #2: accuracy = 0.921502
I0227 07:40:40.533361 20800 sgd_solver.cpp:106] Iteration 12920, lr = 0.000392738
I0227 07:40:57.799757 20800 solver.cpp:229] Iteration 12940, loss = 0.136572
I0227 07:40:57.799800 20800 solver.cpp:245]     Train net output #0: accuracy = 0.936983
I0227 07:40:57.799809 20800 solver.cpp:245]     Train net output #1: accuracy = 0.766361
I0227 07:40:57.799816 20800 solver.cpp:245]     Train net output #2: accuracy = 0.837588
I0227 07:40:57.799826 20800 sgd_solver.cpp:106] Iteration 12940, lr = 0.000391739
I0227 07:41:15.038513 20800 solver.cpp:229] Iteration 12960, loss = 0.136621
I0227 07:41:15.038544 20800 solver.cpp:245]     Train net output #0: accuracy = 0.948007
I0227 07:41:15.038553 20800 solver.cpp:245]     Train net output #1: accuracy = 0.858906
I0227 07:41:15.038560 20800 solver.cpp:245]     Train net output #2: accuracy = 0.821364
I0227 07:41:15.038570 20800 sgd_solver.cpp:106] Iteration 12960, lr = 0.00039074
I0227 07:41:32.332528 20800 solver.cpp:229] Iteration 12980, loss = 0.1454
I0227 07:41:32.332559 20800 solver.cpp:245]     Train net output #0: accuracy = 0.936585
I0227 07:41:32.332568 20800 solver.cpp:245]     Train net output #1: accuracy = 0.88675
I0227 07:41:32.332576 20800 solver.cpp:245]     Train net output #2: accuracy = 0.878697
I0227 07:41:32.332585 20800 sgd_solver.cpp:106] Iteration 12980, lr = 0.000389741
I0227 07:41:49.630739 20800 solver.cpp:229] Iteration 13000, loss = 0.136975
I0227 07:41:49.630785 20800 solver.cpp:245]     Train net output #0: accuracy = 0.945866
I0227 07:41:49.630795 20800 solver.cpp:245]     Train net output #1: accuracy = 0.861625
I0227 07:41:49.630801 20800 solver.cpp:245]     Train net output #2: accuracy = 0.738083
I0227 07:41:49.630811 20800 sgd_solver.cpp:106] Iteration 13000, lr = 0.000388742
I0227 07:42:06.900759 20800 solver.cpp:229] Iteration 13020, loss = 0.126391
I0227 07:42:06.900815 20800 solver.cpp:245]     Train net output #0: accuracy = 0.959874
I0227 07:42:06.900823 20800 solver.cpp:245]     Train net output #1: accuracy = 0.911765
I0227 07:42:06.900830 20800 solver.cpp:245]     Train net output #2: accuracy = 0.888251
I0227 07:42:06.900840 20800 sgd_solver.cpp:106] Iteration 13020, lr = 0.000387742
I0227 07:42:24.161226 20800 solver.cpp:229] Iteration 13040, loss = 0.136637
I0227 07:42:24.161270 20800 solver.cpp:245]     Train net output #0: accuracy = 0.964297
I0227 07:42:24.161280 20800 solver.cpp:245]     Train net output #1: accuracy = 0.952609
I0227 07:42:24.161286 20800 solver.cpp:245]     Train net output #2: accuracy = 0.954393
I0227 07:42:24.161296 20800 sgd_solver.cpp:106] Iteration 13040, lr = 0.000386742
I0227 07:42:41.412324 20800 solver.cpp:229] Iteration 13060, loss = 0.142233
I0227 07:42:41.412369 20800 solver.cpp:245]     Train net output #0: accuracy = 0.943843
I0227 07:42:41.412380 20800 solver.cpp:245]     Train net output #1: accuracy = 0.700627
I0227 07:42:41.412387 20800 solver.cpp:245]     Train net output #2: accuracy = 0.72152
I0227 07:42:41.412397 20800 sgd_solver.cpp:106] Iteration 13060, lr = 0.000385742
I0227 07:42:58.672924 20800 solver.cpp:229] Iteration 13080, loss = 0.136347
I0227 07:42:58.672968 20800 solver.cpp:245]     Train net output #0: accuracy = 0.947216
I0227 07:42:58.672977 20800 solver.cpp:245]     Train net output #1: accuracy = 0.754341
I0227 07:42:58.672984 20800 solver.cpp:245]     Train net output #2: accuracy = 0.857187
I0227 07:42:58.672996 20800 sgd_solver.cpp:106] Iteration 13080, lr = 0.000384741
I0227 07:43:15.948937 20800 solver.cpp:229] Iteration 13100, loss = 0.134308
I0227 07:43:15.948966 20800 solver.cpp:245]     Train net output #0: accuracy = 0.949875
I0227 07:43:15.948976 20800 solver.cpp:245]     Train net output #1: accuracy = 0.888401
I0227 07:43:15.948982 20800 solver.cpp:245]     Train net output #2: accuracy = 0.89809
I0227 07:43:15.948992 20800 sgd_solver.cpp:106] Iteration 13100, lr = 0.00038374
I0227 07:43:33.235872 20800 solver.cpp:229] Iteration 13120, loss = 0.136504
I0227 07:43:33.235918 20800 solver.cpp:245]     Train net output #0: accuracy = 0.957049
I0227 07:43:33.235926 20800 solver.cpp:245]     Train net output #1: accuracy = 0.920146
I0227 07:43:33.235934 20800 solver.cpp:245]     Train net output #2: accuracy = 0.77443
I0227 07:43:33.235944 20800 sgd_solver.cpp:106] Iteration 13120, lr = 0.000382739
I0227 07:43:50.493306 20800 solver.cpp:229] Iteration 13140, loss = 0.131482
I0227 07:43:50.493350 20800 solver.cpp:245]     Train net output #0: accuracy = 0.929058
I0227 07:43:50.493360 20800 solver.cpp:245]     Train net output #1: accuracy = 0.785954
I0227 07:43:50.493366 20800 solver.cpp:245]     Train net output #2: accuracy = 0.845748
I0227 07:43:50.493376 20800 sgd_solver.cpp:106] Iteration 13140, lr = 0.000381737
I0227 07:44:07.757982 20800 solver.cpp:229] Iteration 13160, loss = 0.143574
I0227 07:44:07.758026 20800 solver.cpp:245]     Train net output #0: accuracy = 0.954678
I0227 07:44:07.758034 20800 solver.cpp:245]     Train net output #1: accuracy = 0.913194
I0227 07:44:07.758041 20800 solver.cpp:245]     Train net output #2: accuracy = 0.88539
I0227 07:44:07.758050 20800 sgd_solver.cpp:106] Iteration 13160, lr = 0.000380736
I0227 07:44:25.015365 20800 solver.cpp:229] Iteration 13180, loss = 0.135096
I0227 07:44:25.015411 20800 solver.cpp:245]     Train net output #0: accuracy = 0.953247
I0227 07:44:25.015419 20800 solver.cpp:245]     Train net output #1: accuracy = 0.869688
I0227 07:44:25.015426 20800 solver.cpp:245]     Train net output #2: accuracy = 0.875345
I0227 07:44:25.015435 20800 sgd_solver.cpp:106] Iteration 13180, lr = 0.000379734
I0227 07:44:42.304944 20800 solver.cpp:229] Iteration 13200, loss = 0.137451
I0227 07:44:42.304989 20800 solver.cpp:245]     Train net output #0: accuracy = 0.937954
I0227 07:44:42.304997 20800 solver.cpp:245]     Train net output #1: accuracy = 0.909114
I0227 07:44:42.305004 20800 solver.cpp:245]     Train net output #2: accuracy = 0.919489
I0227 07:44:42.305013 20800 sgd_solver.cpp:106] Iteration 13200, lr = 0.000378731
I0227 07:44:59.568953 20800 solver.cpp:229] Iteration 13220, loss = 0.143532
I0227 07:44:59.568984 20800 solver.cpp:245]     Train net output #0: accuracy = 0.946559
I0227 07:44:59.568994 20800 solver.cpp:245]     Train net output #1: accuracy = 0.751046
I0227 07:44:59.569000 20800 solver.cpp:245]     Train net output #2: accuracy = 0.805452
I0227 07:44:59.569010 20800 sgd_solver.cpp:106] Iteration 13220, lr = 0.000377728
I0227 07:45:16.841473 20800 solver.cpp:229] Iteration 13240, loss = 0.136715
I0227 07:45:16.841517 20800 solver.cpp:245]     Train net output #0: accuracy = 0.956157
I0227 07:45:16.841526 20800 solver.cpp:245]     Train net output #1: accuracy = 0.829381
I0227 07:45:16.841533 20800 solver.cpp:245]     Train net output #2: accuracy = 0.772095
I0227 07:45:16.841542 20800 sgd_solver.cpp:106] Iteration 13240, lr = 0.000376726
I0227 07:45:34.128509 20800 solver.cpp:229] Iteration 13260, loss = 0.129645
I0227 07:45:34.128537 20800 solver.cpp:245]     Train net output #0: accuracy = 0.952369
I0227 07:45:34.128546 20800 solver.cpp:245]     Train net output #1: accuracy = 0.751601
I0227 07:45:34.128552 20800 solver.cpp:245]     Train net output #2: accuracy = 0.849038
I0227 07:45:34.128561 20800 sgd_solver.cpp:106] Iteration 13260, lr = 0.000375722
I0227 07:45:51.392479 20800 solver.cpp:229] Iteration 13280, loss = 0.139875
I0227 07:45:51.392527 20800 solver.cpp:245]     Train net output #0: accuracy = 0.923234
I0227 07:45:51.392536 20800 solver.cpp:245]     Train net output #1: accuracy = 0.811228
I0227 07:45:51.392544 20800 solver.cpp:245]     Train net output #2: accuracy = 0.785033
I0227 07:45:51.392552 20800 sgd_solver.cpp:106] Iteration 13280, lr = 0.000374719
I0227 07:46:08.665637 20800 solver.cpp:229] Iteration 13300, loss = 0.136095
I0227 07:46:08.665669 20800 solver.cpp:245]     Train net output #0: accuracy = 0.955146
I0227 07:46:08.665678 20800 solver.cpp:245]     Train net output #1: accuracy = 0.816382
I0227 07:46:08.665685 20800 solver.cpp:245]     Train net output #2: accuracy = 0.841209
I0227 07:46:08.665695 20800 sgd_solver.cpp:106] Iteration 13300, lr = 0.000373715
I0227 07:46:25.948782 20800 solver.cpp:229] Iteration 13320, loss = 0.134049
I0227 07:46:25.948812 20800 solver.cpp:245]     Train net output #0: accuracy = 0.948543
I0227 07:46:25.948822 20800 solver.cpp:245]     Train net output #1: accuracy = 0.827564
I0227 07:46:25.948828 20800 solver.cpp:245]     Train net output #2: accuracy = 0.711501
I0227 07:46:25.948837 20800 sgd_solver.cpp:106] Iteration 13320, lr = 0.000372711
I0227 07:46:43.196818 20800 solver.cpp:229] Iteration 13340, loss = 0.139613
I0227 07:46:43.196864 20800 solver.cpp:245]     Train net output #0: accuracy = 0.920345
I0227 07:46:43.196873 20800 solver.cpp:245]     Train net output #1: accuracy = 0.655735
I0227 07:46:43.196880 20800 solver.cpp:245]     Train net output #2: accuracy = 0.638252
I0227 07:46:43.196890 20800 sgd_solver.cpp:106] Iteration 13340, lr = 0.000371706
I0227 07:47:00.479785 20800 solver.cpp:229] Iteration 13360, loss = 0.143331
I0227 07:47:00.479828 20800 solver.cpp:245]     Train net output #0: accuracy = 0.944854
I0227 07:47:00.479837 20800 solver.cpp:245]     Train net output #1: accuracy = 0.710456
I0227 07:47:00.479845 20800 solver.cpp:245]     Train net output #2: accuracy = 0.796154
I0227 07:47:00.479853 20800 sgd_solver.cpp:106] Iteration 13360, lr = 0.000370701
I0227 07:47:17.742561 20800 solver.cpp:229] Iteration 13380, loss = 0.143743
I0227 07:47:17.742606 20800 solver.cpp:245]     Train net output #0: accuracy = 0.94997
I0227 07:47:17.742615 20800 solver.cpp:245]     Train net output #1: accuracy = 0.724877
I0227 07:47:17.742622 20800 solver.cpp:245]     Train net output #2: accuracy = 0.786556
I0227 07:47:17.742632 20800 sgd_solver.cpp:106] Iteration 13380, lr = 0.000369696
I0227 07:47:35.023751 20800 solver.cpp:229] Iteration 13400, loss = 0.14165
I0227 07:47:35.023795 20800 solver.cpp:245]     Train net output #0: accuracy = 0.951993
I0227 07:47:35.023804 20800 solver.cpp:245]     Train net output #1: accuracy = 0.811251
I0227 07:47:35.023810 20800 solver.cpp:245]     Train net output #2: accuracy = 0.817352
I0227 07:47:35.023819 20800 sgd_solver.cpp:106] Iteration 13400, lr = 0.000368691
I0227 07:47:52.316916 20800 solver.cpp:229] Iteration 13420, loss = 0.139531
I0227 07:47:52.316947 20800 solver.cpp:245]     Train net output #0: accuracy = 0.964366
I0227 07:47:52.316957 20800 solver.cpp:245]     Train net output #1: accuracy = 0.815716
I0227 07:47:52.316964 20800 solver.cpp:245]     Train net output #2: accuracy = 0.858664
I0227 07:47:52.316973 20800 sgd_solver.cpp:106] Iteration 13420, lr = 0.000367685
I0227 07:48:09.593083 20800 solver.cpp:229] Iteration 13440, loss = 0.143536
I0227 07:48:09.593127 20800 solver.cpp:245]     Train net output #0: accuracy = 0.927127
I0227 07:48:09.593135 20800 solver.cpp:245]     Train net output #1: accuracy = 0.777621
I0227 07:48:09.593142 20800 solver.cpp:245]     Train net output #2: accuracy = 0.800353
I0227 07:48:09.593152 20800 sgd_solver.cpp:106] Iteration 13440, lr = 0.000366679
I0227 07:48:26.870416 20800 solver.cpp:229] Iteration 13460, loss = 0.142203
I0227 07:48:26.870447 20800 solver.cpp:245]     Train net output #0: accuracy = 0.938667
I0227 07:48:26.870456 20800 solver.cpp:245]     Train net output #1: accuracy = 0.58137
I0227 07:48:26.870463 20800 solver.cpp:245]     Train net output #2: accuracy = 0.636849
I0227 07:48:26.870473 20800 sgd_solver.cpp:106] Iteration 13460, lr = 0.000365673
I0227 07:48:44.129307 20800 solver.cpp:229] Iteration 13480, loss = 0.142504
I0227 07:48:44.129336 20800 solver.cpp:245]     Train net output #0: accuracy = 0.929091
I0227 07:48:44.129345 20800 solver.cpp:245]     Train net output #1: accuracy = 0.819857
I0227 07:48:44.129351 20800 solver.cpp:245]     Train net output #2: accuracy = 0.847265
I0227 07:48:44.129361 20800 sgd_solver.cpp:106] Iteration 13480, lr = 0.000364666
I0227 07:49:01.407995 20800 solver.cpp:229] Iteration 13500, loss = 0.129001
I0227 07:49:01.408057 20800 solver.cpp:245]     Train net output #0: accuracy = 0.960083
I0227 07:49:01.408066 20800 solver.cpp:245]     Train net output #1: accuracy = 0.842576
I0227 07:49:01.408073 20800 solver.cpp:245]     Train net output #2: accuracy = 0.848395
I0227 07:49:01.408083 20800 sgd_solver.cpp:106] Iteration 13500, lr = 0.00036366
I0227 07:49:18.672951 20800 solver.cpp:229] Iteration 13520, loss = 0.137511
I0227 07:49:18.672997 20800 solver.cpp:245]     Train net output #0: accuracy = 0.954815
I0227 07:49:18.673007 20800 solver.cpp:245]     Train net output #1: accuracy = 0.770533
I0227 07:49:18.673013 20800 solver.cpp:245]     Train net output #2: accuracy = 0.859891
I0227 07:49:18.673022 20800 sgd_solver.cpp:106] Iteration 13520, lr = 0.000362652
I0227 07:49:35.933434 20800 solver.cpp:229] Iteration 13540, loss = 0.138641
I0227 07:49:35.933480 20800 solver.cpp:245]     Train net output #0: accuracy = 0.955599
I0227 07:49:35.933488 20800 solver.cpp:245]     Train net output #1: accuracy = 0.827799
I0227 07:49:35.933495 20800 solver.cpp:245]     Train net output #2: accuracy = 0.859504
I0227 07:49:35.933506 20800 sgd_solver.cpp:106] Iteration 13540, lr = 0.000361645
I0227 07:49:53.208156 20800 solver.cpp:229] Iteration 13560, loss = 0.133694
I0227 07:49:53.208202 20800 solver.cpp:245]     Train net output #0: accuracy = 0.958061
I0227 07:49:53.208211 20800 solver.cpp:245]     Train net output #1: accuracy = 0.850773
I0227 07:49:53.208218 20800 solver.cpp:245]     Train net output #2: accuracy = 0.878332
I0227 07:49:53.208227 20800 sgd_solver.cpp:106] Iteration 13560, lr = 0.000360637
I0227 07:50:10.480290 20800 solver.cpp:229] Iteration 13580, loss = 0.146896
I0227 07:50:10.480335 20800 solver.cpp:245]     Train net output #0: accuracy = 0.954451
I0227 07:50:10.480343 20800 solver.cpp:245]     Train net output #1: accuracy = 0.81622
I0227 07:50:10.480350 20800 solver.cpp:245]     Train net output #2: accuracy = 0.775174
I0227 07:50:10.480360 20800 sgd_solver.cpp:106] Iteration 13580, lr = 0.000359629
I0227 07:50:27.744925 20800 solver.cpp:229] Iteration 13600, loss = 0.133158
I0227 07:50:27.744971 20800 solver.cpp:245]     Train net output #0: accuracy = 0.952112
I0227 07:50:27.744980 20800 solver.cpp:245]     Train net output #1: accuracy = 0.918312
I0227 07:50:27.744988 20800 solver.cpp:245]     Train net output #2: accuracy = 0.852441
I0227 07:50:27.744997 20800 sgd_solver.cpp:106] Iteration 13600, lr = 0.00035862
I0227 07:50:45.033792 20800 solver.cpp:229] Iteration 13620, loss = 0.135075
I0227 07:50:45.033838 20800 solver.cpp:245]     Train net output #0: accuracy = 0.963114
I0227 07:50:45.033846 20800 solver.cpp:245]     Train net output #1: accuracy = 0.82731
I0227 07:50:45.033854 20800 solver.cpp:245]     Train net output #2: accuracy = 0.785154
I0227 07:50:45.033865 20800 sgd_solver.cpp:106] Iteration 13620, lr = 0.000357612
I0227 07:51:02.311763 20800 solver.cpp:229] Iteration 13640, loss = 0.141285
I0227 07:51:02.311794 20800 solver.cpp:245]     Train net output #0: accuracy = 0.943605
I0227 07:51:02.311802 20800 solver.cpp:245]     Train net output #1: accuracy = 0.847415
I0227 07:51:02.311810 20800 solver.cpp:245]     Train net output #2: accuracy = 0.910095
I0227 07:51:02.311820 20800 sgd_solver.cpp:106] Iteration 13640, lr = 0.000356603
I0227 07:51:19.599048 20800 solver.cpp:229] Iteration 13660, loss = 0.14125
I0227 07:51:19.599092 20800 solver.cpp:245]     Train net output #0: accuracy = 0.932897
I0227 07:51:19.599100 20800 solver.cpp:245]     Train net output #1: accuracy = 0.751938
I0227 07:51:19.599107 20800 solver.cpp:245]     Train net output #2: accuracy = 0.680295
I0227 07:51:19.599117 20800 sgd_solver.cpp:106] Iteration 13660, lr = 0.000355593
I0227 07:51:36.887349 20800 solver.cpp:229] Iteration 13680, loss = 0.144203
I0227 07:51:36.887379 20800 solver.cpp:245]     Train net output #0: accuracy = 0.948649
I0227 07:51:36.887404 20800 solver.cpp:245]     Train net output #1: accuracy = 0.691797
I0227 07:51:36.887411 20800 solver.cpp:245]     Train net output #2: accuracy = 0.760485
I0227 07:51:36.887420 20800 sgd_solver.cpp:106] Iteration 13680, lr = 0.000354583
I0227 07:51:54.147907 20800 solver.cpp:229] Iteration 13700, loss = 0.137578
I0227 07:51:54.147938 20800 solver.cpp:245]     Train net output #0: accuracy = 0.952239
I0227 07:51:54.147948 20800 solver.cpp:245]     Train net output #1: accuracy = 0.939595
I0227 07:51:54.147954 20800 solver.cpp:245]     Train net output #2: accuracy = 0.921514
I0227 07:51:54.147964 20800 sgd_solver.cpp:106] Iteration 13700, lr = 0.000353573
I0227 07:52:11.421795 20800 solver.cpp:229] Iteration 13720, loss = 0.139559
I0227 07:52:11.421825 20800 solver.cpp:245]     Train net output #0: accuracy = 0.923795
I0227 07:52:11.421833 20800 solver.cpp:245]     Train net output #1: accuracy = 0.520255
I0227 07:52:11.421840 20800 solver.cpp:245]     Train net output #2: accuracy = 0.5426
I0227 07:52:11.421849 20800 sgd_solver.cpp:106] Iteration 13720, lr = 0.000352563
I0227 07:52:28.699548 20800 solver.cpp:229] Iteration 13740, loss = 0.152595
I0227 07:52:28.699595 20800 solver.cpp:245]     Train net output #0: accuracy = 0.929599
I0227 07:52:28.699604 20800 solver.cpp:245]     Train net output #1: accuracy = 0.794226
I0227 07:52:28.699611 20800 solver.cpp:245]     Train net output #2: accuracy = 0.779729
I0227 07:52:28.699622 20800 sgd_solver.cpp:106] Iteration 13740, lr = 0.000351552
I0227 07:52:45.983165 20800 solver.cpp:229] Iteration 13760, loss = 0.146255
I0227 07:52:45.983211 20800 solver.cpp:245]     Train net output #0: accuracy = 0.94771
I0227 07:52:45.983222 20800 solver.cpp:245]     Train net output #1: accuracy = 0.936963
I0227 07:52:45.983227 20800 solver.cpp:245]     Train net output #2: accuracy = 0.87651
I0227 07:52:45.983237 20800 sgd_solver.cpp:106] Iteration 13760, lr = 0.000350541
I0227 07:53:03.256341 20800 solver.cpp:229] Iteration 13780, loss = 0.134585
I0227 07:53:03.256386 20800 solver.cpp:245]     Train net output #0: accuracy = 0.930518
I0227 07:53:03.256410 20800 solver.cpp:245]     Train net output #1: accuracy = 0.771922
I0227 07:53:03.256418 20800 solver.cpp:245]     Train net output #2: accuracy = 0.840203
I0227 07:53:03.256428 20800 sgd_solver.cpp:106] Iteration 13780, lr = 0.00034953
I0227 07:53:20.528336 20800 solver.cpp:229] Iteration 13800, loss = 0.126383
I0227 07:53:20.528363 20800 solver.cpp:245]     Train net output #0: accuracy = 0.949494
I0227 07:53:20.528371 20800 solver.cpp:245]     Train net output #1: accuracy = 0.780222
I0227 07:53:20.528378 20800 solver.cpp:245]     Train net output #2: accuracy = 0.831436
I0227 07:53:20.528386 20800 sgd_solver.cpp:106] Iteration 13800, lr = 0.000348518
I0227 07:53:37.814106 20800 solver.cpp:229] Iteration 13820, loss = 0.125905
I0227 07:53:37.814152 20800 solver.cpp:245]     Train net output #0: accuracy = 0.950446
I0227 07:53:37.814160 20800 solver.cpp:245]     Train net output #1: accuracy = 0.803118
I0227 07:53:37.814167 20800 solver.cpp:245]     Train net output #2: accuracy = 0.756064
I0227 07:53:37.814177 20800 sgd_solver.cpp:106] Iteration 13820, lr = 0.000347506
I0227 07:53:55.085574 20800 solver.cpp:229] Iteration 13840, loss = 0.13154
I0227 07:53:55.085602 20800 solver.cpp:245]     Train net output #0: accuracy = 0.952409
I0227 07:53:55.085610 20800 solver.cpp:245]     Train net output #1: accuracy = 0.921457
I0227 07:53:55.085618 20800 solver.cpp:245]     Train net output #2: accuracy = 0.848723
I0227 07:53:55.085626 20800 sgd_solver.cpp:106] Iteration 13840, lr = 0.000346494
I0227 07:54:12.372020 20800 solver.cpp:229] Iteration 13860, loss = 0.136477
I0227 07:54:12.372051 20800 solver.cpp:245]     Train net output #0: accuracy = 0.950327
I0227 07:54:12.372059 20800 solver.cpp:245]     Train net output #1: accuracy = 0.890936
I0227 07:54:12.372066 20800 solver.cpp:245]     Train net output #2: accuracy = 0.792864
I0227 07:54:12.372076 20800 sgd_solver.cpp:106] Iteration 13860, lr = 0.000345481
I0227 07:54:29.652346 20800 solver.cpp:229] Iteration 13880, loss = 0.130325
I0227 07:54:29.652391 20800 solver.cpp:245]     Train net output #0: accuracy = 0.94359
I0227 07:54:29.652400 20800 solver.cpp:245]     Train net output #1: accuracy = 0.715637
I0227 07:54:29.652407 20800 solver.cpp:245]     Train net output #2: accuracy = 0.75935
I0227 07:54:29.652416 20800 sgd_solver.cpp:106] Iteration 13880, lr = 0.000344468
I0227 07:54:46.910907 20800 solver.cpp:229] Iteration 13900, loss = 0.133807
I0227 07:54:46.910953 20800 solver.cpp:245]     Train net output #0: accuracy = 0.961273
I0227 07:54:46.910962 20800 solver.cpp:245]     Train net output #1: accuracy = 0.800121
I0227 07:54:46.910969 20800 solver.cpp:245]     Train net output #2: accuracy = 0.837279
I0227 07:54:46.910980 20800 sgd_solver.cpp:106] Iteration 13900, lr = 0.000343455
I0227 07:55:04.186501 20800 solver.cpp:229] Iteration 13920, loss = 0.13957
I0227 07:55:04.186547 20800 solver.cpp:245]     Train net output #0: accuracy = 0.93118
I0227 07:55:04.186555 20800 solver.cpp:245]     Train net output #1: accuracy = 0.775877
I0227 07:55:04.186563 20800 solver.cpp:245]     Train net output #2: accuracy = 0.702501
I0227 07:55:04.186573 20800 sgd_solver.cpp:106] Iteration 13920, lr = 0.000342441
I0227 07:55:21.449405 20800 solver.cpp:229] Iteration 13940, loss = 0.13162
I0227 07:55:21.449452 20800 solver.cpp:245]     Train net output #0: accuracy = 0.958061
I0227 07:55:21.449461 20800 solver.cpp:245]     Train net output #1: accuracy = 0.82098
I0227 07:55:21.449467 20800 solver.cpp:245]     Train net output #2: accuracy = 0.87627
I0227 07:55:21.449477 20800 sgd_solver.cpp:106] Iteration 13940, lr = 0.000341427
I0227 07:55:38.738759 20800 solver.cpp:229] Iteration 13960, loss = 0.133378
I0227 07:55:38.738802 20800 solver.cpp:245]     Train net output #0: accuracy = 0.951158
I0227 07:55:38.738811 20800 solver.cpp:245]     Train net output #1: accuracy = 0.452645
I0227 07:55:38.738817 20800 solver.cpp:245]     Train net output #2: accuracy = 0.616071
I0227 07:55:38.738826 20800 sgd_solver.cpp:106] Iteration 13960, lr = 0.000340413
I0227 07:55:56.036322 20800 solver.cpp:229] Iteration 13980, loss = 0.133411
I0227 07:55:56.036367 20800 solver.cpp:245]     Train net output #0: accuracy = 0.946703
I0227 07:55:56.036376 20800 solver.cpp:245]     Train net output #1: accuracy = 0.768388
I0227 07:55:56.036383 20800 solver.cpp:245]     Train net output #2: accuracy = 0.843694
I0227 07:55:56.036392 20800 sgd_solver.cpp:106] Iteration 13980, lr = 0.000339398
I0227 07:56:13.336319 20800 solver.cpp:229] Iteration 14000, loss = 0.140612
I0227 07:56:13.336365 20800 solver.cpp:245]     Train net output #0: accuracy = 0.942534
I0227 07:56:13.336374 20800 solver.cpp:245]     Train net output #1: accuracy = 0.687328
I0227 07:56:13.336381 20800 solver.cpp:245]     Train net output #2: accuracy = 0.767533
I0227 07:56:13.336391 20800 sgd_solver.cpp:106] Iteration 14000, lr = 0.000338384
I0227 07:56:30.587086 20800 solver.cpp:229] Iteration 14020, loss = 0.135316
I0227 07:56:30.587131 20800 solver.cpp:245]     Train net output #0: accuracy = 0.939441
I0227 07:56:30.587141 20800 solver.cpp:245]     Train net output #1: accuracy = 0.903264
I0227 07:56:30.587163 20800 solver.cpp:245]     Train net output #2: accuracy = 0.84599
I0227 07:56:30.587173 20800 sgd_solver.cpp:106] Iteration 14020, lr = 0.000337368
I0227 07:56:47.851989 20800 solver.cpp:229] Iteration 14040, loss = 0.139921
I0227 07:56:47.852035 20800 solver.cpp:245]     Train net output #0: accuracy = 0.94765
I0227 07:56:47.852043 20800 solver.cpp:245]     Train net output #1: accuracy = 0.922492
I0227 07:56:47.852051 20800 solver.cpp:245]     Train net output #2: accuracy = 0.869351
I0227 07:56:47.852061 20800 sgd_solver.cpp:106] Iteration 14040, lr = 0.000336352
I0227 07:57:05.141737 20800 solver.cpp:229] Iteration 14060, loss = 0.128067
I0227 07:57:05.141767 20800 solver.cpp:245]     Train net output #0: accuracy = 0.954134
I0227 07:57:05.141777 20800 solver.cpp:245]     Train net output #1: accuracy = 0.892872
I0227 07:57:05.141783 20800 solver.cpp:245]     Train net output #2: accuracy = 0.825025
I0227 07:57:05.141793 20800 sgd_solver.cpp:106] Iteration 14060, lr = 0.000335336
I0227 07:57:22.403920 20800 solver.cpp:229] Iteration 14080, loss = 0.132764
I0227 07:57:22.403964 20800 solver.cpp:245]     Train net output #0: accuracy = 0.943724
I0227 07:57:22.403972 20800 solver.cpp:245]     Train net output #1: accuracy = 0.830267
I0227 07:57:22.403978 20800 solver.cpp:245]     Train net output #2: accuracy = 0.725372
I0227 07:57:22.403988 20800 sgd_solver.cpp:106] Iteration 14080, lr = 0.00033432
I0227 07:57:39.680984 20800 solver.cpp:229] Iteration 14100, loss = 0.134261
I0227 07:57:39.681027 20800 solver.cpp:245]     Train net output #0: accuracy = 0.952707
I0227 07:57:39.681035 20800 solver.cpp:245]     Train net output #1: accuracy = 0.649934
I0227 07:57:39.681042 20800 solver.cpp:245]     Train net output #2: accuracy = 0.642006
I0227 07:57:39.681052 20800 sgd_solver.cpp:106] Iteration 14100, lr = 0.000333303
I0227 07:57:56.958036 20800 solver.cpp:229] Iteration 14120, loss = 0.142763
I0227 07:57:56.958083 20800 solver.cpp:245]     Train net output #0: accuracy = 0.945799
I0227 07:57:56.958092 20800 solver.cpp:245]     Train net output #1: accuracy = 0.724123
I0227 07:57:56.958101 20800 solver.cpp:245]     Train net output #2: accuracy = 0.767453
I0227 07:57:56.958111 20800 sgd_solver.cpp:106] Iteration 14120, lr = 0.000332286
I0227 07:58:14.218763 20800 solver.cpp:229] Iteration 14140, loss = 0.131432
I0227 07:58:14.218797 20800 solver.cpp:245]     Train net output #0: accuracy = 0.935715
I0227 07:58:14.218807 20800 solver.cpp:245]     Train net output #1: accuracy = 0.716206
I0227 07:58:14.218814 20800 solver.cpp:245]     Train net output #2: accuracy = 0.793238
I0227 07:58:14.218824 20800 sgd_solver.cpp:106] Iteration 14140, lr = 0.000331269
I0227 07:58:31.478147 20800 solver.cpp:229] Iteration 14160, loss = 0.144087
I0227 07:58:31.478193 20800 solver.cpp:245]     Train net output #0: accuracy = 0.923803
I0227 07:58:31.478202 20800 solver.cpp:245]     Train net output #1: accuracy = 0.711093
I0227 07:58:31.478209 20800 solver.cpp:245]     Train net output #2: accuracy = 0.712207
I0227 07:58:31.478220 20800 sgd_solver.cpp:106] Iteration 14160, lr = 0.000330251
I0227 07:58:48.768451 20800 solver.cpp:229] Iteration 14180, loss = 0.133103
I0227 07:58:48.768496 20800 solver.cpp:245]     Train net output #0: accuracy = 0.939619
I0227 07:58:48.768507 20800 solver.cpp:245]     Train net output #1: accuracy = 0.875401
I0227 07:58:48.768513 20800 solver.cpp:245]     Train net output #2: accuracy = 0.906403
I0227 07:58:48.768522 20800 sgd_solver.cpp:106] Iteration 14180, lr = 0.000329233
I0227 07:59:06.035356 20800 solver.cpp:229] Iteration 14200, loss = 0.138281
I0227 07:59:06.035403 20800 solver.cpp:245]     Train net output #0: accuracy = 0.954253
I0227 07:59:06.035411 20800 solver.cpp:245]     Train net output #1: accuracy = 0.665783
I0227 07:59:06.035418 20800 solver.cpp:245]     Train net output #2: accuracy = 0.823531
I0227 07:59:06.035428 20800 sgd_solver.cpp:106] Iteration 14200, lr = 0.000328215
I0227 07:59:23.308079 20800 solver.cpp:229] Iteration 14220, loss = 0.122343
I0227 07:59:23.308109 20800 solver.cpp:245]     Train net output #0: accuracy = 0.946866
I0227 07:59:23.308118 20800 solver.cpp:245]     Train net output #1: accuracy = 0.74106
I0227 07:59:23.308126 20800 solver.cpp:245]     Train net output #2: accuracy = 0.821286
I0227 07:59:23.308135 20800 sgd_solver.cpp:106] Iteration 14220, lr = 0.000327196
I0227 07:59:40.559453 20800 solver.cpp:229] Iteration 14240, loss = 0.144279
I0227 07:59:40.559496 20800 solver.cpp:245]     Train net output #0: accuracy = 0.960473
I0227 07:59:40.559504 20800 solver.cpp:245]     Train net output #1: accuracy = 0.893231
I0227 07:59:40.559511 20800 solver.cpp:245]     Train net output #2: accuracy = 0.869184
I0227 07:59:40.559520 20800 sgd_solver.cpp:106] Iteration 14240, lr = 0.000326177
I0227 07:59:57.845926 20800 solver.cpp:229] Iteration 14260, loss = 0.137082
I0227 07:59:57.845953 20800 solver.cpp:245]     Train net output #0: accuracy = 0.926056
I0227 07:59:57.845962 20800 solver.cpp:245]     Train net output #1: accuracy = 0.789183
I0227 07:59:57.845968 20800 solver.cpp:245]     Train net output #2: accuracy = 0.77576
I0227 07:59:57.845978 20800 sgd_solver.cpp:106] Iteration 14260, lr = 0.000325157
I0227 08:00:15.143323 20800 solver.cpp:229] Iteration 14280, loss = 0.137723
I0227 08:00:15.143354 20800 solver.cpp:245]     Train net output #0: accuracy = 0.932731
I0227 08:00:15.143363 20800 solver.cpp:245]     Train net output #1: accuracy = 0.93119
I0227 08:00:15.143369 20800 solver.cpp:245]     Train net output #2: accuracy = 0.884894
I0227 08:00:15.143379 20800 sgd_solver.cpp:106] Iteration 14280, lr = 0.000324138
I0227 08:00:32.401831 20800 solver.cpp:229] Iteration 14300, loss = 0.140952
I0227 08:00:32.401861 20800 solver.cpp:245]     Train net output #0: accuracy = 0.939117
I0227 08:00:32.401870 20800 solver.cpp:245]     Train net output #1: accuracy = 0.818578
I0227 08:00:32.401877 20800 solver.cpp:245]     Train net output #2: accuracy = 0.864619
I0227 08:00:32.401886 20800 sgd_solver.cpp:106] Iteration 14300, lr = 0.000323117
I0227 08:00:49.667476 20800 solver.cpp:229] Iteration 14320, loss = 0.138768
I0227 08:00:49.667505 20800 solver.cpp:245]     Train net output #0: accuracy = 0.943878
I0227 08:00:49.667515 20800 solver.cpp:245]     Train net output #1: accuracy = 0.861708
I0227 08:00:49.667522 20800 solver.cpp:245]     Train net output #2: accuracy = 0.851316
I0227 08:00:49.667531 20800 sgd_solver.cpp:106] Iteration 14320, lr = 0.000322097
I0227 08:01:06.910862 20800 solver.cpp:229] Iteration 14340, loss = 0.13771
I0227 08:01:06.910914 20800 solver.cpp:245]     Train net output #0: accuracy = 0.948662
I0227 08:01:06.910923 20800 solver.cpp:245]     Train net output #1: accuracy = 0.738564
I0227 08:01:06.910930 20800 solver.cpp:245]     Train net output #2: accuracy = 0.760356
I0227 08:01:06.910939 20800 sgd_solver.cpp:106] Iteration 14340, lr = 0.000321076
I0227 08:01:24.200878 20800 solver.cpp:229] Iteration 14360, loss = 0.138029
I0227 08:01:24.200918 20800 solver.cpp:245]     Train net output #0: accuracy = 0.931707
I0227 08:01:24.200932 20800 solver.cpp:245]     Train net output #1: accuracy = 0.904074
I0227 08:01:24.200943 20800 solver.cpp:245]     Train net output #2: accuracy = 0.916164
I0227 08:01:24.200958 20800 sgd_solver.cpp:106] Iteration 14360, lr = 0.000320055
I0227 08:01:41.484477 20800 solver.cpp:229] Iteration 14380, loss = 0.145193
I0227 08:01:41.484505 20800 solver.cpp:245]     Train net output #0: accuracy = 0.937894
I0227 08:01:41.484513 20800 solver.cpp:245]     Train net output #1: accuracy = 0.751124
I0227 08:01:41.484519 20800 solver.cpp:245]     Train net output #2: accuracy = 0.798275
I0227 08:01:41.484529 20800 sgd_solver.cpp:106] Iteration 14380, lr = 0.000319033
I0227 08:01:58.755749 20800 solver.cpp:229] Iteration 14400, loss = 0.134642
I0227 08:01:58.755792 20800 solver.cpp:245]     Train net output #0: accuracy = 0.948636
I0227 08:01:58.755800 20800 solver.cpp:245]     Train net output #1: accuracy = 0.948457
I0227 08:01:58.755806 20800 solver.cpp:245]     Train net output #2: accuracy = 0.936255
I0227 08:01:58.755816 20800 sgd_solver.cpp:106] Iteration 14400, lr = 0.000318011
I0227 08:02:16.030565 20800 solver.cpp:229] Iteration 14420, loss = 0.139055
I0227 08:02:16.030609 20800 solver.cpp:245]     Train net output #0: accuracy = 0.968233
I0227 08:02:16.030618 20800 solver.cpp:245]     Train net output #1: accuracy = 0.908327
I0227 08:02:16.030625 20800 solver.cpp:245]     Train net output #2: accuracy = 0.840916
I0227 08:02:16.030634 20800 sgd_solver.cpp:106] Iteration 14420, lr = 0.000316989
I0227 08:02:33.321668 20800 solver.cpp:229] Iteration 14440, loss = 0.120184
I0227 08:02:33.321713 20800 solver.cpp:245]     Train net output #0: accuracy = 0.968045
I0227 08:02:33.321722 20800 solver.cpp:245]     Train net output #1: accuracy = 0.783578
I0227 08:02:33.321728 20800 solver.cpp:245]     Train net output #2: accuracy = 0.830435
I0227 08:02:33.321738 20800 sgd_solver.cpp:106] Iteration 14440, lr = 0.000315966
I0227 08:02:50.574445 20800 solver.cpp:229] Iteration 14460, loss = 0.134095
I0227 08:02:50.574491 20800 solver.cpp:245]     Train net output #0: accuracy = 0.951935
I0227 08:02:50.574499 20800 solver.cpp:245]     Train net output #1: accuracy = 0.695671
I0227 08:02:50.574506 20800 solver.cpp:245]     Train net output #2: accuracy = 0.713106
I0227 08:02:50.574515 20800 sgd_solver.cpp:106] Iteration 14460, lr = 0.000314943
I0227 08:03:07.848872 20800 solver.cpp:229] Iteration 14480, loss = 0.135713
I0227 08:03:07.848917 20800 solver.cpp:245]     Train net output #0: accuracy = 0.947227
I0227 08:03:07.848925 20800 solver.cpp:245]     Train net output #1: accuracy = 0.633813
I0227 08:03:07.848932 20800 solver.cpp:245]     Train net output #2: accuracy = 0.827685
I0227 08:03:07.848942 20800 sgd_solver.cpp:106] Iteration 14480, lr = 0.000313919
I0227 08:03:25.091616 20800 solver.cpp:229] Iteration 14500, loss = 0.134428
I0227 08:03:25.091662 20800 solver.cpp:245]     Train net output #0: accuracy = 0.950918
I0227 08:03:25.091671 20800 solver.cpp:245]     Train net output #1: accuracy = 0.818371
I0227 08:03:25.091678 20800 solver.cpp:245]     Train net output #2: accuracy = 0.822419
I0227 08:03:25.091687 20800 sgd_solver.cpp:106] Iteration 14500, lr = 0.000312896
I0227 08:03:42.368769 20800 solver.cpp:229] Iteration 14520, loss = 0.147546
I0227 08:03:42.368814 20800 solver.cpp:245]     Train net output #0: accuracy = 0.940784
I0227 08:03:42.368824 20800 solver.cpp:245]     Train net output #1: accuracy = 0.831565
I0227 08:03:42.368830 20800 solver.cpp:245]     Train net output #2: accuracy = 0.720676
I0227 08:03:42.368839 20800 sgd_solver.cpp:106] Iteration 14520, lr = 0.000311871
I0227 08:03:59.623256 20800 solver.cpp:229] Iteration 14540, loss = 0.13878
I0227 08:03:59.623301 20800 solver.cpp:245]     Train net output #0: accuracy = 0.93488
I0227 08:03:59.623308 20800 solver.cpp:245]     Train net output #1: accuracy = 0.861133
I0227 08:03:59.623315 20800 solver.cpp:245]     Train net output #2: accuracy = 0.825479
I0227 08:03:59.623324 20800 sgd_solver.cpp:106] Iteration 14540, lr = 0.000310847
I0227 08:04:16.890163 20800 solver.cpp:229] Iteration 14560, loss = 0.139501
I0227 08:04:16.890192 20800 solver.cpp:245]     Train net output #0: accuracy = 0.962939
I0227 08:04:16.890202 20800 solver.cpp:245]     Train net output #1: accuracy = 0.953825
I0227 08:04:16.890208 20800 solver.cpp:245]     Train net output #2: accuracy = 0.971513
I0227 08:04:16.890218 20800 sgd_solver.cpp:106] Iteration 14560, lr = 0.000309822
I0227 08:04:34.160393 20800 solver.cpp:229] Iteration 14580, loss = 0.135844
I0227 08:04:34.160439 20800 solver.cpp:245]     Train net output #0: accuracy = 0.957676
I0227 08:04:34.160465 20800 solver.cpp:245]     Train net output #1: accuracy = 0.786878
I0227 08:04:34.160471 20800 solver.cpp:245]     Train net output #2: accuracy = 0.825874
I0227 08:04:34.160481 20800 sgd_solver.cpp:106] Iteration 14580, lr = 0.000308797
I0227 08:04:51.450278 20800 solver.cpp:229] Iteration 14600, loss = 0.146074
I0227 08:04:51.450323 20800 solver.cpp:245]     Train net output #0: accuracy = 0.946534
I0227 08:04:51.450332 20800 solver.cpp:245]     Train net output #1: accuracy = 0.777059
I0227 08:04:51.450340 20800 solver.cpp:245]     Train net output #2: accuracy = 0.864168
I0227 08:04:51.450350 20800 sgd_solver.cpp:106] Iteration 14600, lr = 0.000307771
I0227 08:05:08.711881 20800 solver.cpp:229] Iteration 14620, loss = 0.136387
I0227 08:05:08.711926 20800 solver.cpp:245]     Train net output #0: accuracy = 0.953361
I0227 08:05:08.711935 20800 solver.cpp:245]     Train net output #1: accuracy = 0.749883
I0227 08:05:08.711942 20800 solver.cpp:245]     Train net output #2: accuracy = 0.633221
I0227 08:05:08.711952 20800 sgd_solver.cpp:106] Iteration 14620, lr = 0.000306745
I0227 08:05:25.992135 20800 solver.cpp:229] Iteration 14640, loss = 0.139661
I0227 08:05:25.992162 20800 solver.cpp:245]     Train net output #0: accuracy = 0.948483
I0227 08:05:25.992170 20800 solver.cpp:245]     Train net output #1: accuracy = 0.721606
I0227 08:05:25.992177 20800 solver.cpp:245]     Train net output #2: accuracy = 0.740396
I0227 08:05:25.992185 20800 sgd_solver.cpp:106] Iteration 14640, lr = 0.000305718
I0227 08:05:43.297021 20800 solver.cpp:229] Iteration 14660, loss = 0.121417
I0227 08:05:43.297049 20800 solver.cpp:245]     Train net output #0: accuracy = 0.955649
I0227 08:05:43.297057 20800 solver.cpp:245]     Train net output #1: accuracy = 0.77671
I0227 08:05:43.297063 20800 solver.cpp:245]     Train net output #2: accuracy = 0.764372
I0227 08:05:43.297072 20800 sgd_solver.cpp:106] Iteration 14660, lr = 0.000304691
I0227 08:06:00.558738 20800 solver.cpp:229] Iteration 14680, loss = 0.133765
I0227 08:06:00.558770 20800 solver.cpp:245]     Train net output #0: accuracy = 0.964128
I0227 08:06:00.558779 20800 solver.cpp:245]     Train net output #1: accuracy = 0.914941
I0227 08:06:00.558786 20800 solver.cpp:245]     Train net output #2: accuracy = 0.885922
I0227 08:06:00.558796 20800 sgd_solver.cpp:106] Iteration 14680, lr = 0.000303664
I0227 08:06:17.854780 20800 solver.cpp:229] Iteration 14700, loss = 0.13658
I0227 08:06:17.854825 20800 solver.cpp:245]     Train net output #0: accuracy = 0.939631
I0227 08:06:17.854833 20800 solver.cpp:245]     Train net output #1: accuracy = 0.729838
I0227 08:06:17.854840 20800 solver.cpp:245]     Train net output #2: accuracy = 0.737876
I0227 08:06:17.854851 20800 sgd_solver.cpp:106] Iteration 14700, lr = 0.000302637
I0227 08:06:35.136112 20800 solver.cpp:229] Iteration 14720, loss = 0.124931
I0227 08:06:35.136143 20800 solver.cpp:245]     Train net output #0: accuracy = 0.935098
I0227 08:06:35.136152 20800 solver.cpp:245]     Train net output #1: accuracy = 0.832188
I0227 08:06:35.136159 20800 solver.cpp:245]     Train net output #2: accuracy = 0.754962
I0227 08:06:35.136168 20800 sgd_solver.cpp:106] Iteration 14720, lr = 0.000301608
I0227 08:06:52.440855 20800 solver.cpp:229] Iteration 14740, loss = 0.132174
I0227 08:06:52.440884 20800 solver.cpp:245]     Train net output #0: accuracy = 0.950545
I0227 08:06:52.440892 20800 solver.cpp:245]     Train net output #1: accuracy = 0.848435
I0227 08:06:52.440898 20800 solver.cpp:245]     Train net output #2: accuracy = 0.757506
I0227 08:06:52.440907 20800 sgd_solver.cpp:106] Iteration 14740, lr = 0.00030058
I0227 08:07:09.726184 20800 solver.cpp:229] Iteration 14760, loss = 0.134987
I0227 08:07:09.726214 20800 solver.cpp:245]     Train net output #0: accuracy = 0.954075
I0227 08:07:09.726223 20800 solver.cpp:245]     Train net output #1: accuracy = 0.750559
I0227 08:07:09.726230 20800 solver.cpp:245]     Train net output #2: accuracy = 0.776573
I0227 08:07:09.726240 20800 sgd_solver.cpp:106] Iteration 14760, lr = 0.000299551
I0227 08:07:26.987700 20800 solver.cpp:229] Iteration 14780, loss = 0.132247
I0227 08:07:26.987745 20800 solver.cpp:245]     Train net output #0: accuracy = 0.939857
I0227 08:07:26.987753 20800 solver.cpp:245]     Train net output #1: accuracy = 0.791947
I0227 08:07:26.987759 20800 solver.cpp:245]     Train net output #2: accuracy = 0.815447
I0227 08:07:26.987768 20800 sgd_solver.cpp:106] Iteration 14780, lr = 0.000298522
I0227 08:07:44.273671 20800 solver.cpp:229] Iteration 14800, loss = 0.132204
I0227 08:07:44.273699 20800 solver.cpp:245]     Train net output #0: accuracy = 0.944602
I0227 08:07:44.273707 20800 solver.cpp:245]     Train net output #1: accuracy = 0.842737
I0227 08:07:44.273713 20800 solver.cpp:245]     Train net output #2: accuracy = 0.750262
I0227 08:07:44.273722 20800 sgd_solver.cpp:106] Iteration 14800, lr = 0.000297493
I0227 08:08:01.536067 20800 solver.cpp:229] Iteration 14820, loss = 0.136298
I0227 08:08:01.536095 20800 solver.cpp:245]     Train net output #0: accuracy = 0.927722
I0227 08:08:01.536104 20800 solver.cpp:245]     Train net output #1: accuracy = 0.904434
I0227 08:08:01.536110 20800 solver.cpp:245]     Train net output #2: accuracy = 0.841233
I0227 08:08:01.536119 20800 sgd_solver.cpp:106] Iteration 14820, lr = 0.000296463
I0227 08:08:18.803184 20800 solver.cpp:229] Iteration 14840, loss = 0.134833
I0227 08:08:18.803215 20800 solver.cpp:245]     Train net output #0: accuracy = 0.943872
I0227 08:08:18.803223 20800 solver.cpp:245]     Train net output #1: accuracy = 0.67183
I0227 08:08:18.803231 20800 solver.cpp:245]     Train net output #2: accuracy = 0.774441
I0227 08:08:18.803241 20800 sgd_solver.cpp:106] Iteration 14840, lr = 0.000295432
I0227 08:08:36.079447 20800 solver.cpp:229] Iteration 14860, loss = 0.121939
I0227 08:08:36.079494 20800 solver.cpp:245]     Train net output #0: accuracy = 0.94639
I0227 08:08:36.079504 20800 solver.cpp:245]     Train net output #1: accuracy = 0.819726
I0227 08:08:36.079509 20800 solver.cpp:245]     Train net output #2: accuracy = 0.77566
I0227 08:08:36.079519 20800 sgd_solver.cpp:106] Iteration 14860, lr = 0.000294401
I0227 08:08:53.358834 20800 solver.cpp:229] Iteration 14880, loss = 0.12818
I0227 08:08:53.358892 20800 solver.cpp:245]     Train net output #0: accuracy = 0.963654
I0227 08:08:53.358902 20800 solver.cpp:245]     Train net output #1: accuracy = 0.921238
I0227 08:08:53.358909 20800 solver.cpp:245]     Train net output #2: accuracy = 0.851559
I0227 08:08:53.358919 20800 sgd_solver.cpp:106] Iteration 14880, lr = 0.00029337
I0227 08:09:10.652339 20800 solver.cpp:229] Iteration 14900, loss = 0.136241
I0227 08:09:10.652369 20800 solver.cpp:245]     Train net output #0: accuracy = 0.949438
I0227 08:09:10.652379 20800 solver.cpp:245]     Train net output #1: accuracy = 0.828494
I0227 08:09:10.652385 20800 solver.cpp:245]     Train net output #2: accuracy = 0.821985
I0227 08:09:10.652395 20800 sgd_solver.cpp:106] Iteration 14900, lr = 0.000292339
I0227 08:09:27.899616 20800 solver.cpp:229] Iteration 14920, loss = 0.124037
I0227 08:09:27.899663 20800 solver.cpp:245]     Train net output #0: accuracy = 0.959642
I0227 08:09:27.899672 20800 solver.cpp:245]     Train net output #1: accuracy = 0.80552
I0227 08:09:27.899679 20800 solver.cpp:245]     Train net output #2: accuracy = 0.799402
I0227 08:09:27.899689 20800 sgd_solver.cpp:106] Iteration 14920, lr = 0.000291307
I0227 08:09:45.194339 20800 solver.cpp:229] Iteration 14940, loss = 0.130946
I0227 08:09:45.194370 20800 solver.cpp:245]     Train net output #0: accuracy = 0.937222
I0227 08:09:45.194380 20800 solver.cpp:245]     Train net output #1: accuracy = 0.7347
I0227 08:09:45.194386 20800 solver.cpp:245]     Train net output #2: accuracy = 0.816873
I0227 08:09:45.194396 20800 sgd_solver.cpp:106] Iteration 14940, lr = 0.000290274
I0227 08:10:02.452829 20800 solver.cpp:229] Iteration 14960, loss = 0.142822
I0227 08:10:02.452860 20800 solver.cpp:245]     Train net output #0: accuracy = 0.934718
I0227 08:10:02.452869 20800 solver.cpp:245]     Train net output #1: accuracy = 0.79555
I0227 08:10:02.452891 20800 solver.cpp:245]     Train net output #2: accuracy = 0.842856
I0227 08:10:02.452900 20800 sgd_solver.cpp:106] Iteration 14960, lr = 0.000289241
I0227 08:10:19.716550 20800 solver.cpp:229] Iteration 14980, loss = 0.130343
I0227 08:10:19.716594 20800 solver.cpp:245]     Train net output #0: accuracy = 0.957606
I0227 08:10:19.716603 20800 solver.cpp:245]     Train net output #1: accuracy = 0.867219
I0227 08:10:19.716610 20800 solver.cpp:245]     Train net output #2: accuracy = 0.891741
I0227 08:10:19.716620 20800 sgd_solver.cpp:106] Iteration 14980, lr = 0.000288208
I0227 08:10:37.000124 20800 solver.cpp:229] Iteration 15000, loss = 0.129996
I0227 08:10:37.000169 20800 solver.cpp:245]     Train net output #0: accuracy = 0.950024
I0227 08:10:37.000177 20800 solver.cpp:245]     Train net output #1: accuracy = 0.903736
I0227 08:10:37.000183 20800 solver.cpp:245]     Train net output #2: accuracy = 0.908053
I0227 08:10:37.000192 20800 sgd_solver.cpp:106] Iteration 15000, lr = 0.000287175
I0227 08:10:54.280962 20800 solver.cpp:229] Iteration 15020, loss = 0.145555
I0227 08:10:54.280994 20800 solver.cpp:245]     Train net output #0: accuracy = 0.942193
I0227 08:10:54.281003 20800 solver.cpp:245]     Train net output #1: accuracy = 0.836639
I0227 08:10:54.281010 20800 solver.cpp:245]     Train net output #2: accuracy = 0.81525
I0227 08:10:54.281020 20800 sgd_solver.cpp:106] Iteration 15020, lr = 0.000286141
I0227 08:11:11.554639 20800 solver.cpp:229] Iteration 15040, loss = 0.127998
I0227 08:11:11.554692 20800 solver.cpp:245]     Train net output #0: accuracy = 0.959429
I0227 08:11:11.554702 20800 solver.cpp:245]     Train net output #1: accuracy = 0.864181
I0227 08:11:11.554708 20800 solver.cpp:245]     Train net output #2: accuracy = 0.899644
I0227 08:11:11.554718 20800 sgd_solver.cpp:106] Iteration 15040, lr = 0.000285106
I0227 08:11:28.840062 20800 solver.cpp:229] Iteration 15060, loss = 0.139304
I0227 08:11:28.840106 20800 solver.cpp:245]     Train net output #0: accuracy = 0.944676
I0227 08:11:28.840114 20800 solver.cpp:245]     Train net output #1: accuracy = 0.844242
I0227 08:11:28.840121 20800 solver.cpp:245]     Train net output #2: accuracy = 0.851979
I0227 08:11:28.840131 20800 sgd_solver.cpp:106] Iteration 15060, lr = 0.000284071
I0227 08:11:46.125257 20800 solver.cpp:229] Iteration 15080, loss = 0.131883
I0227 08:11:46.125288 20800 solver.cpp:245]     Train net output #0: accuracy = 0.937316
I0227 08:11:46.125313 20800 solver.cpp:245]     Train net output #1: accuracy = 0.795559
I0227 08:11:46.125319 20800 solver.cpp:245]     Train net output #2: accuracy = 0.787051
I0227 08:11:46.125329 20800 sgd_solver.cpp:106] Iteration 15080, lr = 0.000283036
I0227 08:12:03.400053 20800 solver.cpp:229] Iteration 15100, loss = 0.131454
I0227 08:12:03.400097 20800 solver.cpp:245]     Train net output #0: accuracy = 0.939597
I0227 08:12:03.400121 20800 solver.cpp:245]     Train net output #1: accuracy = 0.77212
I0227 08:12:03.400128 20800 solver.cpp:245]     Train net output #2: accuracy = 0.819129
I0227 08:12:03.400137 20800 sgd_solver.cpp:106] Iteration 15100, lr = 0.000282
I0227 08:12:20.710767 20800 solver.cpp:229] Iteration 15120, loss = 0.138441
I0227 08:12:20.710813 20800 solver.cpp:245]     Train net output #0: accuracy = 0.944004
I0227 08:12:20.710821 20800 solver.cpp:245]     Train net output #1: accuracy = 0.696613
I0227 08:12:20.710829 20800 solver.cpp:245]     Train net output #2: accuracy = 0.704196
I0227 08:12:20.710837 20800 sgd_solver.cpp:106] Iteration 15120, lr = 0.000280964
I0227 08:12:37.992569 20800 solver.cpp:229] Iteration 15140, loss = 0.122601
I0227 08:12:37.992614 20800 solver.cpp:245]     Train net output #0: accuracy = 0.954911
I0227 08:12:37.992624 20800 solver.cpp:245]     Train net output #1: accuracy = 0.910838
I0227 08:12:37.992630 20800 solver.cpp:245]     Train net output #2: accuracy = 0.844446
I0227 08:12:37.992640 20800 sgd_solver.cpp:106] Iteration 15140, lr = 0.000279928
I0227 08:12:55.285140 20800 solver.cpp:229] Iteration 15160, loss = 0.140666
I0227 08:12:55.285171 20800 solver.cpp:245]     Train net output #0: accuracy = 0.919162
I0227 08:12:55.285195 20800 solver.cpp:245]     Train net output #1: accuracy = 0.695841
I0227 08:12:55.285202 20800 solver.cpp:245]     Train net output #2: accuracy = 0.680026
I0227 08:12:55.285212 20800 sgd_solver.cpp:106] Iteration 15160, lr = 0.000278891
I0227 08:13:12.539744 20800 solver.cpp:229] Iteration 15180, loss = 0.127378
I0227 08:13:12.539777 20800 solver.cpp:245]     Train net output #0: accuracy = 0.945747
I0227 08:13:12.539785 20800 solver.cpp:245]     Train net output #1: accuracy = 0.917234
I0227 08:13:12.539793 20800 solver.cpp:245]     Train net output #2: accuracy = 0.807936
I0227 08:13:12.539803 20800 sgd_solver.cpp:106] Iteration 15180, lr = 0.000277853
I0227 08:13:29.840939 20800 solver.cpp:229] Iteration 15200, loss = 0.131803
I0227 08:13:29.840967 20800 solver.cpp:245]     Train net output #0: accuracy = 0.95461
I0227 08:13:29.840975 20800 solver.cpp:245]     Train net output #1: accuracy = 0.776498
I0227 08:13:29.840982 20800 solver.cpp:245]     Train net output #2: accuracy = 0.84732
I0227 08:13:29.840991 20800 sgd_solver.cpp:106] Iteration 15200, lr = 0.000276815
I0227 08:13:47.142782 20800 solver.cpp:229] Iteration 15220, loss = 0.129471
I0227 08:13:47.142829 20800 solver.cpp:245]     Train net output #0: accuracy = 0.955562
I0227 08:13:47.142839 20800 solver.cpp:245]     Train net output #1: accuracy = 0.718742
I0227 08:13:47.142846 20800 solver.cpp:245]     Train net output #2: accuracy = 0.780064
I0227 08:13:47.142856 20800 sgd_solver.cpp:106] Iteration 15220, lr = 0.000275777
I0227 08:14:04.427175 20800 solver.cpp:229] Iteration 15240, loss = 0.125557
I0227 08:14:04.427222 20800 solver.cpp:245]     Train net output #0: accuracy = 0.94878
I0227 08:14:04.427230 20800 solver.cpp:245]     Train net output #1: accuracy = 0.79482
I0227 08:14:04.427237 20800 solver.cpp:245]     Train net output #2: accuracy = 0.850727
I0227 08:14:04.427248 20800 sgd_solver.cpp:106] Iteration 15240, lr = 0.000274738
I0227 08:14:21.704934 20800 solver.cpp:229] Iteration 15260, loss = 0.127491
I0227 08:14:21.704979 20800 solver.cpp:245]     Train net output #0: accuracy = 0.951517
I0227 08:14:21.705004 20800 solver.cpp:245]     Train net output #1: accuracy = 0.819755
I0227 08:14:21.705011 20800 solver.cpp:245]     Train net output #2: accuracy = 0.824566
I0227 08:14:21.705021 20800 sgd_solver.cpp:106] Iteration 15260, lr = 0.000273699
I0227 08:14:38.988713 20800 solver.cpp:229] Iteration 15280, loss = 0.13966
I0227 08:14:38.988744 20800 solver.cpp:245]     Train net output #0: accuracy = 0.954962
I0227 08:14:38.988754 20800 solver.cpp:245]     Train net output #1: accuracy = 0.801892
I0227 08:14:38.988760 20800 solver.cpp:245]     Train net output #2: accuracy = 0.793213
I0227 08:14:38.988770 20800 sgd_solver.cpp:106] Iteration 15280, lr = 0.00027266
I0227 08:14:56.256949 20800 solver.cpp:229] Iteration 15300, loss = 0.123327
I0227 08:14:56.256996 20800 solver.cpp:245]     Train net output #0: accuracy = 0.956746
I0227 08:14:56.257005 20800 solver.cpp:245]     Train net output #1: accuracy = 0.954418
I0227 08:14:56.257012 20800 solver.cpp:245]     Train net output #2: accuracy = 0.978513
I0227 08:14:56.257021 20800 sgd_solver.cpp:106] Iteration 15300, lr = 0.00027162
I0227 08:15:13.530917 20800 solver.cpp:229] Iteration 15320, loss = 0.1198
I0227 08:15:13.530949 20800 solver.cpp:245]     Train net output #0: accuracy = 0.970315
I0227 08:15:13.530958 20800 solver.cpp:245]     Train net output #1: accuracy = 0.848262
I0227 08:15:13.530966 20800 solver.cpp:245]     Train net output #2: accuracy = 0.902707
I0227 08:15:13.530975 20800 sgd_solver.cpp:106] Iteration 15320, lr = 0.000270579
I0227 08:15:30.801533 20800 solver.cpp:229] Iteration 15340, loss = 0.135339
I0227 08:15:30.801563 20800 solver.cpp:245]     Train net output #0: accuracy = 0.957406
I0227 08:15:30.801570 20800 solver.cpp:245]     Train net output #1: accuracy = 0.740637
I0227 08:15:30.801576 20800 solver.cpp:245]     Train net output #2: accuracy = 0.695464
I0227 08:15:30.801586 20800 sgd_solver.cpp:106] Iteration 15340, lr = 0.000269538
I0227 08:15:48.110867 20800 solver.cpp:229] Iteration 15360, loss = 0.130287
I0227 08:15:48.110954 20800 solver.cpp:245]     Train net output #0: accuracy = 0.950265
I0227 08:15:48.110963 20800 solver.cpp:245]     Train net output #1: accuracy = 0.756998
I0227 08:15:48.110970 20800 solver.cpp:245]     Train net output #2: accuracy = 0.787194
I0227 08:15:48.110980 20800 sgd_solver.cpp:106] Iteration 15360, lr = 0.000268497
I0227 08:16:05.396106 20800 solver.cpp:229] Iteration 15380, loss = 0.126637
I0227 08:16:05.396150 20800 solver.cpp:245]     Train net output #0: accuracy = 0.955681
I0227 08:16:05.396158 20800 solver.cpp:245]     Train net output #1: accuracy = 0.864646
I0227 08:16:05.396165 20800 solver.cpp:245]     Train net output #2: accuracy = 0.860254
I0227 08:16:05.396174 20800 sgd_solver.cpp:106] Iteration 15380, lr = 0.000267455
I0227 08:16:22.665616 20800 solver.cpp:229] Iteration 15400, loss = 0.137498
I0227 08:16:22.665676 20800 solver.cpp:245]     Train net output #0: accuracy = 0.940512
I0227 08:16:22.665697 20800 solver.cpp:245]     Train net output #1: accuracy = 0.79347
I0227 08:16:22.665704 20800 solver.cpp:245]     Train net output #2: accuracy = 0.647107
I0227 08:16:22.665714 20800 sgd_solver.cpp:106] Iteration 15400, lr = 0.000266413
I0227 08:16:39.951418 20800 solver.cpp:229] Iteration 15420, loss = 0.138553
I0227 08:16:39.951449 20800 solver.cpp:245]     Train net output #0: accuracy = 0.927187
I0227 08:16:39.951458 20800 solver.cpp:245]     Train net output #1: accuracy = 0.71051
I0227 08:16:39.951465 20800 solver.cpp:245]     Train net output #2: accuracy = 0.77455
I0227 08:16:39.951475 20800 sgd_solver.cpp:106] Iteration 15420, lr = 0.00026537
I0227 08:16:57.250844 20800 solver.cpp:229] Iteration 15440, loss = 0.13244
I0227 08:16:57.250913 20800 solver.cpp:245]     Train net output #0: accuracy = 0.957529
I0227 08:16:57.250924 20800 solver.cpp:245]     Train net output #1: accuracy = 0.806336
I0227 08:16:57.250931 20800 solver.cpp:245]     Train net output #2: accuracy = 0.729608
I0227 08:16:57.250942 20800 sgd_solver.cpp:106] Iteration 15440, lr = 0.000264327
I0227 08:17:14.527598 20800 solver.cpp:229] Iteration 15460, loss = 0.13591
I0227 08:17:14.527644 20800 solver.cpp:245]     Train net output #0: accuracy = 0.951717
I0227 08:17:14.527653 20800 solver.cpp:245]     Train net output #1: accuracy = 0.912268
I0227 08:17:14.527660 20800 solver.cpp:245]     Train net output #2: accuracy = 0.930634
I0227 08:17:14.527669 20800 sgd_solver.cpp:106] Iteration 15460, lr = 0.000263283
I0227 08:17:31.807626 20800 solver.cpp:229] Iteration 15480, loss = 0.127529
I0227 08:17:31.807670 20800 solver.cpp:245]     Train net output #0: accuracy = 0.964722
I0227 08:17:31.807679 20800 solver.cpp:245]     Train net output #1: accuracy = 0.718204
I0227 08:17:31.807687 20800 solver.cpp:245]     Train net output #2: accuracy = 0.684884
I0227 08:17:31.807698 20800 sgd_solver.cpp:106] Iteration 15480, lr = 0.000262239
I0227 08:17:49.099088 20800 solver.cpp:229] Iteration 15500, loss = 0.136044
I0227 08:17:49.099119 20800 solver.cpp:245]     Train net output #0: accuracy = 0.948617
I0227 08:17:49.099128 20800 solver.cpp:245]     Train net output #1: accuracy = 0.890318
I0227 08:17:49.099135 20800 solver.cpp:245]     Train net output #2: accuracy = 0.922466
I0227 08:17:49.099145 20800 sgd_solver.cpp:106] Iteration 15500, lr = 0.000261195
I0227 08:18:06.357491 20800 solver.cpp:229] Iteration 15520, loss = 0.140591
I0227 08:18:06.357522 20800 solver.cpp:245]     Train net output #0: accuracy = 0.943597
I0227 08:18:06.357532 20800 solver.cpp:245]     Train net output #1: accuracy = 0.756839
I0227 08:18:06.357538 20800 solver.cpp:245]     Train net output #2: accuracy = 0.837469
I0227 08:18:06.357548 20800 sgd_solver.cpp:106] Iteration 15520, lr = 0.00026015
I0227 08:18:23.648609 20800 solver.cpp:229] Iteration 15540, loss = 0.131898
I0227 08:18:23.648641 20800 solver.cpp:245]     Train net output #0: accuracy = 0.947888
I0227 08:18:23.648650 20800 solver.cpp:245]     Train net output #1: accuracy = 0.832657
I0227 08:18:23.648658 20800 solver.cpp:245]     Train net output #2: accuracy = 0.878901
I0227 08:18:23.648667 20800 sgd_solver.cpp:106] Iteration 15540, lr = 0.000259104
I0227 08:18:40.919579 20800 solver.cpp:229] Iteration 15560, loss = 0.138994
I0227 08:18:40.919625 20800 solver.cpp:245]     Train net output #0: accuracy = 0.950623
I0227 08:18:40.919633 20800 solver.cpp:245]     Train net output #1: accuracy = 0.734823
I0227 08:18:40.919641 20800 solver.cpp:245]     Train net output #2: accuracy = 0.693732
I0227 08:18:40.919652 20800 sgd_solver.cpp:106] Iteration 15560, lr = 0.000258058
I0227 08:18:58.208151 20800 solver.cpp:229] Iteration 15580, loss = 0.137291
I0227 08:18:58.208182 20800 solver.cpp:245]     Train net output #0: accuracy = 0.927932
I0227 08:18:58.208191 20800 solver.cpp:245]     Train net output #1: accuracy = 0.857003
I0227 08:18:58.208197 20800 solver.cpp:245]     Train net output #2: accuracy = 0.820511
I0227 08:18:58.208207 20800 sgd_solver.cpp:106] Iteration 15580, lr = 0.000257012
I0227 08:19:15.471539 20800 solver.cpp:229] Iteration 15600, loss = 0.138018
I0227 08:19:15.471585 20800 solver.cpp:245]     Train net output #0: accuracy = 0.947045
I0227 08:19:15.471593 20800 solver.cpp:245]     Train net output #1: accuracy = 0.676709
I0227 08:19:15.471601 20800 solver.cpp:245]     Train net output #2: accuracy = 0.866552
I0227 08:19:15.471611 20800 sgd_solver.cpp:106] Iteration 15600, lr = 0.000255965
I0227 08:19:32.757658 20800 solver.cpp:229] Iteration 15620, loss = 0.132335
I0227 08:19:32.757704 20800 solver.cpp:245]     Train net output #0: accuracy = 0.950982
I0227 08:19:32.757714 20800 solver.cpp:245]     Train net output #1: accuracy = 0.78226
I0227 08:19:32.757721 20800 solver.cpp:245]     Train net output #2: accuracy = 0.77359
I0227 08:19:32.757745 20800 sgd_solver.cpp:106] Iteration 15620, lr = 0.000254918
I0227 08:19:50.052881 20800 solver.cpp:229] Iteration 15640, loss = 0.138334
I0227 08:19:50.052912 20800 solver.cpp:245]     Train net output #0: accuracy = 0.940869
I0227 08:19:50.052922 20800 solver.cpp:245]     Train net output #1: accuracy = 0.819884
I0227 08:19:50.052928 20800 solver.cpp:245]     Train net output #2: accuracy = 0.828726
I0227 08:19:50.052938 20800 sgd_solver.cpp:106] Iteration 15640, lr = 0.00025387
I0227 08:20:07.344427 20800 solver.cpp:229] Iteration 15660, loss = 0.1236
I0227 08:20:07.344488 20800 solver.cpp:245]     Train net output #0: accuracy = 0.94519
I0227 08:20:07.344497 20800 solver.cpp:245]     Train net output #1: accuracy = 0.900738
I0227 08:20:07.344504 20800 solver.cpp:245]     Train net output #2: accuracy = 0.901961
I0227 08:20:07.344514 20800 sgd_solver.cpp:106] Iteration 15660, lr = 0.000252821
I0227 08:20:24.622287 20800 solver.cpp:229] Iteration 15680, loss = 0.13427
I0227 08:20:24.622318 20800 solver.cpp:245]     Train net output #0: accuracy = 0.95229
I0227 08:20:24.622326 20800 solver.cpp:245]     Train net output #1: accuracy = 0.900856
I0227 08:20:24.622334 20800 solver.cpp:245]     Train net output #2: accuracy = 0.946289
I0227 08:20:24.622344 20800 sgd_solver.cpp:106] Iteration 15680, lr = 0.000251773
I0227 08:20:41.906352 20800 solver.cpp:229] Iteration 15700, loss = 0.142603
I0227 08:20:41.906399 20800 solver.cpp:245]     Train net output #0: accuracy = 0.954551
I0227 08:20:41.906409 20800 solver.cpp:245]     Train net output #1: accuracy = 0.869503
I0227 08:20:41.906415 20800 solver.cpp:245]     Train net output #2: accuracy = 0.921869
I0227 08:20:41.906425 20800 sgd_solver.cpp:106] Iteration 15700, lr = 0.000250723
I0227 08:20:59.191910 20800 solver.cpp:229] Iteration 15720, loss = 0.138979
I0227 08:20:59.191941 20800 solver.cpp:245]     Train net output #0: accuracy = 0.934573
I0227 08:20:59.191951 20800 solver.cpp:245]     Train net output #1: accuracy = 0.855725
I0227 08:20:59.191957 20800 solver.cpp:245]     Train net output #2: accuracy = 0.809865
I0227 08:20:59.191967 20800 sgd_solver.cpp:106] Iteration 15720, lr = 0.000249673
I0227 08:21:16.478245 20800 solver.cpp:229] Iteration 15740, loss = 0.123467
I0227 08:21:16.478274 20800 solver.cpp:245]     Train net output #0: accuracy = 0.951731
I0227 08:21:16.478283 20800 solver.cpp:245]     Train net output #1: accuracy = 0.817936
I0227 08:21:16.478291 20800 solver.cpp:245]     Train net output #2: accuracy = 0.869011
I0227 08:21:16.478301 20800 sgd_solver.cpp:106] Iteration 15740, lr = 0.000248623
I0227 08:21:33.741852 20800 solver.cpp:229] Iteration 15760, loss = 0.135437
I0227 08:21:33.741880 20800 solver.cpp:245]     Train net output #0: accuracy = 0.952112
I0227 08:21:33.741889 20800 solver.cpp:245]     Train net output #1: accuracy = 0.832041
I0227 08:21:33.741895 20800 solver.cpp:245]     Train net output #2: accuracy = 0.879316
I0227 08:21:33.741904 20800 sgd_solver.cpp:106] Iteration 15760, lr = 0.000247572
I0227 08:21:51.020180 20800 solver.cpp:229] Iteration 15780, loss = 0.126269
I0227 08:21:51.020212 20800 solver.cpp:245]     Train net output #0: accuracy = 0.964247
I0227 08:21:51.020221 20800 solver.cpp:245]     Train net output #1: accuracy = 0.928583
I0227 08:21:51.020228 20800 solver.cpp:245]     Train net output #2: accuracy = 0.929811
I0227 08:21:51.020238 20800 sgd_solver.cpp:106] Iteration 15780, lr = 0.000246521
I0227 08:22:08.295070 20800 solver.cpp:229] Iteration 15800, loss = 0.138891
I0227 08:22:08.295100 20800 solver.cpp:245]     Train net output #0: accuracy = 0.944735
I0227 08:22:08.295110 20800 solver.cpp:245]     Train net output #1: accuracy = 0.901954
I0227 08:22:08.295117 20800 solver.cpp:245]     Train net output #2: accuracy = 0.830606
I0227 08:22:08.295126 20800 sgd_solver.cpp:106] Iteration 15800, lr = 0.000245469
I0227 08:22:25.562711 20800 solver.cpp:229] Iteration 15820, loss = 0.12938
I0227 08:22:25.562742 20800 solver.cpp:245]     Train net output #0: accuracy = 0.937299
I0227 08:22:25.562752 20800 solver.cpp:245]     Train net output #1: accuracy = 0.72596
I0227 08:22:25.562758 20800 solver.cpp:245]     Train net output #2: accuracy = 0.782738
I0227 08:22:25.562768 20800 sgd_solver.cpp:106] Iteration 15820, lr = 0.000244417
I0227 08:22:42.850350 20800 solver.cpp:229] Iteration 15840, loss = 0.127147
I0227 08:22:42.850396 20800 solver.cpp:245]     Train net output #0: accuracy = 0.919912
I0227 08:22:42.850404 20800 solver.cpp:245]     Train net output #1: accuracy = 0.830389
I0227 08:22:42.850411 20800 solver.cpp:245]     Train net output #2: accuracy = 0.786416
I0227 08:22:42.850421 20800 sgd_solver.cpp:106] Iteration 15840, lr = 0.000243364
I0227 08:23:00.127941 20800 solver.cpp:229] Iteration 15860, loss = 0.12396
I0227 08:23:00.127986 20800 solver.cpp:245]     Train net output #0: accuracy = 0.935141
I0227 08:23:00.127995 20800 solver.cpp:245]     Train net output #1: accuracy = 0.791123
I0227 08:23:00.128002 20800 solver.cpp:245]     Train net output #2: accuracy = 0.809497
I0227 08:23:00.128012 20800 sgd_solver.cpp:106] Iteration 15860, lr = 0.000242311
I0227 08:23:17.376238 20800 solver.cpp:229] Iteration 15880, loss = 0.121794
I0227 08:23:17.376266 20800 solver.cpp:245]     Train net output #0: accuracy = 0.955741
I0227 08:23:17.376274 20800 solver.cpp:245]     Train net output #1: accuracy = 0.734829
I0227 08:23:17.376281 20800 solver.cpp:245]     Train net output #2: accuracy = 0.84483
I0227 08:23:17.376289 20800 sgd_solver.cpp:106] Iteration 15880, lr = 0.000241257
I0227 08:23:34.663318 20800 solver.cpp:229] Iteration 15900, loss = 0.133275
I0227 08:23:34.663365 20800 solver.cpp:245]     Train net output #0: accuracy = 0.942237
I0227 08:23:34.663374 20800 solver.cpp:245]     Train net output #1: accuracy = 0.753693
I0227 08:23:34.663383 20800 solver.cpp:245]     Train net output #2: accuracy = 0.85794
I0227 08:23:34.663393 20800 sgd_solver.cpp:106] Iteration 15900, lr = 0.000240203
I0227 08:23:51.969146 20800 solver.cpp:229] Iteration 15920, loss = 0.133232
I0227 08:23:51.969193 20800 solver.cpp:245]     Train net output #0: accuracy = 0.952885
I0227 08:23:51.969203 20800 solver.cpp:245]     Train net output #1: accuracy = 0.744656
I0227 08:23:51.969210 20800 solver.cpp:245]     Train net output #2: accuracy = 0.739829
I0227 08:23:51.969220 20800 sgd_solver.cpp:106] Iteration 15920, lr = 0.000239148
I0227 08:24:09.228446 20800 solver.cpp:229] Iteration 15940, loss = 0.133225
I0227 08:24:09.228507 20800 solver.cpp:245]     Train net output #0: accuracy = 0.936443
I0227 08:24:09.228531 20800 solver.cpp:245]     Train net output #1: accuracy = 0.654722
I0227 08:24:09.228538 20800 solver.cpp:245]     Train net output #2: accuracy = 0.811896
I0227 08:24:09.228549 20800 sgd_solver.cpp:106] Iteration 15940, lr = 0.000238093
I0227 08:24:26.507010 20800 solver.cpp:229] Iteration 15960, loss = 0.131802
I0227 08:24:26.507041 20800 solver.cpp:245]     Train net output #0: accuracy = 0.947055
I0227 08:24:26.507050 20800 solver.cpp:245]     Train net output #1: accuracy = 0.767682
I0227 08:24:26.507057 20800 solver.cpp:245]     Train net output #2: accuracy = 0.703909
I0227 08:24:26.507067 20800 sgd_solver.cpp:106] Iteration 15960, lr = 0.000237037
I0227 08:24:43.794991 20800 solver.cpp:229] Iteration 15980, loss = 0.138686
I0227 08:24:43.795035 20800 solver.cpp:245]     Train net output #0: accuracy = 0.931053
I0227 08:24:43.795044 20800 solver.cpp:245]     Train net output #1: accuracy = 0.930081
I0227 08:24:43.795051 20800 solver.cpp:245]     Train net output #2: accuracy = 0.866281
I0227 08:24:43.795061 20800 sgd_solver.cpp:106] Iteration 15980, lr = 0.000235981
I0227 08:25:01.087453 20800 solver.cpp:229] Iteration 16000, loss = 0.144267
I0227 08:25:01.087484 20800 solver.cpp:245]     Train net output #0: accuracy = 0.972576
I0227 08:25:01.087493 20800 solver.cpp:245]     Train net output #1: accuracy = 0.933568
I0227 08:25:01.087500 20800 solver.cpp:245]     Train net output #2: accuracy = 0.863102
I0227 08:25:01.087510 20800 sgd_solver.cpp:106] Iteration 16000, lr = 0.000234924
I0227 08:25:18.345142 20800 solver.cpp:229] Iteration 16020, loss = 0.129769
I0227 08:25:18.345173 20800 solver.cpp:245]     Train net output #0: accuracy = 0.963474
I0227 08:25:18.345182 20800 solver.cpp:245]     Train net output #1: accuracy = 0.874176
I0227 08:25:18.345190 20800 solver.cpp:245]     Train net output #2: accuracy = 0.840319
I0227 08:25:18.345199 20800 sgd_solver.cpp:106] Iteration 16020, lr = 0.000233866
I0227 08:25:35.624207 20800 solver.cpp:229] Iteration 16040, loss = 0.135384
I0227 08:25:35.624238 20800 solver.cpp:245]     Train net output #0: accuracy = 0.94301
I0227 08:25:35.624248 20800 solver.cpp:245]     Train net output #1: accuracy = 0.846928
I0227 08:25:35.624254 20800 solver.cpp:245]     Train net output #2: accuracy = 0.899432
I0227 08:25:35.624264 20800 sgd_solver.cpp:106] Iteration 16040, lr = 0.000232808
I0227 08:25:52.916445 20800 solver.cpp:229] Iteration 16060, loss = 0.135771
I0227 08:25:52.916491 20800 solver.cpp:245]     Train net output #0: accuracy = 0.96282
I0227 08:25:52.916499 20800 solver.cpp:245]     Train net output #1: accuracy = 0.864943
I0227 08:25:52.916505 20800 solver.cpp:245]     Train net output #2: accuracy = 0.820658
I0227 08:25:52.916515 20800 sgd_solver.cpp:106] Iteration 16060, lr = 0.00023175
I0227 08:26:10.180948 20800 solver.cpp:229] Iteration 16080, loss = 0.133181
I0227 08:26:10.180977 20800 solver.cpp:245]     Train net output #0: accuracy = 0.945435
I0227 08:26:10.180986 20800 solver.cpp:245]     Train net output #1: accuracy = 0.854221
I0227 08:26:10.180994 20800 solver.cpp:245]     Train net output #2: accuracy = 0.825961
I0227 08:26:10.181002 20800 sgd_solver.cpp:106] Iteration 16080, lr = 0.000230691
I0227 08:26:27.472923 20800 solver.cpp:229] Iteration 16100, loss = 0.132164
I0227 08:26:27.472954 20800 solver.cpp:245]     Train net output #0: accuracy = 0.960321
I0227 08:26:27.472964 20800 solver.cpp:245]     Train net output #1: accuracy = 0.688826
I0227 08:26:27.472970 20800 solver.cpp:245]     Train net output #2: accuracy = 0.754389
I0227 08:26:27.472980 20800 sgd_solver.cpp:106] Iteration 16100, lr = 0.000229631
I0227 08:26:44.753724 20800 solver.cpp:229] Iteration 16120, loss = 0.119712
I0227 08:26:44.753768 20800 solver.cpp:245]     Train net output #0: accuracy = 0.954499
I0227 08:26:44.753778 20800 solver.cpp:245]     Train net output #1: accuracy = 0.862376
I0227 08:26:44.753784 20800 solver.cpp:245]     Train net output #2: accuracy = 0.887489
I0227 08:26:44.753794 20800 sgd_solver.cpp:106] Iteration 16120, lr = 0.000228571
I0227 08:27:02.037454 20800 solver.cpp:229] Iteration 16140, loss = 0.123185
I0227 08:27:02.037503 20800 solver.cpp:245]     Train net output #0: accuracy = 0.954075
I0227 08:27:02.037513 20800 solver.cpp:245]     Train net output #1: accuracy = 0.834925
I0227 08:27:02.037519 20800 solver.cpp:245]     Train net output #2: accuracy = 0.904539
I0227 08:27:02.037528 20800 sgd_solver.cpp:106] Iteration 16140, lr = 0.000227511
I0227 08:27:19.320304 20800 solver.cpp:229] Iteration 16160, loss = 0.138963
I0227 08:27:19.320346 20800 solver.cpp:245]     Train net output #0: accuracy = 0.97329
I0227 08:27:19.320356 20800 solver.cpp:245]     Train net output #1: accuracy = 0.945608
I0227 08:27:19.320363 20800 solver.cpp:245]     Train net output #2: accuracy = 0.852837
I0227 08:27:19.320372 20800 sgd_solver.cpp:106] Iteration 16160, lr = 0.000226449
I0227 08:27:36.592675 20800 solver.cpp:229] Iteration 16180, loss = 0.141015
I0227 08:27:36.592722 20800 solver.cpp:245]     Train net output #0: accuracy = 0.953366
I0227 08:27:36.592731 20800 solver.cpp:245]     Train net output #1: accuracy = 0.709701
I0227 08:27:36.592738 20800 solver.cpp:245]     Train net output #2: accuracy = 0.766877
I0227 08:27:36.592747 20800 sgd_solver.cpp:106] Iteration 16180, lr = 0.000225388
I0227 08:27:53.877138 20800 solver.cpp:229] Iteration 16200, loss = 0.12756
I0227 08:27:53.877185 20800 solver.cpp:245]     Train net output #0: accuracy = 0.948314
I0227 08:27:53.877194 20800 solver.cpp:245]     Train net output #1: accuracy = 0.873731
I0227 08:27:53.877202 20800 solver.cpp:245]     Train net output #2: accuracy = 0.87954
I0227 08:27:53.877212 20800 sgd_solver.cpp:106] Iteration 16200, lr = 0.000224325
I0227 08:28:11.149271 20800 solver.cpp:229] Iteration 16220, loss = 0.137212
I0227 08:28:11.149317 20800 solver.cpp:245]     Train net output #0: accuracy = 0.958239
I0227 08:28:11.149325 20800 solver.cpp:245]     Train net output #1: accuracy = 0.892865
I0227 08:28:11.149333 20800 solver.cpp:245]     Train net output #2: accuracy = 0.938938
I0227 08:28:11.149343 20800 sgd_solver.cpp:106] Iteration 16220, lr = 0.000223262
I0227 08:28:28.451171 20800 solver.cpp:229] Iteration 16240, loss = 0.134966
I0227 08:28:28.451202 20800 solver.cpp:245]     Train net output #0: accuracy = 0.948937
I0227 08:28:28.451211 20800 solver.cpp:245]     Train net output #1: accuracy = 0.842811
I0227 08:28:28.451218 20800 solver.cpp:245]     Train net output #2: accuracy = 0.847222
I0227 08:28:28.451228 20800 sgd_solver.cpp:106] Iteration 16240, lr = 0.000222199
I0227 08:28:45.725162 20800 solver.cpp:229] Iteration 16260, loss = 0.131021
I0227 08:28:45.725193 20800 solver.cpp:245]     Train net output #0: accuracy = 0.958775
I0227 08:28:45.725203 20800 solver.cpp:245]     Train net output #1: accuracy = 0.887849
I0227 08:28:45.725209 20800 solver.cpp:245]     Train net output #2: accuracy = 0.896473
I0227 08:28:45.725219 20800 sgd_solver.cpp:106] Iteration 16260, lr = 0.000221135
I0227 08:29:02.996991 20800 solver.cpp:229] Iteration 16280, loss = 0.123031
I0227 08:29:02.997036 20800 solver.cpp:245]     Train net output #0: accuracy = 0.943189
I0227 08:29:02.997045 20800 solver.cpp:245]     Train net output #1: accuracy = 0.759059
I0227 08:29:02.997051 20800 solver.cpp:245]     Train net output #2: accuracy = 0.788111
I0227 08:29:02.997061 20800 sgd_solver.cpp:106] Iteration 16280, lr = 0.00022007
I0227 08:29:20.277709 20800 solver.cpp:229] Iteration 16300, loss = 0.130496
I0227 08:29:20.277753 20800 solver.cpp:245]     Train net output #0: accuracy = 0.942475
I0227 08:29:20.277762 20800 solver.cpp:245]     Train net output #1: accuracy = 0.581024
I0227 08:29:20.277770 20800 solver.cpp:245]     Train net output #2: accuracy = 0.702862
I0227 08:29:20.277778 20800 sgd_solver.cpp:106] Iteration 16300, lr = 0.000219005
I0227 08:29:37.554997 20800 solver.cpp:229] Iteration 16320, loss = 0.123075
I0227 08:29:37.555028 20800 solver.cpp:245]     Train net output #0: accuracy = 0.937696
I0227 08:29:37.555037 20800 solver.cpp:245]     Train net output #1: accuracy = 0.890551
I0227 08:29:37.555044 20800 solver.cpp:245]     Train net output #2: accuracy = 0.867442
I0227 08:29:37.555054 20800 sgd_solver.cpp:106] Iteration 16320, lr = 0.00021794
I0227 08:29:54.857751 20800 solver.cpp:229] Iteration 16340, loss = 0.133017
I0227 08:29:54.857798 20800 solver.cpp:245]     Train net output #0: accuracy = 0.932421
I0227 08:29:54.857808 20800 solver.cpp:245]     Train net output #1: accuracy = 0.891575
I0227 08:29:54.857815 20800 solver.cpp:245]     Train net output #2: accuracy = 0.924485
I0227 08:29:54.857825 20800 sgd_solver.cpp:106] Iteration 16340, lr = 0.000216873
I0227 08:30:12.120643 20800 solver.cpp:229] Iteration 16360, loss = 0.128004
I0227 08:30:12.120673 20800 solver.cpp:245]     Train net output #0: accuracy = 0.96689
I0227 08:30:12.120683 20800 solver.cpp:245]     Train net output #1: accuracy = 0.958866
I0227 08:30:12.120689 20800 solver.cpp:245]     Train net output #2: accuracy = 0.918287
I0227 08:30:12.120698 20800 sgd_solver.cpp:106] Iteration 16360, lr = 0.000215806
I0227 08:30:29.385412 20800 solver.cpp:229] Iteration 16380, loss = 0.137745
I0227 08:30:29.385473 20800 solver.cpp:245]     Train net output #0: accuracy = 0.942394
I0227 08:30:29.385481 20800 solver.cpp:245]     Train net output #1: accuracy = 0.824476
I0227 08:30:29.385488 20800 solver.cpp:245]     Train net output #2: accuracy = 0.88981
I0227 08:30:29.385498 20800 sgd_solver.cpp:106] Iteration 16380, lr = 0.000214739
I0227 08:30:46.682174 20800 solver.cpp:229] Iteration 16400, loss = 0.133234
I0227 08:30:46.682205 20800 solver.cpp:245]     Train net output #0: accuracy = 0.964376
I0227 08:30:46.682214 20800 solver.cpp:245]     Train net output #1: accuracy = 0.829179
I0227 08:30:46.682220 20800 solver.cpp:245]     Train net output #2: accuracy = 0.921621
I0227 08:30:46.682230 20800 sgd_solver.cpp:106] Iteration 16400, lr = 0.000213671
I0227 08:31:03.969812 20800 solver.cpp:229] Iteration 16420, loss = 0.14675
I0227 08:31:03.969859 20800 solver.cpp:245]     Train net output #0: accuracy = 0.95693
I0227 08:31:03.969868 20800 solver.cpp:245]     Train net output #1: accuracy = 0.614719
I0227 08:31:03.969877 20800 solver.cpp:245]     Train net output #2: accuracy = 0.633397
I0227 08:31:03.969885 20800 sgd_solver.cpp:106] Iteration 16420, lr = 0.000212602
I0227 08:31:21.252393 20800 solver.cpp:229] Iteration 16440, loss = 0.127115
I0227 08:31:21.252424 20800 solver.cpp:245]     Train net output #0: accuracy = 0.96686
I0227 08:31:21.252434 20800 solver.cpp:245]     Train net output #1: accuracy = 0.845704
I0227 08:31:21.252440 20800 solver.cpp:245]     Train net output #2: accuracy = 0.86289
I0227 08:31:21.252449 20800 sgd_solver.cpp:106] Iteration 16440, lr = 0.000211533
I0227 08:31:38.550123 20800 solver.cpp:229] Iteration 16460, loss = 0.126989
I0227 08:31:38.550170 20800 solver.cpp:245]     Train net output #0: accuracy = 0.961808
I0227 08:31:38.550180 20800 solver.cpp:245]     Train net output #1: accuracy = 0.854714
I0227 08:31:38.550187 20800 solver.cpp:245]     Train net output #2: accuracy = 0.885687
I0227 08:31:38.550197 20800 sgd_solver.cpp:106] Iteration 16460, lr = 0.000210463
I0227 08:31:55.818034 20800 solver.cpp:229] Iteration 16480, loss = 0.13453
I0227 08:31:55.818081 20800 solver.cpp:245]     Train net output #0: accuracy = 0.960628
I0227 08:31:55.818090 20800 solver.cpp:245]     Train net output #1: accuracy = 0.901693
I0227 08:31:55.818097 20800 solver.cpp:245]     Train net output #2: accuracy = 0.883689
I0227 08:31:55.818107 20800 sgd_solver.cpp:106] Iteration 16480, lr = 0.000209393
I0227 08:32:13.079895 20800 solver.cpp:229] Iteration 16500, loss = 0.131347
I0227 08:32:13.079938 20800 solver.cpp:245]     Train net output #0: accuracy = 0.939792
I0227 08:32:13.079947 20800 solver.cpp:245]     Train net output #1: accuracy = 0.809503
I0227 08:32:13.079954 20800 solver.cpp:245]     Train net output #2: accuracy = 0.820394
I0227 08:32:13.079964 20800 sgd_solver.cpp:106] Iteration 16500, lr = 0.000208322
I0227 08:32:30.347539 20800 solver.cpp:229] Iteration 16520, loss = 0.119223
I0227 08:32:30.347585 20800 solver.cpp:245]     Train net output #0: accuracy = 0.952052
I0227 08:32:30.347595 20800 solver.cpp:245]     Train net output #1: accuracy = 0.806195
I0227 08:32:30.347602 20800 solver.cpp:245]     Train net output #2: accuracy = 0.85851
I0227 08:32:30.347612 20800 sgd_solver.cpp:106] Iteration 16520, lr = 0.00020725
I0227 08:32:47.628166 20800 solver.cpp:229] Iteration 16540, loss = 0.125864
I0227 08:32:47.628212 20800 solver.cpp:245]     Train net output #0: accuracy = 0.951219
I0227 08:32:47.628221 20800 solver.cpp:245]     Train net output #1: accuracy = 0.767907
I0227 08:32:47.628228 20800 solver.cpp:245]     Train net output #2: accuracy = 0.819382
I0227 08:32:47.628237 20800 sgd_solver.cpp:106] Iteration 16540, lr = 0.000206178
I0227 08:33:04.903312 20800 solver.cpp:229] Iteration 16560, loss = 0.126724
I0227 08:33:04.903359 20800 solver.cpp:245]     Train net output #0: accuracy = 0.952945
I0227 08:33:04.903368 20800 solver.cpp:245]     Train net output #1: accuracy = 0.841567
I0227 08:33:04.903375 20800 solver.cpp:245]     Train net output #2: accuracy = 0.787298
I0227 08:33:04.903385 20800 sgd_solver.cpp:106] Iteration 16560, lr = 0.000205105
I0227 08:33:22.168031 20800 solver.cpp:229] Iteration 16580, loss = 0.125789
I0227 08:33:22.168078 20800 solver.cpp:245]     Train net output #0: accuracy = 0.973692
I0227 08:33:22.168088 20800 solver.cpp:245]     Train net output #1: accuracy = 0.76328
I0227 08:33:22.168095 20800 solver.cpp:245]     Train net output #2: accuracy = 0.87036
I0227 08:33:22.168105 20800 sgd_solver.cpp:106] Iteration 16580, lr = 0.000204031
I0227 08:33:39.417564 20800 solver.cpp:229] Iteration 16600, loss = 0.138102
I0227 08:33:39.417593 20800 solver.cpp:245]     Train net output #0: accuracy = 0.931172
I0227 08:33:39.417601 20800 solver.cpp:245]     Train net output #1: accuracy = 0.856361
I0227 08:33:39.417608 20800 solver.cpp:245]     Train net output #2: accuracy = 0.827516
I0227 08:33:39.417616 20800 sgd_solver.cpp:106] Iteration 16600, lr = 0.000202957
I0227 08:33:56.713677 20800 solver.cpp:229] Iteration 16620, loss = 0.122259
I0227 08:33:56.713708 20800 solver.cpp:245]     Train net output #0: accuracy = 0.950081
I0227 08:33:56.713717 20800 solver.cpp:245]     Train net output #1: accuracy = 0.75447
I0227 08:33:56.713724 20800 solver.cpp:245]     Train net output #2: accuracy = 0.864774
I0227 08:33:56.713734 20800 sgd_solver.cpp:106] Iteration 16620, lr = 0.000201882
I0227 08:34:13.984894 20800 solver.cpp:229] Iteration 16640, loss = 0.13604
I0227 08:34:13.984925 20800 solver.cpp:245]     Train net output #0: accuracy = 0.95334
I0227 08:34:13.984933 20800 solver.cpp:245]     Train net output #1: accuracy = 0.915068
I0227 08:34:13.984941 20800 solver.cpp:245]     Train net output #2: accuracy = 0.895856
I0227 08:34:13.984949 20800 sgd_solver.cpp:106] Iteration 16640, lr = 0.000200807
I0227 08:34:31.270092 20800 solver.cpp:229] Iteration 16660, loss = 0.12731
I0227 08:34:31.270123 20800 solver.cpp:245]     Train net output #0: accuracy = 0.965675
I0227 08:34:31.270133 20800 solver.cpp:245]     Train net output #1: accuracy = 0.861896
I0227 08:34:31.270139 20800 solver.cpp:245]     Train net output #2: accuracy = 0.859508
I0227 08:34:31.270149 20800 sgd_solver.cpp:106] Iteration 16660, lr = 0.000199731
I0227 08:34:48.543473 20800 solver.cpp:229] Iteration 16680, loss = 0.123639
I0227 08:34:48.543519 20800 solver.cpp:245]     Train net output #0: accuracy = 0.968408
I0227 08:34:48.543527 20800 solver.cpp:245]     Train net output #1: accuracy = 0.829585
I0227 08:34:48.543534 20800 solver.cpp:245]     Train net output #2: accuracy = 0.902647
I0227 08:34:48.543545 20800 sgd_solver.cpp:106] Iteration 16680, lr = 0.000198654
I0227 08:35:05.798058 20800 solver.cpp:229] Iteration 16700, loss = 0.135382
I0227 08:35:05.798102 20800 solver.cpp:245]     Train net output #0: accuracy = 0.955146
I0227 08:35:05.798112 20800 solver.cpp:245]     Train net output #1: accuracy = 0.847294
I0227 08:35:05.798118 20800 solver.cpp:245]     Train net output #2: accuracy = 0.843982
I0227 08:35:05.798127 20800 sgd_solver.cpp:106] Iteration 16700, lr = 0.000197577
I0227 08:35:23.072023 20800 solver.cpp:229] Iteration 16720, loss = 0.129002
I0227 08:35:23.072070 20800 solver.cpp:245]     Train net output #0: accuracy = 0.949774
I0227 08:35:23.072079 20800 solver.cpp:245]     Train net output #1: accuracy = 0.819609
I0227 08:35:23.072088 20800 solver.cpp:245]     Train net output #2: accuracy = 0.850882
I0227 08:35:23.072098 20800 sgd_solver.cpp:106] Iteration 16720, lr = 0.000196499
I0227 08:35:40.338729 20800 solver.cpp:229] Iteration 16740, loss = 0.122718
I0227 08:35:40.338778 20800 solver.cpp:245]     Train net output #0: accuracy = 0.948899
I0227 08:35:40.338785 20800 solver.cpp:245]     Train net output #1: accuracy = 0.872769
I0227 08:35:40.338793 20800 solver.cpp:245]     Train net output #2: accuracy = 0.853654
I0227 08:35:40.338804 20800 sgd_solver.cpp:106] Iteration 16740, lr = 0.00019542
I0227 08:35:57.613268 20800 solver.cpp:229] Iteration 16760, loss = 0.136223
I0227 08:35:57.613314 20800 solver.cpp:245]     Train net output #0: accuracy = 0.9606
I0227 08:35:57.613322 20800 solver.cpp:245]     Train net output #1: accuracy = 0.828739
I0227 08:35:57.613329 20800 solver.cpp:245]     Train net output #2: accuracy = 0.879914
I0227 08:35:57.613338 20800 sgd_solver.cpp:106] Iteration 16760, lr = 0.000194341
I0227 08:36:14.909960 20800 solver.cpp:229] Iteration 16780, loss = 0.138043
I0227 08:36:14.910006 20800 solver.cpp:245]     Train net output #0: accuracy = 0.940466
I0227 08:36:14.910013 20800 solver.cpp:245]     Train net output #1: accuracy = 0.756919
I0227 08:36:14.910020 20800 solver.cpp:245]     Train net output #2: accuracy = 0.660865
I0227 08:36:14.910029 20800 sgd_solver.cpp:106] Iteration 16780, lr = 0.000193261
I0227 08:36:32.201846 20800 solver.cpp:229] Iteration 16800, loss = 0.129627
I0227 08:36:32.201879 20800 solver.cpp:245]     Train net output #0: accuracy = 0.953421
I0227 08:36:32.201889 20800 solver.cpp:245]     Train net output #1: accuracy = 0.922826
I0227 08:36:32.201895 20800 solver.cpp:245]     Train net output #2: accuracy = 0.898309
I0227 08:36:32.201905 20800 sgd_solver.cpp:106] Iteration 16800, lr = 0.00019218
I0227 08:36:49.492600 20800 solver.cpp:229] Iteration 16820, loss = 0.142183
I0227 08:36:49.492632 20800 solver.cpp:245]     Train net output #0: accuracy = 0.92263
I0227 08:36:49.492641 20800 solver.cpp:245]     Train net output #1: accuracy = 0.73461
I0227 08:36:49.492648 20800 solver.cpp:245]     Train net output #2: accuracy = 0.81974
I0227 08:36:49.492658 20800 sgd_solver.cpp:106] Iteration 16820, lr = 0.000191099
I0227 08:37:06.762372 20800 solver.cpp:229] Iteration 16840, loss = 0.126886
I0227 08:37:06.762404 20800 solver.cpp:245]     Train net output #0: accuracy = 0.957644
I0227 08:37:06.762413 20800 solver.cpp:245]     Train net output #1: accuracy = 0.86053
I0227 08:37:06.762420 20800 solver.cpp:245]     Train net output #2: accuracy = 0.872815
I0227 08:37:06.762429 20800 sgd_solver.cpp:106] Iteration 16840, lr = 0.000190017
I0227 08:37:24.035871 20800 solver.cpp:229] Iteration 16860, loss = 0.14009
I0227 08:37:24.035917 20800 solver.cpp:245]     Train net output #0: accuracy = 0.940372
I0227 08:37:24.035926 20800 solver.cpp:245]     Train net output #1: accuracy = 0.92471
I0227 08:37:24.035933 20800 solver.cpp:245]     Train net output #2: accuracy = 0.952299
I0227 08:37:24.035943 20800 sgd_solver.cpp:106] Iteration 16860, lr = 0.000188934
I0227 08:37:41.319845 20800 solver.cpp:229] Iteration 16880, loss = 0.131775
I0227 08:37:41.319890 20800 solver.cpp:245]     Train net output #0: accuracy = 0.95003
I0227 08:37:41.319900 20800 solver.cpp:245]     Train net output #1: accuracy = 0.849007
I0227 08:37:41.319906 20800 solver.cpp:245]     Train net output #2: accuracy = 0.805557
I0227 08:37:41.319916 20800 sgd_solver.cpp:106] Iteration 16880, lr = 0.00018785
I0227 08:37:58.597801 20800 solver.cpp:229] Iteration 16900, loss = 0.129927
I0227 08:37:58.597847 20800 solver.cpp:245]     Train net output #0: accuracy = 0.935716
I0227 08:37:58.597856 20800 solver.cpp:245]     Train net output #1: accuracy = 0.912016
I0227 08:37:58.597863 20800 solver.cpp:245]     Train net output #2: accuracy = 0.807782
I0227 08:37:58.597873 20800 sgd_solver.cpp:106] Iteration 16900, lr = 0.000186766
I0227 08:38:15.878899 20800 solver.cpp:229] Iteration 16920, loss = 0.130552
I0227 08:38:15.878962 20800 solver.cpp:245]     Train net output #0: accuracy = 0.952174
I0227 08:38:15.878971 20800 solver.cpp:245]     Train net output #1: accuracy = 0.872169
I0227 08:38:15.878978 20800 solver.cpp:245]     Train net output #2: accuracy = 0.815539
I0227 08:38:15.878988 20800 sgd_solver.cpp:106] Iteration 16920, lr = 0.000185682
I0227 08:38:33.155817 20800 solver.cpp:229] Iteration 16940, loss = 0.13148
I0227 08:38:33.155867 20800 solver.cpp:245]     Train net output #0: accuracy = 0.944616
I0227 08:38:33.155881 20800 solver.cpp:245]     Train net output #1: accuracy = 0.880612
I0227 08:38:33.155892 20800 solver.cpp:245]     Train net output #2: accuracy = 0.902368
I0227 08:38:33.155905 20800 sgd_solver.cpp:106] Iteration 16940, lr = 0.000184596
I0227 08:38:50.421792 20800 solver.cpp:229] Iteration 16960, loss = 0.133721
I0227 08:38:50.421821 20800 solver.cpp:245]     Train net output #0: accuracy = 0.949316
I0227 08:38:50.421829 20800 solver.cpp:245]     Train net output #1: accuracy = 0.824684
I0227 08:38:50.421835 20800 solver.cpp:245]     Train net output #2: accuracy = 0.894452
I0227 08:38:50.421844 20800 sgd_solver.cpp:106] Iteration 16960, lr = 0.00018351
I0227 08:39:07.687484 20800 solver.cpp:229] Iteration 16980, loss = 0.128749
I0227 08:39:07.687512 20800 solver.cpp:245]     Train net output #0: accuracy = 0.951577
I0227 08:39:07.687521 20800 solver.cpp:245]     Train net output #1: accuracy = 0.923577
I0227 08:39:07.687528 20800 solver.cpp:245]     Train net output #2: accuracy = 0.874908
I0227 08:39:07.687537 20800 sgd_solver.cpp:106] Iteration 16980, lr = 0.000182423
I0227 08:39:24.958865 20800 solver.cpp:229] Iteration 17000, loss = 0.119737
I0227 08:39:24.958900 20800 solver.cpp:245]     Train net output #0: accuracy = 0.926234
I0227 08:39:24.958925 20800 solver.cpp:245]     Train net output #1: accuracy = 0.869473
I0227 08:39:24.958931 20800 solver.cpp:245]     Train net output #2: accuracy = 0.759132
I0227 08:39:24.958940 20800 sgd_solver.cpp:106] Iteration 17000, lr = 0.000181335
I0227 08:39:42.236634 20800 solver.cpp:229] Iteration 17020, loss = 0.128047
I0227 08:39:42.236672 20800 solver.cpp:245]     Train net output #0: accuracy = 0.946044
I0227 08:39:42.236688 20800 solver.cpp:245]     Train net output #1: accuracy = 0.918871
I0227 08:39:42.236702 20800 solver.cpp:245]     Train net output #2: accuracy = 0.711266
I0227 08:39:42.236718 20800 sgd_solver.cpp:106] Iteration 17020, lr = 0.000180247
I0227 08:39:59.514116 20800 solver.cpp:229] Iteration 17040, loss = 0.118816
I0227 08:39:59.514160 20800 solver.cpp:245]     Train net output #0: accuracy = 0.961277
I0227 08:39:59.514169 20800 solver.cpp:245]     Train net output #1: accuracy = 0.652084
I0227 08:39:59.514176 20800 solver.cpp:245]     Train net output #2: accuracy = 0.658303
I0227 08:39:59.514186 20800 sgd_solver.cpp:106] Iteration 17040, lr = 0.000179158
I0227 08:40:16.801370 20800 solver.cpp:229] Iteration 17060, loss = 0.132529
I0227 08:40:16.801400 20800 solver.cpp:245]     Train net output #0: accuracy = 0.955793
I0227 08:40:16.801409 20800 solver.cpp:245]     Train net output #1: accuracy = 0.9346
I0227 08:40:16.801415 20800 solver.cpp:245]     Train net output #2: accuracy = 0.808168
I0227 08:40:16.801426 20800 sgd_solver.cpp:106] Iteration 17060, lr = 0.000178068
I0227 08:40:34.072480 20800 solver.cpp:229] Iteration 17080, loss = 0.129486
I0227 08:40:34.072525 20800 solver.cpp:245]     Train net output #0: accuracy = 0.958944
I0227 08:40:34.072535 20800 solver.cpp:245]     Train net output #1: accuracy = 0.763398
I0227 08:40:34.072541 20800 solver.cpp:245]     Train net output #2: accuracy = 0.890168
I0227 08:40:34.072551 20800 sgd_solver.cpp:106] Iteration 17080, lr = 0.000176977
I0227 08:40:51.347717 20800 solver.cpp:229] Iteration 17100, loss = 0.129628
I0227 08:40:51.347761 20800 solver.cpp:245]     Train net output #0: accuracy = 0.935549
I0227 08:40:51.347770 20800 solver.cpp:245]     Train net output #1: accuracy = 0.855792
I0227 08:40:51.347777 20800 solver.cpp:245]     Train net output #2: accuracy = 0.799569
I0227 08:40:51.347786 20800 sgd_solver.cpp:106] Iteration 17100, lr = 0.000175886
I0227 08:41:08.611863 20800 solver.cpp:229] Iteration 17120, loss = 0.128541
I0227 08:41:08.611891 20800 solver.cpp:245]     Train net output #0: accuracy = 0.949494
I0227 08:41:08.611899 20800 solver.cpp:245]     Train net output #1: accuracy = 0.835774
I0227 08:41:08.611905 20800 solver.cpp:245]     Train net output #2: accuracy = 0.801095
I0227 08:41:08.611914 20800 sgd_solver.cpp:106] Iteration 17120, lr = 0.000174794
I0227 08:41:25.897778 20800 solver.cpp:229] Iteration 17140, loss = 0.129618
I0227 08:41:25.897809 20800 solver.cpp:245]     Train net output #0: accuracy = 0.955979
I0227 08:41:25.897819 20800 solver.cpp:245]     Train net output #1: accuracy = 0.899803
I0227 08:41:25.897825 20800 solver.cpp:245]     Train net output #2: accuracy = 0.893342
I0227 08:41:25.897835 20800 sgd_solver.cpp:106] Iteration 17140, lr = 0.000173701
I0227 08:41:43.201340 20800 solver.cpp:229] Iteration 17160, loss = 0.120383
I0227 08:41:43.201386 20800 solver.cpp:245]     Train net output #0: accuracy = 0.944302
I0227 08:41:43.201395 20800 solver.cpp:245]     Train net output #1: accuracy = 0.944694
I0227 08:41:43.201402 20800 solver.cpp:245]     Train net output #2: accuracy = 0.766767
I0227 08:41:43.201412 20800 sgd_solver.cpp:106] Iteration 17160, lr = 0.000172607
I0227 08:42:00.472359 20800 solver.cpp:229] Iteration 17180, loss = 0.136923
I0227 08:42:00.472404 20800 solver.cpp:245]     Train net output #0: accuracy = 0.932539
I0227 08:42:00.472412 20800 solver.cpp:245]     Train net output #1: accuracy = 0.768088
I0227 08:42:00.472419 20800 solver.cpp:245]     Train net output #2: accuracy = 0.751885
I0227 08:42:00.472429 20800 sgd_solver.cpp:106] Iteration 17180, lr = 0.000171513
I0227 08:42:17.744238 20800 solver.cpp:229] Iteration 17200, loss = 0.137669
I0227 08:42:17.744268 20800 solver.cpp:245]     Train net output #0: accuracy = 0.93724
I0227 08:42:17.744277 20800 solver.cpp:245]     Train net output #1: accuracy = 0.801127
I0227 08:42:17.744284 20800 solver.cpp:245]     Train net output #2: accuracy = 0.820132
I0227 08:42:17.744293 20800 sgd_solver.cpp:106] Iteration 17200, lr = 0.000170418
I0227 08:42:35.019105 20800 solver.cpp:229] Iteration 17220, loss = 0.136007
I0227 08:42:35.019146 20800 solver.cpp:245]     Train net output #0: accuracy = 0.944914
I0227 08:42:35.019155 20800 solver.cpp:245]     Train net output #1: accuracy = 0.75081
I0227 08:42:35.019163 20800 solver.cpp:245]     Train net output #2: accuracy = 0.730978
I0227 08:42:35.019173 20800 sgd_solver.cpp:106] Iteration 17220, lr = 0.000169322
I0227 08:42:52.319690 20800 solver.cpp:229] Iteration 17240, loss = 0.132112
I0227 08:42:52.319734 20800 solver.cpp:245]     Train net output #0: accuracy = 0.969066
I0227 08:42:52.319743 20800 solver.cpp:245]     Train net output #1: accuracy = 0.934733
I0227 08:42:52.319751 20800 solver.cpp:245]     Train net output #2: accuracy = 0.920375
I0227 08:42:52.319759 20800 sgd_solver.cpp:106] Iteration 17240, lr = 0.000168225
I0227 08:43:09.607511 20800 solver.cpp:229] Iteration 17260, loss = 0.122285
I0227 08:43:09.607540 20800 solver.cpp:245]     Train net output #0: accuracy = 0.945092
I0227 08:43:09.607548 20800 solver.cpp:245]     Train net output #1: accuracy = 0.816757
I0227 08:43:09.607555 20800 solver.cpp:245]     Train net output #2: accuracy = 0.853873
I0227 08:43:09.607578 20800 sgd_solver.cpp:106] Iteration 17260, lr = 0.000167128
I0227 08:43:26.890250 20800 solver.cpp:229] Iteration 17280, loss = 0.125597
I0227 08:43:26.890281 20800 solver.cpp:245]     Train net output #0: accuracy = 0.955919
I0227 08:43:26.890290 20800 solver.cpp:245]     Train net output #1: accuracy = 0.791321
I0227 08:43:26.890297 20800 solver.cpp:245]     Train net output #2: accuracy = 0.761095
I0227 08:43:26.890306 20800 sgd_solver.cpp:106] Iteration 17280, lr = 0.000166029
I0227 08:43:44.165769 20800 solver.cpp:229] Iteration 17300, loss = 0.130597
I0227 08:43:44.165814 20800 solver.cpp:245]     Train net output #0: accuracy = 0.959142
I0227 08:43:44.165822 20800 solver.cpp:245]     Train net output #1: accuracy = 0.841181
I0227 08:43:44.165830 20800 solver.cpp:245]     Train net output #2: accuracy = 0.912946
I0227 08:43:44.165839 20800 sgd_solver.cpp:106] Iteration 17300, lr = 0.00016493
I0227 08:44:01.428776 20800 solver.cpp:229] Iteration 17320, loss = 0.125895
I0227 08:44:01.428820 20800 solver.cpp:245]     Train net output #0: accuracy = 0.934558
I0227 08:44:01.428828 20800 solver.cpp:245]     Train net output #1: accuracy = 0.686673
I0227 08:44:01.428835 20800 solver.cpp:245]     Train net output #2: accuracy = 0.675099
I0227 08:44:01.428844 20800 sgd_solver.cpp:106] Iteration 17320, lr = 0.00016383
I0227 08:44:18.718622 20800 solver.cpp:229] Iteration 17340, loss = 0.12585
I0227 08:44:18.718650 20800 solver.cpp:245]     Train net output #0: accuracy = 0.971148
I0227 08:44:18.718658 20800 solver.cpp:245]     Train net output #1: accuracy = 0.834391
I0227 08:44:18.718665 20800 solver.cpp:245]     Train net output #2: accuracy = 0.860749
I0227 08:44:18.718673 20800 sgd_solver.cpp:106] Iteration 17340, lr = 0.00016273
I0227 08:44:36.012567 20800 solver.cpp:229] Iteration 17360, loss = 0.122262
I0227 08:44:36.012614 20800 solver.cpp:245]     Train net output #0: accuracy = 0.929539
I0227 08:44:36.012624 20800 solver.cpp:245]     Train net output #1: accuracy = 0.717905
I0227 08:44:36.012630 20800 solver.cpp:245]     Train net output #2: accuracy = 0.682865
I0227 08:44:36.012640 20800 sgd_solver.cpp:106] Iteration 17360, lr = 0.000161628
I0227 08:44:53.270578 20800 solver.cpp:229] Iteration 17380, loss = 0.125834
I0227 08:44:53.270609 20800 solver.cpp:245]     Train net output #0: accuracy = 0.955325
I0227 08:44:53.270618 20800 solver.cpp:245]     Train net output #1: accuracy = 0.815331
I0227 08:44:53.270625 20800 solver.cpp:245]     Train net output #2: accuracy = 0.869965
I0227 08:44:53.270634 20800 sgd_solver.cpp:106] Iteration 17380, lr = 0.000160526
I0227 08:45:10.570226 20800 solver.cpp:229] Iteration 17400, loss = 0.137332
I0227 08:45:10.570256 20800 solver.cpp:245]     Train net output #0: accuracy = 0.94878
I0227 08:45:10.570266 20800 solver.cpp:245]     Train net output #1: accuracy = 0.939921
I0227 08:45:10.570272 20800 solver.cpp:245]     Train net output #2: accuracy = 0.921356
I0227 08:45:10.570281 20800 sgd_solver.cpp:106] Iteration 17400, lr = 0.000159422
I0227 08:45:27.850589 20800 solver.cpp:229] Iteration 17420, loss = 0.129446
I0227 08:45:27.850618 20800 solver.cpp:245]     Train net output #0: accuracy = 0.943189
I0227 08:45:27.850627 20800 solver.cpp:245]     Train net output #1: accuracy = 0.750738
I0227 08:45:27.850633 20800 solver.cpp:245]     Train net output #2: accuracy = 0.794845
I0227 08:45:27.850643 20800 sgd_solver.cpp:106] Iteration 17420, lr = 0.000158318
I0227 08:45:45.115510 20800 solver.cpp:229] Iteration 17440, loss = 0.123796
I0227 08:45:45.115542 20800 solver.cpp:245]     Train net output #0: accuracy = 0.963831
I0227 08:45:45.115551 20800 solver.cpp:245]     Train net output #1: accuracy = 0.817053
I0227 08:45:45.115558 20800 solver.cpp:245]     Train net output #2: accuracy = 0.881781
I0227 08:45:45.115568 20800 sgd_solver.cpp:106] Iteration 17440, lr = 0.000157213
I0227 08:46:02.385977 20800 solver.cpp:229] Iteration 17460, loss = 0.129681
I0227 08:46:02.386023 20800 solver.cpp:245]     Train net output #0: accuracy = 0.946282
I0227 08:46:02.386032 20800 solver.cpp:245]     Train net output #1: accuracy = 0.870633
I0227 08:46:02.386040 20800 solver.cpp:245]     Train net output #2: accuracy = 0.830038
I0227 08:46:02.386049 20800 sgd_solver.cpp:106] Iteration 17460, lr = 0.000156107
I0227 08:46:19.650254 20800 solver.cpp:229] Iteration 17480, loss = 0.137871
I0227 08:46:19.650300 20800 solver.cpp:245]     Train net output #0: accuracy = 0.955741
I0227 08:46:19.650308 20800 solver.cpp:245]     Train net output #1: accuracy = 0.83377
I0227 08:46:19.650315 20800 solver.cpp:245]     Train net output #2: accuracy = 0.910353
I0227 08:46:19.650326 20800 sgd_solver.cpp:106] Iteration 17480, lr = 0.000155001
I0227 08:46:36.917793 20800 solver.cpp:229] Iteration 17500, loss = 0.109693
I0227 08:46:36.917822 20800 solver.cpp:245]     Train net output #0: accuracy = 0.944973
I0227 08:46:36.917831 20800 solver.cpp:245]     Train net output #1: accuracy = 0.663003
I0227 08:46:36.917838 20800 solver.cpp:245]     Train net output #2: accuracy = 0.735876
I0227 08:46:36.917848 20800 sgd_solver.cpp:106] Iteration 17500, lr = 0.000153893
I0227 08:46:54.189690 20800 solver.cpp:229] Iteration 17520, loss = 0.127582
I0227 08:46:54.189735 20800 solver.cpp:245]     Train net output #0: accuracy = 0.939505
I0227 08:46:54.189744 20800 solver.cpp:245]     Train net output #1: accuracy = 0.748662
I0227 08:46:54.189751 20800 solver.cpp:245]     Train net output #2: accuracy = 0.775726
I0227 08:46:54.189760 20800 sgd_solver.cpp:106] Iteration 17520, lr = 0.000152785
I0227 08:47:11.449087 20800 solver.cpp:229] Iteration 17540, loss = 0.141345
I0227 08:47:11.449131 20800 solver.cpp:245]     Train net output #0: accuracy = 0.943308
I0227 08:47:11.449139 20800 solver.cpp:245]     Train net output #1: accuracy = 0.877393
I0227 08:47:11.449146 20800 solver.cpp:245]     Train net output #2: accuracy = 0.806658
I0227 08:47:11.449156 20800 sgd_solver.cpp:106] Iteration 17540, lr = 0.000151675
I0227 08:47:28.733494 20800 solver.cpp:229] Iteration 17560, loss = 0.127944
I0227 08:47:28.733539 20800 solver.cpp:245]     Train net output #0: accuracy = 0.944658
I0227 08:47:28.733549 20800 solver.cpp:245]     Train net output #1: accuracy = 0.810065
I0227 08:47:28.733556 20800 solver.cpp:245]     Train net output #2: accuracy = 0.733582
I0227 08:47:28.733566 20800 sgd_solver.cpp:106] Iteration 17560, lr = 0.000150565
I0227 08:47:46.006781 20800 solver.cpp:229] Iteration 17580, loss = 0.130487
I0227 08:47:46.006826 20800 solver.cpp:245]     Train net output #0: accuracy = 0.940646
I0227 08:47:46.006835 20800 solver.cpp:245]     Train net output #1: accuracy = 0.897814
I0227 08:47:46.006842 20800 solver.cpp:245]     Train net output #2: accuracy = 0.895782
I0227 08:47:46.006851 20800 sgd_solver.cpp:106] Iteration 17580, lr = 0.000149454
I0227 08:48:03.288509 20800 solver.cpp:229] Iteration 17600, loss = 0.120669
I0227 08:48:03.288555 20800 solver.cpp:245]     Train net output #0: accuracy = 0.944021
I0227 08:48:03.288564 20800 solver.cpp:245]     Train net output #1: accuracy = 0.803328
I0227 08:48:03.288573 20800 solver.cpp:245]     Train net output #2: accuracy = 0.784323
I0227 08:48:03.288581 20800 sgd_solver.cpp:106] Iteration 17600, lr = 0.000148342
I0227 08:48:20.560590 20800 solver.cpp:229] Iteration 17620, loss = 0.127005
I0227 08:48:20.560634 20800 solver.cpp:245]     Train net output #0: accuracy = 0.965199
I0227 08:48:20.560643 20800 solver.cpp:245]     Train net output #1: accuracy = 0.946657
I0227 08:48:20.560650 20800 solver.cpp:245]     Train net output #2: accuracy = 0.965488
I0227 08:48:20.560659 20800 sgd_solver.cpp:106] Iteration 17620, lr = 0.000147229
I0227 08:48:37.827370 20800 solver.cpp:229] Iteration 17640, loss = 0.127241
I0227 08:48:37.827399 20800 solver.cpp:245]     Train net output #0: accuracy = 0.961273
I0227 08:48:37.827409 20800 solver.cpp:245]     Train net output #1: accuracy = 0.876707
I0227 08:48:37.827415 20800 solver.cpp:245]     Train net output #2: accuracy = 0.932858
I0227 08:48:37.827425 20800 sgd_solver.cpp:106] Iteration 17640, lr = 0.000146115
I0227 08:48:55.098690 20800 solver.cpp:229] Iteration 17660, loss = 0.123978
I0227 08:48:55.098747 20800 solver.cpp:245]     Train net output #0: accuracy = 0.959191
I0227 08:48:55.098755 20800 solver.cpp:245]     Train net output #1: accuracy = 0.906807
I0227 08:48:55.098762 20800 solver.cpp:245]     Train net output #2: accuracy = 0.881263
I0227 08:48:55.098772 20800 sgd_solver.cpp:106] Iteration 17660, lr = 0.000145
I0227 08:49:12.379122 20800 solver.cpp:229] Iteration 17680, loss = 0.118152
I0227 08:49:12.379151 20800 solver.cpp:245]     Train net output #0: accuracy = 0.940869
I0227 08:49:12.379161 20800 solver.cpp:245]     Train net output #1: accuracy = 0.893797
I0227 08:49:12.379168 20800 solver.cpp:245]     Train net output #2: accuracy = 0.762519
I0227 08:49:12.379178 20800 sgd_solver.cpp:106] Iteration 17680, lr = 0.000143884
I0227 08:49:29.690291 20800 solver.cpp:229] Iteration 17700, loss = 0.12958
I0227 08:49:29.690335 20800 solver.cpp:245]     Train net output #0: accuracy = 0.970018
I0227 08:49:29.690345 20800 solver.cpp:245]     Train net output #1: accuracy = 0.82499
I0227 08:49:29.690351 20800 solver.cpp:245]     Train net output #2: accuracy = 0.823149
I0227 08:49:29.690374 20800 sgd_solver.cpp:106] Iteration 17700, lr = 0.000142767
I0227 08:49:46.972529 20800 solver.cpp:229] Iteration 17720, loss = 0.124237
I0227 08:49:46.972574 20800 solver.cpp:245]     Train net output #0: accuracy = 0.958894
I0227 08:49:46.972584 20800 solver.cpp:245]     Train net output #1: accuracy = 0.879948
I0227 08:49:46.972590 20800 solver.cpp:245]     Train net output #2: accuracy = 0.912684
I0227 08:49:46.972600 20800 sgd_solver.cpp:106] Iteration 17720, lr = 0.000141649
I0227 08:50:04.254367 20800 solver.cpp:229] Iteration 17740, loss = 0.12306
I0227 08:50:04.254410 20800 solver.cpp:245]     Train net output #0: accuracy = 0.931597
I0227 08:50:04.254420 20800 solver.cpp:245]     Train net output #1: accuracy = 0.662873
I0227 08:50:04.254426 20800 solver.cpp:245]     Train net output #2: accuracy = 0.749709
I0227 08:50:04.254436 20800 sgd_solver.cpp:106] Iteration 17740, lr = 0.00014053
I0227 08:50:21.518033 20800 solver.cpp:229] Iteration 17760, loss = 0.125161
I0227 08:50:21.518064 20800 solver.cpp:245]     Train net output #0: accuracy = 0.944458
I0227 08:50:21.518072 20800 solver.cpp:245]     Train net output #1: accuracy = 0.820236
I0227 08:50:21.518079 20800 solver.cpp:245]     Train net output #2: accuracy = 0.858777
I0227 08:50:21.518090 20800 sgd_solver.cpp:106] Iteration 17760, lr = 0.000139411
I0227 08:50:38.815846 20800 solver.cpp:229] Iteration 17780, loss = 0.130396
I0227 08:50:38.815892 20800 solver.cpp:245]     Train net output #0: accuracy = 0.952384
I0227 08:50:38.815902 20800 solver.cpp:245]     Train net output #1: accuracy = 0.690584
I0227 08:50:38.815908 20800 solver.cpp:245]     Train net output #2: accuracy = 0.72363
I0227 08:50:38.815919 20800 sgd_solver.cpp:106] Iteration 17780, lr = 0.00013829
I0227 08:50:56.061666 20800 solver.cpp:229] Iteration 17800, loss = 0.135638
I0227 08:50:56.061709 20800 solver.cpp:245]     Train net output #0: accuracy = 0.965651
I0227 08:50:56.061718 20800 solver.cpp:245]     Train net output #1: accuracy = 0.818176
I0227 08:50:56.061725 20800 solver.cpp:245]     Train net output #2: accuracy = 0.853839
I0227 08:50:56.061735 20800 sgd_solver.cpp:106] Iteration 17800, lr = 0.000137168
I0227 08:51:13.338135 20800 solver.cpp:229] Iteration 17820, loss = 0.14242
I0227 08:51:13.338181 20800 solver.cpp:245]     Train net output #0: accuracy = 0.930993
I0227 08:51:13.338188 20800 solver.cpp:245]     Train net output #1: accuracy = 0.858122
I0227 08:51:13.338196 20800 solver.cpp:245]     Train net output #2: accuracy = 0.840417
I0227 08:51:13.338205 20800 sgd_solver.cpp:106] Iteration 17820, lr = 0.000136045
I0227 08:51:30.640282 20800 solver.cpp:229] Iteration 17840, loss = 0.138778
I0227 08:51:30.640328 20800 solver.cpp:245]     Train net output #0: accuracy = 0.952478
I0227 08:51:30.640337 20800 solver.cpp:245]     Train net output #1: accuracy = 0.953877
I0227 08:51:30.640343 20800 solver.cpp:245]     Train net output #2: accuracy = 0.894118
I0227 08:51:30.640353 20800 sgd_solver.cpp:106] Iteration 17840, lr = 0.000134922
I0227 08:51:47.913377 20800 solver.cpp:229] Iteration 17860, loss = 0.127374
I0227 08:51:47.913422 20800 solver.cpp:245]     Train net output #0: accuracy = 0.955622
I0227 08:51:47.913431 20800 solver.cpp:245]     Train net output #1: accuracy = 0.682635
I0227 08:51:47.913437 20800 solver.cpp:245]     Train net output #2: accuracy = 0.779408
I0227 08:51:47.913446 20800 sgd_solver.cpp:106] Iteration 17860, lr = 0.000133797
I0227 08:52:05.204895 20800 solver.cpp:229] Iteration 17880, loss = 0.138292
I0227 08:52:05.204926 20800 solver.cpp:245]     Train net output #0: accuracy = 0.951779
I0227 08:52:05.204933 20800 solver.cpp:245]     Train net output #1: accuracy = 0.881574
I0227 08:52:05.204941 20800 solver.cpp:245]     Train net output #2: accuracy = 0.877746
I0227 08:52:05.204951 20800 sgd_solver.cpp:106] Iteration 17880, lr = 0.000132671
I0227 08:52:22.501961 20800 solver.cpp:229] Iteration 17900, loss = 0.121823
I0227 08:52:22.501991 20800 solver.cpp:245]     Train net output #0: accuracy = 0.951261
I0227 08:52:22.501998 20800 solver.cpp:245]     Train net output #1: accuracy = 0.826317
I0227 08:52:22.502004 20800 solver.cpp:245]     Train net output #2: accuracy = 0.890984
I0227 08:52:22.502013 20800 sgd_solver.cpp:106] Iteration 17900, lr = 0.000131544
I0227 08:52:39.788167 20800 solver.cpp:229] Iteration 17920, loss = 0.127592
I0227 08:52:39.788197 20800 solver.cpp:245]     Train net output #0: accuracy = 0.939976
I0227 08:52:39.788206 20800 solver.cpp:245]     Train net output #1: accuracy = 0.814401
I0227 08:52:39.788213 20800 solver.cpp:245]     Train net output #2: accuracy = 0.83419
I0227 08:52:39.788221 20800 sgd_solver.cpp:106] Iteration 17920, lr = 0.000130416
I0227 08:52:57.077612 20800 solver.cpp:229] Iteration 17940, loss = 0.124102
I0227 08:52:57.077657 20800 solver.cpp:245]     Train net output #0: accuracy = 0.948427
I0227 08:52:57.077682 20800 solver.cpp:245]     Train net output #1: accuracy = 0.837026
I0227 08:52:57.077689 20800 solver.cpp:245]     Train net output #2: accuracy = 0.88739
I0227 08:52:57.077698 20800 sgd_solver.cpp:106] Iteration 17940, lr = 0.000129287
I0227 08:53:14.350438 20800 solver.cpp:229] Iteration 17960, loss = 0.125843
I0227 08:53:14.350467 20800 solver.cpp:245]     Train net output #0: accuracy = 0.954194
I0227 08:53:14.350476 20800 solver.cpp:245]     Train net output #1: accuracy = 0.862944
I0227 08:53:14.350481 20800 solver.cpp:245]     Train net output #2: accuracy = 0.874651
I0227 08:53:14.350492 20800 sgd_solver.cpp:106] Iteration 17960, lr = 0.000128156
I0227 08:53:31.632968 20800 solver.cpp:229] Iteration 17980, loss = 0.136463
I0227 08:53:31.633014 20800 solver.cpp:245]     Train net output #0: accuracy = 0.944795
I0227 08:53:31.633024 20800 solver.cpp:245]     Train net output #1: accuracy = 0.701016
I0227 08:53:31.633031 20800 solver.cpp:245]     Train net output #2: accuracy = 0.718433
I0227 08:53:31.633040 20800 sgd_solver.cpp:106] Iteration 17980, lr = 0.000127025
I0227 08:53:48.892913 20800 solver.cpp:229] Iteration 18000, loss = 0.122927
I0227 08:53:48.892946 20800 solver.cpp:245]     Train net output #0: accuracy = 0.956354
I0227 08:53:48.892954 20800 solver.cpp:245]     Train net output #1: accuracy = 0.819341
I0227 08:53:48.892961 20800 solver.cpp:245]     Train net output #2: accuracy = 0.853254
I0227 08:53:48.892971 20800 sgd_solver.cpp:106] Iteration 18000, lr = 0.000125893
I0227 08:54:06.146463 20800 solver.cpp:229] Iteration 18020, loss = 0.110742
I0227 08:54:06.146513 20800 solver.cpp:245]     Train net output #0: accuracy = 0.953497
I0227 08:54:06.146522 20800 solver.cpp:245]     Train net output #1: accuracy = 0.922037
I0227 08:54:06.146529 20800 solver.cpp:245]     Train net output #2: accuracy = 0.904337
I0227 08:54:06.146539 20800 sgd_solver.cpp:106] Iteration 18020, lr = 0.000124759
I0227 08:54:23.406205 20800 solver.cpp:229] Iteration 18040, loss = 0.121207
I0227 08:54:23.406250 20800 solver.cpp:245]     Train net output #0: accuracy = 0.951159
I0227 08:54:23.406275 20800 solver.cpp:245]     Train net output #1: accuracy = 0.651531
I0227 08:54:23.406281 20800 solver.cpp:245]     Train net output #2: accuracy = 0.721775
I0227 08:54:23.406291 20800 sgd_solver.cpp:106] Iteration 18040, lr = 0.000123624
I0227 08:54:40.696545 20800 solver.cpp:229] Iteration 18060, loss = 0.129488
I0227 08:54:40.696589 20800 solver.cpp:245]     Train net output #0: accuracy = 0.943129
I0227 08:54:40.696597 20800 solver.cpp:245]     Train net output #1: accuracy = 0.90924
I0227 08:54:40.696604 20800 solver.cpp:245]     Train net output #2: accuracy = 0.93615
I0227 08:54:40.696614 20800 sgd_solver.cpp:106] Iteration 18060, lr = 0.000122488
I0227 08:54:57.944679 20800 solver.cpp:229] Iteration 18080, loss = 0.126325
I0227 08:54:57.944721 20800 solver.cpp:245]     Train net output #0: accuracy = 0.966371
I0227 08:54:57.944730 20800 solver.cpp:245]     Train net output #1: accuracy = 0.846095
I0227 08:54:57.944737 20800 solver.cpp:245]     Train net output #2: accuracy = 0.823943
I0227 08:54:57.944748 20800 sgd_solver.cpp:106] Iteration 18080, lr = 0.000121351
I0227 08:55:15.240029 20800 solver.cpp:229] Iteration 18100, loss = 0.125235
I0227 08:55:15.240073 20800 solver.cpp:245]     Train net output #0: accuracy = 0.936815
I0227 08:55:15.240082 20800 solver.cpp:245]     Train net output #1: accuracy = 0.787917
I0227 08:55:15.240088 20800 solver.cpp:245]     Train net output #2: accuracy = 0.560332
I0227 08:55:15.240098 20800 sgd_solver.cpp:106] Iteration 18100, lr = 0.000120213
I0227 08:55:32.528426 20800 solver.cpp:229] Iteration 18120, loss = 0.12168
I0227 08:55:32.528471 20800 solver.cpp:245]     Train net output #0: accuracy = 0.956157
I0227 08:55:32.528481 20800 solver.cpp:245]     Train net output #1: accuracy = 0.837751
I0227 08:55:32.528487 20800 solver.cpp:245]     Train net output #2: accuracy = 0.860207
I0227 08:55:32.528496 20800 sgd_solver.cpp:106] Iteration 18120, lr = 0.000119073
I0227 08:55:49.804188 20800 solver.cpp:229] Iteration 18140, loss = 0.131142
I0227 08:55:49.804234 20800 solver.cpp:245]     Train net output #0: accuracy = 0.96446
I0227 08:55:49.804244 20800 solver.cpp:245]     Train net output #1: accuracy = 0.906851
I0227 08:55:49.804250 20800 solver.cpp:245]     Train net output #2: accuracy = 0.925809
I0227 08:55:49.804260 20800 sgd_solver.cpp:106] Iteration 18140, lr = 0.000117933
I0227 08:56:07.069546 20800 solver.cpp:229] Iteration 18160, loss = 0.123926
I0227 08:56:07.069577 20800 solver.cpp:245]     Train net output #0: accuracy = 0.941538
I0227 08:56:07.069586 20800 solver.cpp:245]     Train net output #1: accuracy = 0.763659
I0227 08:56:07.069593 20800 solver.cpp:245]     Train net output #2: accuracy = 0.773862
I0227 08:56:07.069604 20800 sgd_solver.cpp:106] Iteration 18160, lr = 0.000116791
I0227 08:56:24.359238 20800 solver.cpp:229] Iteration 18180, loss = 0.144028
I0227 08:56:24.359282 20800 solver.cpp:245]     Train net output #0: accuracy = 0.95235
I0227 08:56:24.359292 20800 solver.cpp:245]     Train net output #1: accuracy = 0.766298
I0227 08:56:24.359297 20800 solver.cpp:245]     Train net output #2: accuracy = 0.754973
I0227 08:56:24.359308 20800 sgd_solver.cpp:106] Iteration 18180, lr = 0.000115648
I0227 08:56:41.630410 20800 solver.cpp:229] Iteration 18200, loss = 0.11457
I0227 08:56:41.630440 20800 solver.cpp:245]     Train net output #0: accuracy = 0.952588
I0227 08:56:41.630450 20800 solver.cpp:245]     Train net output #1: accuracy = 0.825956
I0227 08:56:41.630456 20800 solver.cpp:245]     Train net output #2: accuracy = 0.837674
I0227 08:56:41.630466 20800 sgd_solver.cpp:106] Iteration 18200, lr = 0.000114503
I0227 08:56:58.902209 20800 solver.cpp:229] Iteration 18220, loss = 0.124477
I0227 08:56:58.902240 20800 solver.cpp:245]     Train net output #0: accuracy = 0.950741
I0227 08:56:58.902248 20800 solver.cpp:245]     Train net output #1: accuracy = 0.891692
I0227 08:56:58.902256 20800 solver.cpp:245]     Train net output #2: accuracy = 0.82342
I0227 08:56:58.902266 20800 sgd_solver.cpp:106] Iteration 18220, lr = 0.000113358
I0227 08:57:16.178530 20800 solver.cpp:229] Iteration 18240, loss = 0.135565
I0227 08:57:16.178575 20800 solver.cpp:245]     Train net output #0: accuracy = 0.901368
I0227 08:57:16.178584 20800 solver.cpp:245]     Train net output #1: accuracy = 0.756526
I0227 08:57:16.178591 20800 solver.cpp:245]     Train net output #2: accuracy = 0.673665
I0227 08:57:16.178601 20800 sgd_solver.cpp:106] Iteration 18240, lr = 0.000112211
I0227 08:57:33.466351 20800 solver.cpp:229] Iteration 18260, loss = 0.127345
I0227 08:57:33.466380 20800 solver.cpp:245]     Train net output #0: accuracy = 0.941931
I0227 08:57:33.466389 20800 solver.cpp:245]     Train net output #1: accuracy = 0.814914
I0227 08:57:33.466397 20800 solver.cpp:245]     Train net output #2: accuracy = 0.779263
I0227 08:57:33.466406 20800 sgd_solver.cpp:106] Iteration 18260, lr = 0.000111062
I0227 08:57:50.731663 20800 solver.cpp:229] Iteration 18280, loss = 0.130844
I0227 08:57:50.731707 20800 solver.cpp:245]     Train net output #0: accuracy = 0.932183
I0227 08:57:50.731715 20800 solver.cpp:245]     Train net output #1: accuracy = 0.845462
I0227 08:57:50.731722 20800 solver.cpp:245]     Train net output #2: accuracy = 0.766672
I0227 08:57:50.731731 20800 sgd_solver.cpp:106] Iteration 18280, lr = 0.000109913
I0227 08:58:08.043349 20800 solver.cpp:229] Iteration 18300, loss = 0.123011
I0227 08:58:08.043393 20800 solver.cpp:245]     Train net output #0: accuracy = 0.955562
I0227 08:58:08.043403 20800 solver.cpp:245]     Train net output #1: accuracy = 0.855642
I0227 08:58:08.043411 20800 solver.cpp:245]     Train net output #2: accuracy = 0.839666
I0227 08:58:08.043435 20800 sgd_solver.cpp:106] Iteration 18300, lr = 0.000108762
I0227 08:58:25.315918 20800 solver.cpp:229] Iteration 18320, loss = 0.127649
I0227 08:58:25.315948 20800 solver.cpp:245]     Train net output #0: accuracy = 0.945687
I0227 08:58:25.315956 20800 solver.cpp:245]     Train net output #1: accuracy = 0.782109
I0227 08:58:25.315963 20800 solver.cpp:245]     Train net output #2: accuracy = 0.868234
I0227 08:58:25.315973 20800 sgd_solver.cpp:106] Iteration 18320, lr = 0.00010761
I0227 08:58:42.572615 20800 solver.cpp:229] Iteration 18340, loss = 0.128267
I0227 08:58:42.572659 20800 solver.cpp:245]     Train net output #0: accuracy = 0.953338
I0227 08:58:42.572669 20800 solver.cpp:245]     Train net output #1: accuracy = 0.699211
I0227 08:58:42.572675 20800 solver.cpp:245]     Train net output #2: accuracy = 0.824165
I0227 08:58:42.572685 20800 sgd_solver.cpp:106] Iteration 18340, lr = 0.000106456
I0227 08:58:59.872529 20800 solver.cpp:229] Iteration 18360, loss = 0.128605
I0227 08:58:59.872558 20800 solver.cpp:245]     Train net output #0: accuracy = 0.953398
I0227 08:58:59.872568 20800 solver.cpp:245]     Train net output #1: accuracy = 0.847411
I0227 08:58:59.872575 20800 solver.cpp:245]     Train net output #2: accuracy = 0.864172
I0227 08:58:59.872586 20800 sgd_solver.cpp:106] Iteration 18360, lr = 0.000105301
I0227 08:59:17.143689 20800 solver.cpp:229] Iteration 18380, loss = 0.134828
I0227 08:59:17.143734 20800 solver.cpp:245]     Train net output #0: accuracy = 0.929268
I0227 08:59:17.143743 20800 solver.cpp:245]     Train net output #1: accuracy = 0.831016
I0227 08:59:17.143750 20800 solver.cpp:245]     Train net output #2: accuracy = 0.808388
I0227 08:59:17.143760 20800 sgd_solver.cpp:106] Iteration 18380, lr = 0.000104145
I0227 08:59:34.420794 20800 solver.cpp:229] Iteration 18400, loss = 0.133509
I0227 08:59:34.420826 20800 solver.cpp:245]     Train net output #0: accuracy = 0.936023
I0227 08:59:34.420835 20800 solver.cpp:245]     Train net output #1: accuracy = 0.923258
I0227 08:59:34.420842 20800 solver.cpp:245]     Train net output #2: accuracy = 0.847553
I0227 08:59:34.420851 20800 sgd_solver.cpp:106] Iteration 18400, lr = 0.000102987
I0227 08:59:51.693783 20800 solver.cpp:229] Iteration 18420, loss = 0.139407
I0227 08:59:51.693814 20800 solver.cpp:245]     Train net output #0: accuracy = 0.931648
I0227 08:59:51.693823 20800 solver.cpp:245]     Train net output #1: accuracy = 0.73124
I0227 08:59:51.693831 20800 solver.cpp:245]     Train net output #2: accuracy = 0.729089
I0227 08:59:51.693840 20800 sgd_solver.cpp:106] Iteration 18420, lr = 0.000101827
I0227 09:00:08.961360 20800 solver.cpp:229] Iteration 18440, loss = 0.141373
I0227 09:00:08.961391 20800 solver.cpp:245]     Train net output #0: accuracy = 0.934756
I0227 09:00:08.961400 20800 solver.cpp:245]     Train net output #1: accuracy = 0.794174
I0227 09:00:08.961406 20800 solver.cpp:245]     Train net output #2: accuracy = 0.854524
I0227 09:00:08.961416 20800 sgd_solver.cpp:106] Iteration 18440, lr = 0.000100667
I0227 09:00:26.237176 20800 solver.cpp:229] Iteration 18460, loss = 0.121138
I0227 09:00:26.237206 20800 solver.cpp:245]     Train net output #0: accuracy = 0.953659
I0227 09:00:26.237215 20800 solver.cpp:245]     Train net output #1: accuracy = 0.720558
I0227 09:00:26.237222 20800 solver.cpp:245]     Train net output #2: accuracy = 0.755833
I0227 09:00:26.237231 20800 sgd_solver.cpp:106] Iteration 18460, lr = 9.95043e-05
I0227 09:00:43.515731 20800 solver.cpp:229] Iteration 18480, loss = 0.126091
I0227 09:00:43.515763 20800 solver.cpp:245]     Train net output #0: accuracy = 0.963236
I0227 09:00:43.515771 20800 solver.cpp:245]     Train net output #1: accuracy = 0.925791
I0227 09:00:43.515779 20800 solver.cpp:245]     Train net output #2: accuracy = 0.910449
I0227 09:00:43.515789 20800 sgd_solver.cpp:106] Iteration 18480, lr = 9.83404e-05
I0227 09:01:00.799633 20800 solver.cpp:229] Iteration 18500, loss = 0.126009
I0227 09:01:00.799664 20800 solver.cpp:245]     Train net output #0: accuracy = 0.940571
I0227 09:01:00.799672 20800 solver.cpp:245]     Train net output #1: accuracy = 0.841368
I0227 09:01:00.799679 20800 solver.cpp:245]     Train net output #2: accuracy = 0.790653
I0227 09:01:00.799690 20800 sgd_solver.cpp:106] Iteration 18500, lr = 9.71751e-05
I0227 09:01:18.074851 20800 solver.cpp:229] Iteration 18520, loss = 0.117175
I0227 09:01:18.074905 20800 solver.cpp:245]     Train net output #0: accuracy = 0.945747
I0227 09:01:18.074932 20800 solver.cpp:245]     Train net output #1: accuracy = 0.831002
I0227 09:01:18.074939 20800 solver.cpp:245]     Train net output #2: accuracy = 0.828063
I0227 09:01:18.074949 20800 sgd_solver.cpp:106] Iteration 18520, lr = 9.60083e-05
I0227 09:01:35.338649 20800 solver.cpp:229] Iteration 18540, loss = 0.122808
I0227 09:01:35.338696 20800 solver.cpp:245]     Train net output #0: accuracy = 0.960024
I0227 09:01:35.338703 20800 solver.cpp:245]     Train net output #1: accuracy = 0.715991
I0227 09:01:35.338711 20800 solver.cpp:245]     Train net output #2: accuracy = 0.791464
I0227 09:01:35.338721 20800 sgd_solver.cpp:106] Iteration 18540, lr = 9.48398e-05
I0227 09:01:52.618296 20800 solver.cpp:229] Iteration 18560, loss = 0.140467
I0227 09:01:52.618341 20800 solver.cpp:245]     Train net output #0: accuracy = 0.95229
I0227 09:01:52.618350 20800 solver.cpp:245]     Train net output #1: accuracy = 0.846615
I0227 09:01:52.618357 20800 solver.cpp:245]     Train net output #2: accuracy = 0.881189
I0227 09:01:52.618367 20800 sgd_solver.cpp:106] Iteration 18560, lr = 9.36698e-05
I0227 09:02:09.891052 20800 solver.cpp:229] Iteration 18580, loss = 0.130851
I0227 09:02:09.891080 20800 solver.cpp:245]     Train net output #0: accuracy = 0.957287
I0227 09:02:09.891106 20800 solver.cpp:245]     Train net output #1: accuracy = 0.917395
I0227 09:02:09.891113 20800 solver.cpp:245]     Train net output #2: accuracy = 0.949286
I0227 09:02:09.891124 20800 sgd_solver.cpp:106] Iteration 18580, lr = 9.2498e-05
I0227 09:02:27.170763 20800 solver.cpp:229] Iteration 18600, loss = 0.127141
I0227 09:02:27.170790 20800 solver.cpp:245]     Train net output #0: accuracy = 0.948256
I0227 09:02:27.170799 20800 solver.cpp:245]     Train net output #1: accuracy = 0.909647
I0227 09:02:27.170805 20800 solver.cpp:245]     Train net output #2: accuracy = 0.937459
I0227 09:02:27.170814 20800 sgd_solver.cpp:106] Iteration 18600, lr = 9.13247e-05
I0227 09:02:44.444121 20800 solver.cpp:229] Iteration 18620, loss = 0.114421
I0227 09:02:44.444166 20800 solver.cpp:245]     Train net output #0: accuracy = 0.954221
I0227 09:02:44.444176 20800 solver.cpp:245]     Train net output #1: accuracy = 0.831399
I0227 09:02:44.444183 20800 solver.cpp:245]     Train net output #2: accuracy = 0.893355
I0227 09:02:44.444192 20800 sgd_solver.cpp:106] Iteration 18620, lr = 9.01497e-05
I0227 09:03:01.737332 20800 solver.cpp:229] Iteration 18640, loss = 0.146317
I0227 09:03:01.737377 20800 solver.cpp:245]     Train net output #0: accuracy = 0.942653
I0227 09:03:01.737386 20800 solver.cpp:245]     Train net output #1: accuracy = 0.913307
I0227 09:03:01.737393 20800 solver.cpp:245]     Train net output #2: accuracy = 0.874804
I0227 09:03:01.737403 20800 sgd_solver.cpp:106] Iteration 18640, lr = 8.8973e-05
I0227 09:03:19.001694 20800 solver.cpp:229] Iteration 18660, loss = 0.125373
I0227 09:03:19.001725 20800 solver.cpp:245]     Train net output #0: accuracy = 0.957525
I0227 09:03:19.001734 20800 solver.cpp:245]     Train net output #1: accuracy = 0.764489
I0227 09:03:19.001741 20800 solver.cpp:245]     Train net output #2: accuracy = 0.893229
I0227 09:03:19.001751 20800 sgd_solver.cpp:106] Iteration 18660, lr = 8.77945e-05
I0227 09:03:36.270666 20800 solver.cpp:229] Iteration 18680, loss = 0.123959
I0227 09:03:36.270710 20800 solver.cpp:245]     Train net output #0: accuracy = 0.953956
I0227 09:03:36.270720 20800 solver.cpp:245]     Train net output #1: accuracy = 0.845321
I0227 09:03:36.270725 20800 solver.cpp:245]     Train net output #2: accuracy = 0.902792
I0227 09:03:36.270735 20800 sgd_solver.cpp:106] Iteration 18680, lr = 8.66143e-05
I0227 09:03:53.532778 20800 solver.cpp:229] Iteration 18700, loss = 0.128475
I0227 09:03:53.532806 20800 solver.cpp:245]     Train net output #0: accuracy = 0.95818
I0227 09:03:53.532830 20800 solver.cpp:245]     Train net output #1: accuracy = 0.740108
I0227 09:03:53.532837 20800 solver.cpp:245]     Train net output #2: accuracy = 0.763825
I0227 09:03:53.532847 20800 sgd_solver.cpp:106] Iteration 18700, lr = 8.54323e-05
I0227 09:04:10.796084 20800 solver.cpp:229] Iteration 18720, loss = 0.137519
I0227 09:04:10.796130 20800 solver.cpp:245]     Train net output #0: accuracy = 0.961178
I0227 09:04:10.796139 20800 solver.cpp:245]     Train net output #1: accuracy = 0.706329
I0227 09:04:10.796146 20800 solver.cpp:245]     Train net output #2: accuracy = 0.8592
I0227 09:04:10.796155 20800 sgd_solver.cpp:106] Iteration 18720, lr = 8.42485e-05
I0227 09:04:28.087082 20800 solver.cpp:229] Iteration 18740, loss = 0.122758
I0227 09:04:28.087111 20800 solver.cpp:245]     Train net output #0: accuracy = 0.962998
I0227 09:04:28.087119 20800 solver.cpp:245]     Train net output #1: accuracy = 0.749874
I0227 09:04:28.087126 20800 solver.cpp:245]     Train net output #2: accuracy = 0.817676
I0227 09:04:28.087136 20800 sgd_solver.cpp:106] Iteration 18740, lr = 8.30628e-05
I0227 09:04:45.363660 20800 solver.cpp:229] Iteration 18760, loss = 0.127074
I0227 09:04:45.363692 20800 solver.cpp:245]     Train net output #0: accuracy = 0.944616
I0227 09:04:45.363700 20800 solver.cpp:245]     Train net output #1: accuracy = 0.918137
I0227 09:04:45.363708 20800 solver.cpp:245]     Train net output #2: accuracy = 0.945495
I0227 09:04:45.363718 20800 sgd_solver.cpp:106] Iteration 18760, lr = 8.18752e-05
I0227 09:05:02.629261 20800 solver.cpp:229] Iteration 18780, loss = 0.129839
I0227 09:05:02.629308 20800 solver.cpp:245]     Train net output #0: accuracy = 0.94034
I0227 09:05:02.629317 20800 solver.cpp:245]     Train net output #1: accuracy = 0.876004
I0227 09:05:02.629324 20800 solver.cpp:245]     Train net output #2: accuracy = 0.814735
I0227 09:05:02.629334 20800 sgd_solver.cpp:106] Iteration 18780, lr = 8.06857e-05
I0227 09:05:19.914326 20800 solver.cpp:229] Iteration 18800, loss = 0.131783
I0227 09:05:19.914372 20800 solver.cpp:245]     Train net output #0: accuracy = 0.943843
I0227 09:05:19.914381 20800 solver.cpp:245]     Train net output #1: accuracy = 0.821249
I0227 09:05:19.914388 20800 solver.cpp:245]     Train net output #2: accuracy = 0.805805
I0227 09:05:19.914398 20800 sgd_solver.cpp:106] Iteration 18800, lr = 7.94943e-05
I0227 09:05:37.190060 20800 solver.cpp:229] Iteration 18820, loss = 0.13384
I0227 09:05:37.190091 20800 solver.cpp:245]     Train net output #0: accuracy = 0.945092
I0227 09:05:37.190100 20800 solver.cpp:245]     Train net output #1: accuracy = 0.827231
I0227 09:05:37.190109 20800 solver.cpp:245]     Train net output #2: accuracy = 0.916037
I0227 09:05:37.190117 20800 sgd_solver.cpp:106] Iteration 18820, lr = 7.83009e-05
I0227 09:05:54.460592 20800 solver.cpp:229] Iteration 18840, loss = 0.118751
I0227 09:05:54.460638 20800 solver.cpp:245]     Train net output #0: accuracy = 0.928554
I0227 09:05:54.460646 20800 solver.cpp:245]     Train net output #1: accuracy = 0.539319
I0227 09:05:54.460654 20800 solver.cpp:245]     Train net output #2: accuracy = 0.688713
I0227 09:05:54.460664 20800 sgd_solver.cpp:106] Iteration 18840, lr = 7.71055e-05
I0227 09:06:11.734763 20800 solver.cpp:229] Iteration 18860, loss = 0.13794
I0227 09:06:11.734809 20800 solver.cpp:245]     Train net output #0: accuracy = 0.964898
I0227 09:06:11.734817 20800 solver.cpp:245]     Train net output #1: accuracy = 0.83611
I0227 09:06:11.734824 20800 solver.cpp:245]     Train net output #2: accuracy = 0.862849
I0227 09:06:11.734834 20800 sgd_solver.cpp:106] Iteration 18860, lr = 7.5908e-05
I0227 09:06:29.000605 20800 solver.cpp:229] Iteration 18880, loss = 0.137343
I0227 09:06:29.000650 20800 solver.cpp:245]     Train net output #0: accuracy = 0.941247
I0227 09:06:29.000659 20800 solver.cpp:245]     Train net output #1: accuracy = 0.781568
I0227 09:06:29.000668 20800 solver.cpp:245]     Train net output #2: accuracy = 0.810918
I0227 09:06:29.000676 20800 sgd_solver.cpp:106] Iteration 18880, lr = 7.47084e-05
I0227 09:06:46.258267 20800 solver.cpp:229] Iteration 18900, loss = 0.119085
I0227 09:06:46.258296 20800 solver.cpp:245]     Train net output #0: accuracy = 0.958032
I0227 09:06:46.258304 20800 solver.cpp:245]     Train net output #1: accuracy = 0.749701
I0227 09:06:46.258311 20800 solver.cpp:245]     Train net output #2: accuracy = 0.793439
I0227 09:06:46.258319 20800 sgd_solver.cpp:106] Iteration 18900, lr = 7.35066e-05
I0227 09:07:03.542642 20800 solver.cpp:229] Iteration 18920, loss = 0.133204
I0227 09:07:03.542688 20800 solver.cpp:245]     Train net output #0: accuracy = 0.93414
I0227 09:07:03.542696 20800 solver.cpp:245]     Train net output #1: accuracy = 0.822886
I0227 09:07:03.542703 20800 solver.cpp:245]     Train net output #2: accuracy = 0.835772
I0227 09:07:03.542713 20800 sgd_solver.cpp:106] Iteration 18920, lr = 7.23027e-05
I0227 09:07:20.837328 20800 solver.cpp:229] Iteration 18940, loss = 0.127859
I0227 09:07:20.837359 20800 solver.cpp:245]     Train net output #0: accuracy = 0.944914
I0227 09:07:20.837368 20800 solver.cpp:245]     Train net output #1: accuracy = 0.684183
I0227 09:07:20.837374 20800 solver.cpp:245]     Train net output #2: accuracy = 0.763419
I0227 09:07:20.837384 20800 sgd_solver.cpp:106] Iteration 18940, lr = 7.10965e-05
I0227 09:07:38.077741 20800 solver.cpp:229] Iteration 18960, loss = 0.120404
I0227 09:07:38.077800 20800 solver.cpp:245]     Train net output #0: accuracy = 0.958418
I0227 09:07:38.077808 20800 solver.cpp:245]     Train net output #1: accuracy = 0.910937
I0227 09:07:38.077816 20800 solver.cpp:245]     Train net output #2: accuracy = 0.859992
I0227 09:07:38.077826 20800 sgd_solver.cpp:106] Iteration 18960, lr = 6.98881e-05
I0227 09:07:55.347715 20800 solver.cpp:229] Iteration 18980, loss = 0.128528
I0227 09:07:55.347745 20800 solver.cpp:245]     Train net output #0: accuracy = 0.94128
I0227 09:07:55.347755 20800 solver.cpp:245]     Train net output #1: accuracy = 0.829901
I0227 09:07:55.347762 20800 solver.cpp:245]     Train net output #2: accuracy = 0.790974
I0227 09:07:55.347772 20800 sgd_solver.cpp:106] Iteration 18980, lr = 6.86773e-05
I0227 09:08:12.606178 20800 solver.cpp:229] Iteration 19000, loss = 0.123007
I0227 09:08:12.606223 20800 solver.cpp:245]     Train net output #0: accuracy = 0.951825
I0227 09:08:12.606232 20800 solver.cpp:245]     Train net output #1: accuracy = 0.826155
I0227 09:08:12.606240 20800 solver.cpp:245]     Train net output #2: accuracy = 0.842489
I0227 09:08:12.606250 20800 sgd_solver.cpp:106] Iteration 19000, lr = 6.74642e-05
I0227 09:08:29.895364 20800 solver.cpp:229] Iteration 19020, loss = 0.126598
I0227 09:08:29.895408 20800 solver.cpp:245]     Train net output #0: accuracy = 0.949687
I0227 09:08:29.895416 20800 solver.cpp:245]     Train net output #1: accuracy = 0.748303
I0227 09:08:29.895423 20800 solver.cpp:245]     Train net output #2: accuracy = 0.842452
I0227 09:08:29.895433 20800 sgd_solver.cpp:106] Iteration 19020, lr = 6.62486e-05
I0227 09:08:47.195967 20800 solver.cpp:229] Iteration 19040, loss = 0.14446
I0227 09:08:47.195996 20800 solver.cpp:245]     Train net output #0: accuracy = 0.937763
I0227 09:08:47.196005 20800 solver.cpp:245]     Train net output #1: accuracy = 0.895267
I0227 09:08:47.196012 20800 solver.cpp:245]     Train net output #2: accuracy = 0.775556
I0227 09:08:47.196022 20800 sgd_solver.cpp:106] Iteration 19040, lr = 6.50305e-05
I0227 09:09:04.451094 20800 solver.cpp:229] Iteration 19060, loss = 0.123035
I0227 09:09:04.451124 20800 solver.cpp:245]     Train net output #0: accuracy = 0.951933
I0227 09:09:04.451133 20800 solver.cpp:245]     Train net output #1: accuracy = 0.825218
I0227 09:09:04.451140 20800 solver.cpp:245]     Train net output #2: accuracy = 0.754708
I0227 09:09:04.451150 20800 sgd_solver.cpp:106] Iteration 19060, lr = 6.38099e-05
I0227 09:09:21.732854 20800 solver.cpp:229] Iteration 19080, loss = 0.12337
I0227 09:09:21.732900 20800 solver.cpp:245]     Train net output #0: accuracy = 0.957882
I0227 09:09:21.732909 20800 solver.cpp:245]     Train net output #1: accuracy = 0.92749
I0227 09:09:21.732915 20800 solver.cpp:245]     Train net output #2: accuracy = 0.807114
I0227 09:09:21.732925 20800 sgd_solver.cpp:106] Iteration 19080, lr = 6.25867e-05
I0227 09:09:39.013487 20800 solver.cpp:229] Iteration 19100, loss = 0.118124
I0227 09:09:39.013531 20800 solver.cpp:245]     Train net output #0: accuracy = 0.958986
I0227 09:09:39.013540 20800 solver.cpp:245]     Train net output #1: accuracy = 0.920196
I0227 09:09:39.013547 20800 solver.cpp:245]     Train net output #2: accuracy = 0.744454
I0227 09:09:39.013556 20800 sgd_solver.cpp:106] Iteration 19100, lr = 6.13609e-05
I0227 09:09:56.262948 20800 solver.cpp:229] Iteration 19120, loss = 0.122746
I0227 09:09:56.262979 20800 solver.cpp:245]     Train net output #0: accuracy = 0.95056
I0227 09:09:56.262987 20800 solver.cpp:245]     Train net output #1: accuracy = 0.897192
I0227 09:09:56.262995 20800 solver.cpp:245]     Train net output #2: accuracy = 0.837297
I0227 09:09:56.263005 20800 sgd_solver.cpp:106] Iteration 19120, lr = 6.01323e-05
I0227 09:10:13.534637 20800 solver.cpp:229] Iteration 19140, loss = 0.119464
I0227 09:10:13.534682 20800 solver.cpp:245]     Train net output #0: accuracy = 0.964842
I0227 09:10:13.534689 20800 solver.cpp:245]     Train net output #1: accuracy = 0.906314
I0227 09:10:13.534696 20800 solver.cpp:245]     Train net output #2: accuracy = 0.913828
I0227 09:10:13.534705 20800 sgd_solver.cpp:106] Iteration 19140, lr = 5.89008e-05
I0227 09:10:30.805892 20800 solver.cpp:229] Iteration 19160, loss = 0.12904
I0227 09:10:30.805934 20800 solver.cpp:245]     Train net output #0: accuracy = 0.967222
I0227 09:10:30.805953 20800 solver.cpp:245]     Train net output #1: accuracy = 0.773133
I0227 09:10:30.805965 20800 solver.cpp:245]     Train net output #2: accuracy = 0.879995
I0227 09:10:30.805981 20800 sgd_solver.cpp:106] Iteration 19160, lr = 5.76666e-05
I0227 09:10:48.106360 20800 solver.cpp:229] Iteration 19180, loss = 0.130431
I0227 09:10:48.106405 20800 solver.cpp:245]     Train net output #0: accuracy = 0.916716
I0227 09:10:48.106415 20800 solver.cpp:245]     Train net output #1: accuracy = 0.738807
I0227 09:10:48.106421 20800 solver.cpp:245]     Train net output #2: accuracy = 0.813777
I0227 09:10:48.106431 20800 sgd_solver.cpp:106] Iteration 19180, lr = 5.64294e-05
I0227 09:11:05.350328 20800 solver.cpp:229] Iteration 19200, loss = 0.126921
I0227 09:11:05.350371 20800 solver.cpp:245]     Train net output #0: accuracy = 0.949732
I0227 09:11:05.350380 20800 solver.cpp:245]     Train net output #1: accuracy = 0.885965
I0227 09:11:05.350386 20800 solver.cpp:245]     Train net output #2: accuracy = 0.779927
I0227 09:11:05.350396 20800 sgd_solver.cpp:106] Iteration 19200, lr = 5.51892e-05
I0227 09:11:22.624511 20800 solver.cpp:229] Iteration 19220, loss = 0.127919
I0227 09:11:22.624557 20800 solver.cpp:245]     Train net output #0: accuracy = 0.965199
I0227 09:11:22.624564 20800 solver.cpp:245]     Train net output #1: accuracy = 0.945958
I0227 09:11:22.624572 20800 solver.cpp:245]     Train net output #2: accuracy = 0.920264
I0227 09:11:22.624581 20800 sgd_solver.cpp:106] Iteration 19220, lr = 5.39458e-05
I0227 09:11:39.924724 20800 solver.cpp:229] Iteration 19240, loss = 0.135219
I0227 09:11:39.924769 20800 solver.cpp:245]     Train net output #0: accuracy = 0.923676
I0227 09:11:39.924778 20800 solver.cpp:245]     Train net output #1: accuracy = 0.663602
I0227 09:11:39.924784 20800 solver.cpp:245]     Train net output #2: accuracy = 0.717342
I0227 09:11:39.924809 20800 sgd_solver.cpp:106] Iteration 19240, lr = 5.26993e-05
I0227 09:11:57.196126 20800 solver.cpp:229] Iteration 19260, loss = 0.126262
I0227 09:11:57.196169 20800 solver.cpp:245]     Train net output #0: accuracy = 0.952367
I0227 09:11:57.196194 20800 solver.cpp:245]     Train net output #1: accuracy = 0.833092
I0227 09:11:57.196200 20800 solver.cpp:245]     Train net output #2: accuracy = 0.808939
I0227 09:11:57.196209 20800 sgd_solver.cpp:106] Iteration 19260, lr = 5.14496e-05
I0227 09:12:14.446573 20800 solver.cpp:229] Iteration 19280, loss = 0.13462
I0227 09:12:14.446617 20800 solver.cpp:245]     Train net output #0: accuracy = 0.961273
I0227 09:12:14.446625 20800 solver.cpp:245]     Train net output #1: accuracy = 0.891095
I0227 09:12:14.446632 20800 solver.cpp:245]     Train net output #2: accuracy = 0.924377
I0227 09:12:14.446641 20800 sgd_solver.cpp:106] Iteration 19280, lr = 5.01964e-05
I0227 09:12:31.714053 20800 solver.cpp:229] Iteration 19300, loss = 0.134787
I0227 09:12:31.714082 20800 solver.cpp:245]     Train net output #0: accuracy = 0.940274
I0227 09:12:31.714092 20800 solver.cpp:245]     Train net output #1: accuracy = 0.805285
I0227 09:12:31.714097 20800 solver.cpp:245]     Train net output #2: accuracy = 0.835652
I0227 09:12:31.714107 20800 sgd_solver.cpp:106] Iteration 19300, lr = 4.89397e-05
I0227 09:12:48.973017 20800 solver.cpp:229] Iteration 19320, loss = 0.121281
I0227 09:12:48.973062 20800 solver.cpp:245]     Train net output #0: accuracy = 0.953123
I0227 09:12:48.973070 20800 solver.cpp:245]     Train net output #1: accuracy = 0.781454
I0227 09:12:48.973078 20800 solver.cpp:245]     Train net output #2: accuracy = 0.904163
I0227 09:12:48.973086 20800 sgd_solver.cpp:106] Iteration 19320, lr = 4.76794e-05
I0227 09:13:06.265621 20800 solver.cpp:229] Iteration 19340, loss = 0.127065
I0227 09:13:06.265650 20800 solver.cpp:245]     Train net output #0: accuracy = 0.935455
I0227 09:13:06.265658 20800 solver.cpp:245]     Train net output #1: accuracy = 0.78596
I0227 09:13:06.265664 20800 solver.cpp:245]     Train net output #2: accuracy = 0.8314
I0227 09:13:06.265673 20800 sgd_solver.cpp:106] Iteration 19340, lr = 4.64154e-05
I0227 09:13:23.544504 20800 solver.cpp:229] Iteration 19360, loss = 0.123402
I0227 09:13:23.544551 20800 solver.cpp:245]     Train net output #0: accuracy = 0.941225
I0227 09:13:23.544560 20800 solver.cpp:245]     Train net output #1: accuracy = 0.922687
I0227 09:13:23.544567 20800 solver.cpp:245]     Train net output #2: accuracy = 0.929376
I0227 09:13:23.544577 20800 sgd_solver.cpp:106] Iteration 19360, lr = 4.51476e-05
I0227 09:13:40.812311 20800 solver.cpp:229] Iteration 19380, loss = 0.118211
I0227 09:13:40.812357 20800 solver.cpp:245]     Train net output #0: accuracy = 0.962903
I0227 09:13:40.812366 20800 solver.cpp:245]     Train net output #1: accuracy = 0.83309
I0227 09:13:40.812373 20800 solver.cpp:245]     Train net output #2: accuracy = 0.889481
I0227 09:13:40.812382 20800 sgd_solver.cpp:106] Iteration 19380, lr = 4.38759e-05
I0227 09:13:58.089530 20800 solver.cpp:229] Iteration 19400, loss = 0.136606
I0227 09:13:58.089561 20800 solver.cpp:245]     Train net output #0: accuracy = 0.949078
I0227 09:13:58.089570 20800 solver.cpp:245]     Train net output #1: accuracy = 0.881588
I0227 09:13:58.089576 20800 solver.cpp:245]     Train net output #2: accuracy = 0.794778
I0227 09:13:58.089586 20800 sgd_solver.cpp:106] Iteration 19400, lr = 4.25999e-05
I0227 09:14:15.351487 20800 solver.cpp:229] Iteration 19420, loss = 0.130499
I0227 09:14:15.351517 20800 solver.cpp:245]     Train net output #0: accuracy = 0.946993
I0227 09:14:15.351526 20800 solver.cpp:245]     Train net output #1: accuracy = 0.84323
I0227 09:14:15.351533 20800 solver.cpp:245]     Train net output #2: accuracy = 0.87105
I0227 09:14:15.351542 20800 sgd_solver.cpp:106] Iteration 19420, lr = 4.13198e-05
I0227 09:14:32.647228 20800 solver.cpp:229] Iteration 19440, loss = 0.12824
I0227 09:14:32.647275 20800 solver.cpp:245]     Train net output #0: accuracy = 0.953659
I0227 09:14:32.647284 20800 solver.cpp:245]     Train net output #1: accuracy = 0.75221
I0227 09:14:32.647291 20800 solver.cpp:245]     Train net output #2: accuracy = 0.693177
I0227 09:14:32.647300 20800 sgd_solver.cpp:106] Iteration 19440, lr = 4.00352e-05
I0227 09:14:49.930033 20800 solver.cpp:229] Iteration 19460, loss = 0.123752
I0227 09:14:49.930078 20800 solver.cpp:245]     Train net output #0: accuracy = 0.93462
I0227 09:14:49.930088 20800 solver.cpp:245]     Train net output #1: accuracy = 0.80326
I0227 09:14:49.930094 20800 solver.cpp:245]     Train net output #2: accuracy = 0.778037
I0227 09:14:49.930104 20800 sgd_solver.cpp:106] Iteration 19460, lr = 3.87461e-05
I0227 09:15:07.212383 20800 solver.cpp:229] Iteration 19480, loss = 0.115908
I0227 09:15:07.212427 20800 solver.cpp:245]     Train net output #0: accuracy = 0.951398
I0227 09:15:07.212436 20800 solver.cpp:245]     Train net output #1: accuracy = 0.871701
I0227 09:15:07.212443 20800 solver.cpp:245]     Train net output #2: accuracy = 0.853206
I0227 09:15:07.212452 20800 sgd_solver.cpp:106] Iteration 19480, lr = 3.74521e-05
I0227 09:15:24.489914 20800 solver.cpp:229] Iteration 19500, loss = 0.129973
I0227 09:15:24.489959 20800 solver.cpp:245]     Train net output #0: accuracy = 0.94765
I0227 09:15:24.489967 20800 solver.cpp:245]     Train net output #1: accuracy = 0.712521
I0227 09:15:24.489974 20800 solver.cpp:245]     Train net output #2: accuracy = 0.721351
I0227 09:15:24.489984 20800 sgd_solver.cpp:106] Iteration 19500, lr = 3.61531e-05
I0227 09:15:41.759984 20800 solver.cpp:229] Iteration 19520, loss = 0.123541
I0227 09:15:41.760016 20800 solver.cpp:245]     Train net output #0: accuracy = 0.941642
I0227 09:15:41.760025 20800 solver.cpp:245]     Train net output #1: accuracy = 0.892008
I0227 09:15:41.760031 20800 solver.cpp:245]     Train net output #2: accuracy = 0.798757
I0227 09:15:41.760041 20800 sgd_solver.cpp:106] Iteration 19520, lr = 3.4849e-05
I0227 09:15:59.040940 20800 solver.cpp:229] Iteration 19540, loss = 0.130236
I0227 09:15:59.040982 20800 solver.cpp:245]     Train net output #0: accuracy = 0.965866
I0227 09:15:59.041000 20800 solver.cpp:245]     Train net output #1: accuracy = 0.928797
I0227 09:15:59.041014 20800 solver.cpp:245]     Train net output #2: accuracy = 0.908359
I0227 09:15:59.041030 20800 sgd_solver.cpp:106] Iteration 19540, lr = 3.35394e-05
I0227 09:16:16.335162 20800 solver.cpp:229] Iteration 19560, loss = 0.132491
I0227 09:16:16.335206 20800 solver.cpp:245]     Train net output #0: accuracy = 0.952766
I0227 09:16:16.335216 20800 solver.cpp:245]     Train net output #1: accuracy = 0.879778
I0227 09:16:16.335222 20800 solver.cpp:245]     Train net output #2: accuracy = 0.912925
I0227 09:16:16.335232 20800 sgd_solver.cpp:106] Iteration 19560, lr = 3.22241e-05
I0227 09:16:33.610225 20800 solver.cpp:229] Iteration 19580, loss = 0.120486
I0227 09:16:33.610255 20800 solver.cpp:245]     Train net output #0: accuracy = 0.959131
I0227 09:16:33.610265 20800 solver.cpp:245]     Train net output #1: accuracy = 0.893115
I0227 09:16:33.610271 20800 solver.cpp:245]     Train net output #2: accuracy = 0.909023
I0227 09:16:33.610281 20800 sgd_solver.cpp:106] Iteration 19580, lr = 3.09028e-05
I0227 09:16:50.891697 20800 solver.cpp:229] Iteration 19600, loss = 0.120724
I0227 09:16:50.891741 20800 solver.cpp:245]     Train net output #0: accuracy = 0.964069
I0227 09:16:50.891750 20800 solver.cpp:245]     Train net output #1: accuracy = 0.851113
I0227 09:16:50.891757 20800 solver.cpp:245]     Train net output #2: accuracy = 0.876599
I0227 09:16:50.891767 20800 sgd_solver.cpp:106] Iteration 19600, lr = 2.95751e-05
I0227 09:17:08.196333 20800 solver.cpp:229] Iteration 19620, loss = 0.130621
I0227 09:17:08.196377 20800 solver.cpp:245]     Train net output #0: accuracy = 0.95348
I0227 09:17:08.196386 20800 solver.cpp:245]     Train net output #1: accuracy = 0.9493
I0227 09:17:08.196393 20800 solver.cpp:245]     Train net output #2: accuracy = 0.870517
I0227 09:17:08.196403 20800 sgd_solver.cpp:106] Iteration 19620, lr = 2.82409e-05
I0227 09:17:25.470181 20800 solver.cpp:229] Iteration 19640, loss = 0.1218
I0227 09:17:25.470227 20800 solver.cpp:245]     Train net output #0: accuracy = 0.94878
I0227 09:17:25.470235 20800 solver.cpp:245]     Train net output #1: accuracy = 0.935794
I0227 09:17:25.470242 20800 solver.cpp:245]     Train net output #2: accuracy = 0.95439
I0227 09:17:25.470252 20800 sgd_solver.cpp:106] Iteration 19640, lr = 2.68996e-05
I0227 09:17:42.745293 20800 solver.cpp:229] Iteration 19660, loss = 0.135375
I0227 09:17:42.745338 20800 solver.cpp:245]     Train net output #0: accuracy = 0.943486
I0227 09:17:42.745347 20800 solver.cpp:245]     Train net output #1: accuracy = 0.851955
I0227 09:17:42.745354 20800 solver.cpp:245]     Train net output #2: accuracy = 0.782742
I0227 09:17:42.745364 20800 sgd_solver.cpp:106] Iteration 19660, lr = 2.55508e-05
I0227 09:18:00.012823 20800 solver.cpp:229] Iteration 19680, loss = 0.13011
I0227 09:18:00.012854 20800 solver.cpp:245]     Train net output #0: accuracy = 0.957333
I0227 09:18:00.012866 20800 solver.cpp:245]     Train net output #1: accuracy = 0.753525
I0227 09:18:00.012872 20800 solver.cpp:245]     Train net output #2: accuracy = 0.719083
I0227 09:18:00.012881 20800 sgd_solver.cpp:106] Iteration 19680, lr = 2.4194e-05
I0227 09:18:17.265161 20800 solver.cpp:229] Iteration 19700, loss = 0.12217
I0227 09:18:17.265204 20800 solver.cpp:245]     Train net output #0: accuracy = 0.951101
I0227 09:18:17.265214 20800 solver.cpp:245]     Train net output #1: accuracy = 0.835235
I0227 09:18:17.265220 20800 solver.cpp:245]     Train net output #2: accuracy = 0.86825
I0227 09:18:17.265230 20800 sgd_solver.cpp:106] Iteration 19700, lr = 2.28287e-05
I0227 09:18:34.549326 20800 solver.cpp:229] Iteration 19720, loss = 0.122193
I0227 09:18:34.549372 20800 solver.cpp:245]     Train net output #0: accuracy = 0.961511
I0227 09:18:34.549382 20800 solver.cpp:245]     Train net output #1: accuracy = 0.812537
I0227 09:18:34.549388 20800 solver.cpp:245]     Train net output #2: accuracy = 0.910781
I0227 09:18:34.549398 20800 sgd_solver.cpp:106] Iteration 19720, lr = 2.14543e-05
I0227 09:18:51.856653 20800 solver.cpp:229] Iteration 19740, loss = 0.12544
I0227 09:18:51.856699 20800 solver.cpp:245]     Train net output #0: accuracy = 0.958656
I0227 09:18:51.856709 20800 solver.cpp:245]     Train net output #1: accuracy = 0.86888
I0227 09:18:51.856716 20800 solver.cpp:245]     Train net output #2: accuracy = 0.883709
I0227 09:18:51.856725 20800 sgd_solver.cpp:106] Iteration 19740, lr = 2.00701e-05
I0227 09:19:09.136158 20800 solver.cpp:229] Iteration 19760, loss = 0.116659
I0227 09:19:09.136205 20800 solver.cpp:245]     Train net output #0: accuracy = 0.9514
I0227 09:19:09.136214 20800 solver.cpp:245]     Train net output #1: accuracy = 0.801739
I0227 09:19:09.136221 20800 solver.cpp:245]     Train net output #2: accuracy = 0.736096
I0227 09:19:09.136230 20800 sgd_solver.cpp:106] Iteration 19760, lr = 1.86751e-05
I0227 09:19:26.399260 20800 solver.cpp:229] Iteration 19780, loss = 0.116821
I0227 09:19:26.399322 20800 solver.cpp:245]     Train net output #0: accuracy = 0.938307
I0227 09:19:26.399332 20800 solver.cpp:245]     Train net output #1: accuracy = 0.831317
I0227 09:19:26.399338 20800 solver.cpp:245]     Train net output #2: accuracy = 0.815515
I0227 09:19:26.399348 20800 sgd_solver.cpp:106] Iteration 19780, lr = 1.72684e-05
I0227 09:19:43.693523 20800 solver.cpp:229] Iteration 19800, loss = 0.120057
I0227 09:19:43.693569 20800 solver.cpp:245]     Train net output #0: accuracy = 0.961379
I0227 09:19:43.693578 20800 solver.cpp:245]     Train net output #1: accuracy = 0.924726
I0227 09:19:43.693585 20800 solver.cpp:245]     Train net output #2: accuracy = 0.91141
I0227 09:19:43.693595 20800 sgd_solver.cpp:106] Iteration 19800, lr = 1.58489e-05
I0227 09:20:00.982807 20800 solver.cpp:229] Iteration 19820, loss = 0.118918
I0227 09:20:00.982852 20800 solver.cpp:245]     Train net output #0: accuracy = 0.949494
I0227 09:20:00.982861 20800 solver.cpp:245]     Train net output #1: accuracy = 0.851287
I0227 09:20:00.982869 20800 solver.cpp:245]     Train net output #2: accuracy = 0.86113
I0227 09:20:00.982889 20800 sgd_solver.cpp:106] Iteration 19820, lr = 1.44151e-05
I0227 09:20:18.267158 20800 solver.cpp:229] Iteration 19840, loss = 0.137643
I0227 09:20:18.267187 20800 solver.cpp:245]     Train net output #0: accuracy = 0.946438
I0227 09:20:18.267196 20800 solver.cpp:245]     Train net output #1: accuracy = 0.780047
I0227 09:20:18.267202 20800 solver.cpp:245]     Train net output #2: accuracy = 0.86619
I0227 09:20:18.267212 20800 sgd_solver.cpp:106] Iteration 19840, lr = 1.29653e-05
I0227 09:20:35.530135 20800 solver.cpp:229] Iteration 19860, loss = 0.12039
I0227 09:20:35.530179 20800 solver.cpp:245]     Train net output #0: accuracy = 0.937167
I0227 09:20:35.530189 20800 solver.cpp:245]     Train net output #1: accuracy = 0.849064
I0227 09:20:35.530195 20800 solver.cpp:245]     Train net output #2: accuracy = 0.837603
I0227 09:20:35.530205 20800 sgd_solver.cpp:106] Iteration 19860, lr = 1.14971e-05
I0227 09:20:52.815312 20800 solver.cpp:229] Iteration 19880, loss = 0.130088
I0227 09:20:52.815358 20800 solver.cpp:245]     Train net output #0: accuracy = 0.941294
I0227 09:20:52.815367 20800 solver.cpp:245]     Train net output #1: accuracy = 0.721196
I0227 09:20:52.815374 20800 solver.cpp:245]     Train net output #2: accuracy = 0.81805
I0227 09:20:52.815384 20800 sgd_solver.cpp:106] Iteration 19880, lr = 1.00077e-05
I0227 09:21:10.078862 20800 solver.cpp:229] Iteration 19900, loss = 0.12804
I0227 09:21:10.078918 20800 solver.cpp:245]     Train net output #0: accuracy = 0.954847
I0227 09:21:10.078927 20800 solver.cpp:245]     Train net output #1: accuracy = 0.840845
I0227 09:21:10.078933 20800 solver.cpp:245]     Train net output #2: accuracy = 0.829198
I0227 09:21:10.078943 20800 sgd_solver.cpp:106] Iteration 19900, lr = 8.49323e-06
I0227 09:21:27.349432 20800 solver.cpp:229] Iteration 19920, loss = 0.129523
I0227 09:21:27.349460 20800 solver.cpp:245]     Train net output #0: accuracy = 0.95586
I0227 09:21:27.349468 20800 solver.cpp:245]     Train net output #1: accuracy = 0.914409
I0227 09:21:27.349475 20800 solver.cpp:245]     Train net output #2: accuracy = 0.904528
I0227 09:21:27.349483 20800 sgd_solver.cpp:106] Iteration 19920, lr = 6.94792e-06
I0227 09:21:44.634464 20800 solver.cpp:229] Iteration 19940, loss = 0.124534
I0227 09:21:44.634507 20800 solver.cpp:245]     Train net output #0: accuracy = 0.959131
I0227 09:21:44.634516 20800 solver.cpp:245]     Train net output #1: accuracy = 0.869867
I0227 09:21:44.634523 20800 solver.cpp:245]     Train net output #2: accuracy = 0.865771
I0227 09:21:44.634532 20800 sgd_solver.cpp:106] Iteration 19940, lr = 5.36305e-06
I0227 09:22:01.903769 20800 solver.cpp:229] Iteration 19960, loss = 0.12717
I0227 09:22:01.903800 20800 solver.cpp:245]     Train net output #0: accuracy = 0.961214
I0227 09:22:01.903810 20800 solver.cpp:245]     Train net output #1: accuracy = 0.955156
I0227 09:22:01.903816 20800 solver.cpp:245]     Train net output #2: accuracy = 0.820084
I0227 09:22:01.903825 20800 sgd_solver.cpp:106] Iteration 19960, lr = 3.72325e-06
I0227 09:22:19.188484 20800 solver.cpp:229] Iteration 19980, loss = 0.132444
I0227 09:22:19.188513 20800 solver.cpp:245]     Train net output #0: accuracy = 0.94271
I0227 09:22:19.188524 20800 solver.cpp:245]     Train net output #1: accuracy = 0.636399
I0227 09:22:19.188530 20800 solver.cpp:245]     Train net output #2: accuracy = 0.729924
I0227 09:22:19.188540 20800 sgd_solver.cpp:106] Iteration 19980, lr = 1.99524e-06
I0227 09:22:35.686311 20800 solver.cpp:456] Snapshotting to binary proto file models/model-f_iter_20000.caffemodel
I0227 09:22:36.676862 20800 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/model-f_iter_20000.solverstate
I0227 09:22:37.267825 20800 solver.cpp:318] Iteration 20000, loss = 0.133789
I0227 09:22:37.267855 20800 solver.cpp:323] Optimization Done.
done solving
UNIQUESTRING 4
/media/ssd1/austin/Point-DSRG/deeplab-public-ver2/python
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0227 09:22:39.277832 31399 net.cpp:49] Initializing net from parameters:
name: "DSRG"
input: "images"
input_dim: 1
input_dim: 3
input_dim: 321
input_dim: 321
state {
  phase: TEST
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "images"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    pad: 1
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    pad: 1
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    pad: 1
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    dilation: 2
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    dilation: 2
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    dilation: 2
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "pool5a"
  type: "Pooling"
  bottom: "pool5"
  top: "pool5a"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "fc6_1"
  type: "Convolution"
  bottom: "pool5a"
  top: "fc6_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    pad: 6
    kernel_size: 3
    dilation: 6
  }
}
layer {
  name: "relu6_1"
  type: "ReLU"
  bottom: "fc6_1"
  top: "fc6_1"
}
layer {
  name: "drop6_1"
  type: "Dropout"
  bottom: "fc6_1"
  top: "fc6_1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7_1"
  type: "Convolution"
  bottom: "fc6_1"
  top: "fc7_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    kernel_size: 1
  }
}
layer {
  name: "relu7_1"
  type: "ReLU"
  bottom: "fc7_1"
  top: "fc7_1"
}
layer {
  name: "drop7_1"
  type: "Dropout"
  bottom: "fc7_1"
  top: "fc7_1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8-SEC_1"
  type: "Convolution"
  bottom: "fc7_1"
  top: "fc8-SEC_1"
  param {
    lr_mult: 10
    decay_mult: 1
  }
  param {
    lr_mult: 20
    decay_mult: 0
  }
  convolution_param {
    num_output: 21
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fc6_2"
  type: "Convolution"
  bottom: "pool5a"
  top: "fc6_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    pad: 12
    kernel_size: 3
    dilation: 12
  }
}
layer {
  name: "relu6_2"
  type: "ReLU"
  bottom: "fc6_2"
  top: "fc6_2"
}
layer {
  name: "drop6_2"
  type: "Dropout"
  bottom: "fc6_2"
  top: "fc6_2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7_2"
  type: "Convolution"
  bottom: "fc6_2"
  top: "fc7_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    kernel_size: 1
  }
}
layer {
  name: "relu7_2"
  type: "ReLU"
  bottom: "fc7_2"
  top: "fc7_2"
}
layer {
  name: "drop7_2"
  type: "Dropout"
  bottom: "fc7_2"
  top: "fc7_2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8-SEC_2"
  type: "Convolution"
  bottom: "fc7_2"
  top: "fc8-SEC_2"
  param {
    lr_mult: 10
    decay_mult: 1
  }
  param {
    lr_mult: 20
    decay_mult: 0
  }
  convolution_param {
    num_output: 21
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fc6_3"
  type: "Convolution"
  bottom: "pool5a"
  top: "fc6_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    pad: 18
    kernel_size: 3
    dilation: 18
  }
}
layer {
  name: "relu6_3"
  type: "ReLU"
  bottom: "fc6_3"
  top: "fc6_3"
}
layer {
  name: "drop6_3"
  type: "Dropout"
  bottom: "fc6_3"
  top: "fc6_3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7_3"
  type: "Convolution"
  bottom: "fc6_3"
  top: "fc7_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    kernel_size: 1
  }
}
layer {
  name: "relu7_3"
  type: "ReLU"
  bottom: "fc7_3"
  top: "fc7_3"
}
layer {
  name: "drop7_3"
  type: "Dropout"
  bottom: "fc7_3"
  top: "fc7_3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8-SEC_3"
  type: "Convolution"
  bottom: "fc7_3"
  top: "fc8-SEC_3"
  param {
    lr_mult: 10
    decay_mult: 1
  }
  param {
    lr_mult: 20
    decay_mult: 0
  }
  convolution_param {
    num_output: 21
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fc6_4"
  type: "Convolution"
  bottom: "pool5a"
  top: "fc6_4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    pad: 24
    kernel_size: 3
    dilation: 24
  }
}
layer {
  name: "relu6_4"
  type: "ReLU"
  bottom: "fc6_4"
  top: "fc6_4"
}
layer {
  name: "drop6_4"
  type: "Dropout"
  bottom: "fc6_4"
  top: "fc6_4"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7_4"
  type: "Convolution"
  bottom: "fc6_4"
  top: "fc7_4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    kernel_size: 1
  }
}
layer {
  name: "relu7_4"
  type: "ReLU"
  bottom: "fc7_4"
  top: "fc7_4"
}
layer {
  name: "drop7_4"
  type: "Dropout"
  bottom: "fc7_4"
  top: "fc7_4"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8-SEC_4"
  type: "Convolution"
  bottom: "fc7_4"
  top: "fc8-SEC_4"
  param {
    lr_mult: 10
    decay_mult: 1
  }
  param {
    lr_mult: 20
    decay_mult: 0
  }
  convolution_param {
    num_output: 21
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fc8-SEC"
  type: "Eltwise"
  bottom: "fc8-SEC_1"
  bottom: "fc8-SEC_2"
  bottom: "fc8-SEC_3"
  bottom: "fc8-SEC_4"
  top: "fc8-SEC"
  eltwise_param {
    operation: SUM
  }
}
I0227 09:22:39.280504 31399 net.cpp:413] Input 0 -> images
I0227 09:22:39.297878 31399 layer_factory.hpp:77] Creating layer conv1_1
I0227 09:22:39.297914 31399 net.cpp:106] Creating Layer conv1_1
I0227 09:22:39.297924 31399 net.cpp:454] conv1_1 <- images
I0227 09:22:39.297937 31399 net.cpp:411] conv1_1 -> conv1_1
I0227 09:22:39.300495 31399 net.cpp:150] Setting up conv1_1
I0227 09:22:39.300520 31399 net.cpp:157] Top shape: 1 64 321 321 (6594624)
I0227 09:22:39.300529 31399 net.cpp:165] Memory required for data: 26378496
I0227 09:22:39.300547 31399 layer_factory.hpp:77] Creating layer relu1_1
I0227 09:22:39.300561 31399 net.cpp:106] Creating Layer relu1_1
I0227 09:22:39.300568 31399 net.cpp:454] relu1_1 <- conv1_1
I0227 09:22:39.300581 31399 net.cpp:397] relu1_1 -> conv1_1 (in-place)
I0227 09:22:39.300595 31399 net.cpp:150] Setting up relu1_1
I0227 09:22:39.300603 31399 net.cpp:157] Top shape: 1 64 321 321 (6594624)
I0227 09:22:39.300611 31399 net.cpp:165] Memory required for data: 52756992
I0227 09:22:39.300618 31399 layer_factory.hpp:77] Creating layer conv1_2
I0227 09:22:39.300631 31399 net.cpp:106] Creating Layer conv1_2
I0227 09:22:39.300639 31399 net.cpp:454] conv1_2 <- conv1_1
I0227 09:22:39.300649 31399 net.cpp:411] conv1_2 -> conv1_2
I0227 09:22:39.302011 31399 net.cpp:150] Setting up conv1_2
I0227 09:22:39.302034 31399 net.cpp:157] Top shape: 1 64 321 321 (6594624)
I0227 09:22:39.302042 31399 net.cpp:165] Memory required for data: 79135488
I0227 09:22:39.302055 31399 layer_factory.hpp:77] Creating layer relu1_2
I0227 09:22:39.302068 31399 net.cpp:106] Creating Layer relu1_2
I0227 09:22:39.302076 31399 net.cpp:454] relu1_2 <- conv1_2
I0227 09:22:39.302085 31399 net.cpp:397] relu1_2 -> conv1_2 (in-place)
I0227 09:22:39.302098 31399 net.cpp:150] Setting up relu1_2
I0227 09:22:39.302106 31399 net.cpp:157] Top shape: 1 64 321 321 (6594624)
I0227 09:22:39.302114 31399 net.cpp:165] Memory required for data: 105513984
I0227 09:22:39.302119 31399 layer_factory.hpp:77] Creating layer pool1
I0227 09:22:39.302134 31399 net.cpp:106] Creating Layer pool1
I0227 09:22:39.302141 31399 net.cpp:454] pool1 <- conv1_2
I0227 09:22:39.302151 31399 net.cpp:411] pool1 -> pool1
I0227 09:22:39.302197 31399 net.cpp:150] Setting up pool1
I0227 09:22:39.302211 31399 net.cpp:157] Top shape: 1 64 161 161 (1658944)
I0227 09:22:39.302217 31399 net.cpp:165] Memory required for data: 112149760
I0227 09:22:39.302225 31399 layer_factory.hpp:77] Creating layer conv2_1
I0227 09:22:39.302237 31399 net.cpp:106] Creating Layer conv2_1
I0227 09:22:39.302245 31399 net.cpp:454] conv2_1 <- pool1
I0227 09:22:39.302254 31399 net.cpp:411] conv2_1 -> conv2_1
I0227 09:22:39.302532 31399 net.cpp:150] Setting up conv2_1
I0227 09:22:39.302547 31399 net.cpp:157] Top shape: 1 128 161 161 (3317888)
I0227 09:22:39.302554 31399 net.cpp:165] Memory required for data: 125421312
I0227 09:22:39.302567 31399 layer_factory.hpp:77] Creating layer relu2_1
I0227 09:22:39.302577 31399 net.cpp:106] Creating Layer relu2_1
I0227 09:22:39.302585 31399 net.cpp:454] relu2_1 <- conv2_1
I0227 09:22:39.302594 31399 net.cpp:397] relu2_1 -> conv2_1 (in-place)
I0227 09:22:39.302603 31399 net.cpp:150] Setting up relu2_1
I0227 09:22:39.302613 31399 net.cpp:157] Top shape: 1 128 161 161 (3317888)
I0227 09:22:39.302618 31399 net.cpp:165] Memory required for data: 138692864
I0227 09:22:39.302625 31399 layer_factory.hpp:77] Creating layer conv2_2
I0227 09:22:39.302637 31399 net.cpp:106] Creating Layer conv2_2
I0227 09:22:39.302644 31399 net.cpp:454] conv2_2 <- conv2_1
I0227 09:22:39.302652 31399 net.cpp:411] conv2_2 -> conv2_2
I0227 09:22:39.303004 31399 net.cpp:150] Setting up conv2_2
I0227 09:22:39.303019 31399 net.cpp:157] Top shape: 1 128 161 161 (3317888)
I0227 09:22:39.303025 31399 net.cpp:165] Memory required for data: 151964416
I0227 09:22:39.303035 31399 layer_factory.hpp:77] Creating layer relu2_2
I0227 09:22:39.303046 31399 net.cpp:106] Creating Layer relu2_2
I0227 09:22:39.303055 31399 net.cpp:454] relu2_2 <- conv2_2
I0227 09:22:39.303063 31399 net.cpp:397] relu2_2 -> conv2_2 (in-place)
I0227 09:22:39.303072 31399 net.cpp:150] Setting up relu2_2
I0227 09:22:39.303081 31399 net.cpp:157] Top shape: 1 128 161 161 (3317888)
I0227 09:22:39.303087 31399 net.cpp:165] Memory required for data: 165235968
I0227 09:22:39.303094 31399 layer_factory.hpp:77] Creating layer pool2
I0227 09:22:39.303103 31399 net.cpp:106] Creating Layer pool2
I0227 09:22:39.303110 31399 net.cpp:454] pool2 <- conv2_2
I0227 09:22:39.303119 31399 net.cpp:411] pool2 -> pool2
I0227 09:22:39.303158 31399 net.cpp:150] Setting up pool2
I0227 09:22:39.303169 31399 net.cpp:157] Top shape: 1 128 81 81 (839808)
I0227 09:22:39.303175 31399 net.cpp:165] Memory required for data: 168595200
I0227 09:22:39.303181 31399 layer_factory.hpp:77] Creating layer conv3_1
I0227 09:22:39.303194 31399 net.cpp:106] Creating Layer conv3_1
I0227 09:22:39.303201 31399 net.cpp:454] conv3_1 <- pool2
I0227 09:22:39.303210 31399 net.cpp:411] conv3_1 -> conv3_1
I0227 09:22:39.305641 31399 net.cpp:150] Setting up conv3_1
I0227 09:22:39.305665 31399 net.cpp:157] Top shape: 1 256 81 81 (1679616)
I0227 09:22:39.305672 31399 net.cpp:165] Memory required for data: 175313664
I0227 09:22:39.305689 31399 layer_factory.hpp:77] Creating layer relu3_1
I0227 09:22:39.305701 31399 net.cpp:106] Creating Layer relu3_1
I0227 09:22:39.305708 31399 net.cpp:454] relu3_1 <- conv3_1
I0227 09:22:39.305717 31399 net.cpp:397] relu3_1 -> conv3_1 (in-place)
I0227 09:22:39.305729 31399 net.cpp:150] Setting up relu3_1
I0227 09:22:39.305738 31399 net.cpp:157] Top shape: 1 256 81 81 (1679616)
I0227 09:22:39.305745 31399 net.cpp:165] Memory required for data: 182032128
I0227 09:22:39.305753 31399 layer_factory.hpp:77] Creating layer conv3_2
I0227 09:22:39.305765 31399 net.cpp:106] Creating Layer conv3_2
I0227 09:22:39.305773 31399 net.cpp:454] conv3_2 <- conv3_1
I0227 09:22:39.305783 31399 net.cpp:411] conv3_2 -> conv3_2
I0227 09:22:39.307731 31399 net.cpp:150] Setting up conv3_2
I0227 09:22:39.307754 31399 net.cpp:157] Top shape: 1 256 81 81 (1679616)
I0227 09:22:39.307761 31399 net.cpp:165] Memory required for data: 188750592
I0227 09:22:39.307772 31399 layer_factory.hpp:77] Creating layer relu3_2
I0227 09:22:39.307781 31399 net.cpp:106] Creating Layer relu3_2
I0227 09:22:39.307790 31399 net.cpp:454] relu3_2 <- conv3_2
I0227 09:22:39.307798 31399 net.cpp:397] relu3_2 -> conv3_2 (in-place)
I0227 09:22:39.307808 31399 net.cpp:150] Setting up relu3_2
I0227 09:22:39.307818 31399 net.cpp:157] Top shape: 1 256 81 81 (1679616)
I0227 09:22:39.307826 31399 net.cpp:165] Memory required for data: 195469056
I0227 09:22:39.307832 31399 layer_factory.hpp:77] Creating layer conv3_3
I0227 09:22:39.307844 31399 net.cpp:106] Creating Layer conv3_3
I0227 09:22:39.307852 31399 net.cpp:454] conv3_3 <- conv3_2
I0227 09:22:39.307862 31399 net.cpp:411] conv3_3 -> conv3_3
I0227 09:22:39.309631 31399 net.cpp:150] Setting up conv3_3
I0227 09:22:39.309653 31399 net.cpp:157] Top shape: 1 256 81 81 (1679616)
I0227 09:22:39.309661 31399 net.cpp:165] Memory required for data: 202187520
I0227 09:22:39.309671 31399 layer_factory.hpp:77] Creating layer relu3_3
I0227 09:22:39.309681 31399 net.cpp:106] Creating Layer relu3_3
I0227 09:22:39.309689 31399 net.cpp:454] relu3_3 <- conv3_3
I0227 09:22:39.309700 31399 net.cpp:397] relu3_3 -> conv3_3 (in-place)
I0227 09:22:39.309710 31399 net.cpp:150] Setting up relu3_3
I0227 09:22:39.309720 31399 net.cpp:157] Top shape: 1 256 81 81 (1679616)
I0227 09:22:39.309736 31399 net.cpp:165] Memory required for data: 208905984
I0227 09:22:39.309744 31399 layer_factory.hpp:77] Creating layer pool3
I0227 09:22:39.309756 31399 net.cpp:106] Creating Layer pool3
I0227 09:22:39.309762 31399 net.cpp:454] pool3 <- conv3_3
I0227 09:22:39.309782 31399 net.cpp:411] pool3 -> pool3
I0227 09:22:39.309824 31399 net.cpp:150] Setting up pool3
I0227 09:22:39.309836 31399 net.cpp:157] Top shape: 1 256 41 41 (430336)
I0227 09:22:39.309844 31399 net.cpp:165] Memory required for data: 210627328
I0227 09:22:39.309851 31399 layer_factory.hpp:77] Creating layer conv4_1
I0227 09:22:39.309864 31399 net.cpp:106] Creating Layer conv4_1
I0227 09:22:39.309871 31399 net.cpp:454] conv4_1 <- pool3
I0227 09:22:39.309881 31399 net.cpp:411] conv4_1 -> conv4_1
I0227 09:22:39.313927 31399 net.cpp:150] Setting up conv4_1
I0227 09:22:39.313951 31399 net.cpp:157] Top shape: 1 512 41 41 (860672)
I0227 09:22:39.313958 31399 net.cpp:165] Memory required for data: 214070016
I0227 09:22:39.313968 31399 layer_factory.hpp:77] Creating layer relu4_1
I0227 09:22:39.313980 31399 net.cpp:106] Creating Layer relu4_1
I0227 09:22:39.313988 31399 net.cpp:454] relu4_1 <- conv4_1
I0227 09:22:39.313997 31399 net.cpp:397] relu4_1 -> conv4_1 (in-place)
I0227 09:22:39.314007 31399 net.cpp:150] Setting up relu4_1
I0227 09:22:39.314016 31399 net.cpp:157] Top shape: 1 512 41 41 (860672)
I0227 09:22:39.314025 31399 net.cpp:165] Memory required for data: 217512704
I0227 09:22:39.314033 31399 layer_factory.hpp:77] Creating layer conv4_2
I0227 09:22:39.314045 31399 net.cpp:106] Creating Layer conv4_2
I0227 09:22:39.314054 31399 net.cpp:454] conv4_2 <- conv4_1
I0227 09:22:39.314067 31399 net.cpp:411] conv4_2 -> conv4_2
I0227 09:22:39.319634 31399 net.cpp:150] Setting up conv4_2
I0227 09:22:39.319655 31399 net.cpp:157] Top shape: 1 512 41 41 (860672)
I0227 09:22:39.319663 31399 net.cpp:165] Memory required for data: 220955392
I0227 09:22:39.319679 31399 layer_factory.hpp:77] Creating layer relu4_2
I0227 09:22:39.319690 31399 net.cpp:106] Creating Layer relu4_2
I0227 09:22:39.319699 31399 net.cpp:454] relu4_2 <- conv4_2
I0227 09:22:39.319708 31399 net.cpp:397] relu4_2 -> conv4_2 (in-place)
I0227 09:22:39.319720 31399 net.cpp:150] Setting up relu4_2
I0227 09:22:39.319730 31399 net.cpp:157] Top shape: 1 512 41 41 (860672)
I0227 09:22:39.319736 31399 net.cpp:165] Memory required for data: 224398080
I0227 09:22:39.319744 31399 layer_factory.hpp:77] Creating layer conv4_3
I0227 09:22:39.319756 31399 net.cpp:106] Creating Layer conv4_3
I0227 09:22:39.319762 31399 net.cpp:454] conv4_3 <- conv4_2
I0227 09:22:39.319774 31399 net.cpp:411] conv4_3 -> conv4_3
I0227 09:22:39.325567 31399 net.cpp:150] Setting up conv4_3
I0227 09:22:39.325588 31399 net.cpp:157] Top shape: 1 512 41 41 (860672)
I0227 09:22:39.325608 31399 net.cpp:165] Memory required for data: 227840768
I0227 09:22:39.325618 31399 layer_factory.hpp:77] Creating layer relu4_3
I0227 09:22:39.325629 31399 net.cpp:106] Creating Layer relu4_3
I0227 09:22:39.325639 31399 net.cpp:454] relu4_3 <- conv4_3
I0227 09:22:39.325647 31399 net.cpp:397] relu4_3 -> conv4_3 (in-place)
I0227 09:22:39.325659 31399 net.cpp:150] Setting up relu4_3
I0227 09:22:39.325666 31399 net.cpp:157] Top shape: 1 512 41 41 (860672)
I0227 09:22:39.325673 31399 net.cpp:165] Memory required for data: 231283456
I0227 09:22:39.325682 31399 layer_factory.hpp:77] Creating layer pool4
I0227 09:22:39.325691 31399 net.cpp:106] Creating Layer pool4
I0227 09:22:39.325698 31399 net.cpp:454] pool4 <- conv4_3
I0227 09:22:39.325709 31399 net.cpp:411] pool4 -> pool4
I0227 09:22:39.325752 31399 net.cpp:150] Setting up pool4
I0227 09:22:39.325763 31399 net.cpp:157] Top shape: 1 512 41 41 (860672)
I0227 09:22:39.325772 31399 net.cpp:165] Memory required for data: 234726144
I0227 09:22:39.325778 31399 layer_factory.hpp:77] Creating layer conv5_1
I0227 09:22:39.325791 31399 net.cpp:106] Creating Layer conv5_1
I0227 09:22:39.325799 31399 net.cpp:454] conv5_1 <- pool4
I0227 09:22:39.325811 31399 net.cpp:411] conv5_1 -> conv5_1
I0227 09:22:39.331979 31399 net.cpp:150] Setting up conv5_1
I0227 09:22:39.332001 31399 net.cpp:157] Top shape: 1 512 41 41 (860672)
I0227 09:22:39.332020 31399 net.cpp:165] Memory required for data: 238168832
I0227 09:22:39.332032 31399 layer_factory.hpp:77] Creating layer relu5_1
I0227 09:22:39.332042 31399 net.cpp:106] Creating Layer relu5_1
I0227 09:22:39.332051 31399 net.cpp:454] relu5_1 <- conv5_1
I0227 09:22:39.332062 31399 net.cpp:397] relu5_1 -> conv5_1 (in-place)
I0227 09:22:39.332073 31399 net.cpp:150] Setting up relu5_1
I0227 09:22:39.332082 31399 net.cpp:157] Top shape: 1 512 41 41 (860672)
I0227 09:22:39.332090 31399 net.cpp:165] Memory required for data: 241611520
I0227 09:22:39.332098 31399 layer_factory.hpp:77] Creating layer conv5_2
I0227 09:22:39.332111 31399 net.cpp:106] Creating Layer conv5_2
I0227 09:22:39.332119 31399 net.cpp:454] conv5_2 <- conv5_1
I0227 09:22:39.332129 31399 net.cpp:411] conv5_2 -> conv5_2
I0227 09:22:39.340273 31399 net.cpp:150] Setting up conv5_2
I0227 09:22:39.340310 31399 net.cpp:157] Top shape: 1 512 41 41 (860672)
I0227 09:22:39.340319 31399 net.cpp:165] Memory required for data: 245054208
I0227 09:22:39.340332 31399 layer_factory.hpp:77] Creating layer relu5_2
I0227 09:22:39.340343 31399 net.cpp:106] Creating Layer relu5_2
I0227 09:22:39.340353 31399 net.cpp:454] relu5_2 <- conv5_2
I0227 09:22:39.340363 31399 net.cpp:397] relu5_2 -> conv5_2 (in-place)
I0227 09:22:39.340374 31399 net.cpp:150] Setting up relu5_2
I0227 09:22:39.340384 31399 net.cpp:157] Top shape: 1 512 41 41 (860672)
I0227 09:22:39.340401 31399 net.cpp:165] Memory required for data: 248496896
I0227 09:22:39.340411 31399 layer_factory.hpp:77] Creating layer conv5_3
I0227 09:22:39.340425 31399 net.cpp:106] Creating Layer conv5_3
I0227 09:22:39.340433 31399 net.cpp:454] conv5_3 <- conv5_2
I0227 09:22:39.340445 31399 net.cpp:411] conv5_3 -> conv5_3
I0227 09:22:39.351991 31399 net.cpp:150] Setting up conv5_3
I0227 09:22:39.352021 31399 net.cpp:157] Top shape: 1 512 41 41 (860672)
I0227 09:22:39.352031 31399 net.cpp:165] Memory required for data: 251939584
I0227 09:22:39.352044 31399 layer_factory.hpp:77] Creating layer relu5_3
I0227 09:22:39.352057 31399 net.cpp:106] Creating Layer relu5_3
I0227 09:22:39.352068 31399 net.cpp:454] relu5_3 <- conv5_3
I0227 09:22:39.352082 31399 net.cpp:397] relu5_3 -> conv5_3 (in-place)
I0227 09:22:39.352095 31399 net.cpp:150] Setting up relu5_3
I0227 09:22:39.352107 31399 net.cpp:157] Top shape: 1 512 41 41 (860672)
I0227 09:22:39.352114 31399 net.cpp:165] Memory required for data: 255382272
I0227 09:22:39.352124 31399 layer_factory.hpp:77] Creating layer pool5
I0227 09:22:39.352135 31399 net.cpp:106] Creating Layer pool5
I0227 09:22:39.352144 31399 net.cpp:454] pool5 <- conv5_3
I0227 09:22:39.352155 31399 net.cpp:411] pool5 -> pool5
I0227 09:22:39.352211 31399 net.cpp:150] Setting up pool5
I0227 09:22:39.352229 31399 net.cpp:157] Top shape: 1 512 41 41 (860672)
I0227 09:22:39.352241 31399 net.cpp:165] Memory required for data: 258824960
I0227 09:22:39.352249 31399 layer_factory.hpp:77] Creating layer pool5a
I0227 09:22:39.352260 31399 net.cpp:106] Creating Layer pool5a
I0227 09:22:39.352269 31399 net.cpp:454] pool5a <- pool5
I0227 09:22:39.352283 31399 net.cpp:411] pool5a -> pool5a
I0227 09:22:39.352314 31399 net.cpp:150] Setting up pool5a
I0227 09:22:39.352326 31399 net.cpp:157] Top shape: 1 512 41 41 (860672)
I0227 09:22:39.352336 31399 net.cpp:165] Memory required for data: 262267648
I0227 09:22:39.352345 31399 layer_factory.hpp:77] Creating layer pool5a_pool5a_0_split
I0227 09:22:39.352368 31399 net.cpp:106] Creating Layer pool5a_pool5a_0_split
I0227 09:22:39.352378 31399 net.cpp:454] pool5a_pool5a_0_split <- pool5a
I0227 09:22:39.352391 31399 net.cpp:411] pool5a_pool5a_0_split -> pool5a_pool5a_0_split_0
I0227 09:22:39.352402 31399 net.cpp:411] pool5a_pool5a_0_split -> pool5a_pool5a_0_split_1
I0227 09:22:39.352414 31399 net.cpp:411] pool5a_pool5a_0_split -> pool5a_pool5a_0_split_2
I0227 09:22:39.352427 31399 net.cpp:411] pool5a_pool5a_0_split -> pool5a_pool5a_0_split_3
I0227 09:22:39.352502 31399 net.cpp:150] Setting up pool5a_pool5a_0_split
I0227 09:22:39.352517 31399 net.cpp:157] Top shape: 1 512 41 41 (860672)
I0227 09:22:39.352530 31399 net.cpp:157] Top shape: 1 512 41 41 (860672)
I0227 09:22:39.352538 31399 net.cpp:157] Top shape: 1 512 41 41 (860672)
I0227 09:22:39.352550 31399 net.cpp:157] Top shape: 1 512 41 41 (860672)
I0227 09:22:39.352558 31399 net.cpp:165] Memory required for data: 276038400
I0227 09:22:39.352567 31399 layer_factory.hpp:77] Creating layer fc6_1
I0227 09:22:39.352582 31399 net.cpp:106] Creating Layer fc6_1
I0227 09:22:39.352591 31399 net.cpp:454] fc6_1 <- pool5a_pool5a_0_split_0
I0227 09:22:39.352603 31399 net.cpp:411] fc6_1 -> fc6_1
I0227 09:22:39.367682 31399 net.cpp:150] Setting up fc6_1
I0227 09:22:39.367708 31399 net.cpp:157] Top shape: 1 1024 41 41 (1721344)
I0227 09:22:39.367717 31399 net.cpp:165] Memory required for data: 282923776
I0227 09:22:39.367728 31399 layer_factory.hpp:77] Creating layer relu6_1
I0227 09:22:39.367741 31399 net.cpp:106] Creating Layer relu6_1
I0227 09:22:39.367750 31399 net.cpp:454] relu6_1 <- fc6_1
I0227 09:22:39.367760 31399 net.cpp:397] relu6_1 -> fc6_1 (in-place)
I0227 09:22:39.367771 31399 net.cpp:150] Setting up relu6_1
I0227 09:22:39.367780 31399 net.cpp:157] Top shape: 1 1024 41 41 (1721344)
I0227 09:22:39.367787 31399 net.cpp:165] Memory required for data: 289809152
I0227 09:22:39.367794 31399 layer_factory.hpp:77] Creating layer drop6_1
I0227 09:22:39.367817 31399 net.cpp:106] Creating Layer drop6_1
I0227 09:22:39.367825 31399 net.cpp:454] drop6_1 <- fc6_1
I0227 09:22:39.367833 31399 net.cpp:397] drop6_1 -> fc6_1 (in-place)
I0227 09:22:39.367869 31399 net.cpp:150] Setting up drop6_1
I0227 09:22:39.367882 31399 net.cpp:157] Top shape: 1 1024 41 41 (1721344)
I0227 09:22:39.367889 31399 net.cpp:165] Memory required for data: 296694528
I0227 09:22:39.367897 31399 layer_factory.hpp:77] Creating layer fc7_1
I0227 09:22:39.367909 31399 net.cpp:106] Creating Layer fc7_1
I0227 09:22:39.367918 31399 net.cpp:454] fc7_1 <- fc6_1
I0227 09:22:39.367928 31399 net.cpp:411] fc7_1 -> fc7_1
I0227 09:22:39.370621 31399 net.cpp:150] Setting up fc7_1
I0227 09:22:39.370645 31399 net.cpp:157] Top shape: 1 1024 41 41 (1721344)
I0227 09:22:39.370652 31399 net.cpp:165] Memory required for data: 303579904
I0227 09:22:39.370663 31399 layer_factory.hpp:77] Creating layer relu7_1
I0227 09:22:39.370673 31399 net.cpp:106] Creating Layer relu7_1
I0227 09:22:39.370682 31399 net.cpp:454] relu7_1 <- fc7_1
I0227 09:22:39.370692 31399 net.cpp:397] relu7_1 -> fc7_1 (in-place)
I0227 09:22:39.370702 31399 net.cpp:150] Setting up relu7_1
I0227 09:22:39.370710 31399 net.cpp:157] Top shape: 1 1024 41 41 (1721344)
I0227 09:22:39.370718 31399 net.cpp:165] Memory required for data: 310465280
I0227 09:22:39.370724 31399 layer_factory.hpp:77] Creating layer drop7_1
I0227 09:22:39.370734 31399 net.cpp:106] Creating Layer drop7_1
I0227 09:22:39.370741 31399 net.cpp:454] drop7_1 <- fc7_1
I0227 09:22:39.370751 31399 net.cpp:397] drop7_1 -> fc7_1 (in-place)
I0227 09:22:39.370779 31399 net.cpp:150] Setting up drop7_1
I0227 09:22:39.370788 31399 net.cpp:157] Top shape: 1 1024 41 41 (1721344)
I0227 09:22:39.370795 31399 net.cpp:165] Memory required for data: 317350656
I0227 09:22:39.370802 31399 layer_factory.hpp:77] Creating layer fc8-SEC_1
I0227 09:22:39.370815 31399 net.cpp:106] Creating Layer fc8-SEC_1
I0227 09:22:39.370823 31399 net.cpp:454] fc8-SEC_1 <- fc7_1
I0227 09:22:39.370834 31399 net.cpp:411] fc8-SEC_1 -> fc8-SEC_1
I0227 09:22:39.371779 31399 net.cpp:150] Setting up fc8-SEC_1
I0227 09:22:39.371798 31399 net.cpp:157] Top shape: 1 21 41 41 (35301)
I0227 09:22:39.371804 31399 net.cpp:165] Memory required for data: 317491860
I0227 09:22:39.371815 31399 layer_factory.hpp:77] Creating layer fc6_2
I0227 09:22:39.371829 31399 net.cpp:106] Creating Layer fc6_2
I0227 09:22:39.371850 31399 net.cpp:454] fc6_2 <- pool5a_pool5a_0_split_1
I0227 09:22:39.371860 31399 net.cpp:411] fc6_2 -> fc6_2
I0227 09:22:39.383538 31399 net.cpp:150] Setting up fc6_2
I0227 09:22:39.383565 31399 net.cpp:157] Top shape: 1 1024 41 41 (1721344)
I0227 09:22:39.383574 31399 net.cpp:165] Memory required for data: 324377236
I0227 09:22:39.383599 31399 layer_factory.hpp:77] Creating layer relu6_2
I0227 09:22:39.383610 31399 net.cpp:106] Creating Layer relu6_2
I0227 09:22:39.383620 31399 net.cpp:454] relu6_2 <- fc6_2
I0227 09:22:39.383632 31399 net.cpp:397] relu6_2 -> fc6_2 (in-place)
I0227 09:22:39.383646 31399 net.cpp:150] Setting up relu6_2
I0227 09:22:39.383654 31399 net.cpp:157] Top shape: 1 1024 41 41 (1721344)
I0227 09:22:39.383661 31399 net.cpp:165] Memory required for data: 331262612
I0227 09:22:39.383669 31399 layer_factory.hpp:77] Creating layer drop6_2
I0227 09:22:39.383679 31399 net.cpp:106] Creating Layer drop6_2
I0227 09:22:39.383687 31399 net.cpp:454] drop6_2 <- fc6_2
I0227 09:22:39.383697 31399 net.cpp:397] drop6_2 -> fc6_2 (in-place)
I0227 09:22:39.383728 31399 net.cpp:150] Setting up drop6_2
I0227 09:22:39.383740 31399 net.cpp:157] Top shape: 1 1024 41 41 (1721344)
I0227 09:22:39.383749 31399 net.cpp:165] Memory required for data: 338147988
I0227 09:22:39.383756 31399 layer_factory.hpp:77] Creating layer fc7_2
I0227 09:22:39.383769 31399 net.cpp:106] Creating Layer fc7_2
I0227 09:22:39.383776 31399 net.cpp:454] fc7_2 <- fc6_2
I0227 09:22:39.383786 31399 net.cpp:411] fc7_2 -> fc7_2
I0227 09:22:39.386907 31399 net.cpp:150] Setting up fc7_2
I0227 09:22:39.386929 31399 net.cpp:157] Top shape: 1 1024 41 41 (1721344)
I0227 09:22:39.386937 31399 net.cpp:165] Memory required for data: 345033364
I0227 09:22:39.386948 31399 layer_factory.hpp:77] Creating layer relu7_2
I0227 09:22:39.386958 31399 net.cpp:106] Creating Layer relu7_2
I0227 09:22:39.386967 31399 net.cpp:454] relu7_2 <- fc7_2
I0227 09:22:39.386977 31399 net.cpp:397] relu7_2 -> fc7_2 (in-place)
I0227 09:22:39.386989 31399 net.cpp:150] Setting up relu7_2
I0227 09:22:39.386998 31399 net.cpp:157] Top shape: 1 1024 41 41 (1721344)
I0227 09:22:39.387006 31399 net.cpp:165] Memory required for data: 351918740
I0227 09:22:39.387013 31399 layer_factory.hpp:77] Creating layer drop7_2
I0227 09:22:39.387023 31399 net.cpp:106] Creating Layer drop7_2
I0227 09:22:39.387032 31399 net.cpp:454] drop7_2 <- fc7_2
I0227 09:22:39.387042 31399 net.cpp:397] drop7_2 -> fc7_2 (in-place)
I0227 09:22:39.387069 31399 net.cpp:150] Setting up drop7_2
I0227 09:22:39.387079 31399 net.cpp:157] Top shape: 1 1024 41 41 (1721344)
I0227 09:22:39.387087 31399 net.cpp:165] Memory required for data: 358804116
I0227 09:22:39.387094 31399 layer_factory.hpp:77] Creating layer fc8-SEC_2
I0227 09:22:39.387107 31399 net.cpp:106] Creating Layer fc8-SEC_2
I0227 09:22:39.387115 31399 net.cpp:454] fc8-SEC_2 <- fc7_2
I0227 09:22:39.387126 31399 net.cpp:411] fc8-SEC_2 -> fc8-SEC_2
I0227 09:22:39.387614 31399 net.cpp:150] Setting up fc8-SEC_2
I0227 09:22:39.387627 31399 net.cpp:157] Top shape: 1 21 41 41 (35301)
I0227 09:22:39.387634 31399 net.cpp:165] Memory required for data: 358945320
I0227 09:22:39.387645 31399 layer_factory.hpp:77] Creating layer fc6_3
I0227 09:22:39.387657 31399 net.cpp:106] Creating Layer fc6_3
I0227 09:22:39.387665 31399 net.cpp:454] fc6_3 <- pool5a_pool5a_0_split_2
I0227 09:22:39.387676 31399 net.cpp:411] fc6_3 -> fc6_3
I0227 09:22:39.399292 31399 net.cpp:150] Setting up fc6_3
I0227 09:22:39.399315 31399 net.cpp:157] Top shape: 1 1024 41 41 (1721344)
I0227 09:22:39.399323 31399 net.cpp:165] Memory required for data: 365830696
I0227 09:22:39.399335 31399 layer_factory.hpp:77] Creating layer relu6_3
I0227 09:22:39.399346 31399 net.cpp:106] Creating Layer relu6_3
I0227 09:22:39.399355 31399 net.cpp:454] relu6_3 <- fc6_3
I0227 09:22:39.399366 31399 net.cpp:397] relu6_3 -> fc6_3 (in-place)
I0227 09:22:39.399379 31399 net.cpp:150] Setting up relu6_3
I0227 09:22:39.399387 31399 net.cpp:157] Top shape: 1 1024 41 41 (1721344)
I0227 09:22:39.399394 31399 net.cpp:165] Memory required for data: 372716072
I0227 09:22:39.399401 31399 layer_factory.hpp:77] Creating layer drop6_3
I0227 09:22:39.399411 31399 net.cpp:106] Creating Layer drop6_3
I0227 09:22:39.399418 31399 net.cpp:454] drop6_3 <- fc6_3
I0227 09:22:39.399430 31399 net.cpp:397] drop6_3 -> fc6_3 (in-place)
I0227 09:22:39.399458 31399 net.cpp:150] Setting up drop6_3
I0227 09:22:39.399467 31399 net.cpp:157] Top shape: 1 1024 41 41 (1721344)
I0227 09:22:39.399475 31399 net.cpp:165] Memory required for data: 379601448
I0227 09:22:39.399482 31399 layer_factory.hpp:77] Creating layer fc7_3
I0227 09:22:39.399495 31399 net.cpp:106] Creating Layer fc7_3
I0227 09:22:39.399503 31399 net.cpp:454] fc7_3 <- fc6_3
I0227 09:22:39.399514 31399 net.cpp:411] fc7_3 -> fc7_3
I0227 09:22:39.403024 31399 net.cpp:150] Setting up fc7_3
I0227 09:22:39.403045 31399 net.cpp:157] Top shape: 1 1024 41 41 (1721344)
I0227 09:22:39.403053 31399 net.cpp:165] Memory required for data: 386486824
I0227 09:22:39.403065 31399 layer_factory.hpp:77] Creating layer relu7_3
I0227 09:22:39.403075 31399 net.cpp:106] Creating Layer relu7_3
I0227 09:22:39.403084 31399 net.cpp:454] relu7_3 <- fc7_3
I0227 09:22:39.403093 31399 net.cpp:397] relu7_3 -> fc7_3 (in-place)
I0227 09:22:39.403105 31399 net.cpp:150] Setting up relu7_3
I0227 09:22:39.403113 31399 net.cpp:157] Top shape: 1 1024 41 41 (1721344)
I0227 09:22:39.403120 31399 net.cpp:165] Memory required for data: 393372200
I0227 09:22:39.403127 31399 layer_factory.hpp:77] Creating layer drop7_3
I0227 09:22:39.403138 31399 net.cpp:106] Creating Layer drop7_3
I0227 09:22:39.403146 31399 net.cpp:454] drop7_3 <- fc7_3
I0227 09:22:39.403156 31399 net.cpp:397] drop7_3 -> fc7_3 (in-place)
I0227 09:22:39.403185 31399 net.cpp:150] Setting up drop7_3
I0227 09:22:39.403195 31399 net.cpp:157] Top shape: 1 1024 41 41 (1721344)
I0227 09:22:39.403223 31399 net.cpp:165] Memory required for data: 400257576
I0227 09:22:39.403230 31399 layer_factory.hpp:77] Creating layer fc8-SEC_3
I0227 09:22:39.403244 31399 net.cpp:106] Creating Layer fc8-SEC_3
I0227 09:22:39.403252 31399 net.cpp:454] fc8-SEC_3 <- fc7_3
I0227 09:22:39.403264 31399 net.cpp:411] fc8-SEC_3 -> fc8-SEC_3
I0227 09:22:39.403772 31399 net.cpp:150] Setting up fc8-SEC_3
I0227 09:22:39.403789 31399 net.cpp:157] Top shape: 1 21 41 41 (35301)
I0227 09:22:39.403797 31399 net.cpp:165] Memory required for data: 400398780
I0227 09:22:39.403807 31399 layer_factory.hpp:77] Creating layer fc6_4
I0227 09:22:39.403821 31399 net.cpp:106] Creating Layer fc6_4
I0227 09:22:39.403831 31399 net.cpp:454] fc6_4 <- pool5a_pool5a_0_split_3
I0227 09:22:39.403841 31399 net.cpp:411] fc6_4 -> fc6_4
I0227 09:22:39.421779 31399 net.cpp:150] Setting up fc6_4
I0227 09:22:39.421823 31399 net.cpp:157] Top shape: 1 1024 41 41 (1721344)
I0227 09:22:39.421834 31399 net.cpp:165] Memory required for data: 407284156
I0227 09:22:39.421851 31399 layer_factory.hpp:77] Creating layer relu6_4
I0227 09:22:39.421865 31399 net.cpp:106] Creating Layer relu6_4
I0227 09:22:39.421877 31399 net.cpp:454] relu6_4 <- fc6_4
I0227 09:22:39.421893 31399 net.cpp:397] relu6_4 -> fc6_4 (in-place)
I0227 09:22:39.421910 31399 net.cpp:150] Setting up relu6_4
I0227 09:22:39.421923 31399 net.cpp:157] Top shape: 1 1024 41 41 (1721344)
I0227 09:22:39.421933 31399 net.cpp:165] Memory required for data: 414169532
I0227 09:22:39.421943 31399 layer_factory.hpp:77] Creating layer drop6_4
I0227 09:22:39.421957 31399 net.cpp:106] Creating Layer drop6_4
I0227 09:22:39.421967 31399 net.cpp:454] drop6_4 <- fc6_4
I0227 09:22:39.421981 31399 net.cpp:397] drop6_4 -> fc6_4 (in-place)
I0227 09:22:39.422021 31399 net.cpp:150] Setting up drop6_4
I0227 09:22:39.422044 31399 net.cpp:157] Top shape: 1 1024 41 41 (1721344)
I0227 09:22:39.422056 31399 net.cpp:165] Memory required for data: 421054908
I0227 09:22:39.422066 31399 layer_factory.hpp:77] Creating layer fc7_4
I0227 09:22:39.422085 31399 net.cpp:106] Creating Layer fc7_4
I0227 09:22:39.422096 31399 net.cpp:454] fc7_4 <- fc6_4
I0227 09:22:39.422111 31399 net.cpp:411] fc7_4 -> fc7_4
I0227 09:22:39.426755 31399 net.cpp:150] Setting up fc7_4
I0227 09:22:39.426791 31399 net.cpp:157] Top shape: 1 1024 41 41 (1721344)
I0227 09:22:39.426803 31399 net.cpp:165] Memory required for data: 427940284
I0227 09:22:39.426820 31399 layer_factory.hpp:77] Creating layer relu7_4
I0227 09:22:39.426834 31399 net.cpp:106] Creating Layer relu7_4
I0227 09:22:39.426846 31399 net.cpp:454] relu7_4 <- fc7_4
I0227 09:22:39.426861 31399 net.cpp:397] relu7_4 -> fc7_4 (in-place)
I0227 09:22:39.426904 31399 net.cpp:150] Setting up relu7_4
I0227 09:22:39.426919 31399 net.cpp:157] Top shape: 1 1024 41 41 (1721344)
I0227 09:22:39.426929 31399 net.cpp:165] Memory required for data: 434825660
I0227 09:22:39.426940 31399 layer_factory.hpp:77] Creating layer drop7_4
I0227 09:22:39.426956 31399 net.cpp:106] Creating Layer drop7_4
I0227 09:22:39.426968 31399 net.cpp:454] drop7_4 <- fc7_4
I0227 09:22:39.426980 31399 net.cpp:397] drop7_4 -> fc7_4 (in-place)
I0227 09:22:39.427024 31399 net.cpp:150] Setting up drop7_4
I0227 09:22:39.427042 31399 net.cpp:157] Top shape: 1 1024 41 41 (1721344)
I0227 09:22:39.427055 31399 net.cpp:165] Memory required for data: 441711036
I0227 09:22:39.427065 31399 layer_factory.hpp:77] Creating layer fc8-SEC_4
I0227 09:22:39.427085 31399 net.cpp:106] Creating Layer fc8-SEC_4
I0227 09:22:39.427098 31399 net.cpp:454] fc8-SEC_4 <- fc7_4
I0227 09:22:39.427114 31399 net.cpp:411] fc8-SEC_4 -> fc8-SEC_4
I0227 09:22:39.427718 31399 net.cpp:150] Setting up fc8-SEC_4
I0227 09:22:39.427734 31399 net.cpp:157] Top shape: 1 21 41 41 (35301)
I0227 09:22:39.427743 31399 net.cpp:165] Memory required for data: 441852240
I0227 09:22:39.427755 31399 layer_factory.hpp:77] Creating layer fc8-SEC
I0227 09:22:39.427775 31399 net.cpp:106] Creating Layer fc8-SEC
I0227 09:22:39.427786 31399 net.cpp:454] fc8-SEC <- fc8-SEC_1
I0227 09:22:39.427796 31399 net.cpp:454] fc8-SEC <- fc8-SEC_2
I0227 09:22:39.427805 31399 net.cpp:454] fc8-SEC <- fc8-SEC_3
I0227 09:22:39.427814 31399 net.cpp:454] fc8-SEC <- fc8-SEC_4
I0227 09:22:39.427827 31399 net.cpp:411] fc8-SEC -> fc8-SEC
I0227 09:22:39.427865 31399 net.cpp:150] Setting up fc8-SEC
I0227 09:22:39.427875 31399 net.cpp:157] Top shape: 1 21 41 41 (35301)
I0227 09:22:39.427883 31399 net.cpp:165] Memory required for data: 441993444
I0227 09:22:39.427894 31399 net.cpp:228] fc8-SEC does not need backward computation.
I0227 09:22:39.427903 31399 net.cpp:228] fc8-SEC_4 does not need backward computation.
I0227 09:22:39.427912 31399 net.cpp:228] drop7_4 does not need backward computation.
I0227 09:22:39.427922 31399 net.cpp:228] relu7_4 does not need backward computation.
I0227 09:22:39.427929 31399 net.cpp:228] fc7_4 does not need backward computation.
I0227 09:22:39.427937 31399 net.cpp:228] drop6_4 does not need backward computation.
I0227 09:22:39.427947 31399 net.cpp:228] relu6_4 does not need backward computation.
I0227 09:22:39.427954 31399 net.cpp:228] fc6_4 does not need backward computation.
I0227 09:22:39.427963 31399 net.cpp:228] fc8-SEC_3 does not need backward computation.
I0227 09:22:39.427970 31399 net.cpp:228] drop7_3 does not need backward computation.
I0227 09:22:39.427978 31399 net.cpp:228] relu7_3 does not need backward computation.
I0227 09:22:39.427987 31399 net.cpp:228] fc7_3 does not need backward computation.
I0227 09:22:39.427995 31399 net.cpp:228] drop6_3 does not need backward computation.
I0227 09:22:39.428004 31399 net.cpp:228] relu6_3 does not need backward computation.
I0227 09:22:39.428011 31399 net.cpp:228] fc6_3 does not need backward computation.
I0227 09:22:39.428020 31399 net.cpp:228] fc8-SEC_2 does not need backward computation.
I0227 09:22:39.428028 31399 net.cpp:228] drop7_2 does not need backward computation.
I0227 09:22:39.428038 31399 net.cpp:228] relu7_2 does not need backward computation.
I0227 09:22:39.428046 31399 net.cpp:228] fc7_2 does not need backward computation.
I0227 09:22:39.428055 31399 net.cpp:228] drop6_2 does not need backward computation.
I0227 09:22:39.428062 31399 net.cpp:228] relu6_2 does not need backward computation.
I0227 09:22:39.428071 31399 net.cpp:228] fc6_2 does not need backward computation.
I0227 09:22:39.428079 31399 net.cpp:228] fc8-SEC_1 does not need backward computation.
I0227 09:22:39.428087 31399 net.cpp:228] drop7_1 does not need backward computation.
I0227 09:22:39.428095 31399 net.cpp:228] relu7_1 does not need backward computation.
I0227 09:22:39.428103 31399 net.cpp:228] fc7_1 does not need backward computation.
I0227 09:22:39.428112 31399 net.cpp:228] drop6_1 does not need backward computation.
I0227 09:22:39.428120 31399 net.cpp:228] relu6_1 does not need backward computation.
I0227 09:22:39.428129 31399 net.cpp:228] fc6_1 does not need backward computation.
I0227 09:22:39.428138 31399 net.cpp:228] pool5a_pool5a_0_split does not need backward computation.
I0227 09:22:39.428148 31399 net.cpp:228] pool5a does not need backward computation.
I0227 09:22:39.428155 31399 net.cpp:228] pool5 does not need backward computation.
I0227 09:22:39.428164 31399 net.cpp:228] relu5_3 does not need backward computation.
I0227 09:22:39.428174 31399 net.cpp:228] conv5_3 does not need backward computation.
I0227 09:22:39.428181 31399 net.cpp:228] relu5_2 does not need backward computation.
I0227 09:22:39.428190 31399 net.cpp:228] conv5_2 does not need backward computation.
I0227 09:22:39.428198 31399 net.cpp:228] relu5_1 does not need backward computation.
I0227 09:22:39.428206 31399 net.cpp:228] conv5_1 does not need backward computation.
I0227 09:22:39.428215 31399 net.cpp:228] pool4 does not need backward computation.
I0227 09:22:39.428227 31399 net.cpp:228] relu4_3 does not need backward computation.
I0227 09:22:39.428236 31399 net.cpp:228] conv4_3 does not need backward computation.
I0227 09:22:39.428243 31399 net.cpp:228] relu4_2 does not need backward computation.
I0227 09:22:39.428252 31399 net.cpp:228] conv4_2 does not need backward computation.
I0227 09:22:39.428261 31399 net.cpp:228] relu4_1 does not need backward computation.
I0227 09:22:39.428269 31399 net.cpp:228] conv4_1 does not need backward computation.
I0227 09:22:39.428278 31399 net.cpp:228] pool3 does not need backward computation.
I0227 09:22:39.428287 31399 net.cpp:228] relu3_3 does not need backward computation.
I0227 09:22:39.428294 31399 net.cpp:228] conv3_3 does not need backward computation.
I0227 09:22:39.428303 31399 net.cpp:228] relu3_2 does not need backward computation.
I0227 09:22:39.428313 31399 net.cpp:228] conv3_2 does not need backward computation.
I0227 09:22:39.428321 31399 net.cpp:228] relu3_1 does not need backward computation.
I0227 09:22:39.428330 31399 net.cpp:228] conv3_1 does not need backward computation.
I0227 09:22:39.428339 31399 net.cpp:228] pool2 does not need backward computation.
I0227 09:22:39.428347 31399 net.cpp:228] relu2_2 does not need backward computation.
I0227 09:22:39.428356 31399 net.cpp:228] conv2_2 does not need backward computation.
I0227 09:22:39.428364 31399 net.cpp:228] relu2_1 does not need backward computation.
I0227 09:22:39.428372 31399 net.cpp:228] conv2_1 does not need backward computation.
I0227 09:22:39.428380 31399 net.cpp:228] pool1 does not need backward computation.
I0227 09:22:39.428390 31399 net.cpp:228] relu1_2 does not need backward computation.
I0227 09:22:39.428397 31399 net.cpp:228] conv1_2 does not need backward computation.
I0227 09:22:39.428406 31399 net.cpp:228] relu1_1 does not need backward computation.
I0227 09:22:39.428413 31399 net.cpp:228] conv1_1 does not need backward computation.
I0227 09:22:39.428422 31399 net.cpp:270] This network produces output fc8-SEC
I0227 09:22:39.428469 31399 net.cpp:283] Network initialization done.
I0227 09:22:39.519639 31399 net.cpp:816] Ignoring source layer data
I0227 09:22:39.549430 31399 net.cpp:816] Ignoring source layer fc8-SEC_fc8-SEC_0_split
I0227 09:22:39.549453 31399 net.cpp:816] Ignoring source layer label_shrink
I0227 09:22:39.549460 31399 net.cpp:816] Ignoring source layer label_shrink_label_shrink_0_split
I0227 09:22:39.549468 31399 net.cpp:816] Ignoring source layer loss
I0227 09:22:39.549474 31399 net.cpp:816] Ignoring source layer accuracy
0 2007_000033
/home/austin/.virtualenvs/pdsrg/local/lib/python2.7/site-packages/scipy/ndimage/interpolation.py:568: UserWarning: From scipy 0.13.0, the output shape of zoom() is calculated with round() instead of int() - for these inputs the size of the returned array has changed.
  "the returned array has changed.", UserWarning)
1 2007_000042
2 2007_000061
3 2007_000123
4 2007_000129
5 2007_000175
6 2007_000187
7 2007_000323
8 2007_000332
9 2007_000346
10 2007_000452
11 2007_000464
12 2007_000491
13 2007_000529
14 2007_000559
15 2007_000572
16 2007_000629
17 2007_000636
18 2007_000661
19 2007_000663
20 2007_000676
21 2007_000727
22 2007_000762
23 2007_000783
24 2007_000799
25 2007_000804
26 2007_000830
27 2007_000837
28 2007_000847
29 2007_000862
30 2007_000925
31 2007_000999
32 2007_001154
33 2007_001175
34 2007_001239
35 2007_001284
36 2007_001288
37 2007_001289
38 2007_001299
39 2007_001311
40 2007_001321
41 2007_001377
42 2007_001408
43 2007_001423
44 2007_001430
45 2007_001457
46 2007_001458
47 2007_001526
48 2007_001568
49 2007_001585
50 2007_001586
51 2007_001587
52 2007_001594
53 2007_001630
54 2007_001677
55 2007_001678
56 2007_001717
57 2007_001733
58 2007_001761
59 2007_001763
60 2007_001774
61 2007_001884
62 2007_001955
63 2007_002046
64 2007_002094
65 2007_002119
66 2007_002132
67 2007_002260
68 2007_002266
69 2007_002268
70 2007_002284
71 2007_002376
72 2007_002378
73 2007_002387
74 2007_002400
75 2007_002412
76 2007_002426
77 2007_002427
78 2007_002445
79 2007_002470
80 2007_002539
81 2007_002565
82 2007_002597
83 2007_002618
84 2007_002619
85 2007_002624
86 2007_002643
87 2007_002648
88 2007_002719
89 2007_002728
90 2007_002823
91 2007_002824
92 2007_002852
93 2007_002903
94 2007_003011
95 2007_003020
96 2007_003022
97 2007_003051
98 2007_003088
99 2007_003101
100 2007_003106
101 2007_003110
102 2007_003131
103 2007_003134
104 2007_003137
105 2007_003143
106 2007_003169
107 2007_003188
108 2007_003194
109 2007_003195
110 2007_003201
111 2007_003349
112 2007_003367
113 2007_003373
114 2007_003499
115 2007_003503
116 2007_003506
117 2007_003530
118 2007_003571
119 2007_003587
120 2007_003611
121 2007_003621
122 2007_003682
123 2007_003711
124 2007_003714
125 2007_003742
126 2007_003786
127 2007_003841
128 2007_003848
129 2007_003861
130 2007_003872
131 2007_003917
132 2007_003957
133 2007_003991
134 2007_004033
135 2007_004052
136 2007_004112
137 2007_004121
138 2007_004143
139 2007_004189
140 2007_004190
141 2007_004193
142 2007_004241
143 2007_004275
144 2007_004281
145 2007_004380
146 2007_004392
147 2007_004405
148 2007_004468
149 2007_004483
150 2007_004510
151 2007_004538
152 2007_004558
153 2007_004644
154 2007_004649
155 2007_004712
156 2007_004722
157 2007_004856
158 2007_004866
159 2007_004902
160 2007_004969
161 2007_005058
162 2007_005074
163 2007_005107
164 2007_005114
165 2007_005149
166 2007_005173
167 2007_005281
168 2007_005294
169 2007_005296
170 2007_005304
171 2007_005331
172 2007_005354
173 2007_005358
174 2007_005428
175 2007_005460
176 2007_005469
177 2007_005509
178 2007_005547
179 2007_005600
180 2007_005608
181 2007_005626
182 2007_005689
183 2007_005696
184 2007_005705
185 2007_005759
186 2007_005803
187 2007_005813
188 2007_005828
189 2007_005844
190 2007_005845
191 2007_005857
192 2007_005911
193 2007_005915
194 2007_005978
195 2007_006028
196 2007_006035
197 2007_006046
198 2007_006076
199 2007_006086
200 2007_006117
201 2007_006171
202 2007_006241
203 2007_006260
204 2007_006277
205 2007_006348
206 2007_006364
207 2007_006373
208 2007_006444
209 2007_006449
210 2007_006549
211 2007_006553
212 2007_006560
213 2007_006647
214 2007_006678
215 2007_006680
216 2007_006698
217 2007_006761
218 2007_006802
219 2007_006837
220 2007_006841
221 2007_006864
222 2007_006866
223 2007_006946
224 2007_007007
225 2007_007084
226 2007_007109
227 2007_007130
228 2007_007165
229 2007_007168
230 2007_007195
231 2007_007196
232 2007_007203
233 2007_007211
234 2007_007235
235 2007_007341
236 2007_007414
237 2007_007417
238 2007_007470
239 2007_007477
240 2007_007493
241 2007_007498
242 2007_007524
243 2007_007534
244 2007_007624
245 2007_007651
246 2007_007688
247 2007_007748
248 2007_007795
249 2007_007810
250 2007_007815
251 2007_007818
252 2007_007836
253 2007_007849
254 2007_007881
255 2007_007996
256 2007_008051
257 2007_008084
258 2007_008106
259 2007_008110
260 2007_008204
261 2007_008222
262 2007_008256
263 2007_008260
264 2007_008339
265 2007_008374
266 2007_008415
267 2007_008430
268 2007_008543
269 2007_008547
270 2007_008596
271 2007_008645
272 2007_008670
273 2007_008708
274 2007_008722
275 2007_008747
276 2007_008802
277 2007_008815
278 2007_008897
279 2007_008944
280 2007_008964
281 2007_008973
282 2007_008980
283 2007_009015
284 2007_009068
285 2007_009084
286 2007_009088
287 2007_009096
288 2007_009221
289 2007_009245
290 2007_009251
291 2007_009252
292 2007_009258
293 2007_009320
294 2007_009323
295 2007_009331
296 2007_009346
297 2007_009392
298 2007_009413
299 2007_009419
300 2007_009446
301 2007_009458
302 2007_009521
303 2007_009562
304 2007_009592
305 2007_009654
306 2007_009655
307 2007_009684
308 2007_009687
309 2007_009691
310 2007_009706
311 2007_009750
312 2007_009756
313 2007_009764
314 2007_009794
315 2007_009817
316 2007_009841
317 2007_009897
318 2007_009911
319 2007_009923
320 2007_009938
321 2008_000009
322 2008_000016
323 2008_000073
324 2008_000075
325 2008_000080
326 2008_000107
327 2008_000120
328 2008_000123
329 2008_000149
330 2008_000182
331 2008_000213
332 2008_000215
333 2008_000223
334 2008_000233
335 2008_000234
336 2008_000239
337 2008_000254
338 2008_000270
339 2008_000271
340 2008_000345
341 2008_000359
342 2008_000391
343 2008_000401
344 2008_000464
345 2008_000469
346 2008_000474
347 2008_000501
348 2008_000510
349 2008_000533
350 2008_000573
351 2008_000589
352 2008_000602
353 2008_000630
354 2008_000657
355 2008_000661
356 2008_000662
357 2008_000666
358 2008_000673
359 2008_000700
360 2008_000725
361 2008_000731
362 2008_000763
363 2008_000765
364 2008_000782
365 2008_000795
366 2008_000811
367 2008_000848
368 2008_000853
369 2008_000863
370 2008_000911
371 2008_000919
372 2008_000943
373 2008_000992
374 2008_001013
375 2008_001028
376 2008_001040
377 2008_001070
378 2008_001074
379 2008_001076
380 2008_001078
381 2008_001135
382 2008_001150
383 2008_001170
384 2008_001231
385 2008_001249
386 2008_001260
387 2008_001283
388 2008_001308
389 2008_001379
390 2008_001404
391 2008_001433
392 2008_001439
393 2008_001478
394 2008_001491
395 2008_001504
396 2008_001513
397 2008_001514
398 2008_001531
399 2008_001546
400 2008_001547
401 2008_001580
402 2008_001629
403 2008_001640
404 2008_001682
405 2008_001688
406 2008_001715
407 2008_001821
408 2008_001874
409 2008_001885
410 2008_001895
411 2008_001966
412 2008_001971
413 2008_001992
414 2008_002043
415 2008_002152
416 2008_002205
417 2008_002212
418 2008_002239
419 2008_002240
420 2008_002241
421 2008_002269
422 2008_002273
423 2008_002358
424 2008_002379
425 2008_002383
426 2008_002429
427 2008_002464
428 2008_002467
429 2008_002492
430 2008_002495
431 2008_002504
432 2008_002521
433 2008_002536
434 2008_002588
435 2008_002623
436 2008_002680
437 2008_002681
438 2008_002775
439 2008_002778
440 2008_002835
441 2008_002859
442 2008_002864
443 2008_002900
444 2008_002904
445 2008_002929
446 2008_002936
447 2008_002942
448 2008_002958
449 2008_003003
450 2008_003026
451 2008_003034
452 2008_003076
453 2008_003105
454 2008_003108
455 2008_003110
456 2008_003135
457 2008_003141
458 2008_003155
459 2008_003210
460 2008_003238
461 2008_003270
462 2008_003330
463 2008_003333
464 2008_003369
465 2008_003379
466 2008_003451
467 2008_003461
468 2008_003477
469 2008_003492
470 2008_003499
471 2008_003511
472 2008_003546
473 2008_003576
474 2008_003577
475 2008_003676
476 2008_003709
477 2008_003733
478 2008_003777
479 2008_003782
480 2008_003821
481 2008_003846
482 2008_003856
483 2008_003858
484 2008_003874
485 2008_003876
486 2008_003885
487 2008_003886
488 2008_003926
489 2008_003976
490 2008_004069
491 2008_004101
492 2008_004140
493 2008_004172
494 2008_004175
495 2008_004212
496 2008_004279
497 2008_004339
498 2008_004345
499 2008_004363
500 2008_004367
501 2008_004396
502 2008_004399
503 2008_004453
504 2008_004477
505 2008_004552
506 2008_004562
507 2008_004575
508 2008_004610
509 2008_004612
510 2008_004621
511 2008_004624
512 2008_004654
513 2008_004659
514 2008_004687
515 2008_004701
516 2008_004704
517 2008_004705
518 2008_004754
519 2008_004758
520 2008_004854
521 2008_004910
522 2008_004995
523 2008_005049
524 2008_005089
525 2008_005097
526 2008_005105
527 2008_005145
528 2008_005197
529 2008_005217
530 2008_005242
531 2008_005245
532 2008_005254
533 2008_005262
534 2008_005338
535 2008_005398
536 2008_005399
537 2008_005422
538 2008_005439
539 2008_005445
540 2008_005525
541 2008_005544
542 2008_005628
543 2008_005633
544 2008_005637
545 2008_005642
546 2008_005676
547 2008_005680
548 2008_005691
549 2008_005727
550 2008_005738
551 2008_005812
552 2008_005904
553 2008_005915
554 2008_006008
555 2008_006036
556 2008_006055
557 2008_006063
558 2008_006108
559 2008_006130
560 2008_006143
561 2008_006159
562 2008_006216
563 2008_006219
564 2008_006229
565 2008_006254
566 2008_006275
567 2008_006325
568 2008_006327
569 2008_006341
570 2008_006408
571 2008_006480
572 2008_006523
573 2008_006526
574 2008_006528
575 2008_006553
576 2008_006554
577 2008_006703
578 2008_006722
579 2008_006752
580 2008_006784
581 2008_006835
582 2008_006874
583 2008_006981
584 2008_006986
585 2008_007025
586 2008_007031
587 2008_007048
588 2008_007120
589 2008_007123
590 2008_007143
591 2008_007194
592 2008_007219
593 2008_007273
594 2008_007350
595 2008_007378
596 2008_007392
597 2008_007402
598 2008_007497
599 2008_007498
600 2008_007507
601 2008_007513
602 2008_007527
603 2008_007548
604 2008_007596
605 2008_007677
606 2008_007737
607 2008_007797
608 2008_007804
609 2008_007811
610 2008_007814
611 2008_007828
612 2008_007836
613 2008_007945
614 2008_007994
615 2008_008051
616 2008_008103
617 2008_008127
618 2008_008221
619 2008_008252
620 2008_008268
621 2008_008296
622 2008_008301
623 2008_008335
624 2008_008362
625 2008_008392
626 2008_008393
627 2008_008421
628 2008_008434
629 2008_008469
630 2008_008629
631 2008_008682
632 2008_008711
633 2008_008746
634 2009_000012
635 2009_000013
636 2009_000022
637 2009_000032
638 2009_000037
639 2009_000039
640 2009_000074
641 2009_000080
642 2009_000087
643 2009_000096
644 2009_000121
645 2009_000136
646 2009_000149
647 2009_000156
648 2009_000201
649 2009_000205
650 2009_000219
651 2009_000242
652 2009_000309
653 2009_000318
654 2009_000335
655 2009_000351
656 2009_000354
657 2009_000387
658 2009_000391
659 2009_000412
660 2009_000418
661 2009_000421
662 2009_000426
663 2009_000440
664 2009_000446
665 2009_000455
666 2009_000457
667 2009_000469
668 2009_000487
669 2009_000488
670 2009_000523
671 2009_000573
672 2009_000619
673 2009_000628
674 2009_000641
675 2009_000664
676 2009_000675
677 2009_000704
678 2009_000705
679 2009_000712
680 2009_000716
681 2009_000723
682 2009_000727
683 2009_000730
684 2009_000731
685 2009_000732
686 2009_000771
687 2009_000825
688 2009_000828
689 2009_000839
690 2009_000840
691 2009_000845
692 2009_000879
693 2009_000892
694 2009_000919
695 2009_000924
696 2009_000931
697 2009_000935
698 2009_000964
699 2009_000989
700 2009_000991
701 2009_000998
702 2009_001008
703 2009_001082
704 2009_001108
705 2009_001160
706 2009_001215
707 2009_001240
708 2009_001255
709 2009_001278
710 2009_001299
711 2009_001300
712 2009_001314
713 2009_001332
714 2009_001333
715 2009_001363
716 2009_001391
717 2009_001411
718 2009_001433
719 2009_001505
720 2009_001535
721 2009_001536
722 2009_001565
723 2009_001607
724 2009_001644
725 2009_001663
726 2009_001683
727 2009_001684
728 2009_001687
729 2009_001718
730 2009_001731
731 2009_001765
732 2009_001768
733 2009_001775
734 2009_001804
735 2009_001816
736 2009_001818
737 2009_001850
738 2009_001851
739 2009_001854
740 2009_001941
741 2009_001991
742 2009_002012
743 2009_002035
744 2009_002042
745 2009_002082
746 2009_002094
747 2009_002097
748 2009_002122
749 2009_002150
750 2009_002155
751 2009_002164
752 2009_002165
753 2009_002171
754 2009_002185
755 2009_002202
756 2009_002221
757 2009_002238
758 2009_002239
759 2009_002265
760 2009_002268
761 2009_002291
762 2009_002295
763 2009_002317
764 2009_002320
765 2009_002346
766 2009_002366
767 2009_002372
768 2009_002382
769 2009_002390
770 2009_002415
771 2009_002445
772 2009_002487
773 2009_002521
774 2009_002527
775 2009_002535
776 2009_002539
777 2009_002549
778 2009_002562
779 2009_002568
780 2009_002571
781 2009_002573
782 2009_002584
783 2009_002591
784 2009_002594
785 2009_002604
786 2009_002618
787 2009_002635
788 2009_002638
789 2009_002649
790 2009_002651
791 2009_002727
792 2009_002732
793 2009_002749
794 2009_002753
795 2009_002771
796 2009_002808
797 2009_002856
798 2009_002887
799 2009_002888
800 2009_002928
801 2009_002936
802 2009_002975
803 2009_002982
804 2009_002990
805 2009_003003
806 2009_003005
807 2009_003043
808 2009_003059
809 2009_003063
810 2009_003065
811 2009_003071
812 2009_003080
813 2009_003105
814 2009_003123
815 2009_003193
816 2009_003196
817 2009_003217
818 2009_003224
819 2009_003241
820 2009_003269
821 2009_003273
822 2009_003299
823 2009_003304
824 2009_003311
825 2009_003323
826 2009_003343
827 2009_003378
828 2009_003387
829 2009_003406
830 2009_003433
831 2009_003450
832 2009_003466
833 2009_003481
834 2009_003494
835 2009_003498
836 2009_003504
837 2009_003507
838 2009_003517
839 2009_003523
840 2009_003542
841 2009_003549
842 2009_003551
843 2009_003564
844 2009_003569
845 2009_003576
846 2009_003589
847 2009_003607
848 2009_003640
849 2009_003666
850 2009_003696
851 2009_003703
852 2009_003707
853 2009_003756
854 2009_003771
855 2009_003773
856 2009_003804
857 2009_003806
858 2009_003810
859 2009_003849
860 2009_003857
861 2009_003858
862 2009_003895
863 2009_003903
864 2009_003904
865 2009_003928
866 2009_003938
867 2009_003971
868 2009_003991
869 2009_004021
870 2009_004033
871 2009_004043
872 2009_004070
873 2009_004072
874 2009_004084
875 2009_004099
876 2009_004125
877 2009_004140
878 2009_004217
879 2009_004221
880 2009_004247
881 2009_004248
882 2009_004255
883 2009_004298
884 2009_004324
885 2009_004455
886 2009_004494
887 2009_004497
888 2009_004504
889 2009_004507
890 2009_004509
891 2009_004540
892 2009_004568
893 2009_004579
894 2009_004581
895 2009_004590
896 2009_004592
897 2009_004594
898 2009_004635
899 2009_004653
900 2009_004687
901 2009_004721
902 2009_004730
903 2009_004732
904 2009_004738
905 2009_004748
906 2009_004789
907 2009_004799
908 2009_004801
909 2009_004848
910 2009_004859
911 2009_004867
912 2009_004882
913 2009_004886
914 2009_004895
915 2009_004942
916 2009_004969
917 2009_004987
918 2009_004993
919 2009_004994
920 2009_005038
921 2009_005078
922 2009_005087
923 2009_005089
924 2009_005137
925 2009_005148
926 2009_005156
927 2009_005158
928 2009_005189
929 2009_005190
930 2009_005217
931 2009_005219
932 2009_005220
933 2009_005231
934 2009_005260
935 2009_005262
936 2009_005302
937 2010_000003
938 2010_000038
939 2010_000065
940 2010_000083
941 2010_000084
942 2010_000087
943 2010_000110
944 2010_000159
945 2010_000160
946 2010_000163
947 2010_000174
948 2010_000216
949 2010_000238
950 2010_000241
951 2010_000256
952 2010_000272
953 2010_000284
954 2010_000309
955 2010_000318
956 2010_000330
957 2010_000335
958 2010_000342
959 2010_000372
960 2010_000422
961 2010_000426
962 2010_000427
963 2010_000502
964 2010_000530
965 2010_000552
966 2010_000559
967 2010_000572
968 2010_000573
969 2010_000622
970 2010_000628
971 2010_000639
972 2010_000666
973 2010_000679
974 2010_000682
975 2010_000683
976 2010_000724
977 2010_000738
978 2010_000764
979 2010_000788
980 2010_000814
981 2010_000836
982 2010_000874
983 2010_000904
984 2010_000906
985 2010_000907
986 2010_000918
987 2010_000929
988 2010_000941
989 2010_000952
990 2010_000961
991 2010_001000
992 2010_001010
993 2010_001011
994 2010_001016
995 2010_001017
996 2010_001024
997 2010_001036
998 2010_001061
999 2010_001069
1000 2010_001070
1001 2010_001079
1002 2010_001104
1003 2010_001124
1004 2010_001149
1005 2010_001151
1006 2010_001174
1007 2010_001206
1008 2010_001246
1009 2010_001251
1010 2010_001256
1011 2010_001264
1012 2010_001292
1013 2010_001313
1014 2010_001327
1015 2010_001331
1016 2010_001351
1017 2010_001367
1018 2010_001376
1019 2010_001403
1020 2010_001448
1021 2010_001451
1022 2010_001522
1023 2010_001534
1024 2010_001553
1025 2010_001557
1026 2010_001563
1027 2010_001577
1028 2010_001579
1029 2010_001646
1030 2010_001656
1031 2010_001692
1032 2010_001699
1033 2010_001734
1034 2010_001752
1035 2010_001767
1036 2010_001768
1037 2010_001773
1038 2010_001820
1039 2010_001830
1040 2010_001851
1041 2010_001908
1042 2010_001913
1043 2010_001951
1044 2010_001956
1045 2010_001962
1046 2010_001966
1047 2010_001995
1048 2010_002017
1049 2010_002025
1050 2010_002030
1051 2010_002106
1052 2010_002137
1053 2010_002142
1054 2010_002146
1055 2010_002147
1056 2010_002150
1057 2010_002161
1058 2010_002200
1059 2010_002228
1060 2010_002232
1061 2010_002251
1062 2010_002271
1063 2010_002305
1064 2010_002310
1065 2010_002336
1066 2010_002348
1067 2010_002361
1068 2010_002390
1069 2010_002396
1070 2010_002422
1071 2010_002450
1072 2010_002480
1073 2010_002512
1074 2010_002531
1075 2010_002536
1076 2010_002538
1077 2010_002546
1078 2010_002623
1079 2010_002682
1080 2010_002691
1081 2010_002693
1082 2010_002701
1083 2010_002763
1084 2010_002792
1085 2010_002868
1086 2010_002900
1087 2010_002902
1088 2010_002921
1089 2010_002929
1090 2010_002939
1091 2010_002988
1092 2010_003014
1093 2010_003060
1094 2010_003123
1095 2010_003127
1096 2010_003132
1097 2010_003168
1098 2010_003183
1099 2010_003187
1100 2010_003207
1101 2010_003231
1102 2010_003239
1103 2010_003275
1104 2010_003276
1105 2010_003293
1106 2010_003302
1107 2010_003325
1108 2010_003362
1109 2010_003365
1110 2010_003381
1111 2010_003402
1112 2010_003409
1113 2010_003418
1114 2010_003446
1115 2010_003453
1116 2010_003468
1117 2010_003473
1118 2010_003495
1119 2010_003506
1120 2010_003514
1121 2010_003531
1122 2010_003532
1123 2010_003541
1124 2010_003547
1125 2010_003597
1126 2010_003675
1127 2010_003708
1128 2010_003716
1129 2010_003746
1130 2010_003758
1131 2010_003764
1132 2010_003768
1133 2010_003771
1134 2010_003772
1135 2010_003781
1136 2010_003813
1137 2010_003820
1138 2010_003854
1139 2010_003912
1140 2010_003915
1141 2010_003947
1142 2010_003956
1143 2010_003971
1144 2010_004041
1145 2010_004042
1146 2010_004056
1147 2010_004063
1148 2010_004104
1149 2010_004120
1150 2010_004149
1151 2010_004165
1152 2010_004208
1153 2010_004219
1154 2010_004226
1155 2010_004314
1156 2010_004320
1157 2010_004322
1158 2010_004337
1159 2010_004348
1160 2010_004355
1161 2010_004369
1162 2010_004382
1163 2010_004419
1164 2010_004432
1165 2010_004472
1166 2010_004479
1167 2010_004519
1168 2010_004520
1169 2010_004529
1170 2010_004543
1171 2010_004550
1172 2010_004551
1173 2010_004556
1174 2010_004559
1175 2010_004628
1176 2010_004635
1177 2010_004662
1178 2010_004697
1179 2010_004757
1180 2010_004763
1181 2010_004772
1182 2010_004783
1183 2010_004789
1184 2010_004795
1185 2010_004815
1186 2010_004825
1187 2010_004828
1188 2010_004856
1189 2010_004857
1190 2010_004861
1191 2010_004941
1192 2010_004946
1193 2010_004951
1194 2010_004980
1195 2010_004994
1196 2010_005013
1197 2010_005021
1198 2010_005046
1199 2010_005063
1200 2010_005108
1201 2010_005118
1202 2010_005159
1203 2010_005160
1204 2010_005166
1205 2010_005174
1206 2010_005180
1207 2010_005187
1208 2010_005206
1209 2010_005245
1210 2010_005252
1211 2010_005284
1212 2010_005305
1213 2010_005344
1214 2010_005353
1215 2010_005366
1216 2010_005401
1217 2010_005421
1218 2010_005428
1219 2010_005432
1220 2010_005433
1221 2010_005496
1222 2010_005501
1223 2010_005508
1224 2010_005531
1225 2010_005534
1226 2010_005575
1227 2010_005582
1228 2010_005606
1229 2010_005626
1230 2010_005644
1231 2010_005664
1232 2010_005705
1233 2010_005706
1234 2010_005709
1235 2010_005718
1236 2010_005719
1237 2010_005727
1238 2010_005762
1239 2010_005788
1240 2010_005860
1241 2010_005871
1242 2010_005877
1243 2010_005888
1244 2010_005899
1245 2010_005922
1246 2010_005991
1247 2010_005992
1248 2010_006026
1249 2010_006034
1250 2010_006054
1251 2010_006070
1252 2011_000045
1253 2011_000051
1254 2011_000054
1255 2011_000066
1256 2011_000070
1257 2011_000112
1258 2011_000173
1259 2011_000178
1260 2011_000185
1261 2011_000226
1262 2011_000234
1263 2011_000238
1264 2011_000239
1265 2011_000248
1266 2011_000283
1267 2011_000291
1268 2011_000310
1269 2011_000312
1270 2011_000338
1271 2011_000396
1272 2011_000412
1273 2011_000419
1274 2011_000435
1275 2011_000436
1276 2011_000438
1277 2011_000455
1278 2011_000456
1279 2011_000479
1280 2011_000481
1281 2011_000482
1282 2011_000503
1283 2011_000512
1284 2011_000521
1285 2011_000526
1286 2011_000536
1287 2011_000548
1288 2011_000566
1289 2011_000585
1290 2011_000598
1291 2011_000607
1292 2011_000618
1293 2011_000638
1294 2011_000658
1295 2011_000661
1296 2011_000669
1297 2011_000747
1298 2011_000780
1299 2011_000789
1300 2011_000807
1301 2011_000809
1302 2011_000813
1303 2011_000830
1304 2011_000843
1305 2011_000874
1306 2011_000888
1307 2011_000900
1308 2011_000912
1309 2011_000953
1310 2011_000969
1311 2011_001005
1312 2011_001014
1313 2011_001020
1314 2011_001047
1315 2011_001060
1316 2011_001064
1317 2011_001069
1318 2011_001071
1319 2011_001082
1320 2011_001110
1321 2011_001114
1322 2011_001159
1323 2011_001161
1324 2011_001190
1325 2011_001232
1326 2011_001263
1327 2011_001276
1328 2011_001281
1329 2011_001287
1330 2011_001292
1331 2011_001313
1332 2011_001341
1333 2011_001346
1334 2011_001350
1335 2011_001407
1336 2011_001416
1337 2011_001421
1338 2011_001434
1339 2011_001447
1340 2011_001489
1341 2011_001529
1342 2011_001530
1343 2011_001534
1344 2011_001546
1345 2011_001567
1346 2011_001589
1347 2011_001597
1348 2011_001601
1349 2011_001607
1350 2011_001613
1351 2011_001614
1352 2011_001619
1353 2011_001624
1354 2011_001642
1355 2011_001665
1356 2011_001669
1357 2011_001674
1358 2011_001708
1359 2011_001713
1360 2011_001714
1361 2011_001722
1362 2011_001726
1363 2011_001745
1364 2011_001748
1365 2011_001775
1366 2011_001782
1367 2011_001793
1368 2011_001794
1369 2011_001812
1370 2011_001862
1371 2011_001863
1372 2011_001868
1373 2011_001880
1374 2011_001910
1375 2011_001984
1376 2011_001988
1377 2011_002002
1378 2011_002040
1379 2011_002041
1380 2011_002064
1381 2011_002075
1382 2011_002098
1383 2011_002110
1384 2011_002121
1385 2011_002124
1386 2011_002150
1387 2011_002156
1388 2011_002178
1389 2011_002200
1390 2011_002223
1391 2011_002244
1392 2011_002247
1393 2011_002279
1394 2011_002295
1395 2011_002298
1396 2011_002308
1397 2011_002317
1398 2011_002322
1399 2011_002327
1400 2011_002343
1401 2011_002358
1402 2011_002371
1403 2011_002379
1404 2011_002391
1405 2011_002498
1406 2011_002509
1407 2011_002515
1408 2011_002532
1409 2011_002535
1410 2011_002548
1411 2011_002575
1412 2011_002578
1413 2011_002589
1414 2011_002592
1415 2011_002623
1416 2011_002641
1417 2011_002644
1418 2011_002662
1419 2011_002675
1420 2011_002685
1421 2011_002713
1422 2011_002730
1423 2011_002754
1424 2011_002812
1425 2011_002863
1426 2011_002879
1427 2011_002885
1428 2011_002929
1429 2011_002951
1430 2011_002975
1431 2011_002993
1432 2011_002997
1433 2011_003003
1434 2011_003011
1435 2011_003019
1436 2011_003030
1437 2011_003055
1438 2011_003085
1439 2011_003103
1440 2011_003114
1441 2011_003145
1442 2011_003146
1443 2011_003182
1444 2011_003197
1445 2011_003205
1446 2011_003240
1447 2011_003256
1448 2011_003271
UNIQUESTRING 5
0 processd of 1449
100 processd of 1449
200 processd of 1449
300 processd of 1449
400 processd of 1449
500 processd of 1449
600 processd of 1449
700 processd of 1449
800 processd of 1449
900 processd of 1449
1000 processd of 1449
1100 processd of 1449
1200 processd of 1449
1300 processd of 1449
1400 processd of 1449
made it
UNIQUESTRING 6
(pdsrg) austin@vader:/media/ssd1/austin/Point-DSRG/training/experiment/seed_mc$ head DSRG_
DSRG_final_output/         DSRG_result_final_old.txt  DSRG_result_final.txt
(pdsrg) austin@vader:/media/ssd1/austin/Point-DSRG/training/experiment/seed_mc$ ls -lah
total 168K
drwxrwxr-x 7 austin austin 4.0K Feb 26 12:56 .
drwxrwxr-x 3 austin austin 4.0K Dec  7 14:21 ..
-rw-rw-r-- 1 austin austin  11K Dec  7 14:21 deploy.prototxt
drwxrwxr-x 2 austin austin  52K Jan 25 10:50 DSRG_final_output
-rw-rw-r-- 1 austin austin 8.1K Jan 30 09:37 DSRG_result_final_old.txt
-rw-rw-r-- 1 austin austin 8.1K Feb 27 10:08 DSRG_result_final.txt
-rw-rw-r-- 1 austin austin 1.4K Jan 14 11:11 install-tk.txt
drwxrwxr-x 2 austin austin 4.0K Feb  5 16:05 list
drwxrwxr-x 2 austin austin 4.0K Feb 27 04:34 models
drwxrwxr-x 2 austin austin 4.0K Jan 16 10:36 models-complete
-rw-rw-r-- 1 austin austin  206 Jan 17 14:09 plot-stuff.sh
-rw-rw-r-- 1 austin austin 1.1K Jan 25 11:11 run.sh
-rw-rw-r-- 1 austin austin  256 Dec  7 14:21 solver-f.prototxt
-rw-rw-r-- 1 austin austin  271 Jan 22 15:25 solver-s.prototxt
-rw-rw-r-- 1 austin austin  733 Jan  9 11:33 stacktrace.txt
drwxrwxr-x 5 austin austin 4.0K Jan 23 22:33 tests
-rw-rw-r-- 1 austin austin  14K Jan 10 10:29 train-f.prototxt
-rw-rw-r-- 1 austin austin  15K Dec 12 15:11 train-s.prototxt
(pdsrg) austin@vader:/media/ssd1/austin/Point-DSRG/training/experiment/seed_mc$ head DSRG_result_fina
l.txt
meanIOU: 0.542715669848
[0.84280749951162059, 0.61254727639294337, 0.21481852298110485, 0.7170209348196408, 0.31861331950206279, 0.51855709211830614, 0.74157180974154835, 0.64525247410018105, 0.75253551111974282, 0.22365510131659921, 0.6397631803932744, 0.28009886401444933, 0.73524604567345397, 0.60249576085898249, 0.56233643321327609, 0.68255304586288024, 0.35752112532829572, 0.65071373511286179, 0.34125265786345943, 0.49006675672029631, 0.4676019201539513]
[[  1.72244390e+08   1.02935200e+06   1.99773500e+06   4.92719000e+05
    2.11435700e+06   6.03121000e+05   8.27714000e+05   1.09557200e+06
    1.04833100e+06   1.17379500e+06   3.36182000e+05   1.47619000e+05
    5.86763000e+05   6.11040000e+05   9.78671000e+05   2.34863600e+06
    7.93930000e+05   4.40297000e+05   6.77427000e+05   2.85881100e+06
    1.37258100e+06]
 [  9.89000000e+04   1.82446900e+06   0.00000000e+00   0.00000000e+00
    4.36000000e+02   0.00000000e+00   0.00000000e+00   8.00000000e+00
